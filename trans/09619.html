<html>
<head>
<title>Emotion-Based Art Generation Using C-GAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于情感的C-GAN艺术生成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/emotion-based-art-generation-using-c-gan-de9abed6fa2f?source=collection_archive---------17-----------------------#2021-09-07">https://towardsdatascience.com/emotion-based-art-generation-using-c-gan-de9abed6fa2f?source=collection_archive---------17-----------------------#2021-09-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8716" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">AI能有创造力，通过艺术理解情感吗？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0c931d3add2b6650372af6cbc95d0f11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qrf3AOgmK0QD3vWWLVZEoA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于深度学习的艺术生成:风景+正面情感，作者图像</p></figure><h1 id="946e" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">介绍</h1><p id="5e27" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">随着基于深度学习的图像生成和情感分类解决方案的出现，我在想，我们是否可以将这两个目标结合起来，建立一个模型，以一种简单的情感(积极、消极和中性)作为输入，并生成一件艺术作品，以某种方式整合之前提供的情感。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mj"><img src="../Images/7b8778dd34d461c83426cb2138b240ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RYCs2B-L1TAUU-VC"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae mk" href="https://unsplash.com/@igormiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">伊戈尔·米斯克</a>在<a class="ae mk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="0835" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">这个项目带来了计算机科学和艺术中的哲学问题。</p><p id="7a45" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">当我们看一幅画时，一种情绪是仅仅来自视觉刺激还是有其他无意识的因素影响我们的感觉？如果是这样的话，这些视觉刺激一般会唤起一种共同的感觉吗，不管观看者是谁？</p><p id="a5ff" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">大多数艺术家和情感专家会拒绝这两个建议，他们会回答说，每个人都有自己的欣赏，受自己的生活经历的指导，情感的起源很难破译。</p><p id="c429" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">我将把这些哲学问题留给引言，并希望像神经网络这样令人惊讶的系统能够提取出可能导致基本情绪的一般模式。例如，深色可能会引起负面反应，而亮色/彩色可能会引起正面反应。</p><p id="dc36" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">令人惊讶的是，我第一次想利用数据集中隐藏的偏见，并最终利用它们来创造艺术！</p><h1 id="9d24" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">数据集</h1><p id="6eff" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">→ <a class="ae mk" href="https://www.kaggle.com/ipythonx/wikiart-gangogh-creating-art-gan" rel="noopener ugc nofollow" target="_blank"> <strong class="lp ir"> Wiki-Art </strong> </a>:视觉艺术百科(<a class="ae mk" href="https://www.wikiart.org/" rel="noopener ugc nofollow" target="_blank">https://www.wikiart.org/</a>，公开可用数据集)</p><p id="c394" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">Wiki-Art是一个大型数据集，包含来自100多个国家的博物馆、大学、市政厅和其他市政建筑的绘画图像。这些作品大多不公开展出。维基艺术包含了195位不同艺术家的作品。该数据集有近<strong class="lp ir"> 100，000 </strong>幅图像。该数据集在<strong class="lp ir"> Kaggle </strong>中可用，并提供各种风格类别:<code class="fe mq mr ms mt b">'abstract', 'animal-painting', 'cityscape', 'figurative', 'flower-painting', 'genre-painting', 'landscape', 'marina', 'mythological-painting', 'nude-painting-nu', 'portrait', 'religious-painting', 'still-life', 'symbolic-painting'.</code></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/8640daca07d1bc88cb37c5b204a70467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3eaIBJIshXQs3JvP.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae mk" href="https://paperswithcode.com/dataset/wikiart" rel="noopener ugc nofollow" target="_blank">来自维基百科的图片</a></p></figure><p id="434b" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">→ <a class="ae mk" href="http://saifmohammad.com/WebPages/wikiartemotions.html" rel="noopener ugc nofollow" target="_blank">维基-艺术情感</a></p><blockquote class="mv mw mx"><p id="878b" class="ln lo my lp b lq ml jr ls lt mm ju lv mz mn ly lz na mo mc md nb mp mg mh mi ij bi translated">由Art. Saif M. Mohammad和Svetlana Kiritchenko唤起的情感注释数据集。在<em class="iq">2018年5月日本宫崎第11版语言资源与评价会议论文集(LREC-2018) </em>。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ec5227b54aae896083043f1dc7009d6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/0*5GaGpeI8DtTiXg2m"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae mk" href="https://aclanthology.org/L18-1197.pdf" rel="noopener ugc nofollow" target="_blank">wikiartemotion</a>数据集的汇总表(Mohammad、Saif和Svetlana Kiritchenko)。</p></figure><p id="8332" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated"><strong class="lp ir"> Wiki-Art Emotions </strong>由<strong class="lp ir"> 4105 </strong>张用情感标注的艺术图片组成，由WikiArt构建而成。每个图像都被标注了至少一个到二十个情感类别。</p><p id="f907" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">为了简单起见，我合并了几种情绪，每张图片只有3种最终情绪(积极的、消极的和中性的)。例如，我把“后悔”、“恐惧”合并成一个消极的类别。同样，我将“乐观”、“爱”归入积极的类别。最后，对于<strong class="lp ir">中性</strong>类别，我合并了“中性”、“谦逊”等标签。</p><p id="bfd8" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">我意识到，只有3个类别和4105幅图像，我定制的维基艺术情感版本不足以训练一个生成性对抗神经网络(该模型将遭受崩溃模式)。</p><p id="38be" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">因此，我决定创建一个图像分类器，它将一张图像作为输入，并将其分为3种情绪类别(积极、消极和中性)，这样我就可以使用这个分类器来标记原始WikiArt dataset中的其他数据。我将在下一节讨论我用来构建图像-情感分类器的模型的架构。</p><p id="b474" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">总的来说，我最终得到了一个由95808张图片组成的维基艺术情感，这95808张图片被标记为3种基本情感:<strong class="lp ir">积极(43792张图片)、消极(33091张图片)、</strong>和<strong class="lp ir">中性(18925张图片)。</strong></p><p id="7f2f" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">因为我已经有了构建情感到图像生成器的目标，所以我不想通过允许选择生成的假画的风格来增加任务的复杂性。</p><p id="8f5f" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">相反，我决定构建几个情感到图像生成器，分别用于以下风格:<strong class="lp ir">抽象(15000张图像)、花卉绘画(1800张图像)、风景(15000张图像)、</strong>和<strong class="lp ir">肖像(15000张图像)。</strong></p><p id="db2e" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">以下是每种所选风格的“情绪”分布:</p><div class="kg kh ki kj gt ab cb"><figure class="nd kk ne nf ng nh ni paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/0f85b9b5ee6cab0f40104c5bd030dc1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*hwjxt9gqIBm3zjjz2ZSP_w.png"/></div></figure><figure class="nd kk nj nf ng nh ni paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/6bf368df3810fadfa40d5c5bfded91a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*2KZKKgTqvixItFXywqqgdw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk nk di nl nm translated">作者图片</p></figure></div><h1 id="2dd7" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">模型</h1><p id="3b5f" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">正如您在上一节中可能已经猜到的，我使用了两个模型来实现生成基于情感的艺术的目标。我创建的第一个模型是“图像到情感”分类器，我将其用作数据增强的标记工具，第二个模型(也更有趣)是“情感到图像”生成器。</p><h2 id="f91a" class="nn kw iq bd kx no np dn lb nq nr dp lf lw ns nt lh ma nu nv lj me nw nx ll ny bi translated"><strong class="ak">图像到情感</strong></h2><p id="a0c9" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">使用来自原始wiki-art情感数据集的4105幅图像，我使用Pytorch训练了一个预训练的深度卷积神经网络。</p><p id="36d5" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">我用于迁移学习任务的基础架构是VGG16:</p><div class="kg kh ki kj gt ab cb"><figure class="nd kk nz nf ng nh ni paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/c9074efdac7d79f243d8299a134c6e45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*j2HZZfioKqwBDoIO1WGcrw.png"/></div></figure><figure class="nd kk oa nf ng nh ni paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/f532fe4a4658874021b7d35dfdff7b59.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*ZTTW6SSK5DEQtEgaU8zNZw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk ob di oc nm translated"><a class="ae mk" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> VGG16架构</a></p></figure></div><p id="56b2" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">除了这个预训练的ConvNet，我还添加了一个具有3个输出神经元的多层感知器(针对每种情绪)。我完全冻结了VGG16，因为我假设最初学习的特性(使用Imagenet)足够通用，可以提取绘画中常见的视觉模式。</p><p id="052e" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">我还利用Pytorch变换来使用数据扩充技术(裁剪、翻转等)。</p><p id="5069" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">以下是我获得的训练图:</p><div class="kg kh ki kj gt ab cb"><figure class="nd kk od nf ng nh ni paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/80124e6b6d89cad87799e7aeb7e7ae73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*2dBssNTNVgHmuWJkswcJaw.png"/></div></figure><figure class="nd kk oe nf ng nh ni paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/04ad237c8fab540b261ea0e85917f65d.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*HDTt65o5CryNv66T5A9Zcw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk of di og nm translated">作者图片</p></figure></div><p id="15f5" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">很明显，我的模型遭受了过度拟合，因为验证曲线是平坦的，并且不遵循学习曲线。正如我所料，这意味着我的“图像到情绪”分类器未能提取一般特征来分类情绪。<br/>经过几次尝试和实验，我意识到，以这样的数据量和任务的复杂性，我可能不会得到更好的结果。同样很有可能的是，数据本身非常主观(正如艺术专家倾向于解释的那样)，对于神经网络来说没有意义。</p><p id="7c1a" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">所以我决定继续前进，希望我的VGG16在用大型Wiki-Art数据集标记剩余的艺术图像方面不会太差。注意，我在数据集部分描述的统计数据是由这个模型生成的。</p><h2 id="bccc" class="nn kw iq bd kx no np dn lb nq nr dp lf lw ns nt lh ma nu nv lj me nw nx ll ny bi translated"><strong class="ak">情感到图像</strong></h2><p id="8a47" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">使用新标记的绘画图像，我决定训练4个情感到图像生成器(每种风格一个:抽象、花卉绘画、风景和肖像)。</p><p id="1e4e" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">对于情绪到图像模型，我决定使用条件生成对抗性神经网络(CGAN)，下面是它的架构图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/7b404e08015384d60fd178b519ec2759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sr7bAbKjpAFHW1KWfawnXQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae mk" href="https://www.researchgate.net/publication/330593980_Paired_3D_Model_Generation_with_Conditional_Generative_Adversarial_Networks/figures?lo=1" rel="noopener ugc nofollow" target="_blank"> CGAN架构</a>(来自<a class="ae mk" href="https://www.researchgate.net/profile/Alptekin-Temizel" rel="noopener ugc nofollow" target="_blank"> Alptekin Temizel </a>)</p></figure><p id="1968" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">它是一个有两个演员(像大多数GANs一样)的神经网络训练，一个被称为生成器(G)，负责生成与给定的C类(这里是我们基于情感的绘画)相关的64x64假图像，另一个被称为鉴别器(D)，负责检测图像是真是假。</p><p id="c014" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">发生器G由噪声向量Z(通常称为潜在空间)与类别C(这里是情感)的编码向量连接而成。</p><p id="7504" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">鉴别器D由两个部分提供:由G产生的应该属于类别C的假图像和实际上属于类别C的真实图像。这两个图像，假图像和真实图像，与类别C的编码版本连接在一起(使得D也具有要区分的类别的信息)。</p><p id="f911" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">使用反向传播和梯度下降来训练发生器G和鉴别器D。</p><p id="0cab" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">关于GANs(以及CGANs)有趣的事情是，G更善于从D的反馈中学习，同样，D通过观察G的工作更善于检测伪造的图像。这就像一场战斗，两个战斗者在整个游戏中学会了压制对方。</p><p id="fa76" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">在训练过程中，我们可以看到发电机越来越好:</p><div class="kg kh ki kj gt ab cb"><figure class="nd kk oi nf ng nh ni paragraph-image"><img src="../Images/a912d9a6a43fa4dfc74ffde9e2e41384.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*1Eg_TAsmps8OwMsgSBouNQ.gif"/></figure><figure class="nd kk oi nf ng nh ni paragraph-image"><img src="../Images/1388ff396292c62153123922536419e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*DdgXgY9YOI5Oi96simnRZA.gif"/><p class="kr ks gj gh gi kt ku bd b be z dk oj di ok nm translated">风景(左)和花卉(右)G训练，图片作者</p></figure></div><p id="e828" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">最后，一旦训练完成，我们只保留生成器G来生成作为输入提供的给定类C的新的假图像。</p><p id="1647" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">换句话说，我可以只通过向我训练过的生成器提供一个噪声向量和一个编码的情感类来生成一幅应该具有“正面”(或“负面”，或“中性”)类的绘画(风景、肖像等)。</p><h2 id="d689" class="nn kw iq bd kx no np dn lb nq nr dp lf lw ns nt lh ma nu nv lj me nw nx ll ny bi translated">推理</h2><p id="a110" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在这篇文章的最后，我与你分享我在Github库中的代码，这样你就可以生成你自己的基于情感的绘画。</p><pre class="kg kh ki kj gt ol mt om on aw oo bi"><span id="d989" class="nn kw iq mt b gy op oq l or os">git clone <a class="ae mk" href="https://github.com/MarvinMartin24/CGAN-Emotion-Art/" rel="noopener ugc nofollow" target="_blank">https://github.com/MarvinMartin24/CGAN-Emotion-Art/</a></span><span id="505f" class="nn kw iq mt b gy ot oq l or os"># python3 generator_64.py STYLE EMOTION NUM_IMG_TO_GENERATE</span><span id="129d" class="nn kw iq mt b gy ot oq l or os">python3 generator_64.py landscape positive 20<br/>python3 generator_64.py portrait negative 2</span></pre><h1 id="cd3c" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">结果</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/1f6cd499e23fb8a10b231b98701d8bd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/0*wme01iQzy2YA4Oh8"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">鲜花+正片(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/3ae111754248dd06e116253e8d8724a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/0*Z3PD5d7HQ0iKGqmW"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">肖像+负片(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/6f9172297932fcbc212dd794379fe6f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/0*m9lrA7JGsYM5LqsV"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">风景+正片(作者图片)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/89dbf07c2d16c3c1248bc75b9cb13634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/0*Y27nuyNwI3q6crlr"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">抽象+神经(作者图片)</p></figure><p id="722f" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">我为你生成了几幅基于情感的画作，它们的伟大之处在于它们在风格上相当现实(抽象、风景、肖像和花卉)。然而，相对于输入中提供的情感，结果的质量相当令人失望。</p><p id="99d8" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">看起来CGAN并没有产生任何特定情感的特征。这并不奇怪，因为训练数据集本身是由VGG16标记的，而vgg 16也不理解它。我希望颜色或形状会随着情绪的变化而变化，但事实似乎并非如此。再说一遍，这个项目纯粹是为了好玩和探索，我也预料到结果会是那样。</p><h1 id="71f2" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">密码</h1><p id="3f09" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">部署在Heroku上的GitHub存储库和<a class="ae mk" href="https://neurogram.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"> Flask Web应用</a>:</p><div class="ov ow gp gr ox oy"><a href="https://github.com/MarvinMartin24/CGAN-Emotion-Art" rel="noopener  ugc nofollow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd ir gy z fp pd fr fs pe fu fw ip bi translated">GitHub-Marvin Martin 24/CGAN-情感-艺术</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">从Wiki-Art情感，我们建立了一个VGG16分类器(98%训练acc - 50 val acc ),具有3个情感类别(积极的…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">github.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm kp oy"/></div></div></a></div><p id="558c" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated"><strong class="lp ir">图像到情感</strong> : VGG16(识别情感，不考虑艺术风格)</p><div class="ov ow gp gr ox oy"><a href="https://colab.research.google.com/drive/1ZqtZx9DP0FoW0SyzHikjCOHjzPznFf0d?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd ir gy z fp pd fr fs pe fu fw ip bi translated">谷歌联合实验室</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">编辑描述</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">colab.research.google.com</p></div></div><div class="ph l"><div class="pn l pj pk pl ph pm kp oy"/></div></div></a></div><p id="ac38" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated"><strong class="lp ir">情感到图像</strong>:条件生成对抗性神经网络(基于情感的人像)</p><div class="ov ow gp gr ox oy"><a href="https://colab.research.google.com/drive/1dQcHAClX1fjBNvt-hMauWEg7x4m7Kq3V?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd ir gy z fp pd fr fs pe fu fw ip bi translated">谷歌联合实验室</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">编辑描述</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">colab.research.google.com</p></div></div><div class="ph l"><div class="po l pj pk pl ph pm kp oy"/></div></div></a></div></div><div class="ab cl pp pq hu pr" role="separator"><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu"/></div><div class="ij ik il im in"><h1 id="7c16" class="kv kw iq bd kx ky pw la lb lc px le lf jw py jx lh jz pz ka lj kc qa kd ll lm bi translated">类似项目</h1><p id="583c" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">→谭，万良等<a class="ae mk" href="https://web.stanford.edu/~yuwangme/project_doc/CS231N_Report.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="my">用于对绘画所唤起的情绪进行分类的CNN模型</em> </a>。技术报告，美国斯坦福大学SVL实验室，2018年</p><p id="7fc7" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">→ Alvarez-Melis、David和Judith Amores。<a class="ae mk" href="https://nips2017creativity.github.io/doc/The_Emotional_GAN.pdf" rel="noopener ugc nofollow" target="_blank">《情感甘》:以情感促发艺术的生成。</a><em class="my">2017 neur IPS面向创意和设计的机器学习工作坊</em>。2017.</p></div><div class="ab cl pp pq hu pr" role="separator"><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu"/></div><div class="ij ik il im in"><h1 id="3926" class="kv kw iq bd kx ky pw la lb lc px le lf jw py jx lh jz pz ka lj kc qa kd ll lm bi translated"><strong class="ak">结论</strong></h1><p id="9d1f" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我真的很喜欢探索艺术发挥作用的深度学习的这一部分。我很高兴看到生成的图像不断改进。就结果而言，我会再次得出结论，深度学习不是魔法，我们需要定性数据和明确的任务来帮助模型理解任务。在这个项目中，这两个要求都不存在。然而，从纯粹的艺术角度来看，这个实验非常有趣。</p></div><div class="ab cl pp pq hu pr" role="separator"><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu"/></div><div class="ij ik il im in"><p id="9b44" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated"><strong class="lp ir"> <em class="my">重要提示:</em> </strong></p><p id="3fa9" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated"><em class="my"> Wiki-Art emotion是根据本文开头讨论的特定研究目标创建的。不建议将数据集用于商业应用，对个人进行推断，以及在数据差异很大的环境中构建机器学习系统。不要使用数据集从人们的面部表情中自动检测他们的情绪。关于数据集的更多问题，请访问</em><a class="ae mk" href="http://saifmohammad.com/WebPages/wikiartemotions.html" rel="noopener ugc nofollow" target="_blank"><em class="my">http://saifmohammad.com/WebPages/wikiartemotions.html</em></a><em class="my">。</em></p><p id="731d" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">请随时在评论区与我分享您的反馈和想法💻🔥💻。</p><p id="0fab" class="pw-post-body-paragraph ln lo iq lp b lq ml jr ls lt mm ju lv lw mn ly lz ma mo mc md me mp mg mh mi ij bi translated">谢谢大家！</p></div></div>    
</body>
</html>