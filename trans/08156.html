<html>
<head>
<title>Monte Carlo Markov Chain (MCMC), Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">蒙特卡洛马尔可夫链(MCMC)，解释说</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/monte-carlo-markov-chain-mcmc-explained-94e3a6c8de11?source=collection_archive---------0-----------------------#2021-07-27">https://towardsdatascience.com/monte-carlo-markov-chain-mcmc-explained-94e3a6c8de11?source=collection_archive---------0-----------------------#2021-07-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dfae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理解使用随机性估计复杂实体背后的魔力</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/794b1bf1425724a6cf3dacd8fbd04658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADiZaUQetyNQxJmzYY0g8Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:图片由来自<a class="ae kv" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1655118" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae kv" href="https://pixabay.com/users/erik_stein-2524241/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1655118" rel="noopener ugc nofollow" target="_blank">埃里克·斯坦</a>拍摄</p></figure><p id="e7fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MCMC是贝叶斯统计中最重要和最流行的概念之一，尤其是在进行推理时。</p><p id="0604" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从更大的角度来看，有时在高维空间中估计推理在计算上可能变得不可行，在这种情况下，我们求助于对其进行近似——或者通过使用<strong class="ky ir"> <em class="ls">采样方法</em> </strong>(其中之一是<strong class="ky ir"> MCMC </strong>)或者用<strong class="ky ir"> <em class="ls">参数化分布</em> </strong> ( <strong class="ky ir">变分推理</strong>)对其进行近似。</p><p id="c11f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本帖中，我们将通过举例来剖析和理解MCMC的组件来讨论它。在这篇文章的后面，我们将会看到一个融合了这个概念的算法，<strong class="ky ir"> Metropolis-Hasting算法。</strong></p><p id="f55c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事不宜迟，让我们开始吧！</p><blockquote class="lt lu lv"><p id="d591" class="kw kx ls ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">注:标有“附加内容”的小节可以跳过，不会影响对概念的总体理解。</p></blockquote></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="e19f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">采样</strong></p><p id="4167" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">抽样是一种通过将人口的一个子集纳入研究来近似估计整个人口的某些特征的方法。</em></p><p id="5f4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">采样有各种各样的用例—</p><ul class=""><li id="b366" class="mg mh iq ky b kz la lc ld lf mi lj mj ln mk lr ml mm mn mo bi translated">它可以用来近似一个棘手的总和或积分。</li><li id="bfbb" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ml mm mn mo bi translated">它可以用于在估计易处理但昂贵的和或积分时提供显著的加速。</li><li id="158e" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ml mm mn mo bi translated">在某些情况下，如密度估计，它可以简单地用于近似概率分布，然后估算缺失数据。</li></ul><p id="e26d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">少数抽样技术— <strong class="ky ir">祖先抽样、逆变换抽样、拒绝抽样、重要性抽样、蒙特卡罗抽样、MCMC抽样。</strong></p><p id="00e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我们只关注MCMC方法，其他方法将在另一篇文章中讨论。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h2 id="31da" class="mu mv iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl nm bi translated">介绍</h2><p id="ae6a" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">MCMC方法是使用马尔可夫链来执行蒙特卡罗估计的一系列算法。</p><p id="e6d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个名字给了我们一个提示，那就是它由两部分组成——<br/><em class="ls">蒙特卡洛</em>和<em class="ls">马尔可夫链。让我们分别地和以它们的组合形式来理解它们。</em></p><h1 id="d22e" class="ns mv iq bd mw nt nu nv mz nw nx ny nc jw nz jx nf jz oa ka ni kc ob kd nl oc bi translated">蒙特卡罗抽样</h1><p id="9db9" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated"><strong class="ky ir">(直觉上)</strong></p><p id="6a44" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">蒙特卡洛法得名于摩纳哥的蒙特卡洛赌场。</p><p id="9a00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一种从概率分布中取样并使用这些样本来逼近所需数量的技术。换句话说，它使用随机性来估计某个确定性的感兴趣的量。</p><blockquote class="lt lu lv"><p id="6f2a" class="kw kx ls ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">示例:如果要求我们计算下图中给定曲线的曲线下面积，可能需要对复杂的解析公式进行积分。<br/>然而，使用蒙特卡罗方法，我们将在矩形中随机生成红点<br/>(点越多越准确)，并计算落在曲线下的点与落在整个矩形中的点的比率——该比率将为我们提供面积，给定矩形的面积。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/c5ad6276d1d4e01bccf8c695f76fd17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*Nbs26Y5r8rQKi_RsbVPo9w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)-蒙特卡洛法估算曲线下的面积</p></figure><p id="ffec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基本上，如果计算某个量具有复杂的分析结构，我们可以简单地执行模拟来生成大量样本，并使用它们来近似该量。这些工作假设渐近地遵循中心极限定理。</p><p id="dc28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它在风险分析、可靠性分析等方面有许多其他用例。</p><p id="ab28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">(数学上)</strong></p><p id="3884" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我们有期望值要估计，这可能是一个非常复杂的积分，甚至难以估计——使用蒙特卡罗方法，我们通过对样本求平均值来近似这些量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/083428984cd5e330ffdd9d646582f4a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*ivarU1lVqNbIDaSw5eHMgA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">要计算的原始期望值</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/8e3def5f1c7826643c54ad14bae27a6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*8C8xp9NwR2JIybxVKnPmBQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">通过刺激f(x)的大样本产生的近似期望</p></figure><p id="bdc5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算大量样本的平均值可以减少标准误差，并为我们提供一个相当准确的近似值。</p><p id="8514" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">这种方法有一个局限性，因为它假设很容易从一个概率分布中抽样，然而这样做并不总是可能的。有时，我们甚至不能从分布中取样。在这种情况下，我们利用马尔可夫链从一个棘手的概率分布中有效地进行采样。”</em> </strong></p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="5384" class="ns mv iq bd mw nt og nv mz nw oh ny nc jw oi jx nf jz oj ka ni kc ok kd nl oc bi translated">马尔可夫链</h1><p id="1138" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">在进入<strong class="ky ir"> <em class="ls">马氏链</em> </strong>之前，让我们先看一下定义它的有用性质——</p><p id="8a9f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">马尔可夫性质:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/e9356e543417428eca2b8c1c0f064d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iPNlWGz9aAsjCdy_zJwlsA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">椭圆形中的实体是状态</p></figure><p id="31a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面的图像中，考虑一个由4个状态组成的系统—</p><p id="a8c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">下雨</em>或<em class="ls">洗车</em>导致<em class="ls">地面潮湿</em>接着<em class="ls">【地面潮湿】</em>导致<em class="ls">【打滑】。</em></p><p id="0619" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">马尔可夫性质只是做了一个假设——<strong class="ky ir"><em class="ls">从一个状态跳到下一个状态的概率只取决于当前状态而不取决于导致这个当前状态的先前状态的序列。</em> </strong></p><blockquote class="lt lu lv"><p id="4fea" class="kw kx ls ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">如果我们要计算某人滑倒的概率，知道地面是否潮湿就提供了足够的证据来估计它。我们不需要知道导致它的状态(“下雨”或“洗车”)。</p></blockquote><p id="beac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">数学上来说:</em> </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/cfeb5445ba6b4aecb997f8d5129beb14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6BjO6HDRuDuN8hdf1NrLA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截断分布的马尔可夫性质</p></figure><p id="fb12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从数学方程中可以明显看出，马尔可夫性质假设可能会节省我们大量的计算。</p><p id="27dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事后看来，如果一个过程展现出<strong class="ky ir"> <em class="ls">马尔可夫性质</em> </strong>，那么它就被称为<br/> <strong class="ky ir"> <em class="ls">马尔可夫链。</em> </strong></p><p id="3b3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经看到了马尔可夫链，让我们来讨论使它如此令人满意的性质— <strong class="ky ir">平稳分布。</strong></p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h2 id="47f8" class="mu mv iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl nm bi translated"><strong class="ak">平稳分布:</strong></h2><p id="ae5b" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">假设，我们有一个很少状态的过程，并且我们有一个固定的状态间转移概率<strong class="ky ir"> (Q) </strong>。<br/>我们从时间步<strong class="ky ir"> i </strong>的所有状态上的一些随机概率分布(<strong class="ky ir"> Sᵢ </strong> ) <br/>开始，为了估计下一个时间步<strong class="ky ir"> i+1 </strong>的所有状态上的概率分布，我们将其乘以转移概率<strong class="ky ir"> Q </strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/2f7a6a0be5c3fdc6492351af4885afb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*rgu3yHQzEIsJsMf7j1yJIA.png"/></div></div></figure><p id="80f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们继续这样做，过一会儿<strong class="ky ir"> S </strong>在与矩阵Q相乘时停止变化，这就是我们说它已经达到了<strong class="ky ir"> <em class="ls">平稳分布。</em> </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ddaba96a6820e5c15e1f15906f32d8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*oYN5_705NpSOFItXZNh45g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">已达到稳定分布</p></figure><p id="2545" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看一个例子——</p><p id="40b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个例子中，我们有3个州(X₁、X₂、X₃)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/99829cbab802e3ef1064c3568c6b3e11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lfrLS1bvCZ_yMIVgzi0sIQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">状态之间的转移概率(<strong class="bd oq"> T </strong></p></figure><p id="cb32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们处于状态<strong class="ky ir"> S₂ </strong>，留在<strong class="ky ir"> S₂ </strong>的概率是0.1，<br/>转换到状态<strong class="ky ir"> S₁ </strong>的概率是0，转换到状态<strong class="ky ir"> S₃ </strong>的概率是0.9(从矩阵的第二行可以明显看出)。</p><p id="7365" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从向量<strong class="ky ir"> Sᵢ </strong>的某个随机值开始(向量显示在任何特定时间步处于每个状态的概率)，我们可以看到向量如何总计为1。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/b8ebc401bcc4554f0455b848b5734aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*F3uS6LYET_ubcHbzTAUXKQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/5f3e576e8f244ee06f481b1f96ece481.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*jHwNo-mujmaTu08DAGnI7g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">应用<strong class="bd oq">后Sᵢ₊₁ </strong> = <strong class="bd oq"> Sᵢ*Q </strong></p></figure><p id="2c49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们继续按时间步长移动，最终我们会到达静止状态，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/c50cdca8a06124275d47dffbcdc2955e.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*_B1iIdoPsCM0t-Dr0nZJHw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">稳定分布</p></figure><p id="6fac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在最需要知道的是，这个平稳分布不依赖于初始状态，你可以尝试不同的初始状态<strong class="ky ir"> Sᵢ </strong>。</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="6110" class="mu mv iq ov b gy oz pa l pb pc">import numpy as np</span><span id="71ce" class="mu mv iq ov b gy pd pa l pb pc">Q = np.matrix([[0,1,0],[0,0.1,0.9],[0.6,0.4,0]])<br/>S_initial = np.matrix([[0.3, 0.4 , 0.3]])<br/>epsilon = 1</span><span id="2046" class="mu mv iq ov b gy pd pa l pb pc">while epsilon &gt; 10e-8:<br/>    S_next = np.dot(S_initial, Q)<br/>    epsilon = np.sqrt(np.sum(np.square(S_next - S_initial)))<br/>    S_initial = S_next</span><span id="96b8" class="mu mv iq ov b gy pd pa l pb pc">print(S_initial)</span></pre><p id="09e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">平稳分布表示在任何给定时间处于任何状态的概率。</p><p id="c955" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">直观地说<strong class="ky ir">马尔可夫链可以被认为是在链上行走，给定特定步骤的状态，我们可以通过查看下一步的“状态概率分布”来决定下一个状态。</strong></p><p id="7988" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好了，现在我们已经看到了马氏链和蒙特卡洛，让我们把我们的重点放在这些美丽的组合形式，即mcmc。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="639e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">临时演员— </strong></p><p id="4a34" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">任何好奇并想了解<strong class="ky ir">为什么马尔可夫链收敛于平稳分布的人</strong>都可以参考下图——</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/9dd6297bc456b270caefff287abde93b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5IhRlwbxeYJqrscEzH6Ag.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:@book{Goodfellow-et-al-2016，title={Deep Learning}，作者= { Ian good fellow and yo shua beng io and AaronCourville }，出版商={MIT Press}，注= { \ URL { http://www . Deep Learning book . org } }，年份={2016}}</p></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="7f74" class="ns mv iq bd mw nt og nv mz nw oh ny nc jw oi jx nf jz oj ka ni kc ok kd nl oc bi translated">马尔可夫链蒙特卡罗(MCMC)</h1><p id="d928" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls"> MCMC可以用来从任何概率分布中抽样。大多数情况下，我们用它来从难以处理的后验分布中进行抽样，以达到推断的目的。</em> </strong></p><p id="365a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用Bayes估计后验概率有时会很困难，在大多数情况下，我们可以找到<strong class="ky ir">可能性</strong> x <strong class="ky ir">先验</strong>的函数形式。然而，计算边缘化概率P(B)在计算上可能是昂贵的，尤其是当它是连续分布时。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/14e52f749446371f69e7c777853b002d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*GgcOFBm64iKoZ0JB.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)具有离散边际概率的贝叶斯定理</p></figure><p id="cb59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的技巧是完全避免计算归一化常数。</p><p id="ec7d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">该算法的总体思路是从一些随机概率分布开始，逐渐向期望的概率分布移动。</strong></p><p id="ad16" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">听起来很简单，但是我们怎么做呢？</p><blockquote class="lt lu lv"><p id="8c17" class="kw kx ls ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">启动一个状态随机概率分布的马尔可夫链，在链中逐渐向稳定分布收敛，应用一些条件(<strong class="ky ir">详细资产负债表</strong>)确保该稳定分布类似于期望的概率分布。</p></blockquote><p id="a412" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在达到平稳分布时，我们已经逼近后验概率分布。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/2947e4282ad345c68080e8a81582ab27.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*NrwNv9_6g1bwrlC-_uUqIg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">详细的资产负债表状况</p></figure><p id="d162" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">概率p(A)表示在A的概率，概率T(A -&gt; B)表示从A移动到B的概率。</p><p id="330d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">概率p(B)代表在B的概率，概率T(B -&gt; A)代表从B移动到A的概率。</p><p id="d194" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每条边代表从A到B或者B到A的概率流<br/>如果条件满足，那么它保证稳态近似代表后验分布。</p><p id="9d22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管MCMC本身很复杂，但它们提供了很大的灵活性。它为我们提供了高效的高维采样。它可以用来解决大状态空间的问题。</p><p id="9ca5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">限制</strong> — MCMC在逼近多模态概率分布时表现不佳。</p><h2 id="5ac1" class="mu mv iq bd mw mx my dn mz na nb dp nc lf nd ne nf lj ng nh ni ln nj nk nl nm bi translated">临时演员—</h2><p id="14d7" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated"><a class="ae kv" href="https://stats.stackexchange.com/questions/481390/why-is-the-normalisation-constant-in-bayesian-not-a-marginal-distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">在这种情况下，边际概率P(B)是一个称为归一化常数的常数，它对分子</strong> </a> <strong class="ky ir">的所有可能值求和。</strong></p><p id="0024" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">存在用于训练或评估具有难以处理的归一化常数(也称为配分函数)的模型的技术。他们很少在算法中使用MCMC进行采样。</p><p id="6d65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如— <strong class="ky ir">对比散度(CD) </strong>对于训练像<em class="ls">受限玻尔兹曼机</em>这样的非结构化图形模型很有用。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="e134" class="ns mv iq bd mw nt og nv mz nw oh ny nc jw oi jx nf jz oj ka ni kc ok kd nl oc bi translated">Metropolis —加速算法</h1><p id="aff2" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">假设我们从分布p(x) = f(x) / Z中采样，其中Z是难以处理的归一化常数。</p><p id="6402" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的目标是以这样一种方式从p(x)中抽样，即只利用分子而避免估计分母。</p><p id="cfca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">(求婚概率)</strong></p><p id="5322" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们先来看一下<strong class="ky ir">提议概率(g) </strong>。<br/>给定一个样本，它建议我们用马尔可夫链中的下一个潜在样本。<br/>(如何决定是接受还是拒绝潜在样本，我们将在下一节中看到)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/d3b794d5c77b9ffa8a8d0b5dd0423f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*VRzEe7IHZ_zflbLmP-JwAQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者拍摄)—提案分发</p></figure><p id="7df3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设<strong class="ky ir"> g(X₂ | X₁) =正态(x₁σ)</strong><br/><strong class="ky ir"><em class="ls">(</em></strong><em class="ls">它可能是任何分布，为简单起见我们选择了正态分布</em> <strong class="ky ir"> <em class="ls"> ) </em> </strong></p><p id="b3e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">保持X₁均值，我们做一个正态分布。然后我们从这个分布中抽取X₂ <br/>作为样本。</p><p id="eae9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们重复同样的步骤对X₃进行采样，保持X₂为平均值。</p><p id="9726" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">(主算法)</strong></p><p id="7dfd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从详细的资产负债表条件开始这个算法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/2947e4282ad345c68080e8a81582ab27.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*NrwNv9_6g1bwrlC-_uUqIg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">详细的资产负债表</p></figure><p id="d14d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从X₁过渡到X₂的可能性可以被视为一个两步走的过程，考虑到我们在X₁州—</p><p id="b778" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一步是用一些<br/> <strong class="ky ir"> <em class="ls">的提议概率</em> g </strong>做出X₂的提议(上一节讨论过)。</p><p id="ca1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二步是接受新状态X₂用某种<br/> <strong class="ky ir"> <em class="ls">接受概率</em></strong><em class="ls"/><strong class="ky ir"/></p><p id="be70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将转移概率代入方程…</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/6b7551a88692786aec9a68e81da0ca8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Yi_H0xlQ98UpnBB6quUGvA.png"/></div></figure><p id="c08e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用f(x)/Z代替p(x)，两边的Z被抵消，我们得到…</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/bcf77616e2ab689ba711ddd28c78761a.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*G_VbjWIb1c_CeaZuuwM0Mw.png"/></div></figure><p id="4e24" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">重新构建等式会导致</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/811ef74010f163beeb1c56467fd5f6d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*P32cvWrB9uaZTtrOZBDiiw.png"/></div></figure><p id="c6c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">替代速记符号</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/bb51c1cd4d58c30553fd8b4850f2f11e.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*5fvdBlT44Y9vsFtd0Qt_oA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/2c34fcb569f2aefe1c26f1599edb7e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*QPwfp8htzZrdA7XFvJ5dOw.png"/></div></figure><p id="0fbd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们得到<strong class="ky ir">接受概率A </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/71609f36fb015c37bebc0741fdcd4aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*vbXirSbB-Fw10U1FzAxZIA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">接受概率</p></figure><p id="5767" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总结一下—</p><ul class=""><li id="0b8b" class="mg mh iq ky b kz la lc ld lf mi lj mj ln mk lr ml mm mn mo bi translated">我们从一个随机状态开始。</li><li id="9c35" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ml mm mn mo bi translated">基于提议概率(g ),我们随机选择一个新的状态。</li><li id="9ea6" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ml mm mn mo bi translated">计算提议的新状态的接受概率(A)。</li><li id="f70d" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ml mm mn mo bi translated">掷硬币，正面着地的概率等于接受概率，如果硬币正面着地，接受样品，否则拒绝。</li><li id="1b26" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ml mm mn mo bi translated">重复这个过程一段时间。</li></ul><p id="30bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们保持长时间的采样，并丢弃最初的几个样本，因为链还没有达到其静止状态(这个时期被称为<br/> <strong class="ky ir">预烧期</strong>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi po"><img src="../Images/28b159089e19e61a0548440c5c8c8c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*Hc6u4frwjbgdnVFFUlqxvw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者拍摄)</p></figure><p id="c9cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">限制:</strong></p><ul class=""><li id="54ef" class="mg mh iq ky b kz la lc ld lf mi lj mj ln mk lr ml mm mn mo bi translated">在近似多模态分布时，由于链被卡住，得到有偏差的样本，因此对所需量的估计不太准确。</li><li id="ffbb" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ml mm mn mo bi translated">当样本空间是高维时，Metropolis-Hasting变得非常慢。(另一个惊人的MCMC方法<strong class="ky ir">哈密顿蒙特卡罗</strong>克服了这些缺点，将在另一篇文章中讨论)。</li></ul><p id="eced" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">结论</strong>:</p><p id="181a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对MCMC方法的讨论到此结束。更多关于类似讨论的帖子将被关注。</p><p id="d7f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这绝不是一个容易理解的概念，因为它是概念的融合，而这些概念隐藏在数学背后。</p><p id="1098" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你一路走来，那么恭喜你！！万事如意！！</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="a077" class="ns mv iq bd mw nt og nv mz nw oh ny nc jw oi jx nf jz oj ka ni kc ok kd nl oc bi translated">参考:</h1><ol class=""><li id="60e4" class="mg mh iq ky b kz nn lc no lf pp lj pq ln pr lr ps mm mn mo bi translated"><a class="ae kv" href="https://www.amazon.in/Deep-Learning-Ian-Goodfellow/dp/0262035618" rel="noopener ugc nofollow" target="_blank">深度学习作者伊恩·古德菲勒、约舒阿·本吉奥和亚伦·库尔维尔。</a></li><li id="42f8" class="mg mh iq ky b kz mp lc mq lf mr lj ms ln mt lr ps mm mn mo bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=yCv2N7wGDCw&amp;t=185s" rel="noopener ugc nofollow" target="_blank">ritvikmath创作的《大都会-加速》</a></li></ol></div></div>    
</body>
</html>