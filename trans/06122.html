<html>
<head>
<title>Using Deep Learning to Quantify, Monitor, and Remove Marine Plastic</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习来量化、监控和清除海洋塑料</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/identifying-and-removing-marine-plastic-a-deep-learning-approach-6ad5e41bec41?source=collection_archive---------23-----------------------#2021-06-01">https://towardsdatascience.com/identifying-and-removing-marine-plastic-a-deep-learning-approach-6ad5e41bec41?source=collection_archive---------23-----------------------#2021-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f56d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">能够识别和量化全世界的地下塑料的通用物体检测器</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/e8e05a85f715418b5b2ff2bf54262cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*g9qkeRUhcUdPhRXccdvAhQ.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">照片由<a class="ae kr" href="https://stock.adobe.com/ee/license-terms" rel="noopener ugc nofollow" target="_blank">土坯库存</a>的<a class="ae kr" href="https://stock.adobe.com/ee/contributor/201039361/jag-cz?load_type=author&amp;prev_url=detail" rel="noopener ugc nofollow" target="_blank"> Jag_cz </a>拍摄</p></figure><p id="3c8a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我和我的团队一起参与了一个名为<em class="lo">深度塑料</em>的项目，这是一种利用深度学习识别海洋塑料的新方法，我想分享一下我的发现:</p><h2 id="6615" class="lp lq iq bd lr ls lt dn lu lv lw dp lx lb ly lz ma lf mb mc md lj me mf mg mh bi translated">85%的平均精度！</h2><p id="2736" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">使用我们的模型，我们现在可以平均检测海洋中85%的表层塑料。我们基于名为<a class="ae kr" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir"> YOLOv5-S </strong> </a>的神经网络架构实现了这一级别的精度。下面我们附上了一段视频，其中包含我们运行模型的海洋塑料示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mn mo l"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">利用深度学习模型检测海洋塑料</p></figure><h1 id="e51f" class="mp lq iq bd lr mq mr ms lu mt mu mv lx jw mw jx ma jz mx ka md kc my kd mg mz bi translated">文件和代码在哪里？</h1><p id="5e58" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">这篇文章将主要作为我们研究论文的无代码摘要。如果你想直接跳到神经网络或代码的本质细节，你可以在这里访问它们:</p><p id="d1b9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">arxiv预印本:<a class="ae kr" href="https://arxiv.org/abs/2105.01882" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2105.01882</a></p><p id="6ac1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">Github代码库:<a class="ae kr" href="https://github.com/gautamtata/DeepPlastic" rel="noopener ugc nofollow" target="_blank">https://github.com/gautamtata/DeepPlastic</a></p><p id="1673" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果你想让我再写一篇解释代码、数据扩充等的博文。，在下面的评论里告诉我吧！</p><h1 id="952a" class="mp lq iq bd lr mq mr ms lu mt mu mv lx jw mw jx ma jz mx ka md kc my kd mg mz bi translated">我是怎么卷进来的？</h1><p id="1425" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">我一直对海洋充满热情。从加州州立大学蒙特利湾分校毕业后，我知道我想开发工具/软件来帮助保护海洋。在我收集、注释和管理数据以及模型之后，我意识到精度指标非常重要，可能有一份手稿可以在这里发表。因此，我向海洋塑料专家萨拉-珍妮·罗耶博士以及杰伊·劳伊·T21和奥利维尔·波里恩博士寻求帮助，帮助撰写和出版手稿。</p><h1 id="2aaa" class="mp lq iq bd lr mq mr ms lu mt mu mv lx jw mw jx ma jz mx ka md kc my kd mg mz bi translated">摘要</h1><p id="c4e2" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">正浮力海洋塑料垃圾的量化对于了解垃圾如何在世界海洋中聚集以及确定急需清除垃圾的高浓度垃圾热点至关重要。</p><p id="5121" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">目前，量化漂浮塑料的最常见监测方法需要使用蝠鲼拖网。在分析之前，物理移除的需要会导致高成本，并需要大量的劳动力，从而阻碍了实时海洋塑料监测服务在海洋中的可扩展部署。如果没有更好的监测和采样方法，塑料污染对整个环境的总体影响，以及特定海洋区域内影响的细节，将仍然是未知的。</p><p id="4909" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这项研究提出了一个自动化的工作流程，利用在海洋表层捕获的视频和图像作为输入，对海洋塑料进行实时量化，以实现精确量化和清除。</p><blockquote class="na nb nc"><p id="c766" class="ks kt lo ku b kv kw jr kx ky kz ju la nd lc ld le ne lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ir"> YOLOv5-S </strong>是性能最好的车型，其平均精度(mAP)为0.851，F1得分为0.89，同时保持接近实时的速度。此外，我们的方法可以利用“现成的”摄像设备和标准的低成本GPU来近乎实时地监测/量化表层塑料。</p></blockquote><h1 id="08f8" class="mp lq iq bd lr mq mr ms lu mt mu mv lx jw mw jx ma jz mx ka md kc my kd mg mz bi translated">项目的目标</h1><p id="afd7" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">我们希望建立一个通用的物体探测器，能够识别和量化世界各地的地下塑料。</p><p id="876d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在我们已经了解了我们的目标以及如何实现它，让我们进入工作流程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ng"><img src="../Images/72c09537d94aabbfac6d84adc51a7d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1skV_X9rF3NrIK0sbx9-tA.jpeg"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">检测海洋塑料的管道；作者照片</p></figure></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="d396" class="mp lq iq bd lr mq ns ms lu mt nt mv lx jw nu jx ma jz nv ka md kc nw kd mg mz bi translated">管理数据集</h1><p id="6ae8" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">找到一个包含海洋废弃物注释图片的数据集非常困难。目前还没有关于海洋表层海洋塑料图像的数据集。所以，我决定创造一个。我买了一台GoPro Hero 9、一套潜水服和浮潜设备，带着2个塑料袋和2个塑料瓶前往加利福尼亚的各个地方。</p><p id="4c19" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我去过的地方有:太浩湖，波德加湾，旧金山湾。在这里，我在4K拍摄了塑料的视频，然后将它们逐帧分解成图像。[在我完成视频拍摄后，所有使用的塑料都经过消毒并从环境中移除]最初的数据集有10万多张图像，然后我煞费苦心地逐一查看，选择了最好的图像，并使用supervise.ly对它们进行了注释。最终的数据集，加上从互联网上收集的图像，有4000张图像。</p><p id="1bef" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我尽力通过将物体埋在沙子里或放置在太阳对面来复制真实世界的场景，如遮挡和亮度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nx"><img src="../Images/682b48931880acb09dde078ec1ed469b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-RJpQ0QEh0OVXsTsYIvYRQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">(<strong class="bd ny">右下</strong>)照片由<a class="ae kr" href="https://unsplash.com/@naja_bertolt_jensen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">娜佳·贝尔托尔特·詹森</a>在<a class="ae kr" href="https://unsplash.com/s/photos/underwater-plastic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄；(<strong class="bd ny">右上</strong>)照片由<a class="ae kr" href="https://unsplash.com/@narimanmesharrafa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">纳里曼·迈沙拉法</a>在<a class="ae kr" href="https://unsplash.com/s/photos/underwater-plastic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄；(<strong class="bd ny">左上，右下</strong>)作者图片</p></figure><h2 id="a13e" class="lp lq iq bd lr ls lt dn lu lv lw dp lx lb ly lz ma lf mb mc md lj me mf mg mh bi translated">数据格式编排</h2><p id="facc" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">图像尺寸调整为416x416，并转换为Darknet和YOLOv5 PyTorch要求的格式。</p><h2 id="b386" class="lp lq iq bd lr ls lt dn lu lv lw dp lx lb ly lz ma lf mb mc md lj me mf mg mh bi translated">数据扩充</h2><p id="0e3d" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">由于最终的数据集只包含4000张图像，我认为增加数据集大小的最佳方式是扩大它。所以，我用翻转，旋转，亮度来复制海洋环境。</p><p id="567d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我还使用了B&amp;W来使模型不被颜色和剪切所影响，来模拟遮挡。</p><h1 id="f367" class="mp lq iq bd lr mq mr ms lu mt mu mv lx jw mw jx ma jz mx ka md kc my kd mg mz bi translated">构建神经网络</h1><p id="66fe" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">构建神经网络是一项简单的任务。我选择模型有两个目标:模型必须有点准确，模型必须很快。足够快，可以用在浮标和无人机上。我试过很多型号，比如更快的R-CNN，EfficientDet，SSD等。，但坚持使用两种型号:YOLOv4-Tiny和YOLOv5-S。</p><p id="6a27" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><em class="lo">对YOLOv5的代码运行感兴趣？请在下面的评论中告诉我或者联系我。</em></p><p id="a4d4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">注意事项/调整超参数:</p><ol class=""><li id="e7c5" class="nz oa iq ku b kv kw ky kz lb ob lf oc lj od ln oe of og oh bi translated">我使用了一个叫做ADAM的<em class="lo">自适应学习率</em>来设置一个衰减的学习率。</li><li id="8674" class="nz oa iq ku b kv oi ky oj lb ok lf ol lj om ln oe of og oh bi translated">使用名为<em class="lo"> W &amp; B </em>的软件包(重量和偏差)并持续监控损失。</li><li id="7ca3" class="nz oa iq ku b kv oi ky oj lb ok lf ol lj om ln oe of og oh bi translated">我使用了一个<em class="lo"> softmax </em>作为最后一层，并且只使用了<em class="lo">一个叫做<em class="lo"> </em> trash_plastic的类</em>。</li><li id="4d7d" class="nz oa iq ku b kv oi ky oj lb ok lf ol lj om ln oe of og oh bi translated">我用paperspace.com和谷歌Colab pro搭配<em class="lo">英伟达v100 GPU</em>来训练模型。</li><li id="a201" class="nz oa iq ku b kv oi ky oj lb ok lf ol lj om ln oe of og oh bi translated">使用在<em class="lo">水下场景</em>和<em class="lo">深海残骸上训练的权重的迁移学习——jam stec JEDI数据集。</em></li></ol><blockquote class="na nb nc"><p id="43ad" class="ks kt lo ku b kv kw jr kx ky kz ju la nd lc ld le ne lg lh li nf lk ll lm ln ij bi translated">所有用于模型的代码包括架构都可以在<a class="ae kr" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank"> YOLOv4 </a>、<a class="ae kr" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLOv5 </a>找到</p><p id="2ac9" class="ks kt lo ku b kv kw jr kx ky kz ju la nd lc ld le ne lg lh li nf lk ll lm ln ij bi translated">对我们的代码感兴趣吗？找到这里:<a class="ae kr" href="https://github.com/gautamtata/DeepPlastic" rel="noopener ugc nofollow" target="_blank">https://github.com/gautamtata/DeepPlastic</a></p></blockquote><h1 id="07fc" class="mp lq iq bd lr mq mr ms lu mt mu mv lx jw mw jx ma jz mx ka md kc my kd mg mz bi translated">结果</h1><p id="cfa4" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">在对训练方法、数据扩充和微调超参数进行了大量实验后，我们最终达到了一个结果足够好的点，可以在现实世界的部署中使用。</p><p id="bd51" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最佳模型<strong class="ku ir"> YOLOv5-S </strong>:精度:96%，均值-均值-精度:85%，F1-得分:0.89，推理速度:2.1毫秒/img。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi on"><img src="../Images/025767f0b92edda8229cb27ed54bbee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcY2qWjMBSqHITHv65HHHQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd ny">(下排)</strong>照片由<a class="ae kr" href="http://www.jamstec.go.jp/e/about/informations/notification_2021_maintenance.html" rel="noopener ugc nofollow" target="_blank">贾姆斯泰克绝地</a>、<strong class="bd ny">(第二排第一张)</strong> ( <strong class="bd ny">右下</strong>)照片由<a class="ae kr" href="https://unsplash.com/@naja_bertolt_jensen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">娜佳·贝尔托尔特·詹森</a>在<a class="ae kr" href="https://unsplash.com/s/photos/underwater-plastic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄；作者提供的所有其他图像</p></figure><h1 id="7c19" class="mp lq iq bd lr mq mr ms lu mt mu mv lx jw mw jx ma jz mx ka md kc my kd mg mz bi translated">下一步是什么？</h1><p id="41be" class="pw-post-body-paragraph ks kt iq ku b kv mi jr kx ky mj ju la lb mk ld le lf ml lh li lj mm ll lm ln ij bi translated">目前，我们正在发表我们的论文。我们正试图让其他研究人员掌握这个模型，以测试和开发创新的方法来合成更多的数据。</p><p id="fb23" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果你感兴趣，想投稿，或者想聊天，你可以在这里联系我:<a class="ae kr" href="mailto:gautamtata.blog@gmail.com" rel="noopener ugc nofollow" target="_blank">gautamtata.blog@gmail.com</a>。</p><p id="af9d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">了解更多</strong> arxiv预印本:<a class="ae kr" href="https://arxiv.org/abs/2105.01882" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2105.01882</a></p></div></div>    
</body>
</html>