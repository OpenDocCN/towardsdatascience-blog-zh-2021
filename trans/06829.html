<html>
<head>
<title>Ask Me Anything about Vector Search</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">问我任何关于矢量搜索的问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ask-me-anything-about-vector-search-4252a01f3889?source=collection_archive---------20-----------------------#2021-06-20">https://towardsdatascience.com/ask-me-anything-about-vector-search-4252a01f3889?source=collection_archive---------20-----------------------#2021-06-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/e1c8375caf9678786950698e1540504c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qii54scKKD8RHFAS"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">本杰明·苏特在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3970" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今年的<a class="ae kf" href="https://2021.berlinbuzzwords.de/" rel="noopener ugc nofollow" target="_blank">柏林流行语</a>特别关注搜索的未来——向量搜索，以及其他真正酷的话题，如<a class="ae kf" href="https://2021.berlinbuzzwords.de/session/should-you-read-kafka-stream-or-batch-should-you-even-care" rel="noopener ugc nofollow" target="_blank">扩展卡夫卡</a>，使用<a class="ae kf" href="https://2021.berlinbuzzwords.de/session/building-observable-streaming-systems-opentelemetry" rel="noopener ugc nofollow" target="_blank"> Opentelemetry </a>的分布式系统跟踪以及<a class="ae kf" href="https://2021.berlinbuzzwords.de/session/scale-your-job-satisfaction-not-your-software" rel="noopener ugc nofollow" target="_blank">提高工作满意度</a>。一些致力于向量搜索主题的会议包括一些令人印象深刻的密集检索技术的<a class="ae kf" href="https://twitter.com/DmitryKan/status/1405592168639651849" rel="noopener ugc nofollow" target="_blank">演示</a>，以支持在你的文本湖中回答问题。</p><p id="a92e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在问我任何问题:矢量搜索！<a class="ae kf" href="https://2021.berlinbuzzwords.de/session/ask-me-anything-vector-search" rel="noopener ugc nofollow" target="_blank">会议</a> <a class="le lf ep" href="https://medium.com/u/ef0b7261dd17?source=post_page-----4252a01f3889--------------------------------" rel="noopener" target="_blank"> Max Irwin </a>和我讨论了矢量搜索的主要话题，从它的<a class="ae kf" href="https://2021.berlinbuzzwords.de/session/text-search-and-recommendation-ads-and-online-dating-approximate-nearest-neighbors-real" rel="noopener ugc nofollow" target="_blank">适用性</a>到它与优秀的ol' sparse search (TF-IDF/BM25)的比较，到它在黄金时间的准备情况以及在向用户提供它之前哪些具体的工程元素需要进一步调整。如果你对矢量搜索感兴趣，你可以从阅读我写的关于这个主题的一系列博客文章开始:在<a class="ae kf" href="https://dmitry-kan.medium.com/neural-search-with-bert-and-solr-ea5ead060b28" rel="noopener"> Solr </a>、<a class="ae kf" href="https://medium.com/swlh/fun-with-apache-lucene-and-bert-embeddings-c2c496baa559" rel="noopener"> Lucene </a>和<a class="ae kf" rel="noopener" target="_blank" href="/speeding-up-bert-search-in-elasticsearch-750f1f34f455"> Elasticsearch </a>中，跳转到GitHub <a class="ae kf" href="https://github.com/DmitryKey/bert-solr-search" rel="noopener ugc nofollow" target="_blank"> repo </a>(在会议期间，我有与会者联系我，分享他们使用它运行内部演示——所以你也可以这样做)。</p><p id="5c93" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更新:AMA会议的录音在这里:</p><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lg"><img src="../Images/c813a18e292e36f6a6cba42ca376abf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A6vnJmtTf-ZDC0zaljbdGA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">链接:<a class="ae kf" href="https://youtu.be/blFe2yOD1WA" rel="noopener ugc nofollow" target="_blank">https://youtu.be/blFe2yOD1WA</a></p></figure><p id="07b9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://www.youtube.com/watch?v=blFe2yOD1WA" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=blFe2yOD1WA</a></p></div><div class="ab cl ll lm hx ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="im in io ip iq"><figure class="lh li lj lk gt ju"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="a403" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这篇博文，我决定从友好的互联网观众中挑选3个最重要的问题(我们在活动前圈了一份在线表格，以收集一组关于矢量搜索的非常有趣和深刻的问题)，并给出我的部分答案，稍微扩展一下(并在可能的情况下增加论文和代码)。</p><blockquote class="lu lv lw"><p id="fbc1" class="kg kh lx ki b kj kk kl km kn ko kp kq ly ks kt ku lz kw kx ky ma la lb lc ld im bi translated">我们从研究和工业两方面看到了密集检索领域出现的一些模式。你对密集检索的下一步有什么想法？事情将走向何方，人们需要做些什么准备？</p></blockquote><p id="7fe6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi mb translated">这里有一篇来自谷歌研究的最近的<a class="ae kf" href="https://arxiv.org/abs/2105.13626" rel="noopener ugc nofollow" target="_blank">论文</a>，关于在<a class="ae kf" href="https://github.com/google-research/byt5" rel="noopener ugc nofollow" target="_blank">字节级</a>上训练嵌入模型，这将有助于解决拼写错误查询的各种令人生畏的问题。另一篇论文应用<a class="ae kf" href="https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/amp/" rel="noopener ugc nofollow" target="_blank">傅立叶变换</a>来提高BERT的速度:快7倍，准确率92%。因此，社区正在解决嵌入带来的各种问题，这将推动密集检索/重新排序和矢量搜索的进一步发展。需要注意的一点是，这些模型是否通用化，根据BEIR的基准测试论文，密集检索方法不能很好地通用化。只有当模型已经为相同的领域训练时，它们才会击败BM25。相比之下，最快的方法是基于重排序的，如ColBERT，但有一个条件:准备多分配10倍的磁盘空间来存储索引，而不是BM25索引(具体数字:900 GB对18 GB)。当谈到将前沿研究产品化时，除了考虑神经搜索如何与当前的搜索解决方案共存之外，您还需要整体评估特定搜索方法对可伸缩性、搜索速度、索引足迹的影响。你还允许预过滤吗？用户对他们在屏幕上看到的结果有发言权吗？你的UX会平稳地支持这种搜索引擎模式的转变，并在转变过程中保持用户效率与当前水平相当吗？</p><p id="3dba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，当您考虑为您的域构建矢量搜索块时，请仔细选择相似性度量:余弦度量在排名中倾向于较短的文档，而点积则倾向于较长的文档，因此可能需要这些度量的组合，甚至是动态度量选择过程。这可以追溯到仔细设计整个搜索栈和/或选择搜索供应商。矢量搜索的总体性能是一个尚未解决的问题，所以你需要寻找最适合你的搜索引擎的模型配置，不要太在意大玩家报告的误差幅度。我也可以推荐阅读一些好的调查论文，比如https://arxiv.org/abs/2106.04554的文章。对于那些想在十亿规模数据集上练习并了解现有人工神经网络算法的能力和局限性的人来说，作为NeurIPS 2021的一部分，有一个出色的<a class="ae kf" href="http://big-ann-benchmarks.com/index.html#call" rel="noopener ugc nofollow" target="_blank">大型人工神经网络竞赛</a>宣布。</p><blockquote class="lu lv lw"><p id="e01f" class="kg kh lx ki b kj kk kl km kn ko kp kq ly ks kt ku lz kw kx ky ma la lb lc ld im bi translated">许多ML应用程序在简单的web服务后面使用faiss/airy/NMS lib进行人工神经网络检索，例如在推荐系统中。这对于简单的应用程序很有效，但是当需要有效的过滤时，你似乎需要跳跃到一个成熟的搜索系统(elastic，vespa等)。你认为“faiss plus filter”工具有没有用武之地，或者你认为像vespa这样的搜索系统带来的额外好处能够弥补它带来的额外复杂性吗</p></blockquote><p id="e2f9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi mb translated"><span class="l mc md me bm mf mg mh mi mj di"> D </span>不同的供应商提供了不同的构建人工神经网络指数的方法。在Elasticsearch世界里，你有两个选择:</p><ol class=""><li id="92d6" class="mk ml it ki b kj kk kn ko kr mm kv mn kz mo ld mp mq mr ms bi translated">实现LSH的Elastiknn插件。</li><li id="fc5c" class="mk ml it ki b kj mt kn mu kr mv kv mw kz mx ld mp mq mr ms bi translated">用HNSW方法实现堆外图搜索。</li></ol><p id="78e9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Elastiknn支持使用字段过滤器对结果进行预过滤，如颜色:蓝色。OpenDistro通过重用Elasticsearch熟悉的功能来实现<a class="ae kf" href="https://opendistro.github.io/for-elasticsearch-docs/docs/knn/" rel="noopener ugc nofollow" target="_blank">预过滤</a>，比如脚本评分和无痛扩展。顺便说一句，我在以前的博客文章中试验了这两种方法(在开头提到过)，并实现了索引和搜索组件来演示这两种实现。</p><p id="8603" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">无论您选择哪种方法，您都需要仔细选择超参数，以便在索引速度、召回率和消耗的内存方面获得最佳性能。HNSW可以很好地扩展到多核架构，它有一系列启发式算法来避免局部极小值，并且它可以构建一个连接良好的图。但是在Lucene中为每个段构建一个图在RAM和磁盘使用方面可能会变得非常昂贵，所以您应该考虑在服务查询之前将段合并成一个(所以考虑一下为这样的优化分配比纯BM25索引更多的时间)。我认为将过滤和人工神经网络结合起来作为搜索的一个单一阶段是一个明智的决定，因为多步检索可能会遭遇速度慢或召回率低或两者兼而有之的问题。此外，当用户预先知道该特定搜索将可能产生非常大量的文档作为回报时，他们可能想要控制文档空间的边界(例如，像工业研究或专利现有技术调查)。</p><blockquote class="lu lv lw"><p id="7d8c" class="kg kh lx ki b kj kk kl km kn ko kp kq ly ks kt ku lz kw kx ky ma la lb lc ld im bi translated">这是一个内容长度“最佳点”吗？密集向量比稀疏向量(普通tf*idf)有明显优势。</p></blockquote><p id="02f8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi mb translated">在你的领域专家团队的帮助下，你可以通过更加关注长文档中的内容来解决这个问题。第一段和第二段最重要吗？文档中的特定章节对于特定的信息需求是否重要？如果是的话，让它们被注释掉重要性和语义角色，并加载到多字段倒排索引中，使用BM25作为基线。顺便说一下，在衡量搜索质量时，你可以重复使用行业标准，如DCG@P、NDCG@P、AP @ T——选择合适的评分者来优化搜索质量本身就是一门艺术，但如果你想开始，请前往Quepid(使用<a class="ae kf" href="https://quepid.com/" rel="noopener ugc nofollow" target="_blank">托管的</a>或<a class="ae kf" href="https://github.com/o19s/quepid" rel="noopener ugc nofollow" target="_blank">本地</a>部署——纯开源),将其连接到Solr / Elasticsearch，并开始使用评分查询来了解你当前的搜索质量。相信我，这项投资将会有回报，并产生大量改进的想法，从而使你的搜索引擎更具结构性。这是我今年用Quepid为学生做的电影搜索的现场演示:<a class="ae kf" href="https://www.youtube.com/watch?v=OOYsWn3LWsM&amp;t=1068s" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=OOYsWn3LWsM&amp;t = 1068s</a></p><p id="f6d2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">密集检索有一个512个单词的自然限制，超过这个限制，无论是在索引速度方面，还是在一个长文本可以压缩成什么语义方面，该模型的性能都不会很好。"所有的神经方法都有文档长度的限制，因为它们有512个单词的限制."——来自BEIR纸业。</p><p id="4e7f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在AMA会议期间，观众提出了更多的问题。请<a class="ae kf" href="https://www.youtube.com/watch?v=blFe2yOD1WA" rel="noopener ugc nofollow" target="_blank">观看</a>录像，了解更多信息，享受矢量搜索的乐趣！</p></div></div>    
</body>
</html>