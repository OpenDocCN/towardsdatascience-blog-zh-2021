<html>
<head>
<title>Serverless GPU-Powered Hosting of Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无服务器GPU驱动的机器学习模型托管</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/serverless-gpu-powered-hosting-of-machine-learning-models-9f2b2be98294?source=collection_archive---------11-----------------------#2021-05-11">https://towardsdatascience.com/serverless-gpu-powered-hosting-of-machine-learning-models-9f2b2be98294?source=collection_archive---------11-----------------------#2021-05-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8956" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Algorithmia的一个工作示例</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7aca53a103d2efea3df27158c5302cb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iJUF0uF41iRd7J-O"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">卡斯帕·卡米尔·鲁宾在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="668f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">动机</h1><p id="2078" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">随着近年来MLOps的兴起，运行机器学习模型进行推理任务变得容易多了。根据使用情况，适当优化的深度学习模型甚至可以直接在移动设备上运行。在客户端-服务器/微服务架构中，具有高精度要求的较大模型通常集中托管，并由下游服务通过定义明确的接口进行查询。TensorFlow Serving等工具现在也使这些用例在适当配置的服务器基础设施上成为可管理的问题。</p><p id="e379" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然而，从软件工程的角度来看，我们知道自我管理的基础设施会变得多么复杂。毫不奇怪，云提供商的无服务器解决方案在应用程序开发领域越来越受欢迎。没有基础设施管理和随用随付是主要优势，这就是为什么我现在几乎只使用这种解决方案。</p><h2 id="3714" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">2021年的无服务器GPU</h2><p id="c369" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">然而，当我发现自己处于将一个相当复杂的用于在线预测的深度学习模型集成到这样一个微服务的无服务器架构中时，我有些惊讶。在我的用例中，要求是以不规则的时间间隔(几秒到几小时)用base64编码的图像处理单个请求，并使用自我训练的深度学习模型返回正确的类。在我看来，一个没有深度复杂性的标准任务。被Cloud Run，Cloud Functions，AWS Lambda等宠坏了。，我天真地认为应该有一个“GPU启用”复选框，然后我们就开始了…</p><p id="9144" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">不完全是。事实上，找到一个真正的无服务器解决方案并不容易。正如已经描述过的<a class="ae kv" rel="noopener" target="_blank" href="/searching-the-clouds-for-serverless-gpu-597b34c59d55">这里的</a>，传统的无服务器解决方案更适合CPU工作负载。在我的例子中，仅使用CPU进行推理是不可能的，因为这种方式无法满足服务的延迟需求。</p><h2 id="1932" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">Google AI平台预测和AWS SageMaker？</h2><p id="2a97" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">与此同时，拥有人工智能平台预测的谷歌和拥有SageMaker的AWS提供了包括深度学习模型推理加速器在内的解决方案。只是简单总结一下为什么这些服务不符合我的要求(目前)。</p><p id="410d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从AWS SageMaker开始，最小实例计数要求为1或更高(<a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling-prerequisites.html" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/sage maker/latest/DG/endpoint-auto-scaling-prerequisites . html</a>)。对于许多持续负载的用例来说，这应该不是问题。然而，对于我来说，这将是一种资源浪费，并且不是100%符合我所寻求的量入为出原则。</p><p id="1e43" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">Google AI平台预测目前只允许使用TensorFlow SavedModel格式的GPU。例如，PyTorch模型只能在没有GPU支持的定制容器(目前是预GA)中使用。此外，谷歌确实允许自动缩放到0，但如果一个请求触发了你的服务，你将被收取最少10分钟的计算时间，即使这个请求只花了几分之一秒(【https://cloud.google.com/ai-platform/prediction/pricing】T2)</p><h2 id="6ece" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">algorithm ia——真正的无服务器替代方案？</h2><p id="2035" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">除了主要的供应商，<a class="ae kv" href="https://algorithmia.com/" rel="noopener ugc nofollow" target="_blank"> Algorithmia </a>正在吹捧自己填补了真正无服务器GPU模型托管市场的空白。Algorithmia提供了具有模型版本控制、无服务器基础设施和透明的现收现付选项的MLOps管道。与谷歌人工智能平台预测相比，你放弃了选择计算资源的灵活性(你必须相信Algorithmia，他们为你的服务分配了足够的CPU、RAM和GPU资源)，但作为回报，你只需支付算法的实际计算时间，并获得真正的无服务器体验。</p><p id="688a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">例如，您还可以通过使用常见的python代码实现单个函数来完全定制预处理和后处理步骤。一个已部署的算法可以作为一个带有预测端点的REST-API来使用，并且可以用一个API密钥来保护。实际执行时间是从算法的起始点开始计算，直到它返回。</p><p id="dcfb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">目前，服务的CPU版本收费为0.0001美元/秒，GPU服务收费为0.0003美元/秒。付款以Algorithmia信用计算，而10，000信用相当于1美元。每个月你可以免费获得5000积分。听起来至少对我的要求来说是完美的匹配。所以我们来看看。</p><h1 id="97ad" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">用Algorithmia实现一个工作示例</h1><p id="21e5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">注册后，您可以切换到您的主页部分，它为您提供了当前算法的清晰概述。您可以通过点击“新建”按钮并选择“算法”来添加一个新的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/25fab9d9f7ab6cde3464638cb080f9ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iDuWKMvn1TCF8IN8mEEf9g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Algorithmia主屏幕</p></figure><p id="2b8e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">给你的算法起一个好听的名字，选择你是想在GitHub还是Algorithmia上托管代码，指定一个预定义的环境(比如Python 3.8 + TensorFlow GPU 2.3)，你就可以开始了。创建第一个算法后，您可以将新的存储库克隆到您的本地计算机上，或者直接使用Web IDE。让我们继续使用Web IDE进行测试。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/26b0db722cca4dfe1be18f632fe8d53e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wt7RNyM1sfqwlWTadM3ohA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Algorithmia Web IDE</p></figure><p id="e0bf" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这看起来很眼熟。左边是您的项目结构，中间的主要区域显示您的代码。我已经为这篇文章准备了一个简单的例子，你可以从下面复制。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="f353" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这里实际发生了什么…在一些必要的导入之后，我们首先定义一个函数，它基本上接受一个base64字符串作为输入，并返回一个图像对象。接下来，我们从TensorFlow Hub加载一个用于图像分类的预训练模型。在我们的例子中，它是一个Mobilenet V2，被训练来分类1000个不同的类。你也可以将自己的模型免费上传到Algorithmia数据商店，或者使用Dropbox或S3。由于模型输出是代表图像类别的单个整数，我们必须加载对应于这些整数的相应标签。现在，我们可以实现强制应用功能。</p><p id="1252" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">每当客户端向我们的服务发送POST请求时，都会调用该函数，并且将主体作为输入提供给该函数。确保在应用函数之外加载模型，以避免每次请求服务时重新加载。在我们的例子中，我们期望一个代表图像的base64字符串。由于我们的模型只需要224×224像素的图像，我们必须相应地缩放输入，将其转换为预期的numpy数组结构，并将所有像素值转换为0到1之间的范围。最后，我们检查我们是否真的有可用的GPU，并返回一个带有GPU数量和输入图像的预测类别的格式化字符串。</p><p id="7003" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">要构建项目，您必须以熟悉的requirements.txt格式指定必要的依赖项。因此，单击依赖项并相应地调整条目。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/e4578961f4631cb2fdd041a2ff9d5d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uT1CDoMkm6_GOXpvrrfn-A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Algorithmia需求编辑器</p></figure><p id="3c09" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在我们可以开始建造了。单击右上角的绿色构建按钮，等待该过程完成。尤其是第一次做这一步，可能需要一段时间。根据我的经验，构建应该在大约3-5分钟后准备好。构建过程完成后，您会在Web IDE底部的控制台中看到一个输出，表明您的算法现已联机。您可以通过直接将输入粘贴到控制台来测试该算法。我们在这里跳过这一步，直接部署模型。因此，点击右上角的“发布”按钮，指定一个发布说明和一个你喜欢的示例输入，最后将可调用性指定为“私有”，点击“发布版本x.x.x”。</p><p id="1440" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">要从外部请求您的服务，您现在需要一个API密钥。在您的Algorithmia主页部分，再次单击“新建”,这次选择“API密钥”。给你的密钥起个名字，现在选择“完全访问”。例如，以后你可以指定只允许调用特定算法的键。</p><p id="5296" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在我们准备好出发了。例如，我们编写了一个简单的python脚本，它加载一个图像，将其转换为base64字符串，并向我们新创建的服务发出请求。为了检查模型的结果，我们使用下面的狮子图片。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/9cad98f3ab21007ab5744acfa772c61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TecwkLat6OhleQS2"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">罗伯特·蒂曼在Unsplash<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">上的照片</a></p></figure><p id="2c75" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">代码使用了Algorithmia包，但是您也可以使用简单的POST请求。有关请求服务的可能选项列表，请单击Algorithmia主页部分中的算法，向下滚动到“安装和使用”并选择您的首选选项。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="fc75" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">输出应该是这样的:<code class="fe nh ni nj nk b">Num GPUs: 1 and prediction class: lion</code></p><p id="4f82" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">瞧，你有一个可用的GPU，它实际上是一只狮子！</p><h1 id="c499" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="822c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在写这篇文章的时候，Algorithmia是唯一一个真正的无服务器平台，可以为GPU支持的模型提供服务，你只需要为实际的计算时间付费。因此，Algorithmia非常适合请求数量相当少(没有恒定负载)的用例。在我的实验中，我注意到在没有请求的特定时间之后，算法必须为下一次调用完全重新加载(冷启动)。这导致了长时间运行的第一个请求。随后的查询又相当快了。这不是Algorithmia的无服务器解决方案的特定行为，但仍然应该作为一种限制来提及。对于真实的在线预测用例，这并不理想。如果你需要即时的答案，请记住这一点。在这些情况下，你可能应该考虑Google AI平台预测，其中至少有一个节点始终处于准备状态。另一种选择是通过从另一个服务发送定期查询来保持您的服务“温暖”,但是请记住，这增加了成本。否则，Algorithmia是一个超级易用的无服务器机器学习平台，所以如果你的用例符合，我肯定建议你尝试一下。</p></div></div>    
</body>
</html>