<html>
<head>
<title>Designing Tokenizers for Low Resource Languages</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为低资源语言设计标记化器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/designing-tokenizers-for-low-resource-languages-7faa4ab30ef4?source=collection_archive---------17-----------------------#2021-12-28">https://towardsdatascience.com/designing-tokenizers-for-low-resource-languages-7faa4ab30ef4?source=collection_archive---------17-----------------------#2021-12-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0b0a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么为迪维希·ދިވެހި这样的语言构建 NLP 标记器如此困难</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/dc9493f4a4adcafcc613ddedcecd9ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AANYB5ISMTiF2178GaogHg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d0f9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我一直在和马尔代夫的伊斯梅尔·阿什拉克讨论自然语言处理。印度洋上一个美丽的群岛，令人难以置信地稳定在平均 25.2-31.6 摄氏度(对于那些生活在 18 世纪的人来说，那是 77.4-88.9 华氏度)。</p><p id="0f70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Ashraq 向我介绍了迪维希语(或马尔代夫语)，这种语言令人着迷。它使用一种叫做 Thaana 的复杂书写系统，我完全无法理解其中的任何一种。它与我所知道的任何事物都大相径庭——但是，就像这个群岛一样，它看起来棒极了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/d578b8a8286afa649ebcf895551ef58b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*USrhGgwaD5a8PmnFPb62yg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae lu" href="https://twitter.com/NajwaFathimath/status/1332701529816621056" rel="noopener ugc nofollow" target="_blank">手写迪维诗，来源</a>。</p></figure><p id="0f44" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">NLP 和马尔代夫不是我通常会在同一背景下想到的两个事物。然而，事实证明，有很多人这样做。</p><p id="7e3a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Ashraq 就是其中之一，他描述了将 NLP 应用于他的母语迪维希语的困难。这有几个原因:</p><ul class=""><li id="dda5" class="lw lx it la b lb lc le lf lh ly ll lz lp ma lt mb mc md me bi translated">迪维希几乎有- <strong class="la iu">零预训车型</strong>。即使是涵盖数百种语言的多语言模型也错过了迪维希。</li><li id="bbab" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt mb mc md me bi translated">非结构化的迪维希文本数据很难找到，带标签的数据更难找到。</li><li id="2fca" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt mb mc md me bi translated">许多现有的 transformer 模型不仅从未见过 Dhivehi，而且由于独特的脚本，现有的 transformer tokenizers 无法处理 Dhivehi 字符(只输出未知的令牌)。</li></ul><p id="37d2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些都是困难的障碍，但并非不可能克服。本文将探讨我们如何解决构建一个有效的 Dhivehi 单词片段分词器的第一步。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mk ml l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">文章的视频演示。</p></figure></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="cb41" class="mt mu it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">获取数据</h1><p id="c4bc" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">在构建我们的标记器之前，我们应该首先找到或创建一些数据。这里<a class="ae lu" href="https://github.com/Sofwath/DhivehiDatasets" rel="noopener ugc nofollow" target="_blank">有几个迪维希数据集</a>，质量还算合理。但是我们需要更大更干净的东西。</p><p id="4298" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Ashraq 整合了一个新的迪维希语数据集，包含了从网上搜集的 1600 多万个迪维希语样本。它并不完美——但它是很好的，也是目前构建我们的标记器(以及后来的模型)的最佳公开可用资源。</p><p id="9839" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了下载数据集，我们使用:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="f3a7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经设置了<code class="fe nr ns nt nu b">streaming=True</code>来避免将整个数据集下载到我们的本地机器。这样，我们将迭代地下载每个样本。</p><p id="7218" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我们将把数据提供给标记器训练函数，所以我们需要修改生成器输出，只生成 Dhivehi 文本，而不是包含 Dhivehi 文本的字典。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="d371" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个输出是我们需要的格式，所以现在让我们把数据留在这里，继续进行 wordpartecokenizer 的设置。</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="1ab7" class="mt mu it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">构建标记器</h1><p id="8e8b" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">令牌化过程包括几个子步骤，它们是:</p><ol class=""><li id="0017" class="lw lx it la b lb lc le lf lh ly ll lz lp ma lt nw mc md me bi translated"><strong class="la iu">规范化</strong> —文本清理，如小写，用<a class="ae lu" rel="noopener" target="_blank" href="/what-on-earth-is-unicode-normalization-56c005c55ad0"> Unicode 规范化</a>去除重音或怪异字符等。</li><li id="b5b8" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt nw mc md me bi translated"><strong class="la iu">预标记化</strong> —分裂成多个部分，通常分裂成由空格字符指示的单词或子单词标记。</li><li id="3266" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt nw mc md me bi translated"><strong class="la iu">模型</strong>——例如<em class="nv">“标记化”</em>或将字符或子词合并成更大的<em class="nv">逻辑</em>组件。</li><li id="1ad8" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt nw mc md me bi translated"><strong class="la iu">后处理</strong> —添加特殊令牌，将令牌转换为令牌 id 等。</li><li id="c2d1" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt nw mc md me bi translated"><strong class="la iu"> <em class="nv">解码器</em> </strong> —获取标记化数据并将其转换回人类可读文本的过程。这一步不是“标记化”过程的一部分，但对于理解任何基于文本的模型输出是必需的。</li></ol><p id="f488" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将利用优秀的🤗<strong class="la iu"> <em class="nv">分词器</em> </strong>库把所有这些都放在一起。我们必须首先初始化<strong class="la iu">模型</strong>，因为我们将通过 tokenizer 模型属性添加剩余的步骤。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="0643" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以添加前两步，规范化和预标记化。</p><h2 id="380d" class="nx mu it bd mv ny nz dn mz oa ob dp nd lh oc od nf ll oe of nh lp og oh nj oi bi translated">正常化</h2><p id="ba9c" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">迪维希语既不包含大写字符，也不包含小写字符。迪维希语中根本就没有“格”这个词，老实说，英语中有这个奇怪的概念不奇怪吗？</p><p id="a13f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">奇怪的是，小写字母的发展(很可能)是因为抄写员急于写得更快——产生了一种更随意的小写字母。</p><p id="5c51" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">随着时间的推移，将重要的句子和单词(比如你的名字)的开头大写成了标准做法。数百年前，印刷店将单个字母“印刷品”保存在名为<em class="nv">盒</em>的盒子里。</p><p id="eacd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">打印店将那些不常用的正式大写字母保存在难以接触到的<em class="nv">大写字母中，</em>而更常用的小写字母保存在容易接触到的<em class="nv">小写字母中</em>。</p><p id="68c9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有时，看似不起眼的小物品的起源故事可能会引人入胜。<em class="nv">反正</em>，回到我们迪维正常化。</p><p id="8851" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然我们不需要担心小写或大写的 Dhivehi，但我们的数据仍然会包含一些非 Dhivehi 文本。这个非 Dhivehi 文本不是我们关注的焦点，所以我们将所有内容都小写，以尽量减少可能产生的标记。</p><p id="0ce2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为什么？假设我们在训练数据中找到单词“hello”和“Hello”。如果没有小写，我们可能会产生两个令牌；<code class="fe nr ns nt nu b">Hello</code>和<code class="fe nr ns nt nu b">hello</code>。对于小写，我们只创建一个令牌；<code class="fe nr ns nt nu b">hello</code>。</p><p id="6b43" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们在标记化中的第一个组件是一个小写函数，用于最小化非 Dhiveh 标记。</p><p id="cfc6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一个好的规范化组件是<strong class="la iu"> Unicode 规范化</strong>。我们不会深入讨论这个问题(更多信息，请点击<a class="ae lu" href="https://www.youtube.com/watch?v=9Od9-DV9kd8" rel="noopener ugc nofollow" target="_blank"/>)，但它允许我们匹配以下内容:</p><pre class="kj kk kl km gt oj nu ok ol aw om bi"><span id="af26" class="nx mu it nu b gy on oo l op oq">ℕ𝕃ℙ == NLP</span></pre><p id="b34e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于一个角色来说，通常有不同的角色代表，对我们人类来说，代表着同一个事物——比如ℕ𝕃ℙ和 NLP。但是，变压器不会将这些视为相同。Unicode 标准化允许我们解决这个问题，将这些字符变体映射到单个字符。</p><p id="0009" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在应用 NFKD 规范化之后，我发现了 600，000 个样本发生了变化。对于 1670 万个样本来说，这个变化似乎很显著，所以我在标记器中添加了一个 NFKD 规范化步骤。</p><p id="548c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们小写并将 NFKD Unicode 规范化应用于所有传入的文本进行规范化。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="f6dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们继续下一个部分。</p><h2 id="c255" class="nx mu it bd mv ny nz dn mz oa ob dp nd lh oc od nf ll oe of nh lp og oh nj oi bi translated">预标记化</h2><p id="47db" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">预标记化组件描述了将文本串分成初始块/标记。这里的标准做法是将文本分成单词和标点符号。意思是这句话:</p><pre class="kj kk kl km gt oj nu ok ol aw om bi"><span id="9d34" class="nx mu it nu b gy on oo l op oq">"hello world! hey have you seen my pet koala?"</span></pre><p id="e396" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">变成了:</p><pre class="kj kk kl km gt oj nu ok ol aw om bi"><span id="245e" class="nx mu it nu b gy on oo l op oq">['hello', 'world', '!', 'hey', 'have', 'you', 'seen', 'my', 'pet', 'koala', '?']</span></pre><p id="6742" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要做到这一点，我们只需要一个<code class="fe nr ns nt nu b">Whitespace</code>预归类器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="ebb1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">目前，这就是我们将添加到记号赋予器的全部内容。培训完后，我们将返回到<strong class="la iu">后处理</strong>组件<em class="nv">。</em></p><h2 id="9ccc" class="nx mu it bd mv ny nz dn mz oa ob dp nd lh oc od nf ll oe of nh lp og oh nj oi bi translated">训练分词器</h2><p id="eccd" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">前三个组件、规范化、预处理和标记化模型初始化后，我们可以继续训练标记化器。</p><p id="3a1b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要迪维希数据(已经存储在🤗<strong class="la iu"> <em class="nv">数据集</em> </strong>迭代器)并指定几个分词器<em class="nv">训练</em>参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="5196" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里我们指定:</p><ul class=""><li id="66eb" class="lw lx it la b lb lc le lf lh ly ll lz lp ma lt mb mc md me bi translated"><code class="fe nr ns nt nu b">vocab_size</code> —标记器词汇表中目标标记的数量。数字越大意味着令牌越多，但训练时间越长，令牌化器文件也越大。</li><li id="a7b1" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt mb mc md me bi translated"><code class="fe nr ns nt nu b">special_tokens</code> —将在我们的 vocab 中包含的特殊令牌，BERT 模型稍后将需要这些令牌。</li><li id="57af" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt mb mc md me bi translated"><code class="fe nr ns nt nu b">min_frequency</code> —“合并”在训练数据中出现的最少次数将被视为成为新令牌。</li><li id="ffda" class="lw lx it la b lb mf le mg lh mh ll mi lp mj lt mb mc md me bi translated"><code class="fe nr ns nt nu b">continuing_subword_prefix</code> —单词片段标记器在子单词标记前附加一个特殊字符。单词<code class="fe nr ns nt nu b">upright</code>可能会变成<code class="fe nr ns nt nu b">['up', '##right']</code>，而单词<code class="fe nr ns nt nu b">right</code>可能会变成<code class="fe nr ns nt nu b">['right']</code>。令牌<code class="fe nr ns nt nu b">##right</code>和<code class="fe nr ns nt nu b">right</code>不一样。第一个是子词标记。</li></ul><p id="1b55" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这样，我们的记号赋予器<code class="fe nr ns nt nu b">trainer</code>就准备好了，我们现在要做的就是调用一个<code class="fe nr ns nt nu b">tokenizer</code>训练方法，并把它传递给我们的<code class="fe nr ns nt nu b">dv_text()</code>生成器和训练器。因为我们将数据存储在一个可迭代的<code class="fe nr ns nt nu b">dataset</code>对象中，所以我们可以调用<code class="fe nr ns nt nu b">train_from_iterator</code>方法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="7f4c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">培训结束后，我们可以进入第四步——后处理。</p><h2 id="2e4a" class="nx mu it bd mv ny nz dn mz oa ob dp nd lh oc od nf ll oe of nh lp og oh nj oi bi translated">后加工</h2><p id="d6a8" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">我们将<em class="nv">的后处理步骤定义留在</em>训练之后，因为它使用将在我们的标记化器词汇表中定义的特殊标记，该词汇表是在训练步骤期间构建的。</p><p id="b3ee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们的后处理步骤中，我们定义了要应用于我们的标记器的输出的任何转换。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5c5e69874b1a4d2441058bbf7405f7ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gkxxUi7jd1AzytFew4njhQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">后处理步骤应用于标记化步骤的输出。</p></figure><p id="42fc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个后处理步骤具体应该做什么？我们正在为 BERT 构建这个标记器，其他 BERT 模型使用的标准格式(翻译成可读文本)是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2bf1a7b660b1e8157f31f7c2386f5da3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zpSlbElUTpMQ6zFAIqZHmA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有特殊<strong class="bd or">【CLS】</strong>和<strong class="bd or">【SEP】</strong>标记的典型 BERT 输入格式。</p></figure><p id="bcd7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了定义这种格式化，我们使用了一个叫做<code class="fe nr ns nt nu b">TemplateProcessing</code>的东西。这个类允许我们指定如何处理单句或双句输入。但是，如果在预处理过程中不使用<a class="ae lu" href="https://youtu.be/1gN1snKBLP0" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">N</strong>ext<strong class="la iu">S</strong>entence<strong class="la iu">P</strong>radio(NSP)</a>，我们就不一定需要使用对语句格式。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="586c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在那些模板定义中有一些东西需要解开。首先，我们有两个特殊的令牌；<code class="fe nr ns nt nu b">[CLS]</code>和<code class="fe nr ns nt nu b">[SEP]</code>，它们分别是‘序列开始’<strong class="la iu">cl</strong>a<strong class="la iu">s</strong>si fier 和<strong class="la iu"> sep </strong> arator 令牌。</p><p id="7dff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将传递给分词器的第一句定义为<code class="fe nr ns nt nu b">$A</code>，将第二句(如果给定的话)定义为<code class="fe nr ns nt nu b">$B</code>。使用这种格式，句子<code class="fe nr ns nt nu b">"hello world"</code>将被后处理为<code class="fe nr ns nt nu b">[CLS] hello world [SEP]</code>。或者对于两个句子<code class="fe nr ns nt nu b">"hello world"</code>和<code class="fe nr ns nt nu b">"pet koala"</code>，我们会看到<code class="fe nr ns nt nu b">[CLS] hello world [SEP] pet koala [SEP]</code>。</p><p id="ac87" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有一件事是已经提到的每个组件后面的<code class="fe nr ns nt nu b">:0</code>和<code class="fe nr ns nt nu b">:1</code>。这些定义了各个组件的<code class="fe nr ns nt nu b">token_type_id</code>值(BERT 使用<code class="fe nr ns nt nu b">token_type_ids</code>来区分不同的句子)。</p><p id="b599" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是我们的令牌化组件，但是还有最后一个额外的组件要添加。</p><h2 id="8050" class="nx mu it bd mv ny nz dn mz oa ob dp nd lh oc od nf ll oe of nh lp og oh nj oi bi translated">解码器</h2><p id="0208" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">解码器步骤是将转换器可读的令牌 id 翻译回人类可读的文本。当我们使用单词片段标记化时，我们设置<code class="fe nr ns nt nu b">decoder</code>属性来使用<code class="fe nr ns nt nu b">WordPiece</code>解码器，并指定前面定义的子单词前缀。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><h2 id="9482" class="nx mu it bd mv ny nz dn mz oa ob dp nd lh oc od nf ll oe of nh lp og oh nj oi bi translated">节约</h2><p id="0c04" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">我们的标记器现在已经完全定义好了。剩下的就只有救了！这样我们就可以直接从🤗<strong class="la iu"> <em class="nv">变形金刚</em> </strong>(而不是用<strong class="la iu"><em class="nv"/></strong>)，我们必须将当前<code class="fe nr ns nt nu b">tokenizer</code>加载到一个变形金刚记号化器对象中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="c23b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们还再次指定了每个特殊标记。之后，我们保存记号赋予器，现在，我们可以像加载任何其他<strong class="la iu"> <em class="nv">变形金刚</em> </strong>记号赋予器一样加载它。</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="7e22" class="mt mu it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">使用</h1><p id="ed97" class="pw-post-body-paragraph ky kz it la b lb nl ju ld le nm jx lg lh nn lj lk ll no ln lo lp np lr ls lt im bi translated">现在可以通过<code class="fe nr ns nt nu b">from_pretrained</code>方法加载 Dhivehi 分词器了，就像加载其他分词器一样。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure><p id="cc55" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们可以继续对迪维希语文本进行标记。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ml l"/></div></figure></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="32af" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是为低资源语言构建标记器的介绍。非常感谢 Ashraq 向我介绍了他的迪维希项目，并让我也参与其中。他正在做一堆很酷的以迪维希语为中心的 NLP 项目，我很期待看到它的进展。</p><p id="e724" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">tokenizer 是为迪维希语言模型和工具建立更多支持的早期步骤。很自然，下一步是创建一个迪维希预训练的 BERT——我们将很快介绍它。</p><p id="9506" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想马上使用迪维希模特，你可以在<a class="ae lu" href="https://huggingface.co/jamescalam" rel="noopener ugc nofollow" target="_blank">我自己的</a>和<a class="ae lu" href="https://huggingface.co/ashraq" rel="noopener ugc nofollow" target="_blank">阿什拉克的</a>拥抱脸简介上找到她们。</p><p id="495d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同时，你可以通过<a class="ae lu" href="https://jamescalam.medium.com/subscribe" rel="noopener">这个链接</a>获得最新的文章。我还在 YouTube 上上传 ML 和 NLP 的每周视频。</p><p id="e551" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="115e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">🎁<a class="ae lu" href="https://www.pinecone.io/learn/nlp" rel="noopener ugc nofollow" target="_blank">面向语义搜索的 NLP 免费课程</a></p><p id="db2b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">🤖<a class="ae lu" href="https://bit.ly/nlp-transformers" rel="noopener ugc nofollow" target="_blank">变压器课程 NLP 的 70%折扣</a></p><p id="1ee8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://github.com/jamescalam/dhivehi_nlp/blob/main/examples/00_create_dv_base/01_tokenizer_components.ipynb" rel="noopener ugc nofollow" target="_blank">文章笔记本脚本</a></p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="d5b6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nv">*除另有说明外，所有图片均出自作者之手</em></p></div></div>    
</body>
</html>