<html>
<head>
<title>Improve ML Model Performance by Combining Categorical Features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过组合分类特征提高ML模型性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improve-ml-model-performance-by-combining-categorical-features-a23efbb6a215?source=collection_archive---------21-----------------------#2021-05-22">https://towardsdatascience.com/improve-ml-model-performance-by-combining-categorical-features-a23efbb6a215?source=collection_archive---------21-----------------------#2021-05-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="be16" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">提高模型性能的一个简单技巧。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/403e2610faf21764adc5cae224811fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C9IaJBN5dVn92nSVO_0vHA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由来自<a class="ae kv" href="https://www.pexels.com/photo/selective-focus-photoraphy-of-chains-during-golden-hour-119562/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">佩克斯</a>的<a class="ae kv" href="https://www.pexels.com/@joey-kyber-31917?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">乔伊·凯伯</a>拍摄</p></figure><p id="3a82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当您训练机器学习模型时，您的数据集中可以有一些表示分类值的要素。分类特征是可以分组的数据类型。</p><p id="8329" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有三种常见的分类数据类型，它们是:</p><ol class=""><li id="582f" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">序数</strong> —这有一组顺序。例如:用1-10的尺度给幸福打分</li><li id="37f5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">二进制</strong> —只有两个值。例如:男性或女性</li><li id="558c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">名义</strong> —它没有任何订单集。示例:国家</li></ol><p id="6ba8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大多数机器学习算法需要数字输入和输出变量。因此，您必须将数据集中的分类特征转换为整数或浮点数，以供机器学习算法使用。您可以对二进制特征使用<a class="ae kv" href="https://www.freecodecamp.org/news/feature-engineering-and-feature-selection-for-beginners/" rel="noopener ugc nofollow" target="_blank">标签编码</a>，或者对名义特征使用<a class="ae kv" href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f" rel="noopener ugc nofollow" target="_blank">一次热编码</a>方法。</p><p id="fad3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，您将了解组合分类特征如何提高机器学习模型的性能。</p><p id="26a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以让我们开始吧。🚀</p><h1 id="4c46" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">在机器学习模型中组合分类特征</h1><p id="afe5" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">您可以创建一个由其他两个分类要素组合而成的新要素。您还可以组合三个或四个以上甚至更多的分类特征。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="5a5d" class="ni mh iq ne b gy nj nk l nl nm">df["new_feature"] = (<br/>	df.feature_1.astype(str)<br/>	 + "_"<br/>	 + df.feature_2.astype(str)<br/>	)</span></pre><p id="3dee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的代码中，您可以看到如何使用pandas合并两个分类要素，并在数据集中形成一个新要素。</p><p id="9154" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么你应该结合哪些分类特征呢？这个问题没有简单的答案。这取决于您的数据和要素类型。一些领域知识可能对创建这样的新特性有用。</p><p id="d129" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了说明整个过程，我们将使用来自<a class="ae kv" href="https://zindi.africa/competitions/financial-inclusion-in-africa" rel="noopener ugc nofollow" target="_blank"> Zindi competition页面</a>的<a class="ae kv" href="https://zindi.africa/competitions/financial-inclusion-in-africa/data" rel="noopener ugc nofollow" target="_blank">非洲金融包容性数据集</a>，它具有许多分类特征，我们可以将其中一些特征结合起来，看看我们是否可以改进模型性能。</p><p id="b572" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据集的目标是预测谁最有可能拥有银行帐户。所以这是一个分类问题。</p><h1 id="802d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">1.加载数据集</h1><p id="4c3e" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我们的第一步是确保我们已经下载了比赛中提供的数据集。你可以在这里下载数据集<a class="ae kv" href="https://zindi.africa/competitions/financial-inclusion-in-africa/data" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="ae4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">导入重要的python包。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="2e2e" class="ni mh iq ne b gy nj nk l nl nm">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import warnings<br/>np.random.seed(123)<br/>warnings.filterwarnings('ignore')<br/>%matplotlib inline</span></pre><p id="5e75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">加载数据集。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="7bed" class="ni mh iq ne b gy nj nk l nl nm"># Import data</span><span id="c2a5" class="ni mh iq ne b gy nn nk l nl nm">data = pd.read_csv('data/Train_v2.csv')</span></pre><p id="7e0a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们观察数据集的形状。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="2858" class="ni mh iq ne b gy nj nk l nl nm"># print shape</span><span id="da79" class="ni mh iq ne b gy nn nk l nl nm">print('data shape :', data.shape)</span><span id="6305" class="ni mh iq ne b gy nn nk l nl nm">data shape : (23524, 13)</span></pre><p id="d30c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的输出显示了数据集中的行数和列数。数据集中有13个变量，12个自变量和1个因变量。</p><p id="d01e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以通过使用pandas库中的<strong class="ky ir"> head() </strong>方法来观察数据集中的前五行。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="bcd3" class="ni mh iq ne b gy nj nk l nl nm"># inspect data </span><span id="6f62" class="ni mh iq ne b gy nn nk l nl nm">data.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/03d2a2e4d52d12ffe4c777f455219965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l8kVSJtSWx4mSIit6MyFKQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">样本daa</p></figure><p id="91f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">理解每个要素的含义非常重要，这样您才能真正理解数据集。您可以阅读<strong class="ky ir"> VariableDefinition.csv </strong>文件来理解数据集中出现的每个变量的含义。</p><h1 id="1170" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">2.了解数据集</h1><p id="f8b5" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">通过使用pandas的<strong class="ky ir"> info() </strong>方法，我们可以获得更多关于这些特性的信息。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="b9af" class="ni mh iq ne b gy nj nk l nl nm">#show Some information about the dataset</span><span id="8b7f" class="ni mh iq ne b gy nn nk l nl nm">print(train_data.info())</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/70d3e0bda6eb738ea6943b11d515406d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*03urULYWIzcR_gVV_QXteg.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据描述</p></figure><p id="bc71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出显示变量/特征列表、大小(如果包含缺失值)以及每个变量的数据类型。从数据集中，我们没有任何缺失值，我们有3个整数数据类型的特征和10个对象数据类型的特征(大多数是分类特征)。</p><h1 id="acbc" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">3.机器学习模型的数据准备</h1><p id="b06d" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">下一步是从数据中分离出自变量和目标(bank_account)。然后使用<a class="ae kv" rel="noopener" target="_blank" href="/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd"> LabelEncoder </a>将目标值从对象数据类型转换成数值。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="ba0e" class="ni mh iq ne b gy nj nk l nl nm">#import preprocessing module<br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.preprocessing import MinMaxScaler</span><span id="22c6" class="ni mh iq ne b gy nn nk l nl nm"># Convert target label to numerical Data<br/>le = LabelEncoder()<br/>data['bank_account'] = le.fit_transform(data['bank_account'])</span><span id="c820" class="ni mh iq ne b gy nn nk l nl nm">#Separate training features from target<br/>X = data.drop(['bank_account'], axis=1)<br/>y = data['bank_account']</span><span id="a884" class="ni mh iq ne b gy nn nk l nl nm">print(y)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/824a43918a5be8b16d5caa693fad864f.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*QucjXyANcPePjMSkLN5Wpg.jpeg"/></div></figure><p id="763f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目标值已转换为数字数据类型，1表示“是”，0表示“否”。</p><p id="a30f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我创建了一个简单的预处理函数来:</p><ul class=""><li id="7f0a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nr ly lz ma bi translated">处理数据类型的转换。</li><li id="d36d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nr ly lz ma bi translated">使用<a class="ae kv" rel="noopener" target="_blank" href="/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd">一键编码器和/或标签编码器</a>将分类特征转换为数字特征。</li><li id="ab9c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nr ly lz ma bi translated">删除uniqueid变量。</li><li id="99b0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nr ly lz ma bi translated">执行<a class="ae kv" rel="noopener" target="_blank" href="/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9">特征缩放</a>。</li></ul><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="9fe6" class="ni mh iq ne b gy nj nk l nl nm"># function to preprocess our data </span><span id="ed8a" class="ni mh iq ne b gy nn nk l nl nm">def preprocessing_data(data):</span><span id="bb37" class="ni mh iq ne b gy nn nk l nl nm">    # Convert the following numerical labels from interger to float<br/>    float_array = data[["household_size", "age_of_respondent", "year"]].values.astype(float<br/>    )<br/>    <br/>    # categorical features to be converted to One Hot Encoding<br/>    categ = [<br/>        "relationship_with_head",<br/>        "marital_status",<br/>        "education_level",<br/>        "job_type",<br/>        "country",<br/>    ]<br/>    <br/>    # One Hot Encoding conversion<br/>    data = pd.get_dummies(data, prefix_sep="_", columns=categ)<br/>    <br/>    # Label Encoder conversion<br/>    data["location_type"] = le.fit_transform(data["location_type"])<br/>    data["cellphone_access"] = le.fit_transform(data["cellphone_access"])<br/>    data["gender_of_respondent"] = le.fit_transform(data["gender_of_respondent"])<br/>    <br/>    # drop uniquid column<br/>    data = data.drop(["uniquid"]), axis=1)<br/>    <br/>    # scale our data <br/>    scaler = StandardScaler()<br/>    data = scaler.fit_transform(data)<br/>    <br/>    return data</span></pre><p id="9b50" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们预处理我们的数据集。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="1a25" class="ni mh iq ne b gy nj nk l nl nm"># preprocess the train data </span><span id="f696" class="ni mh iq ne b gy nn nk l nl nm">processed_test_data = preprocessing_data(X_train)</span></pre><h1 id="36a3" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">4.模型建立和实验</h1><p id="496d" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">数据集的一部分将用于评估我们的模型。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="865e" class="ni mh iq ne b gy nj nk l nl nm"># Split train_data<br/>from sklearn.model_selection import train_test_spilt<br/>X_Train, X_val, y_Train, y_val = train_test_split(processed_train_data, y_train, stratify = y, test_size = 0.1, random_state=42)</span></pre><p id="9b0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">只有数据集的<strong class="ky ir"> 10% </strong>将用于评估机器学习模型。参数<strong class="ky ir">分层= y </strong>将确保训练集和验证集的两个类的值相等(“是”和“否”)。</p><p id="a9f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个分类问题，我们将使用<strong class="ky ir">逻辑回归算法</strong>来训练和预测谁最有可能拥有银行账户。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="b55f" class="ni mh iq ne b gy nj nk l nl nm">#import classifier algorithm here<br/>from sklearn.linear_model import LogisticRegression</span><span id="07d1" class="ni mh iq ne b gy nn nk l nl nm"># create classifier<br/>lg_model = LogisticRegression()</span><span id="9e1f" class="ni mh iq ne b gy nn nk l nl nm">#Training the classifier<br/>lg_model.fit(X_Train,y_Train)</span></pre><p id="caa2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练完分类器之后，让我们使用训练好的模型来预测我们的评估集，看看它的表现如何。我们将使用准确性作为我们的评估标准。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="98d9" class="ni mh iq ne b gy nj nk l nl nm"># import evaluation metrics<br/>from sklearn.metrics import confusion_matrix, accuracy_score</span><span id="9d64" class="ni mh iq ne b gy nn nk l nl nm"># evaluate the model<br/>y_pred = lg_model.predict(X_val)</span><span id="1edc" class="ni mh iq ne b gy nn nk l nl nm"># Get the accuracy<br/>print("Accuracy Score of Logistic Regression classifier: ","{:.4f}".format(accuracy_score(y_val, lg_y_pred)))</span></pre><p id="d8a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Logistic回归分类器的准确率得分:<strong class="ky ir"> 0.8874 </strong></p><h1 id="225c" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">第一个实验:结合教育水平和工作类型特征。</h1><p id="43a4" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">现在我们知道了基本的模型性能，让我们看看是否可以通过结合<strong class="ky ir"> education_level </strong>和<strong class="ky ir"> job_type </strong>特性来改进它。</p><p id="5f4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在第一个实验中需要做的是更新我们已经创建的预处理函数，然后运行剩余的代码。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="c104" class="ni mh iq ne b gy nj nk l nl nm"># function to preprocess our data <br/> <br/>def preprocessing_data(data):</span><span id="0c80" class="ni mh iq ne b gy nn nk l nl nm">    # Convert the following numerical labels from integer to float<br/>    float_array = data[["household_size", "age_of_respondent", "year"]].values.astype(float)</span><span id="f725" class="ni mh iq ne b gy nn nk l nl nm">    # combine some cat features <br/>    data["features_combination"] = (data.education_level.astype(str) + "_" + data.job_type.astype(str) )</span><span id="0a85" class="ni mh iq ne b gy nn nk l nl nm">    # remove individual features that are combined together<br/>    data = data.drop(['education_level','job_type'], axis=1)</span><span id="91a4" class="ni mh iq ne b gy nn nk l nl nm">    # categorical features to be converted by One Hot Encoding<br/>    categ = [<br/>      "relationship_with_head",<br/>      "marital_status",<br/>      "features_combination",<br/>      "country"<br/>      ]</span><span id="e42a" class="ni mh iq ne b gy nn nk l nl nm">    # One Hot Encoding conversion<br/>    data = pd.get_dummies(data, prefix_sep="_", columns=categ)</span><span id="9fc2" class="ni mh iq ne b gy nn nk l nl nm">    # Label Encoder conversion<br/>    data["location_type"] = le.fit_transform(data["location_type"])<br/>    data["cellphone_access"] = le.fit_transform(data["cellphone_access"])<br/>    data["gender_of_respondent"] = le.fit_transform(data["gender_of_respondent"])</span><span id="0380" class="ni mh iq ne b gy nn nk l nl nm">    # drop uniquid column<br/>    data = data.drop(["uniqueid"], axis=1)</span><span id="a277" class="ni mh iq ne b gy nn nk l nl nm">    # scale our data <br/>    scaler = StandardScaler()<br/>    data = scaler.fit_transform(data)</span><span id="a484" class="ni mh iq ne b gy nn nk l nl nm">    return data</span></pre><p id="5bee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上述预处理函数中，我通过以下方式更新了代码</p><ul class=""><li id="fed5" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nr ly lz ma bi translated">将educaion _ level和job_type组合起来，创建一个名为"<strong class="ky ir"> features_combination </strong>"的新特性。</li><li id="1b63" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nr ly lz ma bi translated">从数据集中移除单个要素(education_level和job_type)。</li><li id="a759" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nr ly lz ma bi translated">在分类特征列表中添加一个名为“<strong class="ky ir">feature _ combination</strong>的新特征，通过<strong class="ky ir"> One Hot Encoding </strong>进行转换。</li></ul><p id="7a19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注意:</strong>我只选择了名义分类特征(有2个以上的唯一值)。</p><p id="b791" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在为第一个实验重新训练逻辑回归分类器后，模型性能从<strong class="ky ir"> 0.8874 </strong>提高到<strong class="ky ir"> 0.8882 </strong>。这表明组合分类特征可以提高模型性能。请记住，我们没有改变任何东西，如机器学习分类器中的超参数。</p><h1 id="839d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">第二个实验:结合与头部的关系和婚姻状况特征</h1><p id="a71d" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在我们的第二个实验中，我们将结合另外两个分类特征，它们是<strong class="ky ir">与头部的关系</strong>和<strong class="ky ir">婚姻状况</strong>。</p><p id="1182" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们只需要更新预处理函数(就像第一个实验一样)，然后运行剩下的代码。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="1d59" class="ni mh iq ne b gy nj nk l nl nm"># function to preprocess our data </span><span id="6d0a" class="ni mh iq ne b gy nn nk l nl nm">def preprocessing_data(data):</span><span id="97cb" class="ni mh iq ne b gy nn nk l nl nm">    # Convert the following numerical labels from integer to float<br/>    float_array = data[["household_size", "age_of_respondent", "year"]].values.astype(<br/>        float<br/>    )<br/>    <br/>    # combine some cat features <br/>    data["features_combination"] = (data.relationship_with_head.astype(str) + "_"<br/>                           + data.marital_status.astype(str) <br/>                      )<br/>    # remove individual features that are combined together<br/>    data = data.drop(['relationship_with_head','marital_status'], axis=1)<br/></span><span id="9f44" class="ni mh iq ne b gy nn nk l nl nm">    # categorical features to be converted by One Hot Encoding<br/>    categ = [<br/>        "features_combination",<br/>        "education_level",<br/>        "job_type",<br/>        "country",<br/>    ]</span><span id="5f90" class="ni mh iq ne b gy nn nk l nl nm">    # One Hot Encoding conversion<br/>    data = pd.get_dummies(data, prefix_sep="_", columns=categ)</span><span id="5a11" class="ni mh iq ne b gy nn nk l nl nm">    # Label Encoder conversion<br/>    data["location_type"] = le.fit_transform(data["location_type"])<br/>    data["cellphone_access"] = le.fit_transform(data["cellphone_access"])<br/>    data["gender_of_respondent"] = le.fit_transform(data["gender_of_respondent"])</span><span id="73bb" class="ni mh iq ne b gy nn nk l nl nm">    # drop uniquid column<br/>    data = data.drop(["uniqueid"], axis=1)</span><span id="a48a" class="ni mh iq ne b gy nn nk l nl nm">    # scale our data <br/>    scaler = StandardScaler()<br/>    data = scaler.fit_transform(data)</span><span id="1b3c" class="ni mh iq ne b gy nn nk l nl nm">    return data</span></pre><p id="a932" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上述预处理函数中，我通过以下方式更新了代码</p><ul class=""><li id="7e78" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nr ly lz ma bi translated">结合relation_with_head和marriage _ status创建一个名为“<strong class="ky ir"> features_combination </strong>”的新特征。</li><li id="7a53" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nr ly lz ma bi translated">从数据集中移除单个要素(relation_with_head和marriage _ status)。</li><li id="b34b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nr ly lz ma bi translated">在分类特征列表中添加一个名为“<strong class="ky ir"> feature_combination </strong>的新特征，通过<strong class="ky ir"> One Hot Encoding </strong>进行转换。</li></ul><p id="efaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在为第二个实验重新训练逻辑回归分类器之后，模型性能从<strong class="ky ir"> 0.8874 </strong>下降到<strong class="ky ir"> 0.8865 </strong>。这表明，有时当你结合分类特征时，你的机器学习模型不会像你预期的那样改善。因此，你将需要运行大量的实验，直到你从你的机器学习模型中获得令人满意的性能。</p><h1 id="9cb4" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">包扎</h1><p id="1ebe" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在本文中，您了解了如何组合数据集中的分类特征，以提高机器学习模型的性能。正如我所说的，为了让您的模型获得令人满意的性能，您需要拥有关于您正在解决的问题的领域知识。此外，您需要运行大量需要更多计算资源的实验。</p><p id="e7c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">恭喜</strong>👏👏，你已经做到这篇文章的结尾了！我希望你学到了一些新的东西，对你的下一个机器学习或数据科学项目有所帮助。</p><p id="a90b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你学到了新的东西或者喜欢阅读这篇文章，请分享给其他人看。在那之前，下期帖子再见！</p><p id="fb4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">也可以在Twitter <a class="ae kv" href="https://twitter.com/Davis_McDavid" rel="noopener ugc nofollow" target="_blank"> @Davis_McDavid </a>上找我。</p><p id="366c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">之前发布的<a class="ae kv" href="https://hackernoon.com/improve-machine-learning-model-performance-by-combining-categorical-features-g21u34ep" rel="noopener ugc nofollow" target="_blank">此处</a>。</p></div></div>    
</body>
</html>