<html>
<head>
<title>Benchmark: accelerating batch linear algebra operations with jax</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基准测试:用jax加速批量线性代数运算</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/benchmark-accelerating-batch-linear-algebra-operations-with-jax-6962cdea5011?source=collection_archive---------42-----------------------#2021-05-24">https://towardsdatascience.com/benchmark-accelerating-batch-linear-algebra-operations-with-jax-6962cdea5011?source=collection_archive---------42-----------------------#2021-05-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="bf51" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="3570" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">代码更改最少，速度明显加快</h2></div><p id="cd0a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">像<code class="fe lk ll lm ln b">numpy</code>这样的包是当今数据科学工作的面包和黄油。然而，我们可能会遇到<code class="fe lk ll lm ln b">numpy</code>无法轻松处理或只能以次优方式处理的情况。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/3f5c178be904ab4cb337b39178dd4da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vi6Xi4gQKYsjKRuS"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">当你穿越到未知的领域…照片由<a class="ae me" href="https://unsplash.com/@worthyofelegance?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Alex </a>在<a class="ae me" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="5567" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我最近遇到过这样的情况:当实现一个概率矩阵分解(PMF)推荐系统时，我必须将许多对矩阵<code class="fe lk ll lm ln b">U</code>和<code class="fe lk ll lm ln b">V.T</code>相乘，当我调用<code class="fe lk ll lm ln b">numpy.tensordot</code>来实现我的目标时，我的Jupyter内核崩溃了。</p><p id="4fdc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">不满足于不得不在<em class="mf">多核</em>机器上一个接一个地乘以矩阵，我转向了<code class="fe lk ll lm ln b">jax</code>，粗略地说就是类固醇上的<code class="fe lk ll lm ln b">numpy</code>。DeepMind (cue AlphaGo music)和谷歌的研究人员在日常工作中使用这个<code class="fe lk ll lm ln b"><a class="ae me" href="https://jax.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">jax</a></code>库— —主要是在深度学习方面— —一个丰富的<a class="ae me" href="https://deepmind.com/blog/article/using-jax-to-accelerate-our-research" rel="noopener ugc nofollow" target="_blank">生态系统</a>已经围绕它涌现出来。</p><div class="mg mh gp gr mi mj"><a href="https://deepmind.com/blog/article/using-jax-to-accelerate-our-research" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd ja gy z fp mo fr fs mp fu fw iz bi translated">利用JAX加速我们的研究</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">我们发现越来越多的项目得到了JAX的良好服务，这是一个由…开发的机器学习框架</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">deepmind.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx ly mj"/></div></div></a></div><p id="ecb4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<code class="fe lk ll lm ln b">jax</code>的优点中，我在这里关心的一个是它可以很容易地向量化(<a class="ae me" href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#pure-functions" rel="noopener ugc nofollow" target="_blank">纯</a>)函数，通过底层的并行化实现加速。如此加速的代码可以在CPU、GPU和/或TPU上执行，无需修改！</p></div><div class="ab cl my mz hu na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="ij ik il im in"><h1 id="fd7a" class="nf ng iq bd nh ni nj nk nl nm nn no np kf nq kg nr ki ns kj nt kl nu km nv nw bi translated">问题陈述</h1><p id="3cf1" class="pw-post-body-paragraph ko kp iq kq b kr nx ka kt ku ny kd kw kx nz kz la lb oa ld le lf ob lh li lj ij bi translated">具体来说，这里是<code class="fe lk ll lm ln b">U</code>和<code class="fe lk ll lm ln b">Vt</code>的形状。它们是成批的<em class="mf">矩阵</em>，而不是成批的行，由于表格数据的流行，成批的行更常见。所以<code class="fe lk ll lm ln b">U</code>和<code class="fe lk ll lm ln b">Vt</code>分别包含100个矩阵，</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oc"><img src="../Images/103c3692c60e6600e8cc2798f5a93f5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3K4gB3iVVO8fhu_XHldp4A.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">U和Vt的形状，我会把它们相乘。对于那些好奇的人来说，U和V是<a class="ae me" href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="noopener ugc nofollow" target="_blank"> MCMC </a>的后验样本。文章作者截图。</p></figure><p id="22ea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我想将每一对对应的矩阵相乘得到<code class="fe lk ll lm ln b">R</code>，其形状为(100，610，9724)。换句话说，用<code class="fe lk ll lm ln b">Vt[0]</code>乘以<code class="fe lk ll lm ln b">U[0]</code>，用<code class="fe lk ll lm ln b">Vt[1]</code>乘以<code class="fe lk ll lm ln b">U[1]</code>…,用<code class="fe lk ll lm ln b">Vt[100]</code>乘以<code class="fe lk ll lm ln b">U[100]</code>。</p><p id="dca2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，我想对0轴(所有100个矩阵在<code class="fe lk ll lm ln b">R</code>中)进行平均，最终得到一个610乘9724的矩阵。</p></div><div class="ab cl my mz hu na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="ij ik il im in"><h1 id="0b74" class="nf ng iq bd nh ni nj nk nl nm nn no np kf nq kg nr ki ns kj nt kl nu km nv nw bi translated">基准</h1><p id="4215" class="pw-post-body-paragraph ko kp iq kq b kr nx ka kt ku ny kd kw kx nz kz la lb oa ld le lf ob lh li lj ij bi translated">作为<strong class="kq ja">基线</strong>，让Python一个接一个地乘以矩阵，然后在轴0上平均结果。我的2015 Macbook Pro用了大约10秒，它有16 GBs的内存和英特尔i7 CPUs。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi od"><img src="../Images/563ce8ca15f616013e9588cb0fa596c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*38kFEVIHG7gnwfLHo_z6Lg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">顺序执行的基准。文章作者截图。</p></figure><p id="d341" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">相比之下，如下图截图所示，执行同样的操作仅用了<code class="fe lk ll lm ln b">jax</code> 2.2秒！注意，我必须在<code class="fe lk ll lm ln b">jnp.mean()</code>后添加<code class="fe lk ll lm ln b">.block_until_ready()</code>才能获得有意义的基准，因为<code class="fe lk ll lm ln b">jax</code>遵循惰性/异步评估。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oe"><img src="../Images/843235decfa21386f5b64eb8d9e5be55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AJibDpCko6GiMsSWq-xcMQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">使用jax的基准。文章作者截图。</p></figure><p id="e7a0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后但同样重要的是，当我将批中的矩阵数量从100增加到150时，上面的运行时会有不同的伸缩。朴素的顺序评价用了50秒，而<code class="fe lk ll lm ln b">jax</code>只用了3秒。<strong class="kq ja">换句话说，当问题需要更多内存时，使用</strong> <code class="fe lk ll lm ln b"><strong class="kq ja">jax</strong></code> <strong class="kq ja"> <em class="mf">的好处真的</em>显现出来了。</strong></p><h1 id="aaa2" class="nf ng iq bd nh ni of nk nl nm og no np kf oh kg nr ki oi kj nt kl oj km nv nw bi translated">外卖食品</h1><p id="496e" class="pw-post-body-paragraph ko kp iq kq b kr nx ka kt ku ny kd kw kx nz kz la lb oa ld le lf ob lh li lj ij bi translated">也许有一种简单的方法来完成我想在<code class="fe lk ll lm ln b">numpy</code>中做的事情，但是使用<code class="fe lk ll lm ln b">jax</code>也同样简单— —并且在设备类型和内存使用方面具有巨大的可伸缩性。</p><p id="ebea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">虽然<code class="fe lk ll lm ln b">jax</code>自带数组数据类型，但<a class="ae me" href="https://github.com/google/jax/issues/712" rel="noopener ugc nofollow" target="_blank">是</a> <code class="fe lk ll lm ln b"><a class="ae me" href="https://github.com/google/jax/issues/712" rel="noopener ugc nofollow" target="_blank">numpy.ndarray</a></code>的子类，因此<code class="fe lk ll lm ln b">jax</code>可以与现有的<code class="fe lk ll lm ln b">numpy</code>工作流集成。</p><p id="b57e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">TL；博士--可以的话就用<code class="fe lk ll lm ln b">jax</code>！</p></div></div>    
</body>
</html>