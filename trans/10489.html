<html>
<head>
<title>Hybrid Quantum Neural Network for reduced MNIST Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化MNIST数据的混合量子神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hybrid-quantum-neural-network-for-reduced-mnist-data-840897ad08a?source=collection_archive---------12-----------------------#2021-10-06">https://towardsdatascience.com/hybrid-quantum-neural-network-for-reduced-mnist-data-840897ad08a?source=collection_archive---------12-----------------------#2021-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="def1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用少于200行的Pennylane和量子变分电路求解时尚MNIST</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/95117a87e799b7f8b06d3c64970003f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJsrIV4Ra1bzzIOHcbjDjw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">量子时尚MNIST的标志图片。编辑自<a class="ae kv" href="https://unsplash.com/@matthewhenry?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马太·亨利</a>在<a class="ae kv" href="https://unsplash.com/s/photos/cute?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="72e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> Q </span> <em class="mb"> uantum机器学习</em> (QML)已经被证明在低输入维度的机器学习问题上是有效的。杰尔比[1]和欧文[2]已经解决了南极环境问题。量子卷积已被用来解决一个简化版本的Mnist数字数据集[3]。</p><p id="61d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一种基于降维算法的解决方案已经提出[4]，但在这篇文章中，我们将只关注基于变分量子电路(VQC)的实现。我们将开发一个量子神经网络，使用Pennylane以稍微减少的输入对MNIST时装数据集进行分类。</p><h1 id="7bfb" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">介绍</h1><p id="9834" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">我们将尝试使用QML解决的问题是使用VQC对MNIST数据集进行分类。由于解决整个问题需要时间，我们将使用一个降维的数据集。我们将尝试在我们的VQC中适应的维度将是64，而不是最初的784。</p><p id="4999" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用运行在Colab机器上的Python代码。在这个Colab上，我们需要安装Pennylane作为量子机器学习库，我们将使用已经安装的Tensorflow作为接口。</p><h1 id="bca6" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">数据准备</h1><p id="c837" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">第一步或目标将是准备图书馆和加载我们心爱的MNIST数据。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="afcb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成设置后，我们将定义用于模型的参数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="2aac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据的过滤是通过选择我们感兴趣的列表中的类别的索引来完成的。这段代码确实是临时的，我相信有更好的实现。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="c84e" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">使用自动编码器预处理</h1><p id="8225" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">选择用于降低数据维度的模型是一个非常简单的自动编码器模型，基于Tensorflow自己的教程。[5]</p><p id="2048" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用相对于量子位数量的潜在维度大小。层数和每层中神经元的数量由用户决定。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="c7ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对数据进行编码就像将数据传递给编码器一样简单。然后，我们需要将输出替换为分类值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="430d" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">量子神经网络(QNN)</h1><p id="5409" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">我们现在将准备量子网络来分类我们的时尚数据。首先，我们将简单介绍一下VQC。</p><p id="ed31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">变分量子电路</strong>是一个量子电路，它依赖于许多自由参数，我们可以手动调整这些参数，或者用学习算法来逼近某个函数。它可以被视为一个具有可学习参数的数学近似模型。它们的工作方式类似于神经网络及其权重。</p><h2 id="f8dd" class="nb md iq bd me nc nd dn mi ne nf dp mm lf ng nh mo lj ni nj mq ln nk nl ms nm bi translated">该电路</h2><p id="5780" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">为了使用量子计算机或模拟器，我们需要导入我们的库和将要使用的层。</p><p id="b1e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用的两个主要层是:</p><ul class=""><li id="f1ce" class="nn no iq ky b kz la lc ld lf np lj nq ln nr lr ns nt nu nv bi translated"><strong class="ky ir">mottonestatepreparation:</strong>处理振幅状态准备。振幅状态准备包括将一个量子状态固定到一个给定的向量上，该向量的维数等于量子位数量的2次方。</li><li id="c487" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated"><strong class="ky ir">strong纠缠层:</strong>量子神经网络门，它旋转每个量子比特，然后以循环的方式将它们与CNOT纠缠在一起。这一层类似于神经元之间的致密层，但它们以量子方式表现。</li></ul></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><p id="4470" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="mb">注意</em> </strong> <em class="mb">:我们在这个电路中不使用AmplitudeEmbedding的原因是由于Pennylane中的一个已知问题，尽管在运行实际的量子计算机时，这个算法会适用。</em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="9a6d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型将使用强纠缠层来近似最小化某个损失函数的函数。此外，我们将使用一种称为“数据重新上传”的技术，它包括对网络中的输入数据进行多次采样。众所周知，这种技术可以改善电路效果。[6]</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="b04f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用的QNN模型由上面定义的量子电路组成，后面是一个致密层来准备输出。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="cd8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦模型编译完成，我们就可以用之前选择的数据训练模型了。由于训练可能需要3个小时，但在第一个纪元后没有太大改善，我们将把训练限制在第一个纪元。进一步的时代可能会改善系统，但这是留给读者的一个练习。；)</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="058d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用这个参数，我们得到了95%的分类准确率。</p><p id="c7c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们实际上试图使用相同的6个量子位和10个类，训练过程将花费更长的时间，并且准确率将下降到适度的70%。虽然这不像带有4个标签的previus 95%那样令人印象深刻，但它表明这些模型确实有能力解决实际问题，而无需太多的经典处理。</p><p id="2102" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看10个标签的例子，QNN！<br/> <em class="mb">警告，这在所有人看来都没什么了不起。</em></p><h2 id="8a33" class="nb md iq bd me nc nd dn mi ne nf dp mm lf ng nh mo lj ni nj mq ln nk nl ms nm bi translated">示例1:一对troursers</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/fa77fc585ab2eec10d40500aacf1b037.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*i1Q7_eVkd-xhhib7u_HmWQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MNIST数据集的裤子图像</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/84f5510ed236436f5a60e9d12cd11131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8raZ_EMTn77VADUbiAVcEg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">前一图片类别(左)和图片预测(右)</p></figure><p id="a749" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">QNN可以清楚地检测出图片是一条裤子。</p><h2 id="ad61" class="nb md iq bd me nc nd dn mi ne nf dp mm lf ng nh mo lj ni nj mq ln nk nl ms nm bi translated">示例2:失败的示例</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/0fbbdb9182b79199f66f5be28b448b09.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*rPvnU1LiVV1oHcyaRnBBOQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MNIST数据集的衬衫图像</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/5397dbc87bc6f1f7965e3622a681826e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IE_cpPz58aKAe87AdxR4qQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">前一图片类别(左)和图片预测(右)</p></figure><p id="32d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个例子对我们的网络来说似乎很难，因为它打印了5个可能的类别。当查看预测的类别时，有趣的事情出现了:检测到的标签都是衬衫类型的标签，而所有鞋子和裤子都被丢弃了！</p><h2 id="2eb9" class="nb md iq bd me nc nd dn mi ne nf dp mm lf ng nh mo lj ni nj mq ln nk nl ms nm bi translated">例子3:鞋子很奇怪</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/57efb740d85ec75c4ffb7bb824079909.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*ozISGTyuKr65GNXqmPWLBw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MNIST数据集的鞋子图像</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/843ed38b13372c0463de3413773d57ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lBpABSQoI5S_KzoffBWkEg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">前一图片类别(左)和图片预测(右)</p></figure><p id="0556" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有些鞋确实比其他鞋有更好的结果，但总的来说，它们倾向于聚集在鞋的标签上。</p><h1 id="4290" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">结论</h1><p id="b758" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">正如我们刚刚看到的，量子神经网络比我们想象的更接近现实生活，一些实际案例已经在入门环境和数据集上实现。</p><p id="18b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本帖中，我们已经证明了可以使用QNN对时尚MNIST数据进行分类，并在稍微降低维度的数据上取得良好的结果。我们在64维数据上用4个标签实现了95%的准确率，用10个标签实现了70%的准确率。作为第一步，我们可以开始想象在不久的将来，只有10个量子位的系统将能够在不减少数据的情况下对整个数据集进行分类！</p><h1 id="8912" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">参考</h1><p id="cbc7" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">[1] S. Jerbi，<a class="ae kv" href="https://arxiv.org/abs/2103.05577" rel="noopener ugc nofollow" target="_blank">用于强化学习的变分量子策略</a> (2021)，ArXiV <br/> [2] O. Lockwood和M. Si，<a class="ae kv" href="https://arxiv.org/abs/2008.07524" rel="noopener ugc nofollow" target="_blank">利用量子变分电路的强化学习</a> (2020)，ArXiV <br/> [3] E. Farhi和H. Neven，<a class="ae kv" href="https://arxiv.org/pdf/1802.06002.pdf" rel="noopener ugc nofollow" target="_blank">在近期限处理器上利用量子神经网络进行分类<br/></a>(2018)，ArXiV <br/> [4] I. Kerenidis和A. Luongo，【T10 Tensorflow Core <br/> [6] A. Perez，a .塞尔韦拉，E. Gil，José L .，<a class="ae kv" href="https://arxiv.org/pdf/1907.02085.pdf" rel="noopener ugc nofollow" target="_blank">通用量子分类器的数据重新上传</a> (2020)，ArXiV</p></div></div>    
</body>
</html>