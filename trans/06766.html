<html>
<head>
<title>Data Augmentation with Copy-Paste</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用复制粘贴的数据扩充</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-augmentation-reducing-model-confusion-with-copy-paste-8f41884ca9d1?source=collection_archive---------22-----------------------#2021-06-18">https://towardsdatascience.com/data-augmentation-reducing-model-confusion-with-copy-paste-8f41884ca9d1?source=collection_archive---------22-----------------------#2021-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="8b99" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想与理论</a>，<a class="ae ep" href="https://towardsdatascience.com/tagged/notes-from-industry" rel="noopener" target="_blank">行业笔记</a></h2><div class=""/><div class=""><h2 id="da01" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">减少相似类之间的模型混淆</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/dae6290154dc5d801e759ee0797051c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YZbQ8Cd11yZslt9djNchCw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片经shutterstock.com许可使用，Adnan Ahmad Ali/shutterstock.com</p></figure><p id="9982" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">Doma数据科学的首要主题之一是可推广性。这对于在我们的产品中成功实施我们的机器学习模型非常重要，因为我们的数据来源广泛，并且支持新客户的快速加入(例如冷启动问题)。随着我们向改进模型性能迈进，误报可能是一个主要障碍。简而言之，当计算确定一个实例包含导致模型将其与该实例不包含的东西混淆的特征时，在机器学习模型预测中会出现误报。一个简单的例子是一只被误认为是狗的猫。两者都是四条腿的毛茸茸的动物，所以数学算法没有识别出它们的区别是可以原谅的。然而，鉴于Doma的每个订单都需要处理多达100页左右的文档，我们必须确保我们的错误率很低。</p><p id="fb91" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这篇博客文章中，我将重点关注如何使用数据增强来减少计算机视觉模型中产生假阳性的混乱。最近，我们独立发现，所谓的数据增强“复制-粘贴”技术对于提高在较小数据集上训练的计算机视觉模型的性能非常有效。复制-粘贴技术通过复制对应于要检测或识别的特定对象的图像片段并将其粘贴到其他图像上来生成额外的训练数据，从而扩充数据集(更多细节见下文)。几乎在我们发现的同时，一篇关于复制粘贴技术的文章最近发表在谷歌大脑的<a class="ae ma" href="https://arxiv.org/pdf/2012.07177.pdf" rel="noopener ugc nofollow" target="_blank"> arxiv </a>研究人员上。关于arxiv的论文主要侧重于经验意义上的总体模型性能。在这里，我将重点介绍使用这种技术来减少由于容易混淆的类而导致的误报率。</p><h1 id="5a38" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">构建数据集</h1><p id="68ec" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">作为这种技术的演示，我们从上下文中的公共对象(COCO) [2]开源数据集:<a class="ae ma" href="https://cocodataset.org" rel="noopener ugc nofollow" target="_blank">https://cocodataset.org</a>构建了一个小型数据集。这是一个非常大的行业标准数据集，用于对几个计算机视觉任务进行基准测试。对于当前的用例，重点将放在容易混淆的类的对象检测上。作为一个具体的例子，我将集中讨论自行车和摩托车。从视觉角度来看，这些物体显然是相似的:有两个轮子的车辆，它们经常出现在相似的环境中，并且经常有一两个人坐在上面。</p><p id="1652" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们创建了一个由200幅自行车图像组成的单一训练数据集，包括边界框注释。然而，我们将利用也包括在COCO数据集中的遮罩注释(指示图像中哪些像素包含感兴趣的对象的多边形)来执行复制-粘贴技术。为了理解复制-粘贴数据增强如何能够减少模型混乱，我们将创建两个附加的训练集，它们使用复制-粘贴技术用图像来增强，但是使用两种不同类型的背景图像。这将允许我们探索复制粘贴技术中的选择如何影响整体性能。</p><h2 id="8c96" class="my mc iq bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr iw bi translated">使用复制粘贴方法</h2><p id="4a8a" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">我们可以建立一个自行车的扩充数据集，但要利用COCO提供的掩码。首先，我们选择了200张带注释的自行车图像，使用COCO的工具对这些图像进行了过滤，以确保这些图像中不存在摩托车。接下来，使用COCO注释为每幅图像提供的掩码，我们可以定位属于每辆自行车的所有像素。利用这一点，我们可以为每个图像生成每辆自行车的剪切图像。在选择的200个图像数据集中，共有491个自行车实例。接下来，我们选择了500张包含摩托车但被过滤掉自行车的图片。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nj"><img src="../Images/26fa7537f2cfa6fdd942dfa02e69343e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WsjXCDWZi0AYp1Ng4UMPaw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图一。左图:可可自行车图片示例。中间:一辆自行车的面具。右图:使用蒙版提取(剪切)的自行车图像。需要注意的一点是，COCO set中的遮罩并没有最高级别的精确度。通常它们包括许多背景像素(注意自行车轮胎右侧的额外像素)。改编自<a class="ae ma" href="https://www.flickr.com/photos/comradecosmobot/7127088719/" rel="noopener ugc nofollow" target="_blank">原图</a>，版权2012 <a class="ae ma" href="https://www.flickr.com/photos/comradecosmobot/" rel="noopener ugc nofollow" target="_blank"> ComradeCosmobot </a>并在<a class="ae ma" href="https://creativecommons.org/licenses/by/2.0/" rel="noopener ugc nofollow" target="_blank">attribute 2.0 Generic(CC BY 2.0)许可</a>下提供</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/fea42a44e287fb3dbd8f974ce8dab667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cu1-ClDTtbMgE00Pkm4Lcw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图二。左图:COCO的摩托车图像，图像上随机粘贴了之前提取的自行车。右图:由我们的粘贴代码生成的掩码显示了粘贴自行车的位置。改编自<a class="ae ma" href="https://www.flickr.com/photos/pasa/9433256316/" rel="noopener ugc nofollow" target="_blank">原始照片</a>，版权2013 <a class="ae ma" href="https://www.flickr.com/photos/pasa/" rel="noopener ugc nofollow" target="_blank"> Paul Sableman </a>并根据<a class="ae ma" href="https://creativecommons.org/licenses/by/2.0/" rel="noopener ugc nofollow" target="_blank">attribute 2.0 Generic(CC BY 2.0)许可证</a>提供，以及改编自<a class="ae ma" href="https://www.flickr.com/photos/comradecosmobot/7127088719/" rel="noopener ugc nofollow" target="_blank">原始照片</a>，版权2012 <a class="ae ma" href="https://www.flickr.com/photos/comradecosmobot/" rel="noopener ugc nofollow" target="_blank"> ComradeCosmobot </a>并根据<a class="ae ma" href="https://creativecommons.org/licenses/by/2.0/" rel="noopener ugc nofollow" target="_blank">attribute 2.0 Generic(CC BY 2.0)许可证</a>提供</p></figure><p id="3153" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们的数据扩充过程从COCO中选择的200个图像数据集中提取了491个自行车实例，并将每个实例分别粘贴到最多五个不同的图像上，这些图像包含摩托车而不包含自行车。对于那些有兴趣了解如何用python处理图像的人，请看:<a class="ae ma" href="https://automatetheboringstuff.com/chapter17/" rel="noopener ugc nofollow" target="_blank">https://automatetheboringstuff.com/chapter17/</a>。图2显示了流程结果的几个例子。因为有些摩托车图像比复制的自行车图像小，所以这个过程偶尔会失败。一种解决方法是减小自行车的尺寸。然而，相反，我们选择简单地忽略这些相对罕见的情况。</p><p id="8fbf" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">每次迭代都会产生一个额外的图像和一个额外的自行车实例。在处理了500幅摩托车图像之后，复制粘贴的扩充数据集具有2557幅图像和2848个自行车实例。</p><h1 id="8cd1" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">实验细节</h1><h2 id="be3d" class="my mc iq bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr iw bi translated">区域卷积神经网络</h2><p id="91af" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated"><a class="ae ma" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank">区域卷积神经网络</a>最初于2014年推出[3]。从那时起，已经有了许多迭代，并且许多当前技术水平的对象检测和实例分割模型都是基于该架构的。这使得RCNNs成为展示如何使用复制粘贴数据扩充方法来减少对象检测的假阳性的良好选择。在这里的工作中使用更快的RCNN方法。</p><p id="2f9c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于RCNN的高级介绍，我建议从系列博客文章<a class="ae ma" rel="noopener" target="_blank" href="/understanding-object-detection-and-r-cnn-e39c16f37600">的第一篇开始，该系列博客文章</a>给出了从最初的RCNN到更快的RCNN的发展之旅。为了开发，我们构建了<a class="ae ma" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">探测器2框架。</a></p><h2 id="acf3" class="my mc iq bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr iw bi translated">培养</h2><p id="a416" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">我们训练了三种不同的更快的RCNNs。一个是在没有复制粘贴数据增强的情况下，对200张自行车图像进行训练。在训练中，我们只做了一个简单的随机水平翻转的增强技术。将有效的训练数据集大小增加到400个图像，这也将自行车实例的数量加倍，从491个增加到982个。从现在开始，我们将把它称为普通模型。</p><p id="811a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">第二个更快的RCNN模型是在同样的400幅图像上训练的，但我们也包括了通过将自行车复制粘贴到摩托车图像上而产生的增强图像。还允许随机翻转，这导致自行车实例的总数为5696。然而，人们必须记住，在香草模型的意义上，这些并不是唯一的。该模型将被称为复制粘贴摩托车模型。</p><p id="17c6" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最后，以与复制粘贴摩托车模型完全相同的方式训练第三个更快的RCNN模型，只有一点不同。不是用摩托车贴自行车的背景图片，而是没有自行车的狗的背景图片。</p><p id="f943" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了公平的比较，所有的模型都被训练了5000次迭代，批量大小为2。在下一节中，我们将展示这些模型的结果。有关这三种模式的总结，请参见下表1:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/63fd11e2575ab044032223d9bd3fe0df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wAljlAUmDdeiVnrT2EUuyg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">表1:为比较而训练的模型。作者图片</p></figure><h2 id="6816" class="my mc iq bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr iw bi translated">估价</h2><p id="7791" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">为了测试每个模型在多大程度上混淆了摩托车类别和自行车类别，对包含自行车和摩托车的200幅图像进行了评估。这个数据集中自行车实例的总数是965。正如所料，普通模型将大量的摩托车混淆为自行车，而复制粘贴模型很少预测到摩托车是自行车</p><p id="dbf3" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了直观检查的目的，我们显示了五对结果，其中香草模型将非常明显的摩托车混淆为自行车。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/8562aed5a744b104a7424875f1733d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*neSpJJ5auaqokBLdtMwD1w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">示例1 —左侧:复制粘贴模型的结果检测到一辆自行车。右图:vanilla模型的结果检测到两辆自行车，其中一辆是摩托车。改编自<a class="ae ma" href="https://www.flickr.com/photos/kenjonbro/3336231222/" rel="noopener ugc nofollow" target="_blank">原始照片</a>，版权2009 <a class="ae ma" href="https://www.flickr.com/photos/kenjonbro/" rel="noopener ugc nofollow" target="_blank">肯</a>并以<a class="ae ma" href="https://creativecommons.org/licenses/by-nc/2.0/" rel="noopener ugc nofollow" target="_blank">署名-非商业性2.0通用(CC BY-NC 2.0) </a>提供</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/fb6726f9089078e7ddbd230740279d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zPCcqxULrJA7XGoD-YJAwQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">示例2 —左侧:复制粘贴模型的结果检测到一辆自行车。右图:vanilla模型的结果检测到5辆自行车，其中4辆是摩托车。改编自<a class="ae ma" href="https://www.flickr.com/photos/20158323@N04/3045398800/" rel="noopener ugc nofollow" target="_blank">原始照片</a>，版权2008<a class="ae ma" href="https://www.flickr.com/photos/pasa/" rel="noopener ugc nofollow" target="_blank">P</a>T10】SliceofNYC并在<a class="ae ma" href="https://creativecommons.org/licenses/by/2.0/" rel="noopener ugc nofollow" target="_blank">attribute 2.0 Generic(CC BY 2.0)许可下提供</a></p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/687d38596e4a87e0b9f51db42ed0f06d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kAqypuyN_jLr9Xvg-W4idQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">示例3 —左侧:复制粘贴模型的结果检测到一辆自行车。右图:vanilla模型的结果检测到两辆自行车，其中一辆是摩托车。改编自<a class="ae ma" href="https://www.flickr.com/photos/kenjonbro/6842482507/" rel="noopener ugc nofollow" target="_blank">原图</a>，版权2012 <a class="ae ma" href="https://www.flickr.com/photos/kenjonbro/" rel="noopener ugc nofollow" target="_blank">肯</a>并以<a class="ae ma" href="https://creativecommons.org/licenses/by-nc-sa/2.0/" rel="noopener ugc nofollow" target="_blank">署名-非商业性-共享相似2.0通用(CC BY-NC-SA 2.0) </a>发布</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi np"><img src="../Images/ee2c28665689e8c0f771236a7fbba735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c9Y-tlouvt_bj4mKtKPm4A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">示例4 —左侧:复制粘贴模型的结果检测到一辆自行车。右图:vanilla模型的结果检测到两辆自行车，其中一辆是摩托车。改编自<a class="ae ma" href="https://www.flickr.com/photos/mi8/14313061/" rel="noopener ugc nofollow" target="_blank">原始照片</a>，版权2005 <a class="ae ma" href="https://www.flickr.com/photos/mi8/" rel="noopener ugc nofollow" target="_blank"> britt </a>，以<a class="ae ma" href="https://creativecommons.org/licenses/by-nc-sa/2.0/" rel="noopener ugc nofollow" target="_blank">署名-非商业性使用-类似共享2.0通用(CC BY-NC-SA 2.0) </a>发布</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nq"><img src="../Images/863c1dfd2bb57b748759a6258977bcef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-kOt3WeGbgGbDo4BSCWNw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">示例5 —左侧:复制粘贴模型的结果检测到一辆自行车。右图:vanilla模型的结果检测到两辆自行车，其中一辆是摩托车。改编自<a class="ae ma" href="https://www.flickr.com/photos/sterte/1545832778/" rel="noopener ugc nofollow" target="_blank">原始照片</a>，版权2007 <a class="ae ma" href="https://www.flickr.com/photos/sterte/" rel="noopener ugc nofollow" target="_blank"> Stefano Arteconi </a>并以<a class="ae ma" href="https://creativecommons.org/licenses/by-nc-sa/2.0/" rel="noopener ugc nofollow" target="_blank">署名-非商业性-共享2.0通用(CC BY-NC-SA 2.0) </a>发布</p></figure><p id="7a3b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">总的来说，vanilla模型正确检测到的自行车数量(真阳性)为321辆，而误识别为自行车的摩托车数量(假阳性)为130辆。对于复制粘贴的摩托车模型，206辆自行车被正确识别，11辆摩托车被错误识别为自行车。请注意，我们没有考虑两个模型中实际上不是摩托车的类的任何误报。本质上，我们是在看摩托车被贴上自行车标签的混淆率。在这些术语中，复制粘贴模型的混淆率仅为0.05，而普通模型的混淆率高达0.29。当然，混乱越小越好。复制粘贴狗模型的假阳性率也降低了——它只把38辆摩托车误认为是自行车。然而，真阳性的数量是三个模型中最少的，只有193个。这些结果总结在下表2中:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/7976b4ee737ff52d5b108a47b9dec391.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUZGs-JgqgWPw4X_efEytw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">表2:模型评估。形象。作者图片</p></figure><h1 id="9f7f" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">最后的想法</h1><p id="98fe" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">我们对复制-粘贴技术的演示表明，这种增强确实减少了自行车和摩托车之间的混淆，并表明这是一种很有前途的技术，可以应用于其他类容易混淆的情况。执行此技术的成本是额外的工作，即构建一个额外的类别(此处为摩托车)图像数据集，该模型预计会将其与要检测的类别(此处为自行车)相混淆。然而，这个额外的数据集不需要任何注释，因此构建起来相对便宜。</p><p id="de25" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们还可以看到，通过复制粘贴增强技术来减少混淆，在很大程度上依赖于粘贴实例的图像的选择。在将自行车粘贴到只有摩托车或只有狗的图像上的情况下，我们发现前者的模型有更多的真阳性和更少的假阳性——这两者都是可取的。当粘贴到狗身上时，与普通模型相比，假阳性的数量明显减少，只是没有复制粘贴摩托车模型多。事实上，复制粘贴狗模型的混淆率是复制粘贴摩托车模型的3倍以上。</p><p id="2a3b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最后，如上所述，COCO数据集的注释掩码并不像人们希望的那样干净。如果使用具有更精确掩模的数据集，则预期复制-粘贴技术将给出甚至更好的结果，因为模型将可能较少了解注释方法中固有的特性，而更多了解待检测的实际对象的特征。然而，尽管如此，我们的实验表明，复制粘贴技术可以大大降低假阳性率。</p><p id="6bad" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">参考资料:</p><p id="fd90" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[1] G. Ghiasi，Y. Cui，A. Srinivas，R. Qian，T. Lin，E.D. Cubuk，Q. V. Le和B. Zoph，<a class="ae ma" href="https://arxiv.org/pdf/2012.07177.pdf" rel="noopener ugc nofollow" target="_blank">简单的复制粘贴是一种用于实例分割的强大的数据扩充方法</a> (2020)，arxiv.org:2012.07177v2 [cs .简历]</p><p id="8482" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2] T.-Y .林、m .梅尔、s .贝隆吉、l .布尔德夫、r .吉尔希克、j .海斯、p .佩罗娜、D .拉马南、C. L .兹尼克和p .多拉尔。<a class="ae ma" href="https://arxiv.org/abs/1405.0312" rel="noopener ugc nofollow" target="_blank">微软COCO:上下文中的通用对象</a> (2014)，arxiv:1405.0312【cs。简历]</p><p id="3708" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[3] R. Girshick，J. Donahue，T. Darrell，和M. Jitendra，<a class="ae ma" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank">精确对象检测和语义分割的丰富特征层次</a> (2014)，arxiv:1311.2524 [cs .简历]</p><p id="dfc4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[4] S. Ren，K. He，R. Girshick，和J. Sun <em class="nr">，</em> <a class="ae ma" href="https://papers.nips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf" rel="noopener ugc nofollow" target="_blank">更快的R-CNN:使用区域提议网络实现实时对象检测</a><a class="ae ma" href="https://papers.nips.cc/paper/2015" rel="noopener ugc nofollow" target="_blank">神经信息处理系统进展28 (NIPS 2015) </a> (2015)</p><p id="68e7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[5] Y .吴和a .基里洛夫，f .马萨，w .罗和R，吉希克，<a class="ae ma" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">detectron 2</a>(2019)<a class="ae ma" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>