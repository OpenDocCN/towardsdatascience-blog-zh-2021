<html>
<head>
<title>Data Preprocessing in Python Pandas — Part 6 Dropping Duplicates</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python Pandas中的数据预处理—第6部分删除重复项</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-preprocessing-in-python-pandas-part-6-dropping-duplicates-e35e46bcc9d6?source=collection_archive---------13-----------------------#2021-04-03">https://towardsdatascience.com/data-preprocessing-in-python-pandas-part-6-dropping-duplicates-e35e46bcc9d6?source=collection_archive---------13-----------------------#2021-04-03</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="7cd7" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">数据预处理</h2><div class=""/><div class=""><h2 id="416e" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">使用Python熊猫库删除重复项的快速教程。</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/9e8e20fec5b559111441e62f18283caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0SKy1pjlzgb0HvOE237AAA.jpeg"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">图片来自<a class="ae lk" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2548105" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae lk" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2548105" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a></p></figure><p id="7e2d" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在这个简短的教程中，我将展示如何使用<code class="fe mh mi mj mk b">pandas</code>库提供的<code class="fe mh mi mj mk b">drop_duplicates()</code>函数从数据帧中删除重复项。去重是一种用于预处理数据的技术。数据预处理还包括:</p><ul class=""><li id="1d8b" class="ml mm iw ln b lo lp lr ls lu mn ly mo mc mp mg mq mr ms mt bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/data-preprocessing-with-python-pandas-part-1-missing-data-45e76b781993?source=your_stories_page-------------------------------------">缺失值</a></li><li id="da23" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/data-preprocessing-with-python-pandas-part-4-standardization-ccd5b1608f1c?source=your_stories_page-------------------------------------">标准化</a></li><li id="8b21" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/data-preprocessing-with-python-pandas-part-3-normalisation-5b5392d27673?source=your_stories_page-------------------------------------">正常化</a></li><li id="1345" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/data-processing-with-python-pandas-part-2-data-formatting-710c2eafa426?source=your_stories_page-------------------------------------">格式化</a></li><li id="6c4f" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/data-preprocessing-with-python-pandas-part-5-binning-c5bd5fd1b950?source=your_stories_page-------------------------------------">宁滨。</a></li></ul><p id="2bf8" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">这个教程可以从我的<a class="ae lk" href="https://github.com/alod83/data-science/tree/master/Preprocessing/RemoveDuplicates" rel="noopener ugc nofollow" target="_blank"> Github库</a>下载。</p><h1 id="6f03" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">数据导入</h1><p id="5e5f" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">首先，我导入Python <code class="fe mh mi mj mk b">pandas</code>库，然后通过<code class="fe mh mi mj mk b">read_csv()</code>函数读取CSV文件。在本教程中，我利用了<code class="fe mh mi mj mk b">cupcake.csv</code>数据集，该数据集包含在Google Trends上对单词<code class="fe mh mi mj mk b">cupcake</code>的趋势搜索。数据是从<a class="ae lk" href="https://trends.google.com/trends/explore?q=%2Fm%2F03p1r4&amp;date=all" rel="noopener ugc nofollow" target="_blank">这个环节</a>中提取出来的。我修改了原始数据集，以便包含重复的数据集。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="f12b" class="oa na iw mk b gz ob oc l od oe">import pandas as pd</span><span id="421c" class="oa na iw mk b gz of oc l od oe">df = pd.read_csv('cupcake_duplicates.csv')<br/>df.head()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj og"><img src="../Images/da81f6ad8f73155590e1af467972f060.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*HlMq4Gfm_WhmR_B54MjTuQ.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="a977" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我列出数据帧中包含的记录数。我利用了<code class="fe mh mi mj mk b">shape</code>属性，它显示了数据帧的行数和列数。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="aa0c" class="oa na iw mk b gz ob oc l od oe">df.shape</span></pre><p id="81c4" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它显示了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="c2c5" class="oa na iw mk b gz ob oc l od oe">(210, 2)</span></pre><h1 id="fe73" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">检查是否存在重复</h1><p id="e020" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">为了检查一条记录是否重复，我可以利用<code class="fe mh mi mj mk b">duplicated()</code>函数，如果一条记录有其他重复项，则返回<code class="fe mh mi mj mk b">True</code>，否则返回<code class="fe mh mi mj mk b">False</code>。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="7d2a" class="oa na iw mk b gz ob oc l od oe">df.duplicated()</span></pre><p id="a316" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="ab30" class="oa na iw mk b gz ob oc l od oe">0      False<br/>1       True<br/>2       True<br/>3      False<br/>4      False<br/>       ...  <br/>205    False<br/>206    False<br/>207    False<br/>208    False<br/>209    False<br/>Length: 210, dtype: bool</span></pre><p id="be27" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我还可以在数据帧的列子集上使用<code class="fe mh mi mj mk b">duplicated()</code>函数。在这种情况下，我必须使用<code class="fe mh mi mj mk b">subset</code>参数，它包含要检查的列的列表。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="4a1b" class="oa na iw mk b gz ob oc l od oe">df.duplicated(subset=['Mese'])</span></pre><p id="4fba" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我可以通过<code class="fe mh mi mj mk b">True</code>记录的总和计算出重复的数量。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="d808" class="oa na iw mk b gz ob oc l od oe">df.duplicated().sum()</span></pre><p id="702e" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="b61c" class="oa na iw mk b gz ob oc l od oe">6</span></pre><h1 id="6ad6" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">删除重复项</h1><p id="005e" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">现在，我可以通过<code class="fe mh mi mj mk b">drop_duplicates()</code>功能删除副本。我可以使用不同的策略:</p><ul class=""><li id="a421" class="ml mm iw ln b lo lp lr ls lu mn ly mo mc mp mg mq mr ms mt bi translated">基于所有列删除所有重复项</li><li id="ea3c" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">基于某些列，删除所有重复项</li></ul><p id="6b87" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在这两种策略中，我可以决定是否维护重复值的副本。这可以通过作为输入传递给<code class="fe mh mi mj mk b">drop_duplicates()</code>函数的<code class="fe mh mi mj mk b">keep</code>参数来完成。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="22c7" class="oa na iw mk b gz ob oc l od oe">df1 = df.drop_duplicates()<br/>df1.shape</span></pre><p id="2060" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="e81f" class="oa na iw mk b gz ob oc l od oe">(204, 2)</span></pre><p id="743f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">这意味着已经从数据集中移除了6个元素，这对应于6个副本。</p><p id="fd41" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">或者，我也可以删除第一个副本:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="c328" class="oa na iw mk b gz ob oc l od oe">df2 = df.drop_duplicates(keep=False)<br/>df2.shape</span></pre><p id="5f1c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="ffad" class="oa na iw mk b gz ob oc l od oe">(201, 2)</span></pre><p id="16c9" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我注意到有9条记录已经从数据集中删除。</p><p id="527e" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">作为一种额外的策略，我可以根据列的子集删除重复项。这可以通过使用<code class="fe mh mi mj mk b">subset</code>参数来完成。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="1554" class="oa na iw mk b gz ob oc l od oe">df3 = df.drop_duplicates(subset=["Cupcake"])<br/>df3.shape</span></pre><p id="6ec2" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="3676" class="oa na iw mk b gz ob oc l od oe">(78, 2)</span></pre><p id="a2e2" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在这种情况下，从数据集中删除了大量记录。</p><h1 id="7666" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">摘要</h1><p id="9c11" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">在这篇简短的教程中，我描述了如何使用Python <code class="fe mh mi mj mk b">pandas</code>从数据集中删除重复项。可以使用<code class="fe mh mi mj mk b">drop_duplicates()</code>功能。根据所需的输出，可以向函数传递不同的参数。</p><p id="d81c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae lk" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lk" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae lk" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="e06c" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">相关文章</h1><div class="oh oi gq gs oj ok"><a rel="noopener follow" target="_blank" href="/data-normalization-with-python-scikit-learn-e9c5640fed58"><div class="ol ab fp"><div class="om ab on cl cj oo"><h2 class="bd jg gz z fq op fs ft oq fv fx jf bi translated">使用Python scikit进行数据规范化-学习</h2><div class="or l"><h3 class="bd b gz z fq op fs ft oq fv fx dk translated">继关于数据预处理的系列文章之后，在本教程中，我将讨论Python中的数据规范化…</h3></div><div class="os l"><p class="bd b dl z fq op fs ft oq fv fx dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy le ok"/></div></div></a></div><div class="oh oi gq gs oj ok"><a rel="noopener follow" target="_blank" href="/data-preprocessing-with-python-pandas-part-5-binning-c5bd5fd1b950"><div class="ol ab fp"><div class="om ab on cl cj oo"><h2 class="bd jg gz z fq op fs ft oq fv fx jf bi translated">用Python Pandas进行数据预处理—第5部分宁滨</h2><div class="or l"><h3 class="bd b gz z fq op fs ft oq fv fx dk translated">数据宁滨(或称存储桶)将数据分组到存储箱(或存储桶)中，从这个意义上说，它替换了包含在</h3></div><div class="os l"><p class="bd b dl z fq op fs ft oq fv fx dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy le ok"/></div></div></a></div><div class="oh oi gq gs oj ok"><a rel="noopener follow" target="_blank" href="/data-preprocessing-with-python-pandas-part-4-standardization-ccd5b1608f1c"><div class="ol ab fp"><div class="om ab on cl cj oo"><h2 class="bd jg gz z fq op fs ft oq fv fx jf bi translated">Python Pandas的数据预处理—第4部分标准化</h2><div class="or l"><h3 class="bd b gz z fq op fs ft oq fv fx dk translated">本教程解释了如何使用Pandas库预处理数据。预处理是做一个…</h3></div><div class="os l"><p class="bd b dl z fq op fs ft oq fv fx dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="pa l ov ow ox ot oy le ok"/></div></div></a></div><h1 id="cd03" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">新到中？您可以每月订阅几美元，并解锁无限的文章— <a class="ae lk" href="https://alod83.medium.com/membership" rel="noopener">点击此处</a>。</h1></div></div>    
</body>
</html>