<html>
<head>
<title>On the Fly Transformation of Training Data with Amazon S3 Object Lambda</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用亚马逊S3对象Lambda动态转换训练数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/on-the-fly-transformation-of-training-data-with-amazon-s3-object-lambda-9402e400f912?source=collection_archive---------16-----------------------#2021-05-18">https://towardsdatascience.com/on-the-fly-transformation-of-training-data-with-amazon-s3-object-lambda-9402e400f912?source=collection_archive---------16-----------------------#2021-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="8251" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="ab5e" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">通过在检索期间处理数据，减少训练实例的CPU负载</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/beaa38ba4cb23bcf5c25c6c52bfe18b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rMjUYY_NcrU8IiTJ"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@erinw?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">艾琳·明斯金</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="bd75" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">两个月前(2021年3月)AWS <a class="ae le" href="https://aws.amazon.com/blogs/aws/introducing-amazon-s3-object-lambda-use-your-code-to-process-data-as-it-is-being-retrieved-from-s3/" rel="noopener ugc nofollow" target="_blank">宣布</a>亚马逊S3对象λ功能，这一新功能使人们能够在数据到达调用应用程序之前处理从<a class="ae le" href="https://www.google.com/aclk?sa=L&amp;ai=DChcSEwiR2tuq2rXwAhUEnNUKHYnoAWIYABAAGgJ3cw&amp;ae=2&amp;sig=AOD64_0mYO_J-0ovo666nDL7ZUOBOjtcGA&amp;q&amp;adurl&amp;ved=2ahUKEwih0dKq2rXwAhVQyxoKHZLnBi0Q0Qx6BAgCEAE" rel="noopener ugc nofollow" target="_blank">亚马逊S3 </a>检索的数据。<a class="ae le" href="https://aws.amazon.com/blogs/aws/introducing-amazon-s3-object-lambda-use-your-code-to-process-data-as-it-is-being-retrieved-from-s3/" rel="noopener ugc nofollow" target="_blank">公告</a>强调了如何使用该功能为不同的客户提供不同的数据视图，并描述了其在复杂性和成本方面优于其他解决方案的优势:</p><blockquote class="mb mc md"><p id="9ec4" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated">为了向多个应用程序提供不同的数据视图，目前有两种选择。您要么创建、存储和维护额外的数据衍生副本，以便每个应用程序都有自己的自定义数据集，要么构建和管理基础架构作为S3前端的代理层，以便根据请求拦截和处理数据。这两种选择都增加了复杂性和成本，所以S3团队决定建立一个更好的解决方案。</p><p id="f97d" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated">—引自功能发布。</p></blockquote><p id="798f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这一新功能的前景让我们兴奋不已，我们决定评估它在深度学习培训场景中的使用。</p><h1 id="4df9" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">使用亚马逊S3对象Lambda训练数据转换</h1><p id="5618" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">我们将评估的训练场景是，我们有一个非常大的训练数据集，驻留在<a class="ae le" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank">亚马逊S3 </a>中，我们将它流式传输到一个或多个训练实例上的一个或多个GPU上运行的训练会话中。在典型的设置中，输入的训练数据在被馈送到GPU之前，可能在训练设备的CPU核心上经历一系列的变换、扩充、扭曲、混洗、批处理和其他操作。这一系列操作通常被称为<em class="me">预处理流水线</em>。计算密集型预处理管道可能会导致训练管道中的<em class="me"> CPU瓶颈</em>，这是一种GPU在等待CPU处理时未得到充分利用的情况。这种常见的情况是非常不可取的；GPU是最昂贵的培训资源，我们的目标应该是最大限度地利用它，以便将我们的整体培训成本降至最低。</p><p id="c99b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在之前的一篇博文<a class="ae le" rel="noopener" target="_blank" href="/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851">中，我们扩展了数据预处理瓶颈，并回顾了一些克服它们的方法。尽管您做了所有的尝试，您可能会发现您的CPU处理继续使您的可用资源负担过重。通过为我们提供机会，在训练数据到达设备之前对其进行一些处理，亚马逊S3 Object Lambda功能看起来就像是医生订购的一样。</a></p><p id="c603" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我选择展示的具体用例是，我们正在对一个TensorFlow模型进行训练，该模型基于以<a class="ae le" href="https://github.com/tmbdev/webdataset" rel="noopener ugc nofollow" target="_blank"><em class="me">web dataset</em></a><em class="me"/>文件格式存储在亚马逊S3的训练数据。<a class="ae le" href="https://github.com/tmbdev/webdataset" rel="noopener ugc nofollow" target="_blank"><em class="me">web dataset</em></a><em class="me"/>是一种文件格式，专为使用大型数据集进行训练而设计，其中的样本存储为POSIX tar档案的集合。通过使用<a class="ae le" href="https://github.com/tmbdev/webdataset" rel="noopener ugc nofollow" target="_blank"> <em class="me"> webdataset </em> </a>，样本特征可以以其原始格式进行存储和处理，例如图像为<em class="me"> jpg </em> s，音频文件为<em class="me"> wavs，</em> python结构为<em class="me"> pkl </em>文件等。关于webdataset的更多信息，请参见Github项目页面、pip安装页面和这篇文章。虽然<em class="me"> webdataset </em>包包含用于定义pytorch兼容数据集的API，但在撰写本文时，<em class="me">没有</em>包含对TensorFlow的内置支持。为了与TensorFlow培训课程保持一致，我们将动态执行<em class="me">数据到TensorFlow友好<a class="ae le" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"><em class="me">TF record</em></a><em class="me"/>格式的</em>转换。这个用例的选择有些武断。人们可以很容易地选择用任何其他类型的数据转换来评估亚马逊S3对象Lambda。</p><p id="ec9c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了评估亚马逊S3对象Lambda对我们所选用例的适用性，我们需要考虑替代解决方案。以下是一些选项:</p><ol class=""><li id="08d0" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma nk nl nm nn bi translated">在S3创建并维护一个<em class="me"> TFRecord </em>格式的数据集副本，用于模型训练。这种方法有几个缺点，包括需要额外的存储资源，以及在底层数据发生变化时需要重新创建训练数据。</li><li id="ceb9" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">将<em class="me"> webdataset </em>格式的数据输入训练设备。建立一个接收该格式的<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly" rel="noopener ugc nofollow" target="_blank"> <em class="me"> TensorFlow </em>数据集</a>，或者在训练设备上进行格式转换。这种方法的危险在于增加了对CPU资源的争夺，并有可能导致GPU利用率不足。</li><li id="c655" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">创建一个专用的CPU核心集群，该集群将从S3获取数据，执行格式转换，并将结果提供给训练设备。</li></ol><p id="c8fa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们对在这个场景中使用亚马逊S3对象Lambda的评估将涵盖两个方面:</p><ol class=""><li id="6658" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma nk nl nm nn bi translated"><strong class="lh ja">成本</strong>——与其他选择相比，使用亚马逊S3对象Lambda的成本意味着什么？</li><li id="ab3f" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated"><strong class="lh ja">训练吞吐量</strong> —使用亚马逊S3对象Lambda如何影响训练吞吐量(通过每秒输入模型的样本数来衡量)？</li></ol><p id="170d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">虽然我写这篇文章的个人兴趣是演示和评估该特性的性能，但由于马上就会明白的原因，我们将从讨论使用该特性的成本影响开始。然后，我们将演示使用亚马逊S3对象Lambda将存储在<a class="ae le" href="https://github.com/tmbdev/webdataset" rel="noopener ugc nofollow" target="_blank"><em class="me">web dataset</em></a><em class="me"/>格式中的数据转换为<em class="me"> TFRecord </em>格式。为了完成我们的评估，我们将比较使用亚马逊S3对象Lambda对训练吞吐量的影响和一些替代解决方案。</p><p id="4391" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我要感谢我的同事马克斯·拉宾，他帮助我建立并运行了这篇文章中描述的实验。</p><h1 id="e629" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">亚马逊S3对象Lambda成本分析</h1><p id="fa0d" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">使用亚马逊S3 Object Lambda的费用可以在<a class="ae le" href="https://aws.amazon.com/s3/pricing/" rel="noopener ugc nofollow" target="_blank">亚马逊S3定价</a>页面的S3 Object Lambda标签下找到。如前所述，该特性的成本由三部分组成:从亚马逊S3获取数据的典型成本、运行AWS Lambda函数的成本，以及基于传递给调用应用程序的数据量的额外成本。以下是定价页面的摘录(2021年5月8日拍摄)。</p><blockquote class="mb mc md"><p id="931f" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated">当您使用S3对象Lambda时，您的S3 GET请求会调用您定义的AWS Lambda函数。这个函数将处理您的数据，并将处理后的对象返回给您的应用程序。在美国东部(N. Virginia)地区，您需要为AWS Lambda功能的持续时间支付0.0000167美元/GB/秒，并为每1M AWS Lambda请求支付0.20美元。对于Lambda函数调用的所有S3 GET请求，每1000个请求您还需要支付0.0004美元，对于S3对象Lambda返回到您的应用程序的数据，每GB需要支付0.005美元。</p><p id="6828" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated">—摘自<a class="ae le" href="https://aws.amazon.com/s3/pricing/" rel="noopener ugc nofollow" target="_blank">https://aws.amazon.com/s3/pricing/</a></p></blockquote><p id="0018" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设我们的数据集大小为100 TB，分成1，000，000个文件，每个文件大小为100 MB。单次数据遍历(一个<em class="me">时期</em>)的典型成本仅为<strong class="lh ja"> $0.40 </strong>。通过亚马逊S3对象Lambda提取数据的额外成本将是100，000 x 0.005 = <strong class="lh ja"> $500 </strong>！而且这还是在考虑运行Lambda函数本身的成本之前。显然，应该全面评估这一成本——即它如何影响总体培训成本。但是，除非有任何算术错误(不应该排除)，否则该功能的当前定价模型似乎不适合机器学习等数据密集型应用。至少，它保证了对替代解决方案的成本进行更仔细的研究。</p><p id="8847" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">在亚马逊S3创建和维护数据的衍生产品</strong>:尽管这种解决方案不方便且“丑陋”，但它可能更具成本效益。数据存储相对便宜，虽然我们仍然需要计算资源来应用数据转换，但是每个训练任务只运行一次(而不是每次数据遍历都运行)。问题是这种解决方案并不总是一种选择。通常，深度学习训练会话需要对输入数据应用随机增强。虽然通过随机转换创建数据的许多副本是可能的，但这是非常不切实际的。并且这种固定扰动的集合尽管可能很大，但可能不会对训练产生与在预处理流水线上应用随机操作相同的影响。</p><p id="f7fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">转换训练设备上的数据</strong>:尽管我们希望最大限度地利用GPU资源，但我们的成本分析迫使我们重新审视资源利用不足的代价。显然，成本将取决于许多因素，包括:1 .训练器械的种类和数量。遍历数据所需的时间。让我们考虑如何评估成本的以下示例:假设我们的GPU培训资源每小时花费28美元，我们的数据转换将利用率从100%降至25%，遍历100 TB数据需要20小时。我们发现，在训练设备上运行转换的每次数据遍历的额外成本是0.75 x 20 x 28 = 420美元。在这个例子中，成本低于亚马逊S3对象Lambda函数的成本，但不难理解这是一个不太有吸引力的解决方案。</p><p id="b4d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">在专用CPU集群</strong>上执行数据转换:在前面提到的<a class="ae le" rel="noopener" target="_blank" href="/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851">关于解决CPU计算瓶颈的帖子</a>中，我们展示了使用<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/data/experimental/service" rel="noopener ugc nofollow" target="_blank"> tf.data服务</a>将数据预处理卸载到辅助CPU机器上。如果现有的框架如<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/data/experimental/service" rel="noopener ugc nofollow" target="_blank"> tf.data service </a>或<a class="ae le" href="https://github.com/NVIDIA/aistore" rel="noopener ugc nofollow" target="_blank"> AIStore </a>支持你的数据转换需求，那么使用它可能比亚马逊S3 Object Lambda更具成本效益。否则，您可能需要设计和创建自己的解决方案。虽然这种努力从长远来看可能会有好处，但无论怎么想象，这都不是一件小事。</p><p id="a5cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们在此部分执行的成本分析不完整。全面的成本评估应考虑运行AWS Lambda功能的成本。它还应该考虑使用亚马逊S3对象Lambda如何影响训练吞吐量，从而影响整体训练运行时间和成本。以下是更多相关信息。</p><h1 id="e374" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">构建亚马逊S3对象Lambda解决方案</h1><p id="53c6" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">正如在<a class="ae le" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html" rel="noopener ugc nofollow" target="_blank"> AWS文档</a>中描述的，设置亚马逊S3对象Lambda需要两个主要步骤:<a class="ae le" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/olap-writing-lambda.html" rel="noopener ugc nofollow" target="_blank">定义和部署AWS Lambda函数</a>和<a class="ae le" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/olap-create.html" rel="noopener ugc nofollow" target="_blank">创建对象Lambda访问点</a>。我们假设训练数据已经以<em class="me"> webdataset </em>格式准备好了。你可以在本文的附录中找到一个数据创建的例子。</p><h2 id="7d7a" class="nt mj iq bd mk nu nv dn mo nw nx dp ms lo ny nz mu ls oa ob mw lw oc od my iw bi translated">AWS Lambda函数创建</h2><p id="6c61" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">我们选择使用<a class="ae le" href="https://docs.aws.amazon.com/serverless-application-model/index.html" rel="noopener ugc nofollow" target="_blank"> AWS无服务器应用程序模型</a> (AWS SAM)来定义、构建和部署Lambda函数。类似于<a class="ae le" href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-getting-started-hello-world.html" rel="noopener ugc nofollow" target="_blank">“Hello World”教程</a>中描述的例子，我们创建了一个名为<em class="me"> convert_wds2tf </em>的Lambda函数。该函数的定义由四部分组成:</p><ol class=""><li id="9e77" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma nk nl nm nn bi translated">一个<em class="me"> TFRecord </em>作家类，<em class="me"> TFRecordWriter </em>，<strong class="lh ja"> </strong>改编自<a class="ae le" href="https://github.com/vahidk/tfrecord/blob/master/tfrecord/writer.py" rel="noopener ugc nofollow" target="_blank">此处</a>。</li><li id="01e5" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">一个<em class="me"> webdataset </em>文件解析器，<em class="me"> wds_iter。</em></li><li id="07ae" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">一个格式转换器类，接收一个<em class="me"> wds_iter </em>并返回相应的<em class="me"> TFRecord </em>文件。转换器可以返回单个<em class="me"> TFRecord </em>文件(通过<em class="me"> read </em>函数)或一个遍历<em class="me"> TFRecord </em>样本块的迭代器。当前的<em class="me"> __iter__ </em>实现被硬编码为每个块返回100个样本。</li><li id="d3b0" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">从S3拉<em class="me"> webdataset </em>文件的<em class="me"> lambda_handler </em>函数，创建一个<em class="me"> wds_iter </em>用于遍历它，并使用<em class="me">转换器</em>类将其转换为<em class="me"> TFRecord </em>输出。</li></ol><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="f55c" class="nt mj iq of b gy oj ok l ol om">import boto3, requests, struct, imageio, io, re<br/>import tarfile, crc32c, numpy as np<br/>from botocore.config import Config<br/># python code generated by the <a class="ae le" href="https://developers.google.com/protocol-buffers/docs/reference/python-generated#invocation" rel="noopener ugc nofollow" target="_blank">protocol buffer compiler</a><br/>from pb import example_pb2</span><span id="7f60" class="nt mj iq of b gy on ok l ol om"># TFRecordWriter adapted from <a class="ae le" href="https://github.com/vahidk/tfrecord/blob/master/tfrecord/writer.py" rel="noopener ugc nofollow" target="_blank">here</a><br/>class <strong class="of ja">TFRecordWriter</strong>:<br/>    def __init__(self, data_path=None,file_obj=None):<br/>        self.file = open(data_path, "wb") if data_path <br/>                                          else file_obj</span><span id="dbed" class="nt mj iq of b gy on ok l ol om">    def write(self, datum):<br/>        record = TFRecordWriter.serialize_tf_example(datum)<br/>        length = len(record)<br/>        length_bytes = struct.pack("&lt;Q", length)<br/>        self.file.write(length_bytes)<br/>        self.file.write(TFRecordWriter.masked_crc(length_bytes))<br/>        self.file.write(record)<br/>        self.file.write(TFRecordWriter.masked_crc(record))</span><span id="1213" class="nt mj iq of b gy on ok l ol om">    @staticmethod<br/>    def masked_crc(data):<br/>        mask = 0xa282ead8<br/>        crc = crc32c.crc32c(data)<br/>        masked = ((crc &gt;&gt; 15) | (crc &lt;&lt; 17)) + mask<br/>        masked = np.uint32(masked)<br/>        masked_bytes = struct.pack("&lt;I", masked)<br/>        return masked_bytes</span><span id="5c9f" class="nt mj iq of b gy on ok l ol om">    @staticmethod<br/>    def serialize_tf_example(datum):<br/>        feature_map = {<br/>            "byte": lambda f: example_pb2.Feature(<br/>                bytes_list=example_pb2.BytesList(value=f)),<br/>            "int": lambda f: example_pb2.Feature(<br/>                int64_list=example_pb2.Int64List(value=f))<br/>        }</span><span id="a589" class="nt mj iq of b gy on ok l ol om">        def serialize(value, dtype):<br/>            if not isinstance(value, (list, tuple, np.ndarray)):<br/>                value = [value]<br/>            return feature_map[dtype](value)</span><span id="edc4" class="nt mj iq of b gy on ok l ol om">        features = {key: serialize(value, dtype)<br/>                    for key, (value, dtype) in datum.items()}<br/>        example_proto = example_pb2.Example(<br/>            features=example_pb2.Features(feature=features))<br/>        return example_proto.SerializeToString()</span><span id="7203" class="nt mj iq of b gy on ok l ol om"># iterate over a wds dataset<br/>def <strong class="of ja">wds_iter</strong>(path):<br/>    def my_png_decoder(value):<br/>        return imageio.imread(io.BytesIO(value))<br/>    def my_cls_decoder(value):<br/>        return int(value.decode("utf-8").strip(']['))</span><span id="ef51" class="nt mj iq of b gy on ok l ol om">    stream = tarfile.open(fileobj=path, mode="r|*")<br/>    record = {}<br/>    count = 0<br/>    for tarinfo in stream:<br/>        filename = tarinfo.name<br/>        key, suffix = re.split('\.',filename)<br/>        if not record or record['key'] != key:<br/>            if 'data' in record and 'label' in record:<br/>                count += 1<br/>                yield record['data'], record['label']<br/>            record = {'key':key}<br/>        value = stream.extractfile(tarinfo).read()<br/>        if suffix == 'cls':<br/>            record['label'] = int(<br/>                            value.decode("utf-8").strip(']['))<br/>        elif suffix == 'png':<br/>            record['data'] = imageio.imread(io.BytesIO(value))<br/>    if 'data' in record and 'label' in record:<br/>        yield record['data'], record['label']</span><span id="aa49" class="nt mj iq of b gy on ok l ol om">class <strong class="of ja">Converter</strong>:<br/>    def __init__(self, dataset):<br/>        self.dataset = dataset</span><span id="7fce" class="nt mj iq of b gy on ok l ol om">    def read(self, size=None):<br/>        transformed_object = io.BytesIO()<br/>        record_writer = TFRecordWriter(<br/>                         file_obj=transformed_object)<br/>        for data, label in self.dataset:<br/>            record_writer.write({"image": (data.tobytes(),"byte"), <br/>                                 "label": (label,"int")})<br/>        transformed_object.seek(0)<br/>        return transformed_object.read()</span><span id="b2b5" class="nt mj iq of b gy on ok l ol om">    def __iter__(self):<br/>        transformed_object = io.BytesIO()<br/>        record_writer = TFRecordWriter(<br/>                             file_obj=transformed_object)<br/>        count = 0<br/>        for data, label in self.dataset:<br/>            if count&gt;0 and count%100 == 0:<br/>                transformed_object.seek(0)<br/>                yield transformed_object.read()<br/>                transformed_object = io.BytesIO()<br/>                record_writer = TFRecordWriter(<br/>                          file_obj=transformed_object)<br/>            record_writer.write({"image": (data.tobytes(),"byte"),<br/>                                 "label": (label, "int")})<br/>            count+=1<br/>        transformed_object.seek(0)<br/>        yield transformed_object.read()</span><span id="8425" class="nt mj iq of b gy on ok l ol om">def <strong class="of ja">lambda_handler</strong>(event, context):<br/>    <strong class="of ja">stream_chunks </strong>= False<br/>    object_get_context = event["getObjectContext"]<br/>    request_route = object_get_context["outputRoute"]<br/>    request_token = object_get_context["outputToken"]<br/>    s3_url = object_get_context["inputS3Url"]<br/>    # Get object from S3<br/>    r = requests.get(s3_url, stream=<strong class="of ja">stream_chunks</strong>)<br/>    original_object = r.content<br/>    # Transform object<br/>    convert_to_tfrecord2 = Converter(                                      <br/>                       wds_iter(io.BytesIO(original_object)))<br/>    if <strong class="of ja">stream_chunks</strong>:<br/>        s3 = boto3.client('s3', <br/>                  config=Config(<br/>                           signature_version='s3v4', <br/>                           s3={'payload_signing_enabled': False}))<br/>        body = convert_to_tfrecord2<br/>    else:<br/>        s3 = boto3.client('s3')<br/>        body = convert_to_tfrecord2.read()<br/>    # Write object back to S3 Object Lambda<br/>    s3.write_get_object_response(<br/>        Body=body,<br/>        RequestRoute=request_route,<br/>        RequestToken=request_token<br/>    )<br/>    return {'status_code': 200}</span></pre><p id="d3f4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的实现演示了通过<em class="me">stream _ chunks</em><strong class="lh ja"><em class="me"/></strong>标志<em class="me">将分块数据流回调用应用程序的选项。</em>在许多情况下，您会发现这将提高解决方案的效率，减少延迟，提高吞吐量。由于我们的客户端应用程序将使用<em class="me"> TensorFlow </em>来读取数据文件，并且<em class="me"> TensorFlow </em>目前不支持来自S3的分块数据流，因此我们将<em class="me"> stream_chunks </em>设置为<em class="me"> false。</em></p><p id="0173" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于这段代码是为了演示的目的而创建的，所以我们没有投资于优化实现。优化Lambda函数对于降低成本和潜在减少延迟都非常重要。</p><h2 id="14c0" class="nt mj iq bd mk nu nv dn mo nw nx dp ms lo ny nz mu ls oa ob mw lw oc od my iw bi translated">按范围提取数据文件</h2><p id="23e4" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">亚马逊S3提供的一个重要特性是一个用于在数据文件中提取特定字节范围的API。具体来说，该功能支持<em class="me">多部分数据下载</em>，其中数据文件被分成多个部分并行下载。Needles说，这可以对下载速度产生有意义的影响，进而对数据吞吐量产生影响。如<a class="ae le" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/olap-writing-lambda.html#range-get-olap" rel="noopener ugc nofollow" target="_blank">用户指南</a>中所述，S3对象<em class="me">支持根据<em class="me">范围</em>和<em class="me">零件号</em>检索数据，尽管这需要特殊处理。在数据转换的情况下，正如我们在这里演示的，支持对对象内任意范围的访问可能是非常低效的。一个简单的实现需要转换整个数据文件(或者至少是所有数据，直到我们生成请求的范围)。更有效的实现要求我们能够将Lambda响应的范围映射到源文件的范围。这样的映射并不总是存在的。即使这样，除非调用应用程序被编程为请求与数据样本边界完全一致的范围，否则我们最终仍然会执行比拉动整个对象更多的工作。我们的例子<em class="me">不</em>包括对拉取特定范围的支持。</em></p><h2 id="08fe" class="nt mj iq bd mk nu nv dn mo nw nx dp ms lo ny nz mu ls oa ob mw lw oc od my iw bi translated">S3对象Lambda客户端应用程序示例</h2><p id="9902" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">在下面的例子中，我们展示了如何编程一个tensor flow<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset" rel="noopener ugc nofollow" target="_blank">TFRecordDataset</a>，它通过对象Lambda端点指向S3对象。因为我们只对测量训练数据吞吐量感兴趣，所以我们放弃构建训练模型，而是直接在数据集上迭代。</p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="a84d" class="nt mj iq of b gy oj ok l ol om">import os, tensorflow as<strong class="of ja"> </strong>tf<br/>#replace with your access_point and paths in s3<br/><strong class="of ja">ap_path</strong>='s3://arn:aws:s3-object-lambda:us-east-1:&lt;id&gt;:accesspoint'<br/><strong class="of ja">path_to_s3_wds_folder</strong>='&lt;path-to-webdataset-folder&gt;'<br/><strong class="of ja">path_to_s3_tfr_folder</strong>='&lt;path-to-tfrecord-folder&gt;'<br/><strong class="of ja">s3_path_to_wds</strong>='s3://'+path_to_s3_wds_folder<br/><strong class="of ja">s3_path_to_tfr</strong>='s3://'+path_to_s3_tfr_folder<br/><strong class="of ja">ap_path_to_wds</strong>=os.path.join(ap_path,path_to_s3_wds_folder)</span><span id="3aa8" class="nt mj iq of b gy on ok l ol om">def get_dataset(batch_size, folder_path):<br/>    autotune = tf.data.experimental.AUTOTUNE<br/>    def parse_image_function(example_proto):<br/>        image_feature_description = {<br/>            'image': tf.io.FixedLenFeature([], tf.string),<br/>            'label': tf.io.FixedLenFeature([], tf.int64)<br/>        }<br/>        features = tf.io.parse_single_example(<br/>                   example_proto, image_feature_description)<br/>        image = tf.io.decode_raw(features['image'], tf.uint8)<br/>        image.set_shape([3 * 32 * 32])<br/>        image = tf.reshape(image, [32, 32, 3])<br/>        label = tf.cast(features['label'], tf.int32)<br/>        return image, label</span><span id="fa82" class="nt mj iq of b gy on ok l ol om">    options = tf.data.Options()<br/>    options.experimental_deterministic = False<br/>    records = tf.data.Dataset.list_files(folder_path + '/*',<br/>                            shuffle=True).with_options(options)</span><span id="9e44" class="nt mj iq of b gy on ok l ol om">    ds = tf.data.TFRecordDataset(records, <br/>                           num_parallel_reads=autotune).repeat()<br/>    ds = ds.map(parse_image_function, num_parallel_calls=autotune)<br/>    ds = ds.batch(batch_size)<br/>    ds = ds.prefetch(autotune)<br/>    return ds</span><span id="0e89" class="nt mj iq of b gy on ok l ol om"># get converted dataset via object lambda access point<br/>ds = get_dataset(batch_size=1024, <strong class="of ja">folder_path</strong>=<strong class="of ja">ap_path_to_wds</strong>)</span><span id="195f" class="nt mj iq of b gy on ok l ol om"># uncomment to get raw tfrecord dataset<br/>#ds = get_dataset(batch_size=1024, <strong class="of ja">folder_path</strong>=<strong class="of ja">s3_path_to_tfr</strong>)</span><span id="7385" class="nt mj iq of b gy on ok l ol om">round = 0<br/>start_time = time.time()<br/>for x in ds:<br/>    round = round + 1<br/>    if round % 100 == 0:<br/>        print("round {}: epoch time: {}".<br/>                format(round, time.time() - start_time))<br/>        start_time = time.time()<br/>    if round == 2000:<br/>        break</span></pre><p id="a17e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意，从<em class="me"> webdataset </em>数据源创建由Lambda函数生成的<em class="me"> TFRecord </em>数据集与从原始<em class="me"> TFRecord </em>数据创建<em class="me"> TFRecord </em>数据集之间的唯一区别在于传递给<em class="me"> get_dataset </em>函数的<em class="me"> folder_path </em>。</p><p id="1ba3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">不幸的是，如果您试图用默认安装的<em class="me"> TensorFlow </em>包运行上面的应用程序，它将会失败。需要对<em class="me"> TensorFlow </em>源代码进行一些小的更改，包括更新AWS CPP SDK的版本，增强S3 URL解析器，以及禁止从S3进行多部分和基于范围的下载。这篇博文的附录中详细介绍了所需的更改。</p><p id="a634" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">出于性能比较的目的，我们包含了一个基于原始<em class="me"> webdataset </em>数据构建<em class="me"> TensorFlow </em>数据集的简单实现。</p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="6833" class="nt mj iq of b gy oj ok l ol om">def get_raw_wds(batch_size):<br/>    autotune = tf.data.experimental.AUTOTUNE<br/>    options = tf.data.Options()<br/>    options.experimental_deterministic = False<br/>    dataset = tf.data.Dataset.list_files(<strong class="of ja">s3_path_to_wds</strong>+'/*',<br/>                           shuffle=True).with_options(options)<br/>    def gen(path):<br/>        g = io.BytesIO(tf.io.read_file(path).numpy())<br/>        images = []<br/>        labels = []<br/>        for x, y in wds_iter(g):<br/>            images.append(x)<br/>            labels.append(y)<br/>        return images, labels<br/>    def make_ds(path):<br/>        images, labels = tf.py_function(func=gen, inp=[path], <br/>                                    Tout=(tf.uint8, tf.uint8))<br/>        return tf.data.Dataset.from_tensor_slices((images, <br/>                                                   labels))<br/>    ds = dataset.interleave(make_ds, num_parallel_calls=autotune,<br/>                            deterministic=False)<br/>    autotune = tf.data.experimental.AUTOTUNE<br/>    ds = ds.batch(batch_size)<br/>    ds = ds.repeat().prefetch(autotune)<br/>    return ds</span></pre><p id="9d43" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们再次强调，这里给出的代码没有经过任何优化。代码和测量值仅用于演示目的。</p><h1 id="f009" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">结果</h1><p id="ae0a" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">由于与通过Lambda函数提取数据相关的延迟以及对多部分下载的限制，基于S3对象Lambda的解决方案可能会导致比读取原始<em class="me"> TFRecord </em>文件时更低的吞吐量。挑战在于试图通过并行处理等方法来克服这种潜在的延迟。这里，我们比较了以下五个实验的数据遍历速度，以每100批训练数据的秒数来衡量:</p><ol class=""><li id="d944" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma nk nl nm nn bi translated">读取每个大约150 MB大小的原始TensorFlow文件。</li><li id="f573" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">通过我们的S3对象Lambda访问点读取转换后的数据，其中的webdataset文件每个大约有192 MB。</li><li id="d000" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">通过我们的S3对象Lambda访问点读取转换后的数据，其中<em class="me"> webdataset </em>文件每个大约有8 MB大小</li><li id="9904" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">读取每个大约192 MB大小的原始<em class="me"> webdataset </em>文件</li><li id="beb7" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated">读取每个大约8 MB大小的原始<em class="me"> webdataset </em>文件</li></ol><p id="cf8c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的实验不包括在辅助CPU集群上执行<em class="me"> webdataset </em>到<em class="me"> TFRecord </em>转换的选项。如上所述，这种选择有几个优点，值得评估。我希望在未来的帖子中填补这一空白。</p><p id="9416" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所有实验都在一个c5.4xlarge <a class="ae le" href="https://aws.amazon.com/ec2/instance-types/" rel="noopener ugc nofollow" target="_blank"> Amazon EC2实例类型</a>上运行。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/1512389201a901dc7758f4f32419cbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*jF5aRtZL0PUIg9Xnakwmpg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">实验结果(平均秒数越低越好)</p></figure><p id="1ee7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">结果显示，与原始的<em class="me"> webdataset </em>遍历相比，通过使用S3对象Lambda特性，我们能够将数据集遍历速度提高大约20倍。同时，它仍然比使用原始的<em class="me"> TFRecord </em>文件慢三倍以上。我们还可以看到，在速度和一致性方面，文件大小对基于S3对象Lambda的解决方案的性能有重要影响。很有可能，通过调整并行进程的数量、调整文件大小以及对解决方案实施其他优化，我们可以提高基于Lambda的解决方案的性能，并接近raw <em class="me"> TFRecord </em>读取器的吞吐量。基于我们目前的发现，出于性能和成本的考虑，对我们用例的明确建议是在S3以<em class="me"> TFRecord </em>格式创建和维护我们数据集的副本。</p><h1 id="898c" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">摘要</h1><p id="e6b6" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">关于将亚马逊S3对象Lambda用于输入训练数据的动态转换，我们已经发现，该解决方案的成本模型以及它的使用对训练吞吐量的潜在影响使得它不是最优的解决方案。然而，在所有其他选项被证明不切实际、太困难或更昂贵的情况下，亚马逊S3对象Lambda选项可能会派上用场。</p><h1 id="1bdf" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">附录1-web dataset创建示例</h1><p id="5935" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">在下面的代码块中，我们演示了流行的<a class="ae le" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> cifar10 </a>数据集到<em class="me"> webdataset </em>格式的转换。数据集碎片的大小由<em class="me"> maxsize </em>和<em class="me"> maxcount </em>配置设置决定。</p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="23f3" class="nt mj iq of b gy oj ok l ol om">import webdataset as wds<br/>from tensorflow.keras import datasets<br/>from PIL import Image</span><span id="f309" class="nt mj iq of b gy on ok l ol om">def convert_to_wds():<br/>    (train_images, train_labels), _ = datasets.cifar10.load_data()<br/>    pattern = f"cifar10-%06d.short.tar"<br/>    temp_file = '/tmp/wds.png'<br/>    <strong class="of ja">max_file_size </strong>= 1000000000<br/>    <strong class="of ja">max_samples </strong>= 20000<br/>    with wds.ShardWriter(pattern, <strong class="of ja">maxsize=max_file_size</strong>,<br/>                         <strong class="of ja">maxcount=max_samples</strong>) as sink:<br/>        for i in range(len(train_labels)):<br/>            im = Image.fromarray(train_images[i])<br/>            im.save(temp_file)<br/>            with open(temp_file, "rb") as stream:<br/>                png = stream.read()<br/>            cls = train_labels[i]<br/>            sample = {"__key__": "%07d" % i, "png": png, "cls": cls}<br/>            sink.write(sample)</span></pre><p id="9a6c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">可以创建数据集的多个副本来模拟任意长度的数据集。</p><h1 id="2db4" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">附录TensorFlow源代码的变更</h1><p id="3697" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">在这里，我描述了为了修改和重新编译TensorFlow以使用亚马逊S3对象Lambda解决方案而采取的步骤。为了拉动和重建张量流，我遵循了<a class="ae le" href="https://www.tensorflow.org/install/source" rel="noopener ugc nofollow" target="_blank">从源</a>构建张量流的说明。我在TensorFlow源代码的“2.4”分支上执行了此操作。我所做的改变决不是最佳的。你甚至会认为他们有点粗鲁。如果您选择这种解决方案，我当然会推荐一种更谨慎的方法:</p><p id="1af4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">步骤1 —更新</strong> <a class="ae le" href="https://github.com/aws/aws-sdk-cpp" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> AWS C++ SDK </strong> </a>:当前的TensorFlow代码用<a class="ae le" href="https://github.com/aws/aws-sdk-cpp" rel="noopener ugc nofollow" target="_blank"> AWS C++ SDK </a>的一个版本编译，该版本的<em class="me">不</em>支持访问亚马逊S3对象Lambda端点。要更新SDK版本，需要修改位于<a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/third_party/aws/workspace.bzl" rel="noopener ugc nofollow" target="_blank"> workspace.bzl </a>的AWS bazel构建依赖项。我选择了SDK版本1.8.186:</p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="a942" class="nt mj iq of b gy oj ok l ol om">tf_http_archive( <br/>  <strong class="of ja">name</strong> = "aws", <br/>  <strong class="of ja">urls</strong> = [<br/>"<a class="ae le" href="https://storage.googleapis.com/mirror.tensorflow.org/github.com/aws/aws-sdk-cpp/archive/1.8.186.tar.gz" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/mirror.tensorflow.org/github.com/aws/aws-sdk-cpp/archive/1.8.186.tar.gz</a>", <br/>"<a class="ae le" href="https://github.com/aws/aws-sdk-cpp/archive/refs/tags/1.8.186.tar.gz" rel="noopener ugc nofollow" target="_blank">https://github.com/aws/aws-sdk-cpp/archive/refs/tags/1.8.186.tar.gz</a>", <br/>  ], <br/>  <strong class="of ja">sha256</strong> = "749322a8be4594472512df8a21d9338d7181c643a00e08a0ff12f07e831e3346", <br/>  <strong class="of ja">strip_prefix</strong> = "aws-sdk-cpp-1.8.186", <br/>  <strong class="of ja">build_file</strong> = "//third_party/aws:BUILD.bazel"<br/>)</span></pre><p id="4d8d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">步骤2 —修改S3 URI解析器以支持亚马逊S3对象Lambda端点:</strong>在文件<a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/core/platform/s3/s3_file_system.cc" rel="noopener ugc nofollow" target="_blank">tensor flow/</a><a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/core/platform/s3/s3_file_system.cc" rel="noopener ugc nofollow" target="_blank">core/platform/S3/S3 _ file _ system . cc</a>的<em class="me"> ParseS3Path </em>函数中添加以下代码块，用于寻址亚马逊S3对象Lambda端点:</p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="1659" class="nt mj iq of b gy oj ok l ol om">if (bucket-&gt;rfind("arn:aws", 0) == 0) {<br/>  bucket-&gt;append("/");<br/>  size_t pos = object-&gt;find("/");<br/>  bucket-&gt;append(object-&gt;substr(0, pos));<br/>  object-&gt;erase(0, pos + 1);<br/>}</span></pre><p id="d47f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">步骤3 —禁用多部分和基于范围的对象下载:</strong>这需要更改文件<a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/core/platform/s3/s3_file_system.cc" rel="noopener ugc nofollow" target="_blank">tensor flow/</a><a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/core/platform/s3/s3_file_system.cc" rel="noopener ugc nofollow" target="_blank">core/platform/S3/S3 _ file _ system . cc</a>中的两个函数。下面的代码块突出显示了这些更改。(注意我们是如何重载使用<strong class="lh ja"><em class="me">use _ multi _ part _ download _</em></strong>字段来指示使用亚马逊S3对象Lambda端点的。这不是干净的，但它的工作，因为这个设置的默认值是<em class="me">真。</em>)</p><p id="51fd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="me"> NewRandomAccessFile: </em></p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="8e39" class="nt mj iq of b gy oj ok l ol om">Status S3FileSystem::NewRandomAccessFile(<br/>    const string&amp; fname, TransactionToken* token,<br/>    std::unique_ptr&lt;RandomAccessFile&gt;* result, <br/>    bool use_multi_part_download) {<br/>  string bucket, object;<br/>  TF_RETURN_IF_ERROR(ParseS3Path(fname, false, &amp;bucket, &amp;object));</span><span id="78e9" class="nt mj iq of b gy on ok l ol om"><strong class="of ja">// in case of S3 object lambda endpoint overwrite <br/>  // multipart download<br/>  if (bucket.rfind("arn",0) == 0){<br/>    use_multi_part_download = false;<br/>  }</strong></span><span id="fc26" class="nt mj iq of b gy on ok l ol om">bool use_mpd = this-&gt;use_multi_part_download_ &amp;&amp;<br/>                                 use_multi_part_download;<br/>  result-&gt;reset(new S3RandomAccessFile(<br/>      bucket, object, use_mpd,<br/>      this-&gt;GetTransferManager(<br/>                   Aws::Transfer::TransferDirection::DOWNLOAD),<br/>      this-&gt;GetS3Client()));<br/>  return Status::OK();<br/>}</span></pre><p id="85de" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="me">reads 3客户端:</em></p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="692b" class="nt mj iq of b gy oj ok l ol om">Status ReadS3Client(uint64 offset, size_t n, StringPiece* result,<br/>                      char* scratch) const {<br/>    VLOG(3) &lt;&lt; "ReadFile using S3Client s3://" &lt;&lt; <br/>                          bucket_ &lt;&lt; "/" &lt;&lt; object_;<br/><strong class="of ja">    if (!use_multi_part_download_ &amp;&amp; offset &gt; 0) {<br/>      n = 0;<br/>      *result = StringPiece(scratch, n);<br/>      return Status(error::OUT_OF_RANGE, <br/>                     "Read less bytes than requested");<br/>    }<br/></strong>    Aws::S3::Model::GetObjectRequest getObjectRequest; <br/>    getObjectRequest.WithBucket(bucket_.c_str()).<br/>                            WithKey(object_.c_str());<br/>    if (use_multi_part_download_) {<br/>      string bytes = strings::StrCat("bytes=", offset,<br/>                                      "-", offset + n - 1);<br/>      getObjectRequest.SetRange(bytes.c_str());<br/>    }<br/>    getObjectRequest.SetResponseStreamFactory([]() {<br/>      return Aws::New&lt;Aws::StringStream&gt; <br/>                             (kS3FileSystemAllocationTag);<br/>    });</span><span id="04a5" class="nt mj iq of b gy on ok l ol om">auto getObjectOutcome = this-&gt;s3_client_-&gt;GetObject(<br/>                                          getObjectRequest);<br/>    if (!getObjectOutcome.IsSuccess()) {<br/>      auto error = getObjectOutcome.GetError();<br/>      if (error.GetResponseCode() ==<br/>           Aws::Http::HttpResponseCode::<br/>               REQUESTED_RANGE_NOT_SATISFIABLE) {<br/>        n = 0;<br/>        *result = StringPiece(scratch, n);<br/>        return Status(error::OUT_OF_RANGE,<br/>                       "Read less bytes than requested");<br/>      }<br/>      return CreateStatusFromAwsError(error);<br/>    } else {<br/>      n = getObjectOutcome.GetResult().GetContentLength();<br/><strong class="of ja">      if (use_multi_part_download_) {<br/>        getObjectOutcome.GetResult().GetBody().read(scratch, n);<br/>        *result = StringPiece(scratch, n);<br/>        return Status::OK();<br/>      } else {<br/>        getObjectOutcome.GetResult().GetBody().read(scratch, n);<br/>        *result = StringPiece(scratch, n);<br/>        return Status::OK();<br/>      }<br/></strong>    }<br/>  }</span></pre><p id="7ad3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">步骤4——扩大收集缓冲区的大小，以捕获完整的文件:</strong>这一更改应该适应您的文件大小。由于我们的文件都在200 MBs以下，将缓冲区的大小加倍就足够了。在文件<a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/core/kernels/data/tf_record_dataset_op.cc" rel="noopener ugc nofollow" target="_blank">tensor flow/core/kernels/data/TF _ record _ dataset _ op . cc</a>中增加<em class="me"> kCloudTpuBlockSize: </em>的大小</p><pre class="kp kq kr ks gt oe of og oh aw oi bi"><span id="31e5" class="nt mj iq of b gy oj ok l ol om">constexpr int64 kCloudTpuBlockSize = 127LL &lt;&lt; <strong class="of ja">21</strong>;  // 254MB.</span></pre><p id="6344" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">步骤5 </strong>:按照<a class="ae le" href="https://www.tensorflow.org/install/source" rel="noopener ugc nofollow" target="_blank">构建来自源的张量流</a>页面上的说明创建张量流轮子并安装更新的包。</p></div></div>    
</body>
</html>