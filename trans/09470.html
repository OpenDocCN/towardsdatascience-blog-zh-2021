<html>
<head>
<title>Deploy Multiple TensorFlow Models to One Endpoint</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将多个TensorFlow模型部署到一个端点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-multiple-tensorflow-models-to-one-endpoint-65bea81c3f2f?source=collection_archive---------22-----------------------#2021-09-02">https://towardsdatascience.com/deploy-multiple-tensorflow-models-to-one-endpoint-65bea81c3f2f?source=collection_archive---------22-----------------------#2021-09-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="27eb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Amazon SageMaker的多型号终端</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d670ce67621fc0f5ac3216287c4d8c34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dmIwEszF5J5p6nvp"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://unsplash.com/photos/6QWdecFKyYA" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="4950" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设您正在处理多个模型，并希望根据应用程序的用例选择一个来调用。引入<a class="ae ky" href="https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html" rel="noopener ugc nofollow" target="_blank"> SageMaker多模型端点</a>作为您的可扩展、经济高效的解决方案。使用SageMaker多模型端点(MME)，您可以将<strong class="lb iu">数千个模型集中到一个端点</strong>，并指定您希望根据您的用例调用哪个模型。这个推断选项的主要约束是<strong class="lb iu">模型</strong>所有<strong class="lb iu">都需要在<strong class="lb iu">相同框架</strong>中成为</strong>，因此所有TensorFlow或所有PyTorch都不是两者的混合。如果想要一个众多框架的<strong class="lb iu">组合</strong>，你会想要查看<a class="ae ky" href="https://docs.aws.amazon.com/sagemaker/latest/dg/multi-container-endpoints.html" rel="noopener ugc nofollow" target="_blank"> SageMaker多容器端点</a>。在本文中，为了简单起见，我们将介绍一个例子，其中我们使用了<strong class="lb iu">两个定制的TensorFlow模型</strong>。我们将遍历<strong class="lb iu">端到端示例</strong>，看看如何通过简单的<a class="ae ky" href="https://docs.aws.amazon.com/pythonsdk/" rel="noopener ugc nofollow" target="_blank"> Boto3 API调用</a>来调用或定义每个不同的模型。在开始之前，请确保阅读先决条件/设置部分，因为有足够的AWS &amp; ML知识来完全理解本演示。如果你想获取代码，请查看下面的<a class="ae ky" href="https://github.com/RamVegiraju/SageMaker-Deployment/tree/master/Inference/Multi-Model-Endpoint/TensorFlow" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h1 id="20a9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">目录</h1><ol class=""><li id="fb26" class="mn mo it lb b lc mp lf mq li mr lm ms lq mt lu mu mv mw mx bi translated">先决条件/设置</li><li id="ed9e" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">多模型端点概述</li><li id="6c0d" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">示例演练</li><li id="3d08" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">整个代码和结论</li></ol><h1 id="865f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">先决条件/设置</h1><p id="3a34" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">本文将假设您对AWS服务有中等程度的了解，特别是那些与SageMaker功能高度集成的<a class="ae ky" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"> S3 </a>和<a class="ae ky" href="https://aws.amazon.com/ecr/" rel="noopener ugc nofollow" target="_blank"> ECR </a>的服务。了解<a class="ae ky" href="https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers.html" rel="noopener ugc nofollow" target="_blank"> SageMaker containers </a>的一般运作方式以及幕后发生的事情也很重要。幸运的是，SageMaker已经提供了它管理的TensorFlow容器，因此我们可以通过一个更简单的功能来训练我们的模型，这个功能被称为<a class="ae ky" href="https://aws.amazon.com/blogs/machine-learning/bring-your-own-model-with-amazon-sagemaker-script-mode/" rel="noopener ugc nofollow" target="_blank">脚本模式</a>。使用脚本模式，我们可以在训练脚本中传递自定义模型，我们将该脚本提供给<a class="ae ky" href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html" rel="noopener ugc nofollow" target="_blank">SageMaker tensor flow estimator</a>，它在幕后有一个托管容器。要使用自定义模型跟踪TensorFlow脚本模式的端到端示例，请查看这篇文章<a class="ae ky" rel="noopener" target="_blank" href="/training-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76"/>。在本例中，我们将使用脚本模式和两个不同的TensorFlow模型进行多模型端点设置。</p><p id="7669" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于设置和实例类型，请确保为S3和ECR创建具有适当权限的IAM角色。对于实例类型，一个自由层ml.t3.medium实例应该足够了，但对于更复杂或计算密集型的模型，请查看SageMaker提供的不同的<a class="ae ky" href="https://aws.amazon.com/sagemaker/pricing/" rel="noopener ugc nofollow" target="_blank">计算实例。</a></p><p id="a7f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用的数据集是基于表格和<strong class="lb iu">回归</strong>的。第一个是<strong class="lb iu">波士顿房产</strong>，第二个是来自Kaggle的<a class="ae ky" href="https://www.kaggle.com/harinir/petrol-consumption" rel="noopener ugc nofollow" target="_blank">汽油消耗</a>数据集。</p><h1 id="9033" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">多模型端点概述</h1><p id="46ee" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">对于多模型端点，仍然只有一个容器/实例。你用脚本模式训练你的模型，然后把<strong class="lb iu">训练好的模型工件</strong>推到一个<strong class="lb iu">普通S3桶</strong>位置。注意，模型数据必须是SageMaker的<strong class="lb iu">tar.gz格式</strong>。然后，您可以用这些不同的模型填充您的端点，并在您的端点调用中指定您正在使用的模型。</p><h1 id="032d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">示例演练</h1><h2 id="08c1" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">S3设置和导入</h2><p id="551f" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在开始任何训练或推理代码之前，我们需要确保所有必要的导入和<strong class="lb iu">设置我们将在这个例子中使用的S3桶</strong>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">导入+ S3/IAM设置</p></figure><p id="715d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，我们的S3时段设置是必不可少的，因为我们的多模型端点期望所有的模型工件都在同一个S3位置。我们将使用这个带有不同前缀的桶来指定输入数据、输出数据、MME位置等等。</p><h2 id="3742" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">波士顿住房培训和模型创建</h2><p id="bbc2" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">下一步涉及到我们将在波士顿住宅区使用的第一个数据集。使用Sklearn，我们可以下载数据集，并在准备好用于训练的数据时将其推送到S3。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">波士顿数据集准备</p></figure><p id="e450" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们已经在S3准备好了我们的波士顿数据集，我们可以构建我们的训练脚本，并将其输入到TensorFlow估计器中。训练脚本将包含我们建立的<strong class="lb iu"> TensorFlow ANN </strong>模型，以及我们正在通过TensorFlow估计器传递的其他<strong class="lb iu">超参数</strong>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">波士顿住房培训脚本</p></figure><p id="58e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以将这个脚本传递给TensorFlow估计器，它将适合我们准备开始训练的输入数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">TF估计器波士顿培训</p></figure><p id="5a92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练将需要几分钟来完成，但是一旦成功完成，我们需要通过一个简单的调用从这些训练工件中创建一个模型。然而，在我们这样做之前，我们需要准备一个<strong class="lb iu">推理脚本</strong>。这个脚本让我们指定要传递给端点的数据类型(JSON、JSONline、CSV等)。推理文件将使我们的<strong class="lb iu">端点清楚我们接受和输出什么类型的数据</strong>，我们可以将这个推理文件用于我们将要创建的两个模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">帮助输入/输出数据格式的推理脚本</p></figure><p id="8334" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以创建我们的模型，并传入这个推理脚本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">创建波士顿模型</p></figure><h2 id="aec7" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">汽油消耗培训和模型创建</h2><p id="e140" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在，我们可以用汽油消耗量数据集重复同样的过程。我将跳过数据上传过程，因为这是完全相同的程序，但请确保将数据正确上传到S3或遵循<a class="ae ky" href="https://github.com/RamVegiraju/SageMaker-Deployment/blob/master/Inference/Multi-Model-Endpoint/TensorFlow/tf2-MME-regression.ipynb" rel="noopener ugc nofollow" target="_blank">代码库</a>获取指导。</p><p id="29b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将再次构建一个<a class="ae ky" href="https://github.com/RamVegiraju/SageMaker-Deployment/blob/master/Inference/Multi-Model-Endpoint/TensorFlow/Scripts/petrol.py" rel="noopener ugc nofollow" target="_blank">训练脚本</a> t，这次是为汽油数据集定制的，并将它传递给我们的估计器，然后创建一个模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">石油模型培训和模型创建</p></figure><h2 id="ad93" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">多模型端点创建</h2><p id="2caa" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">太棒了，我们已经准备好将两个模型添加到我们的端点。现在，为了创建端点，我们需要指定我们两个模型数据所在的S3位置，并确保它采用适当的tar.gz格式以及相同的存储桶。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多模型端点创建</p></figure><p id="737a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用多数据模型估计器，我们可以输入包含两个模型的模型工件的模型数据前缀。如果您为模型信息传入model_1或model_2并不重要，因为两者都在<strong class="lb iu">相同的容器</strong>中操作。我们可以通过下面的Boto3调用来确保我们的两个模型都存在。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/d18f087fe258240bc40f5783b2ead3f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*7SUURcYCcn90oDNpvTwLBw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MME模型(作者截图)</p></figure><p id="711e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以像部署单模型端点一样部署我们的端点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/1fe17e7dd78215fa02425ebba14652dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YUTG6wODEIkTtOoVVfHKgg.png"/></div></div></figure><h2 id="3d41" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">多模型端点调用</h2><p id="7dc0" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在我们可以用相同的端点测试我们的两个模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">波士顿住房测验</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/cefab61c6d882a4575c1aa922b55d27f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6AdHd4Nr24IvXv10qh4Qbw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">波士顿房屋祈求(作者截图)</p></figure><p id="eb61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们对汽油房屋数据集做同样的操作，看看两个模型的工作情况。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">汽油消耗试验</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/e6e1d442b5b11d4ef0f6f54cf83d48e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTzUDi04D_NF0GI-tbr25A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">汽油调用(作者截图)</p></figure><p id="ab7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过初始参数，我们可以传入我们想要调用的模型，我们可以看到多模型端点的惊人功能。</p><h1 id="e18a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">整个代码和结论</h1><div class="ny nz gp gr oa ob"><a href="https://github.com/RamVegiraju/SageMaker-Deployment/tree/master/Inference/Multi-Model-Endpoint/TensorFlow" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">sage maker-部署/推理/多模型-端点/主节点上的张量流…</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">SageMaker推理选项和其他功能的例子汇编。…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op ks ob"/></div></div></a></div><p id="fb92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要访问该示例的完整代码，请查看上面的链接。<strong class="lb iu">库</strong>还包含<strong class="lb iu">我构建和编译的各种其他SageMaker推理示例</strong>，你可以参考使用。多模型端点非常强大且经济高效，因为您可以将多个模型加载到一个端点中，而不是将一个端点与每个模型相关联。如果你有这些框架的用例，还有更多关于<a class="ae ky" href="https://github.com/aws/amazon-sagemaker-examples/tree/master/advanced_functionality/multi_model_sklearn_home_value" rel="noopener ugc nofollow" target="_blank"> SKLearn </a>和<a class="ae ky" href="https://github.com/aws/amazon-sagemaker-examples/tree/master/advanced_functionality/multi_model_pytorch" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>的例子。</p><p id="6927" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇文章对使用Amazon SageMaker的人有用。如果你对ML AWS感兴趣，欢迎在评论中留下你的反馈或者在LinkedIn上联系我。如果对我的更多作品感兴趣，请务必关注我的<a class="ae ky" href="https://ram-vegiraju.medium.com/" rel="noopener"> Medium </a>。感谢您的阅读。</p></div></div>    
</body>
</html>