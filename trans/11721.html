<html>
<head>
<title>Still Saving Your Data in CSV? Try these other options</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">还在用CSV格式保存数据吗？尝试这些其他选项</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/still-saving-your-data-in-csv-try-these-other-options-9abe8b83db3a?source=collection_archive---------0-----------------------#2021-11-22">https://towardsdatascience.com/still-saving-your-data-in-csv-try-these-other-options-9abe8b83db3a?source=collection_archive---------0-----------------------#2021-11-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ba80" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何以不同的格式(CSV、压缩、Pickle和Parquet)保存数据，以节省存储空间并减少读/写时间和资金</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0ead2d8891fccd94bd70df0c1df3fb4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CyorCOZs0j2ZB7jB"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@andrescanavesi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">安德烈斯·卡纳维西</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="bc37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保存数据帧最流行的文件格式之一是CSV(逗号分隔值)。CSV是众所周知的，并在各种平台上得到广泛支持。然而，尽管CSV无处不在，但当您处理大量数据时，它并不是一种合适的格式——其大小会变得非常大，并且从中提取数据会变得非常慢。</p><p id="49ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将向您介绍将数据帧保存到存储时的一些选项。特别是，我将讨论将您的数据帧保存为:</p><ul class=""><li id="af32" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">CSV文件</li><li id="6cc0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">应用压缩的CSV文件</li><li id="49a6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用pickle模块的二进制文件</li><li id="59ea" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用pickle模块并应用了压缩的二进制文件</li><li id="d869" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">HDF文件</li><li id="f02a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">镶木地板</li></ul><h1 id="fec6" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">我们的样本数据集</h1><p id="bedd" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我在本文中使用的样本数据集名为<strong class="lb iu"> travel insurance.csv </strong>(来源:<a class="ae ky" href="https://www.kaggle.com/mhdzahier/travel-insurance" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/mhdzahier/travel-insurance</a><strong class="lb iu">)</strong>。它有63，326行和11列，混合了object、int64和float64列。让我们用熊猫作为数据帧来加载它:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="9887" class="nl mk it nh b gy nm nn l no np"><strong class="nh iu">import pandas as pd<br/>import os</strong></span><span id="7a93" class="nl mk it nh b gy nq nn l no np"><strong class="nh iu">filename = 'travel insurance'<br/>df = pd.read_csv(filename + '.csv')</strong></span><span id="cd0f" class="nl mk it nh b gy nq nn l no np"><strong class="nh iu">display(df)<br/>display(df.shape)   # (63326, 11)<br/>display(df.dtypes)  <br/></strong># Agency                   object<br/># Agency Type              object<br/># Distribution Channel     object<br/># Product Name             object<br/># Claim                    object<br/># Duration                  int64<br/># Destination              object<br/># Net Sales               float64<br/># Commision (in value)    float64<br/># Gender                   object<br/># Age                       int64<br/># dtype: object</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/b7908e7227cc08d5cd5b2429b907be6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RhTivf7GvEvEGfo32-qkxw.png"/></div></div></figure><p id="3394" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了记录每种数据格式的文件大小、写入和读取时间，我将创建一个包含四列的数据帧:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7ef1" class="nl mk it nh b gy nm nn l no np">df_results = pd.DataFrame(columns=<br/>    ['method', 'file_size', 'write_time', 'read_time'])<br/>display(df_results)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/e58881e7bf4045a1d9f5d4aa9707add1.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*-qRZViJJqMGSBi9LFrxA3A.png"/></div></figure><p id="dc3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还将创建一个helper函数，向包含每个实验细节的数据帧追加一行:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0da2" class="nl mk it nh b gy nm nn l no np">def add_result(df_results, method, file_size, <br/>               write_time, read_time):<br/>    row = {<br/>        'method': method,<br/>        'file_size': file_size, <br/>        'write_time': write_time, <br/>        'read_time':  read_time   <br/>      }<br/>    return df_results.append(pd.Series(row), ignore_index = True)</span></pre><h1 id="88ba" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">另存为CSV文件</h1><p id="5c05" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我想尝试的第一种方法是将数据帧保存为CSV文件，然后读回它。以下代码块执行以下操作:</p><ul class=""><li id="7f1d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">将数据帧保存为CSV文件</li><li id="6db0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">获取物理CSV文件的大小</li><li id="5782" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">再次将CSV文件作为数据帧加载</li><li id="1e7e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将使用的方法、文件的大小、将数据帧写入文件并再次加载回数据帧所需的平均时间写入<code class="fe nt nu nv nh b">df_results</code>数据帧</li></ul><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="180c" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o <strong class="nh iu">df.to_csv</strong>(filename + '_csv.csv')</span><span id="2e7f" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '_csv.csv') / 1024**2</span><span id="94c5" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o <strong class="nh iu">pd.read_csv</strong>(filename + '_csv.csv')</span><span id="9ff8" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'CSV',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)<br/>df_results</span></pre><p id="2b5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特别是，我使用了<code class="fe nt nu nv nh b"><strong class="lb iu">%timeit</strong></code>这个神奇的命令来记录系统执行一条语句所花费的时间。例如，下面一行记录了系统将数据帧保存到CSV文件所花费的时间:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="dd5d" class="nl mk it nh b gy nm nn l no np"><strong class="nh iu">%timeit -n5 -r5 -o</strong> df.to_csv(filename + '_csv.csv')</span></pre><p id="ba1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nt nu nv nh b">%timeit</code>魔法命令有以下选项:</p><ul class=""><li id="0ff2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe nt nu nv nh b"><strong class="lb iu">-n5</strong></code>选项意味着您希望在一个循环中运行该语句5次。</li><li id="b90a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe nt nu nv nh b"><strong class="lb iu">-r5</strong></code>表示循环运行5次，取最佳结果。这允许我们获得读写文件的平均操作时间。</li><li id="0558" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> -o </strong>选项表示您希望返回计时结果，而不是将其打印出来。在这种情况下，结果被传递给写部分的<code class="fe nt nu nv nh b">result_save</code>变量和读部分的<code class="fe nt nu nv nh b">result_read</code>。</li><li id="c9b5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用从<code class="fe nt nu nv nh b">%timeit</code>命令返回的结果，您可以使用<code class="fe nt nu nv nh b">average</code>属性获得执行写和读操作所需的平均时间。</li></ul><p id="f5cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了写入和读取的结果，现在可以调用<code class="fe nt nu nv nh b">add_result()</code>函数将结果添加到dataframe中。对于这一部分，我得到了以下结果:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f2ac" class="nl mk it nh b gy nm nn l no np">165 ms ± 7.11 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)<br/>50.4 ms ± 9.32 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)</span></pre><p id="ebc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nt nu nv nh b">df_result</code>数据帧看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/2e90f90f0794915b38fb252082101d79.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*YPQeD4HN62Iq6lBPiW_Gyg.png"/></div></figure><p id="7d05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文件大小以兆字节(MB)为单位，时间以秒为单位。</p><h2 id="156a" class="nl mk it bd ml nx ny dn mp nz oa dp mt li ob oc mv lm od oe mx lq of og mz oh bi translated">保存不带索引的CSV</h2><p id="66ec" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">默认情况下，将数据帧保存为CSV文件时，会保存其索引。然而，大多数时候没有必要将索引(它只是一系列流水号)保存到CSV文件中。所以这一次我们将省略它:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0676" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o df.to_csv(filename + '_csv.csv', \<br/>                                           <strong class="nh iu">index=False</strong>)</span><span id="5d5f" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '_csv.csv') / 1024**2</span><span id="5747" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o pd.read_csv(filename + '_csv.csv')</span><span id="5bc7" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'CSV No Index',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="f2e8" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="6d98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/7b7fa2aaf0a1ad69bcd3584b7661e1d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*fwjREGX6m7vKxiHPl5uVZA.png"/></div></figure><p id="8d52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以看到，文件大小略有减小，写入和读取时间都缩短了。</p><h1 id="c762" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">对CSV使用压缩</h1><p id="6ab6" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">当你保存数据帧到CSV文件时，Pandas支持压缩。具体来说，Pandas支持以下压缩算法:</p><ul class=""><li id="d9d6" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">gzip</li><li id="a93b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">bz2</li><li id="0807" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">活力</li><li id="1664" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">xz</li></ul><p id="cfeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看压缩将如何有助于文件大小以及写入和读取时间。</p><h2 id="349e" class="nl mk it bd ml nx ny dn mp nz oa dp mt li ob oc mv lm od oe mx lq of og mz oh bi translated">GZIP</h2><p id="0931" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">要在将数据帧保存为CSV格式时使用压缩，请将<strong class="lb iu">压缩</strong>参数设置为您想要使用的算法。同样，当您加载压缩的CSV文件时，将<strong class="lb iu">压缩</strong>参数设置为用于压缩文件的算法:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="5483" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o df.to_csv(filename + '.gzip', \<br/>                                           index=False, \<br/>                                           <strong class="nh iu">compression='gzip'</strong>)</span><span id="87bd" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.gzip') / 1024**2</span><span id="4155" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o pd.read_csv(filename + '.gzip', \<br/>                                             <strong class="nh iu">compression='gzip'</strong>)</span><span id="5bd4" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'CSV No Index (GZIP)',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="b854" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="d6b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/f1157b5031c64a8c0c05109c07493cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*r0n_EJPgRffzU9jLhby_xQ.png"/></div></figure><p id="fec2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文件大小大幅减少。写入时间稍长，但读取时间与解压缩版本相当。</p><blockquote class="ok ol om"><p id="1fff" class="kz la on lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">有关GZIP的更多信息，请参考:<a class="ae ky" href="https://en.wikipedia.org/wiki/Gzip" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Gzip</a></p></blockquote><h2 id="60e7" class="nl mk it bd ml nx ny dn mp nz oa dp mt li ob oc mv lm od oe mx lq of og mz oh bi translated">BZ2</h2><p id="6097" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">另一种流行的文件压缩算法被称为BZ2。以下代码片段显示了如何使用BZ2压缩数据帧:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="6244" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o df.to_csv(filename + '.bz2', \<br/>                                           index=False, \<br/>                                           <strong class="nh iu">compression='bz2'</strong>)</span><span id="5f1f" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.bz2') / 1024**2</span><span id="3558" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o pd.read_csv(filename + '.bz2', \<br/>                                             <strong class="nh iu">compression='bz2'</strong>)</span><span id="62bb" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'CSV No Index (BZ2)',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="df17" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="b000" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/a9ea4b1325e405fd7c15827bed5bf3da.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Enh4d1RVCgpHlx0zaxh4JQ.png"/></div></figure><p id="7ed1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以观察到，与GZIP相比，BZ2的压缩率更高，但是相应的读写速度更慢。</p><blockquote class="ok ol om"><p id="d60e" class="kz la on lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">有关BZ2的更多信息，请参考:<a class="ae ky" href="https://en.wikipedia.org/wiki/Bzip2" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Bzip2</a></p></blockquote><h1 id="0dbd" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">泡菜</h1><p id="8470" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">CSV文件是纯文本文件(压缩文件除外)，这使得它们无处不在，在所有平台和所有主流软件上都受支持。然而，CSV的主要缺点是它的大小。您可以将数据帧保存为二进制文件，而不是将数据帧保存为纯文本文件。</p><p id="d890" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Python中，可以使用<strong class="lb iu"> pickle </strong>模块将数据(包括数据帧)作为二进制文件持久化。<strong class="lb iu"> pickle </strong>模块<em class="on">将Python中的对象序列化</em>为二进制文件，然后<em class="on">将二进制文件反序列化</em>为Python中的对象。</p><p id="4b78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们尝试使用<strong class="lb iu"> pickle </strong>保存我们的数据帧:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="afdd" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o <strong class="nh iu">df.to_pickle(filename + '.pkl')</strong></span><span id="88e0" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.pkl') / 1024**2</span><span id="4e14" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o <strong class="nh iu">pd.read_pickle(filename + '.pkl')</strong></span><span id="7727" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'Pickle',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="a05e" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="e364" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/bf0140faaf1d39a0903a1f33d14879da.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Cyeaewn9Iq0XbRp30E3hLw.png"/></div></figure><p id="2d1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文件大小小于CSV文件，但大于对CSV文件使用压缩时的大小。但是，请注意，到目前为止，写入和读取时间是最快的。</p><h2 id="14bd" class="nl mk it bd ml nx ny dn mp nz oa dp mt li ob oc mv lm od oe mx lq of og mz oh bi translated">压缩使用泡菜</h2><p id="75f7" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">像另存为CSV一样，也可以用pickle进行压缩。首先，让我们用<strong class="lb iu"> GZIP </strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="092e" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o <strong class="nh iu">df.to_pickle(filename + '.pkl', \<br/>                                              </strong>compression='gzip'<strong class="nh iu">)</strong></span><span id="ba76" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.pkl') / 1024**2</span><span id="6c46" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o <strong class="nh iu">pd.read_pickle(filename + '.pkl', \<br/>                                                compression='gzip')</strong></span><span id="3c2c" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'Pickle (GZIP)',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="5fb4" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="857d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/d927efecae2c30a682af04a139735e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*HXAC74TZNv4pwl08GFMQFw.png"/></div></div></figure><p id="15e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们用<strong class="lb iu"> BZ2 </strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="79ee" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o <strong class="nh iu">df.to_pickle(filename + '.pkl', \<br/>                                              compression='bz2')</strong></span><span id="7290" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.pkl') / 1024**2</span><span id="583c" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o <strong class="nh iu">pd.read_pickle(filename + '.pkl', \<br/>                                                compression='bz2')</strong></span><span id="9f65" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'Pickle (BZ2)',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="a386" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="a5ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/753c9ea64db0ee009f96ba1942d0651b.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*2r-jSZ8jao70UQLaNOPKiQ.png"/></div></figure><p id="7311" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们使用<strong class="lb iu"> zip </strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f7b9" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o <strong class="nh iu">df.to_pickle(filename + '.pkl', \<br/>                                              compression='zip')</strong></span><span id="3ba4" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.pkl') / 1024**2</span><span id="1f65" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o <strong class="nh iu">pd.read_pickle(filename + '.pkl', \<br/>                                                compression='zip')</strong></span><span id="4f43" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'Pickle (ZIP)',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="e5ec" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="7d23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/8b40dfeaa046bd32bec096526adc0eb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*OReFZbMmfR9clxX4HfJcnA.png"/></div></div></figure><blockquote class="ok ol om"><p id="1e46" class="kz la on lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">关于zip的更多信息，请参考:<a class="ae ky" href="https://en.wikipedia.org/wiki/ZIP_(file_format)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/ZIP _(file _ format)</a></p></blockquote><p id="1ab3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们使用<strong class="lb iu"> xz </strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f75a" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o df.to_pickle(filename + '.pkl', \<br/>                                              compression='xz')</span><span id="6ede" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.pkl') / 1024**2</span><span id="d844" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o pd.read_pickle(filename + '.pkl', \<br/>                                                compression='xz')</span><span id="a78c" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'Pickle (xz)',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="cc76" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="1da0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/1d703ce103d06c74a2a18f12381a0b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*bIWnNseftUKd_iJ5qZhOGg.png"/></div></figure><blockquote class="ok ol om"><p id="cde0" class="kz la on lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">关于xz的更多信息，请参考:<a class="ae ky" href="https://en.wikipedia.org/wiki/XZ_Utils" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/XZ_Utils</a></p></blockquote><p id="1860" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从结果中可以看出，在pickle中使用压缩大大减小了文件的大小，而与不使用压缩相比，写入和读取时间略有增加。</p><h1 id="74a1" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">HDF</h1><p id="7243" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">另一种可以用来保存数据帧的文件格式是<strong class="lb iu"> HDF </strong> — <strong class="lb iu">分层数据格式</strong>。HDF是一种开源文件格式，支持大型、复杂、异构的数据。HDF使用类似于文件目录的结构来组织文件中的数据。</p><blockquote class="ok ol om"><p id="e016" class="kz la on lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">可以把HDF想象成一种文件结构，它允许你在一个物理文件中存储不同的数据帧。</p></blockquote><p id="d6ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下代码片段将数据帧保存为HDF文件:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ba90" class="nl mk it nh b gy nm nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o <strong class="nh iu">df.to_hdf(filename + '.h5', \<br/>                                           key='key', \<br/>                                           mode='w')</strong></span><span id="2d74" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.h5') / 1024**2</span><span id="7638" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o <strong class="nh iu">pd.read_hdf(filename + '.h5', \<br/>                                             key='key', \<br/>                                             mode='r')</strong></span><span id="4fba" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'HDF',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="a70c" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="7aa7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/a3f87ba88555a839ada98d591fa7a1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*Fa4pkrJskN5xz8W2EcGh3A.png"/></div></figure><p id="8e6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如您所观察到的，另存为HDF并没有真正减少文件大小，即使写时间比原始CSV好。</p><h1 id="9394" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">镶木地板</h1><p id="bdf4" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我要讨论的最后一个文件格式是<strong class="lb iu"> Parquet </strong>。那么什么是拼花，或者更准确的说，<strong class="lb iu"> <em class="on">阿帕奇拼花</em> </strong>？</p><p id="1014" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Apache Parquet是一种文件格式，旨在支持复杂数据的快速数据处理。它是Apache Hadoop许可下的开源文件格式，与大多数Hadoop处理框架兼容。Parquet是自描述的——包括模式和结构的元数据嵌入在每个文件中。</p><p id="6071" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更重要的是，Parquet将数据存储在<em class="on">列</em>中，而不是<em class="on">行</em>中。</p><h2 id="4203" class="nl mk it bd ml nx ny dn mp nz oa dp mt li ob oc mv lm od oe mx lq of og mz oh bi translated">Parquet如何存储您的数据</h2><p id="9199" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">考虑以下具有三列的数据帧:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/01b9f16511dd29144af5b82e086db56c.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*DSGIpQk1bchUz1ins7Gqaw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="6f80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您将数据帧保存为CSV文件时，它使用<em class="on">基于行的存储</em>。将CSV文件加载到数据帧中时，每行一次加载一行，每行包含三种不同的数据类型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/bc0ae6f1b6db44a31775bb4ca98452fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*-Nthymj7AWn_G0k2p854dg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="3e91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，Parquet使用基于列的存储方式来存储数据。每列数据都被组织为一个特定数据类型的列:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/36ad0fa01140f281b380fa184641a417.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*50EitzORtcaxeG0mfGWT5g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="b544" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，当您在基于列的存储中组织数据时，您的文件将更加轻量级，因为所有相似的数据类型都被分组在一起，并且您可以对每一列应用压缩。更重要的是，使用基于列的存储使得提取特定列变得非常有效，这是数据分析项目中经常要做的事情。</p><p id="f255" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要使用拼花地板，您需要安装<strong class="lb iu">快速拼花地板</strong>模块:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ceef" class="nl mk it nh b gy nm nn l no np"><strong class="nh iu">!pip install fastparquet</strong></span></pre><p id="1ed0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下代码片段将dataframe保存到一个parquet文件中，然后将其加载回来:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f53d" class="nl mk it nh b gy nm nn l no np"># !parq Building_Permits.parquet --head 10</span><span id="0a8c" class="nl mk it nh b gy nq nn l no np">#---saving---<br/>result_save = %timeit -n5 -r5 -o <strong class="nh iu">df.to_parquet(filename + \<br/>                                               '.parquet', \<br/>                                               engine='fastparquet')</strong></span><span id="6de9" class="nl mk it nh b gy nq nn l no np">#---get the size of file---<br/>filesize = os.path.getsize(filename + '.parquet') / 1024**2</span><span id="4c89" class="nl mk it nh b gy nq nn l no np">#---load---<br/>result_read = %timeit -n5 -r5 -o <strong class="nh iu">pd.read_parquet(filename + \<br/>                                                 '.parquet')</strong></span><span id="6632" class="nl mk it nh b gy nq nn l no np">#---save the result to the dataframe---<br/>df_results = add_result(df_results,<br/>                        'Parquet',<br/>                        filesize, <br/>                        result_save.average, <br/>                        result_read.average)</span><span id="75d1" class="nl mk it nh b gy nq nn l no np">df_results</span></pre><p id="6dbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我得到以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/cf6b59bdd345f467e1ac806050448db8.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*i1fRV7dcRwNfm3oqwGgwcA.png"/></div></figure><p id="0b59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从结果中，您可以看到文件大小显著减小(虽然没有在CSV或pickle上使用压缩那么大，但这种减小仍然是显著的)，并且写入和读取时间是最快的。</p><p id="2a0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么拼花地板为什么有用，为什么要用呢？为什么应该使用拼花地板而不是CSV存储数据，有几个令人信服的理由:</p><ul class=""><li id="201c" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">云服务(如AWS和谷歌)根据你的数据大小收费。拼花文件比CSV文件小得多，这意味着您为云存储支付的费用更少。</li><li id="5887" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">云服务也根据每次查询扫描的数据收费。在上面的结果中，你可以看到读写时间比CSV文件快。更短的扫描时间意味着更低的云电荷。</li></ul><p id="468d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了查看parquet在加载特定列时与CSV文件相比的性能，让我们尝试以下实验，我们将从三个CSV文件(一个未压缩，一个用BZ2压缩，一个用GZIP压缩)和一个Parquet文件中加载两列(<strong class="lb iu">代理类型</strong>和<strong class="lb iu">产品名称</strong>):</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="5cc9" class="nl mk it nh b gy nm nn l no np">%timeit -n5 -r5 -o <strong class="nh iu">pd.read_csv(filename + '_csv.csv', \<br/>                             usecols=['Agency Type','Product Name'])</strong></span><span id="8614" class="nl mk it nh b gy nq nn l no np">%timeit -n5 -r5 -o <strong class="nh iu">pd.read_csv(filename + '.bz2', \<br/>                           usecols=['Agency Type','Product Name'], \<br/>                           compression='bz2')</strong></span><span id="55c5" class="nl mk it nh b gy nq nn l no np">%timeit -n5 -r5 -o<strong class="nh iu"> pd.read_csv(filename + '.gzip', \<br/>                           usecols=['Agency Type','Product Name'], \<br/>                           compression='gzip')</strong></span><span id="9587" class="nl mk it nh b gy nq nn l no np">%timeit -n5 -r5 -o <strong class="nh iu">pd.read_parquet(filename + '.parquet', \<br/>                           columns=['Agency Type','Product Name'])</strong></span></pre><p id="7e35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述语句返回以下结果:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="fa68" class="nl mk it nh b gy nm nn l no np">27.4 ms ± 6.23 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)</span><span id="3c39" class="nl mk it nh b gy nq nn l no np">77.4 ms ± 3.26 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)</span><span id="09ee" class="nl mk it nh b gy nq nn l no np">35 ms ± 2.15 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)</span><span id="7698" class="nl mk it nh b gy nq nn l no np"><strong class="nh iu">4.72 ms ± 1.73 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)</strong></span></pre><p id="e08f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后的结果(使用拼花地板)轻而易举地击败了其他人。使用Parquet检索这两列平均需要4.72毫秒，而CSV文件需要27到77毫秒。</p><h1 id="6776" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">为每项任务寻找最佳方法</h1><p id="04cd" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在我们已经有了各种方法的统计数据，我们可以很容易地找出哪种方法对于每项任务来说是最理想的。</p><p id="ddb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想最小化读取时间，使用<strong class="lb iu"> pickle </strong>保存是最好的解决方案:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="adc8" class="nl mk it nh b gy nm nn l no np">df_results.sort_values(by='read_time')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/c262d6f1d51f46d56f98498c92267fb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*8BF4NSugFumfWXDwCPum2Q.png"/></div></figure><p id="ac77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，就读取时间而言，Parquet紧随其后。此外，它还大大减少了文件大小。如前一节所述，在云服务上存储数据时，最大限度地减少读取时间和存储对于降低成本至关重要。</p><p id="ad0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想最大限度地减少写入时间，似乎使用pickle也是保存数据帧的最佳方式:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8c84" class="nl mk it nh b gy nm nn l no np">df_results.sort_values(by='write_time')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/fcec892aec60fdbd595e235e25be85d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*GhLuTOTAevc6ZMiwPd6jiA.png"/></div></figure><p id="6b85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想要最小化数据帧的文件大小，请将pickle与bz2压缩算法结合使用:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ce16" class="nl mk it nh b gy nm nn l no np">df_results.sort_values(by='file_size')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/a89c462ad6c1e8d7199a6c4d3ab6484f.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*DG5clP39Iiq_zE7tcstoQg.png"/></div></figure><h1 id="9e51" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">摘要</h1><p id="a791" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">本文讨论了一些可以用来保存数据帧的文件格式。这绝不是一个详尽的测试，但它让您对每种文件格式的性能有一个总体的感觉。值得注意的是，我在本文中获得的结果是特定于我的数据集的。不同的数据集可能会有不同的结果，这取决于您拥有的数据类型。如果数据集有很多对象(文本)列，压缩会非常有效。重要的是，使用本文中描述的各种方法测试数据集，并得出自己的结论。特别是，比较最常执行的操作的统计数据，并决定哪种方法更适合您的数据。</p><div class="pb pc gp gr pd pe"><a href="https://weimenglee.medium.com/membership" rel="noopener follow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd iu gy z fp pj fr fs pk fu fw is bi translated">加入媒介与我的介绍链接-李伟孟</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">weimenglee.medium.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps ks pe"/></div></div></a></div></div></div>    
</body>
</html>