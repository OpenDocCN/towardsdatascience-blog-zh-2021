<html>
<head>
<title>Apple’s NeuralHash — How it works and how it might be compromised</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">苹果的neural hash——它是如何工作的，以及它可能如何受到损害</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apples-neuralhash-how-it-works-and-ways-to-break-it-577d1edc9838?source=collection_archive---------5-----------------------#2021-08-20">https://towardsdatascience.com/apples-neuralhash-how-it-works-and-ways-to-break-it-577d1edc9838?source=collection_archive---------5-----------------------#2021-08-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="56fe" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/ai-alignment-and-safety" rel="noopener" target="_blank">人工智能校准和安全</a></h2><div class=""/><div class=""><h2 id="6344" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">技术指南、其漏洞和可能的缓解措施</h2></div><p id="ef02" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">苹果公司最近宣布了各种措施来打击儿童性虐待材料的传播(CSAM)。</p><blockquote class="lk ll lm"><p id="fb8d" class="ko kp ln kq b kr ks ka kt ku kv kd kw lo ky kz la lp lc ld le lq lg lh li lj ij bi translated">接下来，iOS和iPadOS将使用加密技术的新应用来帮助限制CSAM病毒在网上的传播，同时为用户隐私进行设计。CSAM检测将帮助苹果公司向执法部门提供关于iCloud照片中CSAM收藏的有价值的信息。<br/> —苹果<a class="ae lr" href="https://www.apple.com/child-safety/" rel="noopener ugc nofollow" target="_blank">声明</a>宣布这些措施</p></blockquote><p id="1fcb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中包括使用一种被称为<a class="ae lr" href="https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf" rel="noopener ugc nofollow" target="_blank"> NeuralHash </a>的新技术扫描CSAM的iCloud照片。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/ffa3d87e1d6f4c474c688f97887109d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*npz1xvLwOsQ0To-F9cme8g.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者图片，灵感来自苹果关于CSAM探测的<a class="ae lr" href="https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf" rel="noopener ugc nofollow" target="_blank">技术总结</a>。这里列出的散列并不是真正的CSAM散列。这不包括细节，如致盲步骤。有关详细的图表，请参考技术总结。</p></figure><h1 id="a078" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">苹果在扫描我的照片？！？</h1><p id="cfeb" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">“扫描”可能是一个错误的词。实际上，苹果打算在不看你照片的情况下检查CSAM。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nf"><img src="../Images/54620ced073821c3419a3984508a9fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lfXwuqWC5Kqd61-h"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">照片由<a class="ae lr" href="https://unsplash.com/@macroman?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Immo Wegmann </a>在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="3edf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">考虑一下指纹的概念——每个人都有其独特之处。它识别一个人，但它本身并不能告诉你这个人的任何信息。在计算机科学中，一个<strong class="kq ja">散列函数</strong>帮助我们计算一个<strong class="kq ja">散列</strong>，它的作用就像一个文件的指纹。散列对于文件来说(有点)是唯一的，但是它本身并不能告诉我们关于文件内容的任何事情。</p><p id="391b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果两个文件产生相同的散列，它们很可能是同一个文件。就像如果两组指纹匹配，它们很可能来自同一个人。</p><p id="937e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">苹果打算存储一个与已知CSAM相对应的哈希数据库。然后，通过散列你所有的iCloud照片，并将你的散列与CSAM散列数据库进行比较，苹果可以在不看你的iCloud照片的情况下识别匹配。</p><p id="845c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是说起来容易做起来难。传统的哈希函数(MD5、SHA256等。)对文件中的变化非常敏感。例如，这两个图像具有完全不同的MD5散列，尽管它们看起来相同(右边的一个在宽度上短了2个像素)。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/d080b6c5410dc79d3dd91d4da2e4300c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*ug1QXapAlzQfBCkVdJAL0Q.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">(<strong class="bd nh">左</strong>原Doge <a class="ae lr" href="https://knowyourmeme.com/memes/doge" rel="noopener ugc nofollow" target="_blank"> meme </a>，MD5:53 facff 91 EC 83 f 60 a 88235 ab 628590 bb |(<strong class="bd nh">右</strong>)作者裁剪的图片，MD5:da 25273 f 33 C4 EC 95 f 71984075079 BD 16</p></figure><p id="3b4d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对变化超级敏感通常是哈希函数的一个有用特性，因为这使得判断文件是否被篡改变得非常容易。</p><p id="a435" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是如果我们用它来探测CSAM，这就成了一个巨大的限制。想象一下，如果上面左边的图像是被禁止的图像。苹果可能会存储MD5哈希<em class="ln"> 53f…0bb </em>。但是仅仅通过稍微裁剪图像，我们仍然得到看起来相同的图像(在右边)，但是具有完全不同的MD5散列值<em class="ln"> da2…d16 </em>，这将会逃避检测。</p><p id="c2cb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">更普遍的情况是，即使苹果有一个已知CSAM的数据库，CSAM经销商也可以旋转、裁剪或调整图像大小来逃避检测。苹果将不得不存储无限数量的散列，以考虑旋转、裁剪或调整图像大小的无限方式。想象一下，当人们减肥、理发或剪指甲时，他们的指纹会发生变化吗？</p><p id="3e1e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了进行检测，即使图像被轻微修改，哈希也必须相同。介绍… <strong class="kq ja">神经哈希</strong>。</p><h1 id="581d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">好吧，跟我说说这个神经哈希</h1><p id="ffd2" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">NeuralHash是一种哈希算法，对输入图像的微小变化不敏感。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/d080b6c5410dc79d3dd91d4da2e4300c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*ug1QXapAlzQfBCkVdJAL0Q.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">(<strong class="bd nh">左</strong>原Doge <a class="ae lr" href="https://knowyourmeme.com/memes/doge" rel="noopener ugc nofollow" target="_blank"> meme </a>，neural hash:11 d9 b 097 AC 960 BD 2c 6c 131 fa |(<strong class="bd nh">右</strong>)作者裁剪的图片，neural hash:11 d9 b 097 AC 960 BD 2c 6c 131 fa</p></figure><p id="0244" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于之前由于不明显的作物而具有非常不同的MD5散列的同一对图像，我们得到相同的神经散列。<br/>(本文中所有的NeuralHashes都是用<a class="ae lr" href="https://greentfrapp.github.io/compute-your-own-neuralhash" rel="noopener ugc nofollow" target="_blank">这个浏览器内演示</a>计算出来的。)</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/aa89977c1141affb956bf7d3bf894093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*L5136uQ1Qr30XRvPctTdjQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">(<strong class="bd nh">左</strong>原Doge <a class="ae lr" href="https://knowyourmeme.com/memes/doge" rel="noopener ugc nofollow" target="_blank"> meme </a>，neural hash:11 d9 b 097 AC 960 BD 2c 6c 131 fa |(<strong class="bd nh">右</strong>)图片由作者翻转，neural hash:20 D8 f 097 AC 960 ad 2c 7c 231 Fe</p></figure><p id="2fd4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">即使在图像被翻转的情况下，神经哈希的重要部分仍然相同:<br/>左神经哈希:11<strong class="kq ja">d</strong>9b<strong class="kq ja">097 AC 960</strong>b<strong class="kq ja">d2c</strong>6<strong class="kq ja">c</strong>1<strong class="kq ja">31f</strong>a<br/>右神经哈希:20<strong class="kq ja">d</strong>8f<strong class="kq ja">097 AC 960<strong class="kq ja"/></strong></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/310ec39bb16894deda225331908c13a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*3v8Qwkh9fCAoh64XQH4jUQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">(<strong class="bd nh">左</strong>原Doge <a class="ae lr" href="https://knowyourmeme.com/memes/doge" rel="noopener ugc nofollow" target="_blank"> meme </a>，neural hash:11 d9 b 097 AC 960 BD 2c 6c 131 fa |(<strong class="bd nh">右</strong>)图片由作者编辑，neural hash:11 d9 B0 b7a 8120 BD 286 C1 B1 Fe</p></figure><p id="3387" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是另一个例子，我们将一些单词叠加到图像上，但得到的NeuralHash仍然是相似的:<br/>左neural hash:<strong class="kq ja">11d9b</strong>09<strong class="kq ja">7a</strong>c96<strong class="kq ja">0bd 2</strong>c<strong class="kq ja">6 C1</strong>31<strong class="kq ja">f</strong>a<br/>右neural hash:<strong class="kq ja">11d9b</strong>0b<strong class="kq ja">7a</strong>812<strong class="kq ja"/></p><p id="0456" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在不深入细节的情况下，NeuralHash算法使用卷积神经网络(CNN)来计算哈希。在训练过程中，CNN会看到成对的图像。正对由彼此简单变换(旋转、裁剪、调整大小)的图像组成，例如上面的图像对。负像对包含完全不同的图像。CNN被训练成将正对映射到相同的散列，将负对映射到不同的散列。这样，它学会忽略应用于图像的小变换。</p><h1 id="8151" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">而你说可以破？</h1><p id="a175" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">大多数人工智能和人工智能的研究人员和学生可能听说过<strong class="kq ja">对抗性攻击</strong>，其中神经网络通过向图像添加噪声来欺骗。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ni"><img src="../Images/8dfddf43ae965133330d5c5c28a64769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UyOqEzTNAgMnel3ZYNOMCw.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者展示对抗性攻击如何欺骗人工智能模型的图片，其灵感来自<strong class="bd nh">图1中的典型熊猫示例，解释并利用了<strong class="bd nh"> </strong> <a class="ae lr" href="https://arxiv.org/abs/1412.6572" rel="noopener ugc nofollow" target="_blank"> Goodfellow等人的对抗性示例</a></strong>，2014 。</p></figure><p id="a123" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">例如，神经网络最初可能会将我们的Doge图像标记为“dingo”。但是我们可以在同一张照片上添加少量的噪声，现在神经网络将这张照片标记为“暹罗猫”。</p><p id="e08e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些攻击在人工智能社区中已经广为人知好几年了，研究人员之间一直在开发对抗性攻击和防御。</p><p id="a43e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在NeuralHash算法中，同样的攻击可以很容易地应用于CNN。8月中旬，Reddit用户AsuharietYgvar <a class="ae lr" href="https://old.reddit.com/r/MachineLearning/comments/p6hsoh/p_appleneuralhash2onnx_reverseengineered_apple/" rel="noopener ugc nofollow" target="_blank">发布了关于如何导出苹果NeuralHash模型副本的</a> <a class="ae lr" href="https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX" rel="noopener ugc nofollow" target="_blank">指令</a>。<a class="ae lr" href="https://github.com/greentfrapp/apple-neuralhash-attack" rel="noopener ugc nofollow" target="_blank">几个</a> <a class="ae lr" href="https://github.com/anishathalye/neural-hash-collider" rel="noopener ugc nofollow" target="_blank">脚本</a> <a class="ae lr" href="https://gist.github.com/unrealwill/c480371c3a4bf3abb29856c29197c0be" rel="noopener ugc nofollow" target="_blank">出现</a>演示成功的攻击仅仅几个小时后。</p><p id="0aa6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对NeuralHash模型的对抗性攻击有两种形式。第一种类型的攻击——让我们称之为“不同的图像，相同的哈希”——将噪声添加到源图像，以便得到的神经哈希与目标图像相同。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/c55b81109894ff404a35bd6caa094e01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*LYzCk9IV_zL8AlNZ7kxqdg.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">一个哈希碰撞对的例子，由作者从<a class="ae lr" href="https://knowyourmeme.com/memes/doge" rel="noopener ugc nofollow" target="_blank"> Doge </a> ( <strong class="bd nh">左</strong>)和<a class="ae lr" href="https://knowyourmeme.com/memes/grumpy-cat" rel="noopener ugc nofollow" target="_blank"> Grumpy Cat </a> ( <strong class="bd nh">右</strong>)模因中生成。两张图像都有相同的neural hash 11 d9b 097 AC 960 BD 2c 6c 131 fa，在给暴躁猫图像添加噪声之后。</p></figure><p id="02d4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在上面的例子中，噪声被添加到Grump猫图像中，因此结果具有与Doge图像完全相同的NeuralHash。这也被称为<strong class="kq ja">哈希冲突</strong>——从不同的图像中计算出相同的哈希。这是有问题的，因为这意味着有人可以在无害的图像中添加噪声，使它们对应于CSAM神经哈希，然后伪装成常规图像，在随机网站上分发它们。这些伪造的CSAM图像会在苹果的服务器上引起假警报，导致人们被错误地标记。同样的攻击也可以用来将CSAM伪装成普通的图像。</p><p id="ae7b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">另一种攻击——让我们称之为“相同的图像，不同的哈希”——增加了一点点噪声，但极大地改变了神经哈希。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/00161d057f6ce57d20b4bc257f946624.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*qkJcrHkv4UtgTqHrOD5KOg.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">(<strong class="bd nh">左</strong>原Doge <a class="ae lr" href="https://knowyourmeme.com/memes/doge" rel="noopener ugc nofollow" target="_blank"> meme </a>，neural hash:11 d9 b 097 AC 960 BD 2c 6c 131 fa |(<strong class="bd nh">右</strong>)图片由作者生成，neural hash:F8 D1 b 897 a 45 E0 BF 2 f 7 E1 b 0 Fe</p></figure><p id="99c3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这个例子中，即使两幅图像看起来很相似(我们在右边添加了一些浅黄绿色斑点的噪声),但神经哈希却完全不同。该噪音是特制的，用于攻击为NeuralHash供电的底层CNN。与之前的例子相比，我们在图像中添加了一些单词，但是神经哈希仍然基本相似。</p><p id="12de" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">通过这种攻击，CSAM的经销商可以通过在他们的图像中添加一点点噪声并极大地改变结果的神经哈希值来逃避检测。如上所示，这可能是少量的噪声，不会显著降低图像质量。</p><h1 id="95ca" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">不要给我带来问题，给我带来解决方案</h1><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nj"><img src="../Images/fa375bf58acd83300d9adb8d53aae9f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kgUP9g08js4WEm90"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">照片由<a class="ae lr" href="https://unsplash.com/@rirri01?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">里里</a>在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="8728" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">避免这些攻击的一个方法是永远不要在用户设备上存储CNN。没有CNN的权重，这些攻击将更加困难。然而，这也意味着苹果在他们的服务器上运行哈希算法，这反过来意味着我们所有的iCloud照片都将被共享。</p><p id="8399" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">或者，苹果可以在许多CNN型号上运行NeuralHash，而不是只有一个型号。使用许多模型增加了产生这些攻击的难度，因为攻击必须同时欺骗所有的模型。然而，这增加了必须在设备上完成的计算，这对于用户来说可能是不期望的。</p><p id="4e77" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">另一个可能的解决方案是在哈希之前对图像进行一些预处理，例如将它改为黑白，增加对比度或生成多个随机裁剪和旋转。这是有帮助的，因为攻击有时是脆弱的，并且可能被充分的预处理所否定。</p></div><div class="ab cl nk nl hu nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="ij ik il im in"><p id="93bb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">NeuralHash算法是一项新技术，其漏洞的程度可能还没有被完全探索。虽然我对苹果抗击CSAM的意图感到振奋，但我会鼓励研究人员继续研究该系统的潜在弱点，以期加以改进。希望这是对NeuralHash技术的一个很好的概述！尝试运行算法<a class="ae lr" href="https://greentfrapp.github.io/compute-your-own-neuralhash" rel="noopener ugc nofollow" target="_blank">这里</a>！</p></div></div>    
</body>
</html>