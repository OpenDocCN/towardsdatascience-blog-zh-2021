<html>
<head>
<title>An example of predicting ratings with SVD in a collaborative filtering recommendation system</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">协同过滤推荐系统中用SVD预测评分的一个例子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predict-ratings-with-svd-in-collaborative-filtering-recommendation-system-733aaa768b14?source=collection_archive---------15-----------------------#2021-03-30">https://towardsdatascience.com/predict-ratings-with-svd-in-collaborative-filtering-recommendation-system-733aaa768b14?source=collection_archive---------15-----------------------#2021-03-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5ee8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何将奇异值分解转换为k维并进行预测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/092b6f30791fc95ee422cb5cebf98196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aYM93Vik51P4wr7gCSdd3A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自维基的乔治-约翰的照片<a class="ae ky" href="http://By Georg-Johann - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=11342212" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="40fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们知道SVD在现实中进行预测有缺点，例如，它甚至不能预测数据集中是否有NaN，但因为这是协作过滤的起点，我想用SVD重现这个过程，看看它是如何工作的，并对数据集进行一些压缩。</p><p id="5946" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个故事将集中在SVD的代码实现上，没有离线测试(没有训练测试数据集的分割)，并且包括一些与线性代数相关的基本术语。</p><p id="091d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">线性代数基础</strong></p><p id="804e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">奇异值分解</strong>是奇异值分解。详细说明见<a class="ae ky" href="https://en.wikipedia.org/wiki/Singular_value_decomposition" rel="noopener ugc nofollow" target="_blank">维基</a>。在这里，我更喜欢推荐系统(RS)的这种解释:它是原始SVD的k阶近似。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/25a2e86d0be782a2f21d60e53edeae30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ugiKpYrOKTfva-zS91GDg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自StackExchange的信息[3]</p></figure><p id="0cfa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">潜在特征</strong>:对应于SVD中的σ。在数据中不能直接观察到的值，但当查看观察到的数据值之间存在的关系和趋势时，可能会识别出这些值[2]。最新特征的数量是西格玛在SVD中的等级。</p><p id="0726" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">欧氏距离:</strong></p><p id="0227" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">欧几里德距离可以看作是两个向量之间的直线距离。对于两个向量<strong class="lb iu"> x </strong>和<strong class="lb iu"> y </strong>，我们可以计算为[2]:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/c8f9b72055785904598a386019b4f324.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*MqSYnTE8t47nNpB6OJOktQ.png"/></div></figure><blockquote class="lx"><p id="135c" class="ly lz it bd ma mb mc md me mf mg lu dk translated"><strong class="ak">我想强调的难点</strong>(至少从我的学习经验来看)是一旦我们知道了U、σ和Vt，如何将原始的SVD转换成k维空间，以及如何将它们与预测联系起来。榜样永远是有效的学习方式。</p></blockquote><p id="9fad" class="pw-post-body-paragraph kz la it lb b lc mh ju le lf mi jx lh li mj lk ll lm mk lo lp lq ml ls lt lu im bi translated"><strong class="lb iu">代码示例</strong></p><p id="19bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据集妥协</strong></p><p id="28a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">协作过滤(这里是基于用户项的)中的RS的目标是预测评级，并且在用户没有评级的情况下做出推荐。</p><p id="41e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是SVD无法预测矩阵中是否有NaN值，用户必须存在于当前已知的费率系统中并给出费率。</p><p id="28b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我觉得有矛盾，但也许我错在这里(如果你找到原因，会感激地指出来)。</p><blockquote class="lx"><p id="69b3" class="ly lz it bd ma mb mm mn mo mp mq lu dk translated">要创建数据集，这里<strong class="ak">折衷</strong>:如果用户没有给电影评分，那么用0填充(如果评分中有0，就会有冲突)。</p></blockquote><p id="12f1" class="pw-post-body-paragraph kz la it lb b lc mh ju le lf mi jx lh li mj lk ll lm mk lo lp lq ml ls lt lu im bi translated">请不要在此处推荐Funk SVD。因为我想在这个故事中了解SVD过程的优点和缺点。</p><p id="a7b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们开始吧。参考代码在这里(中文)【1】。我对它做了一些修改。</p><p id="8fa9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该代码由以下步骤组成:</p><ol class=""><li id="1790" class="mr ms it lb b lc ld lf lg li mt lm mu lq mv lu mw mx my mz bi translated">创建数据集</li><li id="f242" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">计算相似度</li><li id="00a3" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">决定k</li><li id="8be5" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">将原始SVD转换为k维</li><li id="c0ee" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">通过预测评分(原始评分为零)为特定用户进行推荐</li></ol><p id="fc90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">导入库:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="1e6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">创建数据集:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="fce4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">计算相似度</strong></p><p id="44cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用欧几里德距离来度量相似性:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="5c2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">决定k</strong>:k的值由前k个奇异值的平方和占总奇异值平方和的百分比决定。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="c505" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果百分比是0.9，那么当前k个单值的平方和与sigma的总平方和之比大于0.9时，我们已经占了90%以上的权重，可以将矩阵降维到k维。</p><p id="fc50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">将原始SVD转换为k维空间:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="08ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">如何将原始SVD转换为k维，下面是关键:</strong></p><p id="1a55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原始分解的维数为:</p><p id="5071" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">u:11x11，sigma:对角矩阵11，vt: 11x11</p><p id="84c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是k=3，则量纲为:</p><p id="3837" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">u:11x3，sigma:对角矩阵3，vt: 3x11</p><p id="cb54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的代码可以构造k维矩阵:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="7ad4" class="nm nn it ni b gy no np l nq nr">formed_items=np.around(np.dot(np.dot(u[:,:k], sigma_K),vt[:k, :]),decimals=3)</span></pre><p id="b4f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">预测收视率:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="9a97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行以下命令获得结果:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="222f" class="nm nn it ni b gy no np l nq nr">testdata=loadExData()<br/>recommend(testdata,0,sim_meas=ecludSim,est_method=svdEst, percentage=0.9)</span></pre><p id="89f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用具有欧几里德距离的测试数据，如果前k个奇异值的平方和与总奇异值的平方和的百分比大于或等于0.9，则预测用户0的未分级电影的分级。</p><p id="b25b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">用户0的预测评级:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/ba3f4693dc013909578c7565c59e0d59.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*eSHaKzzzRY0THMi_KblScA.png"/></div></figure><p id="e3b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于用户1:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/135b8ff09cd471a5e2b2927f637568ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*vwpY9p14pxLjDcTpyfYeKA.png"/></div></figure><p id="81a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一列显示列索引，第二列是预测评级。</p><p id="9fe7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在用户0的原始数据中，位置0，1，2，3，4，6，7，8，9为零，如下所示:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="c7d2" class="nm nn it ni b gy no np l nq nr">[0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5]</span></pre><p id="55f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了简单起见，完整的代码如下，您可以使用上面的最后两个建议来运行它:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="0858" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在今天的故事中，我介绍了一个例子，展示了如何在获得SVD后将SVD转换到k维空间来预测收视率，特别关注如何将SVD转换到k维空间并进行预测收视率。</p><p id="29af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。</p><p id="84a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong>:</p><ol class=""><li id="8cfa" class="mr ms it lb b lc ld lf lg li mt lm mu lq mv lu mw mx my mz bi translated">https://blog . csdn . net/weixin _ 41988628/article/details/83217255</li><li id="a940" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">Udacity数据科学家Nanodegree —实验设计和建议</li><li id="8f80" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated"><a class="ae ky" href="https://stats.stackexchange.com/questions/33142/what-happens-when-you-apply-svd-to-a-collaborative-filtering-problem-what-is-th/35460#35460" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/33142/what-happens-when-you-apply-SVD-to-a-collaborative-filtering-problem-what-is-th/35460 # 35460</a></li><li id="878d" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">【https://en.wikipedia.org/wiki/Singular_value_decomposition T2】号</li></ol></div></div>    
</body>
</html>