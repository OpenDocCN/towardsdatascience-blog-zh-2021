<html>
<head>
<title>Everything to Know About Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于卷积神经网络的所有知识</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/everything-to-know-about-convolutional-neural-networks-fce7c3e480e7?source=collection_archive---------37-----------------------#2021-04-05">https://towardsdatascience.com/everything-to-know-about-convolutional-neural-networks-fce7c3e480e7?source=collection_archive---------37-----------------------#2021-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/f03646611a93fb4d58dec869f059917d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*El02XZwqZKArUeRL"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">克林特·王茂林在<a class="ae jg" href="https://unsplash.com/s/photos/neural-networks?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="3193" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">数据科学</h2><div class=""/><div class=""><h2 id="3eeb" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">理解卷积神经网络的概念及其在构建图像分类模型中的实现</h2></div><blockquote class="lh li lj"><p id="75ab" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">“从计算机视觉的角度来看，毫无疑问，<strong class="ln jt">深度卷积神经网络</strong>是当今处理感知数据的‘主算法’。”</p><p id="4c39" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">托马斯·马利西维茨</p></blockquote><p id="4abf" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">如今，我们都必须看到和使用各种图像效果和滤镜，以及我们的计算机和智能手机如何检测和识别照片和视频中的人脸。所有这些都可以通过“计算机视觉”来实现，而“计算机视觉”只不过是使用卷积神经网络的机器学习。</p><p id="1d4f" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">计算机视觉类似于人的视觉，它帮助系统识别、分类、检测数据中的复杂特征。它的一些应用可以在自动驾驶汽车、机器人视觉、面部识别中看到。</p><blockquote class="lh li lj"><p id="6c1f" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">但是这种计算机视觉与我们人类的视觉并不完全相同，不像我们，计算机看到的图像是像素矩阵的形式。</p></blockquote><p id="c880" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">图像是由像素组成的。并且每个像素值可以取从0到255的值。</p><h2 id="96ee" class="mk ml jj bd mm mn mo dn mp mq mr dp ms mh mt mu mv mi mw mx my mj mz na nb jp bi translated">什么是卷积神经网络</h2><p id="4de6" class="pw-post-body-paragraph lk ll jj ln b lo nc kt lq lr nd kw lt mh ne lw lx mi nf ma mb mj ng me mf mg im bi translated">卷积神经网络或CNN是一种用于处理输入形状为2D矩阵形式(如图像)的数据的神经网络。</p><p id="648d" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">卷积神经网络的结构是具有若干隐藏层的前馈，主要是卷积和汇集层，随后是激活层。通过这个CNN模型，我们可以识别手写字母和人脸(取决于图像的层数和复杂程度)。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/4ce4044ad52bcec226948840e6e9b68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*9WmPbmk3UL4CjM6JNCv2Og.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://commons.wikimedia.org/wiki/File:ConvolutionAndPooling.svg" rel="noopener ugc nofollow" target="_blank">维基共享资源</a> ) <strong class="bd nm">卷积神经网络模型</strong></p></figure><p id="3e77" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">在本文中，我们将学习CNN的概念，并建立一个图像分类器模型，以便更好地掌握这个主题。</p><p id="0a22" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">在建立模型之前，我们需要理解和学习卷积神经网络的一些重要概念。</p><ul class=""><li id="968b" class="nn no jj ln b lo lp lr ls mh np mi nq mj nr mg ns nt nu nv bi translated">众所周知，计算机将图像视为像素矩阵形式的数字。CNN将图像视为三维对象，其中高度和宽度是前两个维度，颜色编码是第三个维度(例如，3x3x3 RGB图像)。</li></ul><blockquote class="nw"><p id="88e4" class="nx ny jj bd nz oa ob oc od oe of mg dk translated">现在想象一下，处理一幅4K图像(3840 x 2160像素)的计算量会有多大。</p></blockquote><h2 id="4f81" class="mk ml jj bd mm mn og dn mp mq oh dp ms mh oi mu mv mi oj mx my mj ok na nb jp bi translated">盘旋</h2><ul class=""><li id="9d6e" class="nn no jj ln b lo nc lr nd mh ol mi om mj on mg ns nt nu nv bi translated">因此，卷积网络的主要目标是将图像简化为更容易处理的形式，同时保留特征并在预测时保持良好的准确性。</li></ul><blockquote class="lh li lj"><p id="ad10" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">在卷积神经网络中有三个主要的重要单元，即输入图像、特征检测器和特征映射。</p></blockquote><ul class=""><li id="1a73" class="nn no jj ln b lo lp lr ls mh np mi nq mj nr mg ns nt nu nv bi translated">特征检测器是过滤器的核心(一个数字矩阵，通常是3x3)。这里的想法是将图像的矩阵表示与核逐元素相乘，以获得特征图。在这个步骤中，图像的尺寸被减小，以便更快和更简单地处理。保留了图像的重要特征(如图像/对象特有的特征，即识别所必需的特征)。但是，在此步骤中会丢失一些功能。</li></ul><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/0ab714255d02c7c8b497b18c5dbba67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/format:webp/1*d958qW5S-OZGoPZRSCF8_Q.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://commons.wikimedia.org/wiki/File:ConvolutionAndPooling.svg" rel="noopener ugc nofollow" target="_blank">维基共享</a> ) <strong class="bd nm">卷积层——特征图</strong></p></figure><ul class=""><li id="c6b6" class="nn no jj ln b lo lp lr ls mh np mi nq mj nr mg ns nt nu nv bi translated">例如，如果我们有一个5x5x1维的输入图像，而我们应用于图像的卷积核/滤波器是3x3x1维的:</li></ul><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="f254" class="mk ml jj oq b gy ou ov l ow ox"><strong class="oq jt">Image matrix:</strong><br/>1 1 0 1 1<br/>1 0 1 0 1<br/>1 1 1 1 0<br/>0 0 1 1 0<br/>1 1 0 0 0</span><span id="fd41" class="mk ml jj oq b gy oy ov l ow ox"><strong class="oq jt">Kernel matrix:<br/></strong>1 0 1<br/>0 1 0<br/>1 1 0</span></pre><p id="610c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">那么核矩阵与图像矩阵的每个元素相乘后得到的卷积特征将是:</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="0a1e" class="mk ml jj oq b gy ou ov l ow ox"><strong class="oq jt">Convolved matrix:</strong><br/>3 5 3<br/>3 2 5<br/>4 4 2</span></pre><p id="1a61" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">这里，内核移动9次，因为<strong class="ln jt">步长</strong>为1(即滤波器将在图像矩阵的每个元素后滑动)。</p><h2 id="9356" class="mk ml jj bd mm mn mo dn mp mq mr dp ms mh mt mu mv mi mw mx my mj mz na nb jp bi translated">ReLu激活功能</h2><p id="e7a2" class="pw-post-body-paragraph lk ll jj ln b lo nc kt lq lr nd kw lt mh ne lw lx mi nf ma mb mj ng me mf mg im bi translated">应用此<strong class="ln jt"> ReLu函数</strong>(整流线性单元)的目的是增加模型中的非线性。因为图像/物体具有几个彼此非线性的特征。我们应用这个函数，以便我们的模型不会将图像分类视为线性问题。</p><h2 id="e818" class="mk ml jj bd mm mn mo dn mp mq mr dp ms mh mt mu mv mi mw mx my mj mz na nb jp bi translated">汇集层</h2><p id="ad0c" class="pw-post-body-paragraph lk ll jj ln b lo nc kt lq lr nd kw lt mh ne lw lx mi nf ma mb mj ng me mf mg im bi translated">池层类似于卷积层，它负责减少卷积矩阵的大小。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/43426fed9e4b3789539d235d0d652d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*_UCSyZF1cdN0uo8UImbifg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://commons.wikimedia.org/wiki/File:ConvolutionAndPooling.svg" rel="noopener ugc nofollow" target="_blank"> Wikimedia Commons </a> ) <strong class="bd nm">共享图层-要素地图</strong></p></figure><p id="7db2" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">这是卷积神经网络过程中的一个重要步骤。汇集对于<strong class="ln jt">从图像中检测和提取显著特征</strong>是至关重要的，而不管不同的位置、角度、不同的光照等。同时保持训练模型的准确性和效率。</p><p id="dbc1" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">此外，随着图像数据的尺寸<strong class="ln jt">减小</strong>(同时保留主要特征)<strong class="ln jt">，处理数据所需的计算能力也降低。</strong></p><p id="048a" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">有不同类型的池:最大池，最小池，平均池。</p><ul class=""><li id="42e7" class="nn no jj ln b lo lp lr ls mh np mi nq mj nr mg ns nt nu nv bi translated"><strong class="ln jt">最大池</strong>从内核覆盖的特征映射矩阵部分提取最大值(具体池大小如2x2)。</li><li id="e3d4" class="nn no jj ln b lo pa lr pb mh pc mi pd mj pe mg ns nt nu nv bi translated"><strong class="ln jt"> Min pooling </strong>从内核覆盖的特征映射矩阵部分提取最小值(具体池大小如2x2)。</li><li id="ce53" class="nn no jj ln b lo pa lr pb mh pc mi pd mj pe mg ns nt nu nv bi translated">而<strong class="ln jt">平均池</strong>所有值的平均值是从内核覆盖的特征映射矩阵的部分中选择的(特定池大小如2x2)。</li></ul><p id="0b34" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">最大池化是所有池化方法中最有效的(因为它将包含卷积特征图中最主要的特征)。</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="069d" class="mk ml jj oq b gy ou ov l ow ox"><strong class="oq jt">Convolved matrix:</strong><br/>3 5 4 1<br/>2 2 5 6<br/>4 4 2 5<br/>1 3 5 4</span><span id="9819" class="mk ml jj oq b gy oy ov l ow ox"><strong class="oq jt">Max pooled matrix:<br/></strong>5 6<br/>4 5</span><span id="f89c" class="mk ml jj oq b gy oy ov l ow ox"><strong class="oq jt">Min pooled matrix:<br/></strong>2 1<br/>1 2</span><span id="bc31" class="mk ml jj oq b gy oy ov l ow ox"><strong class="oq jt">Average pooled matrix:<br/></strong>3 4<br/>3 4</span></pre><p id="d1dd" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">以上是汇集的要素地图。</p><blockquote class="lh li lj"><p id="fae3" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">根据输入图像的复杂程度以及必须提取的细节和特征的级别，可以增加或减少这些卷积层和池层的数量。但是请记住<strong class="ln jt">你在模型中增加的层数，所需的计算能力也会增加。</strong></p></blockquote><p id="5d94" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">有了这些卷积和池层，我们的模型可以理解提取图像的特征。</p><h2 id="d6c3" class="mk ml jj bd mm mn mo dn mp mq mr dp ms mh mt mu mv mi mw mx my mj mz na nb jp bi translated"><strong class="ak">展平</strong></h2><p id="0c75" class="pw-post-body-paragraph lk ll jj ln b lo nc kt lq lr nd kw lt mh ne lw lx mi nf ma mb mj ng me mf mg im bi translated">下一步是展平所获得的池特征图，即将多维池特征图矩阵转换成一维阵列(线性向量或列),以将其馈送到神经网络进行处理和分类。</p><h2 id="9624" class="mk ml jj bd mm mn mo dn mp mq mr dp ms mh mt mu mv mi mw mx my mj mz na nb jp bi translated">全连接层—分类</h2><p id="fe9e" class="pw-post-body-paragraph lk ll jj ln b lo nc kt lq lr nd kw lt mh ne lw lx mi nf ma mb mj ng me mf mg im bi translated">在我们以列向量的形式获得我们的数据之后，我们将通过前馈神经网络传递它，在训练过程中，在每一次迭代中实现反向传播(提高预测的准确性)。</p><blockquote class="nw"><p id="a82b" class="nx ny jj bd nz oa pf pg ph pi pj mg dk translated">经过几个时期的训练，我们的模型将能够识别和区分图像的突出和低级特征。</p></blockquote><p id="690f" class="pw-post-body-paragraph lk ll jj ln b lo pk kt lq lr pl kw lt mh pm lw lx mi pn ma mb mj po me mf mg im bi translated">从神经网络获得的最终输出值的总和可能不等于1，但是有必要使这些值介于0和1之间。这将表示每个类别的概率，并进一步使用<strong class="ln jt"> softmax技术(用于多类别分类的激活函数)</strong>对它们进行分类。</p><h2 id="ca79" class="mk ml jj bd mm mn mo dn mp mq mr dp ms mh mt mu mv mi mw mx my mj mz na nb jp bi translated">利用MNIST数据集实现CNN</h2><p id="5419" class="pw-post-body-paragraph lk ll jj ln b lo nc kt lq lr nd kw lt mh ne lw lx mi nf ma mb mj ng me mf mg im bi translated">在本文中，我们将使用MNIST数据集，即<strong class="ln jt">一个由70，000张</strong> (60，000张训练图像和10，000张测试图像)<strong class="ln jt">0到9之间的手写单数字的小正方形28×28像素灰度图像</strong>组成的数据集。</p><p id="66e7" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">这里我们模型的目标是<strong class="ln jt">将一组给定的手写数字图像分类为1到10 </strong>(代表从0到9的整数)。</p><blockquote class="lh li lj"><p id="1db5" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">我们将在本文中使用<strong class="ln jt"> Keras </strong>和<strong class="ln jt"> matplotlib </strong>库。</p></blockquote><p id="4f29" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">以下代码将使用Keras API加载MNIST数据集的前九幅图像，并使用matplotlib库绘制这些图像。</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="cbdb" class="mk ml jj oq b gy ou ov l ow ox">from keras.utils import to_categorical<br/>from keras.models import Sequential<br/>from keras.layers import Conv2D<br/>from keras.layers import MaxPooling2D<br/>from keras.layers import Dense<br/>from keras.layers import Flatten<br/>from keras.optimizers import SGD<br/>from keras.datasets import mnist<br/>from matplotlib import pyplot<br/><strong class="oq jt"><br/></strong># load dataset<br/>(trainX, trainy), (testX, testy) = mnist.load_data()</span><span id="985a" class="mk ml jj oq b gy oy ov l ow ox"># plot first 9 images<br/>for i in range(9):<br/> pyplot.subplot(330 + 1 + i)<br/> pyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))</span><span id="51ec" class="mk ml jj oq b gy oy ov l ow ox"><strong class="oq jt">pyplot.show()</strong></span></pre><p id="c793" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">训练和测试图像(已经被模型很好地定义了)被分别加载，如上面的代码所示。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/4721d650be19b252402134deff5d68b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*Rzav8JaLce3b357LbqVWlQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://medium.com/@beginningofthefuture" rel="noopener">作者</a>提供)MNIST数据集中的第<strong class="bd nm">个九位手写数字图片</strong></p></figure><p id="6f89" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">现在，我们将加载完整的数据集，并在将数据输入神经网络之前对其进行预处理。</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="fd5b" class="mk ml jj oq b gy ou ov l ow ox">(trainX, trainY), (testX, testY) = <strong class="oq jt">mnist.load_data()</strong></span><span id="ab72" class="mk ml jj oq b gy oy ov l ow ox">trainX = trainX.<strong class="oq jt">reshape</strong>((<strong class="oq jt">trainX.shape</strong>[0], 28, 28, 1))<br/>testX = testX.<strong class="oq jt">reshape</strong>((<strong class="oq jt">testX.shape</strong>[0], 28, 28, 1))</span><span id="b976" class="mk ml jj oq b gy oy ov l ow ox">trainY = <strong class="oq jt">to_categorical(trainY)</strong><br/>testY = <strong class="oq jt">to_categorical(testY)</strong></span></pre><p id="c276" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">在上面的代码中，我们对数据进行了整形，使其具有单一的颜色通道(因为图像具有相同的28x28像素和灰度形式)。</p><p id="90dd" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">此外，我们有一个热编码的数据集值(使用<code class="fe pq pr ps oq b">to_categorical</code>，一个Keras函数)，因为我们知道有10个不同的类都由唯一的整数表示。这里，每个整数样本都被转换为一个十元素的二进制向量，其中1表示类值的索引，0表示所有其他类的值。</p><p id="81c4" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">完成此操作后，<strong class="ln jt">我们将不得不对数据集</strong>进行归一化，因为我们知道图像的像素值在0和255(黑白)之间变化。为此，我们<strong class="ln jt">将该数据缩放至范围【0，1】</strong>。</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="def7" class="mk ml jj oq b gy ou ov l ow ox">trainX = trainX.<strong class="oq jt">astype('float32')</strong><br/>testX = testX.<strong class="oq jt">astype('float32')</strong></span><span id="59ac" class="mk ml jj oq b gy oy ov l ow ox">trainX = <strong class="oq jt">trainX / 255.0</strong><br/>testX = <strong class="oq jt">testX / 255.0</strong></span></pre><p id="8024" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">在上面的代码中，我们首先将pixel的整数值转换为浮点数。之后，我们将这些值除以最大数(即255)，这样所有的值都将在[0，1]的范围内缩放。</p><p id="63e8" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">现在我们将开始构建我们的神经网络。</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="e7d5" class="mk ml jj oq b gy ou ov l ow ox"> model = Sequential()<br/> model.add(<strong class="oq jt">Conv2D(32, (3, 3), activation='relu',  <br/> kernel_initializer='he_uniform', input_shape=(28, 28, 1))</strong>)<br/> model.add(<strong class="oq jt">MaxPooling2D((2, 2))</strong>)<br/> model.add(<strong class="oq jt">Flatten</strong>())<br/> model.add(Dense(100, activation='relu',   <br/> kernel_initializer='he_uniform'))<br/> model.add(Dense(10, <strong class="oq jt">activation='softmax'</strong>))</span><span id="3c72" class="mk ml jj oq b gy oy ov l ow ox"> opt = SGD(lr=0.01, momentum=0.9)<br/> model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])</span></pre><p id="5fd4" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">在上面的代码中，我们使用了用于逐层创建模型的<code class="fe pq pr ps oq b">Keras API sequentaial()</code>。之后，我们为我们的模型添加了一个卷积层，内核大小为3x3，有32个过滤器。接下来是内核大小(2x2)的单个<code class="fe pq pr ps oq b">MaxPooling()</code>层。然后输出特征图被展平。</p><p id="14e3" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">由于我们知道有10个类，所以在输出层中需要<strong class="ln jt"> 10个节点用于每个类的预测(多类分类)以及<strong class="ln jt"> softmax激活函数</strong>。在特征提取层和输出层之间，我们添加了一个具有100个节点的密集层，用于模型的特征分析和解释。</strong></p><p id="7900" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">模型中使用了<code class="fe pq pr ps oq b"><strong class="ln jt">Stochastic gradient descent</strong></code>(学习率为0.01，动量为0.9) <strong class="ln jt">优化器</strong>和<code class="fe pq pr ps oq b"><strong class="ln jt">categorical_crossentropy</strong></code> <strong class="ln jt">损失函数</strong>(适用于多类分类模型)。</p><p id="ebe3" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">最后，在编译我们的模型之后，需要在训练数据集上对它进行训练，在测试数据集上对它进行测试，并进一步评估它的结果(即准确性和损失)。</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="54b2" class="mk ml jj oq b gy ou ov l ow ox">batch_size = 128<br/>num_epoch = 10<br/>#model training<br/>model_log = <strong class="oq jt">model.fit(trainX, trainY,<br/>          batch_size=batch_size,<br/>          epochs=num_epoch,<br/>          verbose=1,<br/>          validation_data=(testX, testY))</strong></span></pre><p id="60c2" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">在上面的代码中，我们使用了10个<code class="fe pq pr ps oq b">epochs</code>和128个<code class="fe pq pr ps oq b">batch_size</code>(批量大小是一次迭代中训练的样本数)。下面是模型的训练输出:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pt"><img src="../Images/ac92698cc4bfa0fd05ae3dbcd0b0f4a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l7y8HZZ9C1L1ucsrwLTa4w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://medium.com/@beginningofthefuture" rel="noopener">作者</a>)<strong class="bd nm">CNN模型的训练输出</strong></p></figure><p id="d173" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">上述结果可以根据性能进行评估:</p><pre class="ni nj nk nl gt op oq or os aw ot bi"><span id="9550" class="mk ml jj oq b gy ou ov l ow ox"><strong class="oq jt">score = model.evaluate(testX, testY, verbose=0)<br/>print('Test loss:', score[0]) <br/>print('Test accuracy:', score[1])</strong></span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/884a5e0ce9b59acc16318250d4861c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*xLNwzdkW5Pv1BD48tbS2Sg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://medium.com/@beginningofthefuture" rel="noopener">作者</a>)<strong class="bd nm">CNN模型的训练输出</strong></p></figure><p id="6e4a" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">测试准确度&gt; 98%时，我们可以说我们的模型在准确预测方面训练有素。您也可以使用<code class="fe pq pr ps oq b">matplotlib</code>库来可视化这些结果！</p><h2 id="6a8a" class="mk ml jj bd mm mn mo dn mp mq mr dp ms mh mt mu mv mi mw mx my mj mz na nb jp bi translated"><strong class="ak">结论</strong></h2><p id="b955" class="pw-post-body-paragraph lk ll jj ln b lo nc kt lq lr nd kw lt mh ne lw lx mi nf ma mb mj ng me mf mg im bi translated">我希望通过这篇文章，你能够理解和掌握卷积神经网络的概念。</p><p id="7280" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">为了更好地理解这些概念，我建议您尝试编写这些代码。继续探索，我相信你会发现新的特性。</p><p id="8437" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">如果你有任何问题或意见，请发表在评论区。</p></div><div class="ab cl pv pw hx px" role="separator"><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa"/></div><div class="im in io ip iq"><p id="0016" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated">查看完整的数据可视化指南:</p><div class="is it gp gr iu qc"><a rel="noopener follow" target="_blank" href="/data-visualization-with-python-8bc988e44f22"><div class="qd ab fo"><div class="qe ab qf cl cj qg"><h2 class="bd jt gy z fp qh fr fs qi fu fw js bi translated">用Python实现数据可视化</h2><div class="qj l"><h3 class="bd b gy z fp qh fr fs qi fu fw dk translated">Master python的数据可视化库</h3></div><div class="qk l"><p class="bd b dl z fp qh fr fs qi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ql l"><div class="qm l qn qo qp ql qq ja qc"/></div></div></a></div><p id="f5d9" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt mh lv lw lx mi lz ma mb mj md me mf mg im bi translated"><strong class="ln jt"> <em class="lm">最初发表于:</em></strong><a class="ae jg" href="http://www.patataeater.blogspot.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ln jt"><em class="lm">www.patataeater.blogspot.com</em></strong></a></p></div></div>    
</body>
</html>