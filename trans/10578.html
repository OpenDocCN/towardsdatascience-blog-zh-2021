<html>
<head>
<title>How Deep Is Your Love? Or, How to Choose Your First Deep-Learning Side-Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的爱有多深？或者，如何选择你的第一个深度学习项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-deep-is-your-love-or-how-to-choose-your-first-deep-learning-side-project-524f3700813d?source=collection_archive---------15-----------------------#2021-10-09">https://towardsdatascience.com/how-deep-is-your-love-or-how-to-choose-your-first-deep-learning-side-project-524f3700813d?source=collection_archive---------15-----------------------#2021-10-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ec99" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在你最近学习的新领域开始一个副业可能会相当令人生畏。从哪里开始？如何在自己感兴趣的题目中找到已经做过的内容？如何为你的项目寻找和选择一个合理的目标？当我们开始致力于我们的深度学习项目时，我们对这些问题都没有答案。我们就是这样找到他们的。</h2></div><p id="e466" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> <em class="lc">由</em> </strong> <a class="ae ld" href="https://medium.com/@lironsoffer" rel="noopener"> <strong class="ki ir"> <em class="lc">李龙索夫</em></strong></a><a class="ae ld" href="https://medium.com/@dafna.mordechai" rel="noopener"><strong class="ki ir"><em class="lc">达芙娜</em></strong></a><strong class="ki ir"><em class="lc"/></strong><a class="ae ld" href="https://medium.com/search?q=Lior%20Dagan%20Leib" rel="noopener"><strong class="ki ir"><em class="lc">李奥【达甘】莱布</em> </strong> </a></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/6432b2a8edecb6c2c82e7515c560afe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hT38MaFaiXf-HPujo8p0g.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated"><a class="ae ld" href="https://unsplash.com/@mariogogh?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马里奥·高</a>在<a class="ae ld" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="76ff" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">从哪里开始？</h1><p id="f6fa" class="pw-post-body-paragraph kg kh iq ki b kj mm jr kl km mn ju ko kp mo kr ks kt mp kv kw kx mq kz la lb ij bi translated">由于我们都参加了深度学习课程，并熟悉神经网络的基本概念，我们知道我们最感兴趣的技术挑战是建立GAN(生成对抗网络)。很快我们也意识到我们都对艺术相关的项目感到兴奋。我们决定选择一个结合两者的文件，理解它的架构，然后从头开始实现它。话虽如此，有公开代码的论文更好。</p><p id="09ab" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们知道我们在寻找类似于神经风格转移的东西，在这种情况下，你拍摄两张图像，A和B，然后以B的艺术风格创建第三张内容为A“绘画”的图像。当我们在网上搜索它时，我们遇到了<a class="ae ld" href="https://arxiv.org/pdf/1508.06576.pdf" rel="noopener ugc nofollow" target="_blank">艺术风格的神经算法</a>和Raymond Yuan的这篇伟大的博文:<a class="ae ld" href="https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398" rel="noopener">神经风格转移:使用tf.keras和热切的执行来创建深度学习的艺术</a>。<br/>这对我们来说是一个很好的起点，因为它展示了我们所寻找的艺术功能，然而，这不是GAN架构，而是在2015年发布的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mr"><img src="../Images/962639b82d12ca62778df652a1d2bd26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*srnzdCFvnTtAX0nS3bUaOw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">一张照片的内容(A)结合几幅知名艺术品的风格(b-f)来自<a class="ae ld" href="https://arxiv.org/pdf/1508.06576.pdf" rel="noopener ugc nofollow" target="_blank">一种艺术风格的神经算法</a>，arXiv:1508.06576</p></figure><h1 id="c342" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">外面还有什么？</h1><p id="a9da" class="pw-post-body-paragraph kg kh iq ki b kj mm jr kl km mn ju ko kp mo kr ks kt mp kv kw kx mq kz la lb ij bi translated">随着我们对这个主题的进一步探索，我们发现风格转换只是图像到图像翻译的一种类型。如“<a class="ae ld" href="https://arxiv.org/abs/2101.08629" rel="noopener ugc nofollow" target="_blank">图像到图像转换:方法和应用</a>”中所定义的，“图像到图像转换的目标是将输入图像从源域A转换到目标域B，同时保留固有的源内容并转换外部的目标风格。”为了实现这个目标，我们需要训练一个映射G，它将从A中获取一个输入源图像，并在目标域B中生成一个图像，从而使得结果图像与其他目标域图像无法区分。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ms"><img src="../Images/3225f8891841f4fcf2b3540f35ce8709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FHrnvKakq2k9onQ4zXEx4Q.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">在<a class="ae ld" href="https://arxiv.org/abs/2101.08629" rel="noopener ugc nofollow" target="_blank">图像到图像转换:方法和应用</a>，arXiv:2101.08629中提出的图像到图像转换的数学建模</p></figure><p id="a565" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在使用GANs执行图像到图像的翻译领域，一个值得注意的工作是<a class="ae ld" href="https://phillipi.github.io/pix2pix/" rel="noopener ugc nofollow" target="_blank">使用条件对抗网络的图像到图像的翻译</a>(又名pix2pix)。这篇文章演示了许多类型的图像到图像的转换，包括从标签图合成照片，从边缘图重建对象，以及给图像着色(从黑白到全色)。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/e2d0230a0f9c34f6cf1c4a9f55869c99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iyZ08k3GLt4OB00i3tSuFA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">使用条件对抗网络从<a class="ae ld" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank">图像到图像翻译的结果图像</a> (pix2pix)，arXiv:1611.07004</p></figure><p id="08ab" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">第二个值得注意的作品是<a class="ae ld" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">使用循环一致对抗网络的不成对图像到图像翻译</a>(又名CycleGAN)，它将照片的图像到图像翻译成著名艺术家如莫奈、梵高、塞尚等人的艺术作品。此外，CycleGAN出色地介绍了图像中特定对象的翻译，例如将马转换为斑马或将苹果转换为橙子。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mu"><img src="../Images/21ca6a846f0e2419ddc775d5325b0d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUcihdKtM2jVqmJ7Pmg6cw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">使用循环一致的对抗网络 (CycleGAN)，从<a class="ae ld" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank">不成对的图像到图像翻译得到的结果图像，arXiv: 1703.10593</a></p></figure><h1 id="f40c" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">怎么搜？怎么挑？</h1><p id="652e" class="pw-post-body-paragraph kg kh iq ki b kj mm jr kl km mn ju ko kp mo kr ks kt mp kv kw kx mq kz la lb ij bi translated">接下来，我们搜索了引用pix2pix和CycleGAN的文章。然而，这种方法产生了太多的结果。我们在寻找一种快速回顾最新作品的方法，我们发现Károly Zsolnai-Fehér的youtube频道<a class="ae ld" href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg" rel="noopener ugc nofollow" target="_blank"> Two Minute Papers </a>在这个过程中非常有效。</p><p id="1ffa" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们浏览了几十篇似乎与艺术领域相关的论文，并把它们缩小到大约20篇。在我们为该项目考虑的作品中，有<a class="ae ld" href="https://www.youtube.com/watch?v=hW1_Sidq3m8&amp;t=2s" rel="noopener ugc nofollow" target="_blank"> Nvidia的paint </a>、<a class="ae ld" href="https://www.youtube.com/watch?v=cEBgi6QYDhQ" rel="noopener ugc nofollow" target="_blank">基于AI的运动传输</a>，以及<strong class="ki ir"> </strong> <a class="ae ld" href="https://www.youtube.com/watch?v=EjVzjxihGvU" rel="noopener ugc nofollow" target="_blank">这个神经网络恢复旧视频</a>。然而，我们都被<a class="ae ld" href="https://arxiv.org/abs/2002.05638" rel="noopener ugc nofollow" target="_blank"> GANILLA </a>所吸引，它在应用艺术风格的同时保留了原始图像内容，表现出了令人印象深刻的效果。最后，甘尼拉被选中了。</p><h1 id="58db" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结论</h1><p id="6762" class="pw-post-body-paragraph kg kh iq ki b kj mm jr kl km mn ju ko kp mo kr ks kt mp kv kw kx mq kz la lb ij bi translated">我们从这个搜索过程中学到了很多。我们最终找到了我们正在寻找的东西，即使在这个过程的开始，我们没有术语来定义它到底是什么。我们还了解了以前和现在将GAN用于各种目的的工作。现在我们手中有了一份获奖论文，实际工作开始了。在这篇<a class="ae ld" rel="noopener" target="_blank" href="/ganilla-fantasy-enhanced-d4918681820c">博客文章</a>中，我们回顾了GANILLA的架构，并让你感受一下我们实现它的结果。</p></div></div>    
</body>
</html>