<html>
<head>
<title>Deep Natural Language Processing for LinkedIn Search Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LinkedIn搜索系统的深度自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-natural-language-processing-for-linkedin-search-systems-6d136978bcfe?source=collection_archive---------21-----------------------#2021-09-09">https://towardsdatascience.com/deep-natural-language-processing-for-linkedin-search-systems-6d136978bcfe?source=collection_archive---------21-----------------------#2021-09-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d25b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">NLP研究论文摘要</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/baa553e3da740a668d8bb57351718fc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nVq9jJmAGyDC0VcoBYO8vA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://images.unsplash.com/photo-1509475826633-fed577a2c71b?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1051&amp;q=80" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="898a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">在这篇博客中，我尝试根据我的理解总结了LinkedIn搜索系统</em>  <em class="lv">的论文</em> <a class="ae ky" href="https://arxiv.org/pdf/2108.08252.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lv">。请随时评论你的想法！</em></a></p><p id="123f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文介绍了将深度自然语言处理技术应用于五个代表性任务的综合研究，以构建高效且健壮的搜索引擎。除此之外，本文还试图围绕<strong class="lb iu">延迟</strong>、<strong class="lb iu">健壮性、</strong>和<strong class="lb iu">有效性，找到有助于在生产环境中构建和扩展此类系统的三个重要问题的答案。</strong></p><p id="496f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">所以事不宜迟，让我们深入研究一下搜索引擎组件。</em></p><h1 id="e0b1" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">搜索引擎组件</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/7f4402bb90fe8e3302a7083f99215d39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*o5ObGcs1FRKcj5LrXDCcZA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">搜索系统的组成部分|图片来自<a class="ae ky" href="https://arxiv.org/pdf/2108.08252.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="e880" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所示，作者讨论的组件是<em class="lv">查询意图分类、查询标记系统、搜索排名、查询建议和自动完成系统</em>。让我们稍微了解一下每一个细节——</p><p id="a306" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">查询意图</em> — </strong>由于在LinkedIn，人们可以搜索许多垂直领域<em class="lv">(人员、工作、帮助中心、群组等)</em>，同样在<strong class="lb iu">联合搜索</strong>的情况下，尝试从所有垂直搜索中检索文档并将它们混合到同一个搜索结果页面中，确定意图变得非常关键。考虑到任务的类型(即文本分类)，作者用CNN<strong class="lb iu">和LSTM模型</strong>进行了游戏实验。经过评估，他们发现这两个系统<strong class="lb iu">表现同样出色</strong>，尽管他们选择了<strong class="lb iu"> CNN系统，因为它与LSTMs </strong>相比延迟稍低。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/ec33c81cac5b204451b8374fa62c78ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*4C3EdNg7sirDN_k0__7YGA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型|准确性|延迟—查询意图性能</p></figure><p id="8813" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">查询标记— </em> </strong>识别实体，然后<strong class="lb iu">将它们用作特征可以帮助提高其他组件的性能</strong>。例如，作者发现这个特性在文档检索步骤中非常有用。<em class="lv">因为被识别的实体将帮助系统缩小其范围并指向与特定实体类型</em>相匹配的文档。现有的生产模型使用三类特征:<strong class="lb iu">基于字符、基于单词和基于词典</strong>。关于模型开发，他们试验了通用报告格式、SCRF <em class="lv">(当前系统)</em>、LSTM-SCRF模型及其变体。最终，他们发现SCRF是所有实验中表现最好的。</p><p id="d073" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">查询建议— </em> </strong>查询建议也是整体搜索体验中必不可少的一部分。这就是你在LinkedIn的“人们也搜索”协助背后的体验。现有的系统是基于搜索查询的频率及其重构。它从搜索日志中收集查询重构对，并且对于每个输入查询，它基于查询、重构的查询对对建议进行排序。作者遵循某些启发法来识别这些重构，例如查询对必须在同一个会话中，<strong class="lb iu">其中会话由间隔不超过10分钟的查询来定义，并且两个查询必须共享至少一个公共词</strong>。</p><p id="081d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他们还尝试将整个问题公式化为一个<strong class="lb iu">序列来排序任务</strong>，将原始搜索查询作为输入，将重构后的查询作为输出。尽管他们发现该系统比已经部署的系统性能更好。由于这个系统与前一个系统相比有更高的延迟，他们在搜索结果排名的同时为他们的模型服务。</p><p id="5f1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">自动完成— </em> </strong>由于查询自动完成类似于语言生成任务，使用语言模型可以帮助我们实现<strong class="lb iu">令人印象深刻的结果</strong>，但代价是<strong class="lb iu">更高的延迟</strong>。作者修改了原始的语言模型概率步骤，让它为每个单词吐出<strong class="lb iu">未标准化的权重</strong>，从而节省了大量的计算时间。这是由于观察到大部分时间花在整个词汇的概率标准化上。<em class="lv">它们近似这种行为，如下所示— </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/adb8277fe0cd52108a830c2dfb93cb37.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*H_24fv2VQdVlFZnOQy41pA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标准化近似</p></figure><p id="f05c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">文档排名— </em> </strong>这里的目标是检索与查询相关的相关文档。作者对人员搜索和帮助中心搜索进行了实验。人民搜索拥有6亿会员档案，帮助中心有2700个常见问题文档。</p><p id="c21b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为等待时间是文档排序任务中的主要问题之一。对于帮助中心搜索，由于只有2，700个文档，他们预先计算并使用文档嵌入。对于拥有6亿成员档案的人民搜索，他们提出了一个两遍排名策略:首先应用一个轻量级模型来选择前数百个文档，然后使用这个精简集通过更深层次的模型来重新排名文档。</p><p id="ed00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了排序步骤，我们使用CNN对查询和其他文档字段进行编码，然后添加手工制作的特征，再添加一个隐藏层来预测文档的相关性分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/f7898bd97f887269e5eb140a26e674cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*sNG1N19jUrohllqro-E9Jg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">搜索排名模型|图片来自<a class="ae ky" href="https://arxiv.org/pdf/2108.08252.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="090b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了由上述组件构成的搜索引擎的总体系统设计。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/96dc753181dd83a1821ed997ef7bf51a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*Clda2wQ61b139gEyUWMHMw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">搜索系统设计|图片来自<a class="ae ky" href="https://arxiv.org/pdf/2108.08252.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="6753" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原始搜索查询首先进入<strong class="lb iu"> NLU(自然语言理解)引擎</strong>以处理和识别意图、实体和其他细节。我们还有一个<strong class="lb iu">语言生成引擎</strong>，用于自动完成、建议相关查询等。最后，我们转到<strong class="lb iu">检索和排序系统</strong>，该系统首先检索与搜索查询相关的一堆文档，然后为了提高CTR(点击率)而对它们进行排序。</p><h2 id="e4bb" class="na lx it bd ly nb nc dn mc nd ne dp mg li nf ng mi lm nh ni mk lq nj nk mm nl bi translated">深度NLP什么时候有帮助？</h2><ol class=""><li id="c05e" class="nm nn it lb b lc no lf np li nq lm nr lq ns lu nt nu nv nw bi translated"><strong class="lb iu"> <em class="lv">自然语言生成/释义任务</em> </strong> <em class="lv"> — </em>作者发现深度NLP特别有帮助(至少在准确性方面)，尤其是对于语言生成或文本匹配的任务。这是他们在查询建议和文档排序步骤下发现的。</li></ol><h2 id="bdf9" class="na lx it bd ly nb nc dn mc nd ne dp mg li nf ng mi lm nh ni mk lq nj nk mm nl bi translated">如何应对延迟挑战？</h2><ol class=""><li id="c136" class="nm nn it lb b lc no lf np li nq lm nr lq ns lu nt nu nv nw bi translated"><strong class="lb iu"> <em class="lv">重新设计算法</em> </strong> <em class="lv"> — </em>正如在自动完成步骤中所讨论的，他们应用了<strong class="lb iu">非规范化语言模型</strong>，这有助于他们在保持相同相关性水平的同时显著减少计算时间。</li><li id="41a9" class="nm nn it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated"><strong class="lb iu"> <em class="lv">并行计算</em> </strong> <em class="lv"> — </em>这是他们尝试的查询建议，在这里他们尝试并行运行他们的seq模型。</li><li id="047e" class="nm nn it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated"><strong class="lb iu"> <em class="lv">预先计算的嵌入</em> </strong> <em class="lv"> — </em>对于从开始搜索的<strong class="lb iu">有限集合的任务，预先计算并存储嵌入总是比每次运行时都这样做更好。这就是他们在帮助中心搜索中所做的。</strong></li><li id="e656" class="nm nn it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated"><strong class="lb iu"/></li></ol><h2 id="842f" class="na lx it bd ly nb nc dn mc nd ne dp mg li nf ng mi lm nh ni mk lq nj nk mm nl bi translated">如何保证模型的鲁棒性？</h2><p id="c791" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li oc lk ll lm od lo lp lq oe ls lt lu im bi translated">对于这一步，作者要做的事情之一是处理训练数据，并通过删除模型中不需要的噪声模式来净化数据，以防止其记忆。<em class="lv">示例参见查询建议部分。</em></p><p id="24dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其次，他们强调在训练深度网络时，使用手工制作的功能以及其他深度功能。这增加了系统行为的控制和确定性。</p><blockquote class="of"><p id="29dc" class="og oh it bd oi oj ok ol om on oo lu dk translated">如果你愿意，你也可以查看我写的其他研究论文摘要。</p></blockquote><p id="047f" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">好了，这篇博客到此为止。这是一个非常有趣的阅读，了解如何设计搜索系统，而不是在书中，而是可以大规模部署。</p><p id="7588" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请随意阅读整篇论文，并对作者说“<strong class="lb iu"> Hi </strong>”，感谢他们的贡献。此外，如果你喜欢看视频而不是文字内容(就像我一样的:D)，一定要看看</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">更多这样的<a class="ae ky" href="https://www.youtube.com/channel/UCoz8NrwgL7U9535VNc0mRPA" rel="noopener ugc nofollow" target="_blank">视频</a></p></figure><blockquote class="ow ox oy"><p id="387c" class="kz la lv lb b lc ld ju le lf lg jx lh oz lj lk ll pa ln lo lp pb lr ls lt lu im bi translated">⏩论文标题:LinkedIn搜索系统的深度自然语言处理⏩论文:<a class="ae ky" href="https://arxiv.org/abs/2108.08252" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2108.08252</a>⏩作者:、、王思达、迈克尔·卡齐、、傅、高慧姬、、陈伯龙⏩组织:LinkedIn</p></blockquote><p id="1c45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的宝贵时间！</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="c150" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢读这篇文章。如果你愿意支持我成为一名作家，可以考虑注册<a class="ae ky" href="https://prakhar-mishra.medium.com/membership" rel="noopener">成为</a>中的一员。每月只需5美元，你就可以无限制地使用Medium</p></div></div>    
</body>
</html>