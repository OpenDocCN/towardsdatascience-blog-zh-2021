<html>
<head>
<title>Beginner’s guide to learn computer vision in 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年学习计算机视觉的初学者指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beginners-guide-to-learn-computer-vision-in-2021-6083ab6de6af?source=collection_archive---------26-----------------------#2021-06-24">https://towardsdatascience.com/beginners-guide-to-learn-computer-vision-in-2021-6083ab6de6af?source=collection_archive---------26-----------------------#2021-06-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d9d3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">阅读可以帮助你提高计算机视觉技能的资源</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/df2b2c9841c53ff5721230f8baa5f0b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YsUIHzWkCsAjbMGj"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">尼克·莫里森在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="bf05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从我本科学习的第一年开始，我就是机器人俱乐部的一员，在那段时间，深度学习是我们大学里一个相当新的流行词。在我的俱乐部里，每个人都对计算机视觉着迷，因为在一次关于图像处理的研讨会之后，我们都认为这个世界已经向我们展示了它的真正潜力！现在在从众的驱使下，我也学习和发掘了和身边所有人一样的资源，他们给了我很大的基础。但是我第一次面试一家计算机视觉初创公司就让我找到了自己的位置。我不知道这个领域到底有多广阔，所以为了帮助你们避免尴尬，我汇集了一些资源，让你们的旅程更轻松。</p><p id="2006" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，花点时间了解自己是否真的喜欢这个领域。为此，我将链接一些展示特定应用的博客，如果您感兴趣，请继续查看相应的资源。</p><h2 id="46d4" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">在线课程</h2><p id="a0a1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">先说计算机视觉的基础知识，以及大家需要的基本概念。我更喜欢的学习方式总是通过在线讲座，因为我可以控制速度，而且对于更简单的概念，我可以浏览笔记而不是观看整个视频。所以接下来的系列讲座对学习CV是相当全面的。</p><ul class=""><li id="10ea" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><a class="ae ky" href="https://www.udacity.com/course/introduction-to-computer-vision--ud810" rel="noopener ugc nofollow" target="_blank">计算机视觉简介</a>，Udacity，佐治亚理工学院提供。这门课程帮助我克服了学习这个全新领域的恐惧。</li><li id="7c29" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> CS231n:用于视觉识别的卷积神经网络</a>，斯坦福大学。这门课的老师是这个领域的世界知名教授，在我看来，这是CNN最好的课程之一。</li><li id="bcd9" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://www.youtube.com/playlist?list=PL7v9EfkjLswLfjcI-qia-Z-e3ntl9l6vp" rel="noopener ugc nofollow" target="_blank">计算机视觉讲座</a>，Alberto Romay。通俗易懂的讲座系列为了让初学者对CV有一个完整的了解，我的一些朋友学习了这个课程而不是第一个。</li></ul><p id="7458" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了充分利用这些课程，坚持一个系统的时间表，并适当地练习每一项作业，以清除你的基础知识。这将让你在使用计算机视觉和深度学习的通用框架和平台时充满信心。</p><h2 id="8ac7" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">编码和实现</h2><p id="94d1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">学习CV的第一步是用你选择的语言学习OpenCV框架。对于大多数应用程序，我更喜欢OpenCV而不是MATLAB，但这取决于您。学习图像处理、相机几何和OpenCV的一些书籍有:</p><ul class=""><li id="3e61" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">使用OpenCV库学习OpenCV 3:c++中的计算机视觉，Adrian Kaehler和Gary Bradski( <a class="ae ky" href="https://amzn.to/3xnjuCT" rel="noopener ugc nofollow" target="_blank"> Book </a>)</li><li id="7bde" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">3D计算机视觉技术和算法介绍，博古斯瓦夫·西加内克和j .保罗·西伯特(<a class="ae ky" href="https://amzn.to/3gv8KwL" rel="noopener ugc nofollow" target="_blank">书</a>)</li></ul><h2 id="2565" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">深度学习框架:</h2><p id="091c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">深度学习框架帮助你实现各种深度学习架构。它们使得不同神经网络的实现更加容易。最常用的框架有<a class="ae ky" href="https://pytorch.org/tutorials/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">【py torch】</strong></a><strong class="lb iu"/><a class="ae ky" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Keras、</strong> </a>和<a class="ae ky" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> TensorFlow </strong> </a>。我个人在大多数情况下使用PyTorch，因为我觉得它易于理解和实现。还有更多构建在PyTorch或TensorFlow之上的库/框架，使实现更加容易。下面是两个这样的库，我相信会很有帮助。</p><ul class=""><li id="682a" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">Fast.ai 是你应该注意的下一个课程。还有，fast.ai是PyTorch上面的高层框架，但是他们改API太频繁了，文档的缺乏使得用起来不太靠谱。然而，理论和有用的技巧只是花时间观看本课程的幻想。(免费)</li><li id="6360" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">PyTorch Lightning 是当今最热门的图书馆之一。它可以帮助你实现多GPU训练和许多其他工程设施，只需改变一些参数。如果你想学习PyTorch闪电，我写了这篇<a class="ae ky" rel="noopener" target="_blank" href="/an-introduction-of-pytorch-lightning-230d03bcb262">博客</a>。</li></ul><h2 id="81dd" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">研究及其实施</h2><p id="e238" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">计算机视觉在不断进步，这个领域的研究也在以极快的速度进行。因此，尤其是在深度学习和计算机视觉的交汇点，让自己跟上当前最先进的方法是很重要的。</p><ul class=""><li id="25f6" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">ArXiv.org——你可以在这里找到几乎所有的研究论文，最棒的是，它是完全免费的。</li><li id="5199" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://github.com/topics/computer-vision?l=python" rel="noopener ugc nofollow" target="_blank"> Github </a> —你可以在Github上找到所有的开源代码。查看和阅读代码有助于您清晰地实现不同的研究论文，并增强您实现任何新架构的信心。</li></ul><h2 id="22e3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">竞争</h2><p id="0ba2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果你在学习新事物的时候需要持续的动力，参与竞争将是最好的选择。我有很多朋友，只通过参加多个比赛，就了解了很多不同的概念。有许多可用的网站，但我通常更喜欢以下方式:</p><ul class=""><li id="b36f" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">他们有许多活跃的竞争和不活跃的竞争。你可以利用这个地方通过参加不活跃的竞赛来学习，看看哪种方法表现最好，然后找出原因。你可以参与到积极的竞争中来，让自己相信你能够理解问题并相应地处理它(显然，只有当你足够自信，能够找出哪件事最适合当前的问题陈述时，你才应该这样做)</li><li id="2d52" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">参加CVPR、ECCV、ICCV、AAAI等会议组织的比赛。这些会议是顶级的计算机视觉会议，每个人都梦想在这些会议上发表论文，因此如果你能在排行榜上名列前茅，你也将有机会参加这些会议，我个人认为这将使你完美地接触到当前的艺术状态。</li></ul><h2 id="e845" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">必须阅读研究论文</h2><p id="9e53" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">以上提到的东西足以成为计算机视觉的媒介。但是，我强烈建议也阅读下面列出的一些研究论文。阅读研究论文有助于你了解研究中的新观点，并激发你进行创新思维。我还附上不同主题的介绍性博客或视频。</p><ul class=""><li id="89b5" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">图片分类(<a class="ae ky" rel="noopener" target="_blank" href="/how-artificial-intelligence-learns-regardless-of-day-or-night-e9badcc1b649">博客</a>)——<a class="ae ky" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">AlexNet</a>、<a class="ae ky" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank"> GoogLeNet </a>、<a class="ae ky" href="https://arxiv.org/abs/1505.06798" rel="noopener ugc nofollow" target="_blank"> VGG16 </a>、<a class="ae ky" href="https://arxiv.org/abs/1704.06904" rel="noopener ugc nofollow" target="_blank"> ResNet </a>、<a class="ae ky" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank"> Inception </a>、<a class="ae ky" href="https://arxiv.org/abs/1610.02357" rel="noopener ugc nofollow" target="_blank"> Xception </a>、<a class="ae ky" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> MobileNet </a></li><li id="4ba9" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">物体检测。(<a class="ae ky" href="https://www.youtube.com/watch?v=VOC3huqHrss" rel="noopener ugc nofollow" target="_blank">视频</a>)——<a class="ae ky" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank">RCNN</a>、<a class="ae ky" href="https://arxiv.org/abs/1504.08083" rel="noopener ugc nofollow" target="_blank"> Fast-RCNN </a>、<a class="ae ky" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">Fast-RCNN</a>、<a class="ae ky" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank"> SSD </a>、<a class="ae ky" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank"> YOLO </a></li><li id="1992" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">物体跟踪。(<a class="ae ky" href="https://www.youtube.com/watch?v=FuvQ8Melz1o" rel="noopener ugc nofollow" target="_blank">视频</a>)——<a class="ae ky" href="https://paperswithcode.com/paper/smot-single-shot-multi-object-tracking" rel="noopener ugc nofollow" target="_blank">SMOT</a>，<a class="ae ky" href="https://paperswithcode.com/paper/a-simple-baseline-for-multi-object-tracking" rel="noopener ugc nofollow" target="_blank">费尔莫特</a></li><li id="8edc" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">语义分割。(<a class="ae ky" href="https://www.jeremyjordan.me/semantic-segmentation/" rel="noopener ugc nofollow" target="_blank">博客</a>)——<a class="ae ky" href="https://arxiv.org/abs/1411.4038" rel="noopener ugc nofollow" target="_blank">FCN</a>、<a class="ae ky" href="https://arxiv.org/abs/1511.00561" rel="noopener ugc nofollow" target="_blank">塞格内</a> t、<a class="ae ky" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> UNet </a>、<a class="ae ky" href="https://arxiv.org/abs/1612.01105" rel="noopener ugc nofollow" target="_blank"> PSPNet </a>、<a class="ae ky" href="https://arxiv.org/abs/1606.00915" rel="noopener ugc nofollow" target="_blank"> DeepLab </a>、<a class="ae ky" href="https://arxiv.org/abs/1704.08545" rel="noopener ugc nofollow" target="_blank"> ICNet </a>、<a class="ae ky" href="https://arxiv.org/abs/1606.02147" rel="noopener ugc nofollow" target="_blank"> ENet </a></li><li id="b305" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">实例分割。(<a class="ae ky" rel="noopener" target="_blank" href="/deep-learning-for-ship-detection-and-segmentation-71d223aca649">博客</a> ) — <a class="ae ky" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank"> Mask-RCNN </a>，<a class="ae ky" href="https://arxiv.org/abs/1904.02689" rel="noopener ugc nofollow" target="_blank"> YOLACT </a></li></ul><p id="5194" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望这篇文章能为你学习计算机视觉提供必要的资源。如果你认为添加更多的东西可以使这篇文章更好，更值得一读，我随时欢迎你的建议。关注我们的<a class="ae ky" href="https://medium.com/@AnveeNaik" rel="noopener">媒体</a>阅读更多此类内容。</p><p id="26ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nh">成为</em> <a class="ae ky" href="https://medium.com/@AnveeNaik/membership" rel="noopener"> <em class="nh">介质成员</em> </a> <em class="nh">解锁并阅读介质上的许多其他故事。</em></p></div></div>    
</body>
</html>