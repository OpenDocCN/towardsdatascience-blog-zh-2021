<html>
<head>
<title>Testing Your PyTorch Models with Torcheck</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Torcheck测试您的PyTorch模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/testing-your-pytorch-models-with-torcheck-cb689ecbc08c?source=collection_archive---------23-----------------------#2021-06-09">https://towardsdatascience.com/testing-your-pytorch-models-with-torcheck-cb689ecbc08c?source=collection_archive---------23-----------------------#2021-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a51c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一个方便的PyTorch健全性检查工具包</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9c2a537f1dc7505c09b194cdfbd54007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GcP-tp9RvCTpc-A5"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@homajob?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="56dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你是否有过长时间训练PyTorch模型，却发现自己在模型的<code class="fe ls lt lu lv b">forward</code>方法中打错了一行的经历？你是否曾经遇到过这样的情况:你从你的模型中获得了某种程度上合理的输出，但不确定这是否表明你已经建立了正确的模型，或者只是因为深度学习非常强大，甚至错误的模型架构也产生了下降结果？</p><p id="1a41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就我自己而言，测试一个深度学习模型时不时会让我抓狂。最突出的难点是:</p><ul class=""><li id="c0c3" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">它的黑盒性质使它很难测试。如果不是不可能的话，理解中间结果需要很多专业知识。</li><li id="55f9" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">较长的训练时间大大减少了迭代次数。</li><li id="077f" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">没有专用的工具。通常，您会希望在一个小样本数据集上测试您的模型，这涉及到为设置优化器重复编写样板代码、计算损失和反向传播。</li></ul><p id="5821" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了减少这种开销，我以前做过一些研究。我发现了一篇由Chase Roberts撰写的关于这个话题的精彩的<a class="ae kv" href="https://thenerdstation.medium.com/how-to-unit-test-machine-learning-code-57cf6fd81765" rel="noopener"> medium帖子</a>。核心思想是，我们永远不能百分之百确定我们的模型是正确的，但至少它应该能够通过一些健全性检查。换句话说，这些健全性检查是必要的，但可能还不够。</p><p id="c733" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了节省您的时间，以下是他提出的所有理智检查的总结:</p><ul class=""><li id="0449" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">在训练过程中，模型参数应该总是变化的，如果它不是故意冻结的话。这可以是PyTorch线性图层的权重张量。</li><li id="200c" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">如果模型参数被冻结，则在训练过程中不应改变。这可能是您不想更新的预训练层。</li><li id="5824" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">根据模型属性，模型输出的范围应符合某些条件。例如，如果它是一个分类模型，其输出不应该都在范围(0，1)内。否则，在计算损耗之前，很有可能错误地将softmax函数应用于输出。</li><li id="c72f" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">(这个实际上不是那个帖子上的，而是一个常见的)一个模型参数在大多数情况下不应该包含<code class="fe ls lt lu lv b">NaN</code>(不是数字)或者<code class="fe ls lt lu lv b">Inf</code>(无穷大)。这同样适用于模型输出。</li></ul><p id="fed3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了提出这些检查，他还构建了一个实现它们的Python包。这是一个很好的包，但仍然有未解决的痛点。该软件包是几年前构建的，不再维护。</p><p id="be6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，受这种健全性检查思想的启发，旨在创建一个易于使用的Python包，torcheck应运而生！它的主要创新是:</p><ul class=""><li id="d505" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">不再需要额外的测试代码。只需在训练前添加几行指定检查的代码，torcheck就会接管，在训练进行时执行检查，并在检查失败时发出一条信息性错误消息。</li><li id="b11a" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">在不同的层次上检查你的模型是可能的。你可以指定检查一个子模块，一个线性层，甚至是权张量，而不是检查整个模型！这使得围绕复杂体系结构的检查有了更多的定制。</li></ul><p id="68fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们会给你一个关于torcheck的快速教程。以下是一些有用的链接:</p><ul class=""><li id="b3c8" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated"><a class="ae kv" href="https://github.com/pengyan510/torcheck" rel="noopener ugc nofollow" target="_blank"> Torcheck GitHub页面</a></li><li id="383f" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated"><a class="ae kv" href="https://pypi.org/project/torcheck/" rel="noopener ugc nofollow" target="_blank"> Torcheck PyPI页面</a></li></ul></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="a43a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我们已经编写了一个用于分类<a class="ae kv" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>的ConvNet模型。完整的训练程序如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="9733" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型代码中实际上有一个细微的错误。你们中的一些人可能已经注意到:在第16行，我们不小心把<code class="fe ls lt lu lv b">x</code>放在了右手边，它应该是<code class="fe ls lt lu lv b">output</code>。</p><p id="1a7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们看看torcheck如何帮助您检测这个隐藏的错误！</p><h1 id="44e2" class="mt mu iq bd mv mw mx my mz na nb nc nd jw ne jx nf jz ng ka nh kc ni kd nj nk bi translated">步骤0:安装</h1><p id="e581" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">在我们开始之前，首先在一行中安装软件包。</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="cde3" class="nu mu iq lv b gy nv nw l nx ny">$ pip install torcheck</span></pre><h1 id="f98f" class="mt mu iq bd mv mw mx my mz na nb nc nd jw ne jx nf jz ng ka nh kc ni kd nj nk bi translated">步骤1:添加torcheck代码</h1><p id="2b67" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">接下来，我们将添加代码。Torcheck代码总是驻留在模型和优化器实例化之后，紧接在训练for循环之前，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><h1 id="45ee" class="mt mu iq bd mv mw mx my mz na nb nc nd jw ne jx nf jz ng ka nh kc ni kd nj nk bi translated">步骤1.1:注册您的优化器</h1><p id="58d1" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">首先，向torcheck注册您的优化器:</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="7748" class="nu mu iq lv b gy nv nw l nx ny">torcheck.register(optimizer)</span></pre><h1 id="f0c6" class="mt mu iq bd mv mw mx my mz na nb nc nd jw ne jx nf jz ng ka nh kc ni kd nj nk bi translated">步骤1.2:添加健全性检查</h1><p id="f8b3" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">接下来，在这四个类别中添加您想要执行的所有检查。</p><h2 id="12cb" class="nu mu iq bd mv nz oa dn mz ob oc dp nd lf od oe nf lj of og nh ln oh oi nj oj bi translated">1.参数改变/不改变</h2><p id="f1f3" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">对于我们的例子，我们希望所有的模型参数在训练过程中改变。添加检查很简单:</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="987f" class="nu mu iq lv b gy nv nw l nx ny"># check all the model parameters will change<br/># module_name is optional, but it makes error messages more informative when checks fail<br/>torcheck.add_module_changing_check(model, module_name="my_model")</span></pre><h2 id="c183" class="nu mu iq bd mv nz oa dn mz ob oc dp nd lf od oe nf lj of og nh ln oh oi nj oj bi translated">边注</h2><p id="9274" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">为了展示torcheck的全部功能，假设稍后您冻结了卷积层，而只想微调线性层。在这种情况下添加检查类似于:</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="bd79" class="nu mu iq lv b gy nv nw l nx ny"># check the first convolutional layer's parameters won't change<br/>torcheck.add_module_unchanging_check(model.conv1, module_name="conv_layer_1")</span><span id="f6e0" class="nu mu iq lv b gy ok nw l nx ny"># check the second convolutional layer's parameters won't change<br/>torcheck.add_module_unchanging_check(model.conv2, module_name="conv_layer_2")</span><span id="c6bf" class="nu mu iq lv b gy ok nw l nx ny"># check the third convolutional layer's parameters won't change<br/>torcheck.add_module_unchanging_check(model.conv3, module_name="conv_layer_3")</span><span id="0961" class="nu mu iq lv b gy ok nw l nx ny"># check the first linear layer's parameters will change<br/>torcheck.add_module_changing_check(model.fc1, module_name="linear_layer_1")</span><span id="0142" class="nu mu iq lv b gy ok nw l nx ny"># check the second linear layer's parameters will change<br/>torcheck.add_module_changing_check(model.fc2, module_name="linear_layer_2")</span></pre><h2 id="3b70" class="nu mu iq bd mv nz oa dn mz ob oc dp nd lf od oe nf lj of og nh ln oh oi nj oj bi translated">2.输出范围检查</h2><p id="4d88" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">由于我们的模型是一个分类模型，我们想要添加前面提到的检查:模型输出不应该都在范围(0，1)内。</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="8e1e" class="nu mu iq lv b gy nv nw l nx ny"># check model outputs are not all within (0, 1)<br/># aka softmax hasn't been applied before loss calculation<br/>torcheck.add_module_output_range_check(<br/>    model,<br/>    output_range=(0, 1),<br/>    negate_range=True,<br/>)</span></pre><p id="8612" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">negate_range=True</code>的说法带有“并非全部”的意思。如果您只想检查模型输出是否都在某个范围内，只需删除该参数。</p><p id="c805" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管torcheck不适用于我们的示例，但它也使您能够检查子模块的中间输出。</p><h2 id="7946" class="nu mu iq bd mv nz oa dn mz ob oc dp nd lf od oe nf lj of og nh ln oh oi nj oj bi translated">3.NaN检查</h2><p id="aaed" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">我们肯定希望确保模型参数在训练期间不会变成NaN，并且模型输出不包含NaN。添加NaN检查很简单:</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="11e7" class="nu mu iq lv b gy nv nw l nx ny"># check whether model parameters become NaN or outputs contain NaN<br/>torcheck.add_module_nan_check(model)</span></pre><h2 id="54b3" class="nu mu iq bd mv nz oa dn mz ob oc dp nd lf od oe nf lj of og nh ln oh oi nj oj bi translated">4.Inf检查</h2><p id="d7af" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">类似地，添加Inf检查:</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="1335" class="nu mu iq lv b gy nv nw l nx ny"># check whether model parameters become infinite or outputs contain infinite value<br/>torcheck.add_module_inf_check(model)</span></pre><p id="9f5b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">添加所有感兴趣的检查后，最终的训练代码如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><h1 id="7c07" class="mt mu iq bd mv mw mx my mz na nb nc nd jw ne jx nf jz ng ka nh kc ni kd nj nk bi translated">第二步:培训和固定</h1><p id="1308" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">现在让我们像往常一样运行培训，看看会发生什么:</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="f2b7" class="nu mu iq lv b gy nv nw l nx ny">$ python run.py</span><span id="6162" class="nu mu iq lv b gy ok nw l nx ny">Traceback (most recent call last):<br/>  (stack trace information here)<br/>RuntimeError: The following errors are detected while training:<br/>Module my_model's conv1.weight should change.<br/>Module my_model's conv1.bias should change.</span></pre><p id="64cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">砰！我们立即得到一条错误消息，说我们的模型的<code class="fe ls lt lu lv b">conv1.weight</code>和<code class="fe ls lt lu lv b">conv1.bias</code>没有改变。<code class="fe ls lt lu lv b">model.conv1</code>肯定有问题。</p><p id="f4d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如预期的那样，我们转向模型代码，注意到错误，修复它，并重新运行培训。现在一切都像魔咒一样工作:)</p><h1 id="37fa" class="mt mu iq bd mv mw mx my mz na nb nc nd jw ne jx nf jz ng ka nh kc ni kd nj nk bi translated">(可选)步骤3:关闭检查</h1><p id="e5d9" class="pw-post-body-paragraph kw kx iq ky b kz nl jr lb lc nm ju le lf nn lh li lj no ll lm ln np lp lq lr ij bi translated">耶！我们的模型已经通过了所有的检查。为了摆脱它们，我们可以简单地调用</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="2cca" class="nu mu iq lv b gy nv nw l nx ny">torcheck.disable()</span></pre><p id="f64f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当您想要在验证集上运行您的模型，或者您只想从您的模型训练中删除检查开销时，这是非常有用的。</p><p id="687e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想再开支票，就打电话</p><pre class="kg kh ki kj gt nq lv nr ns aw nt bi"><span id="e0b6" class="nu mu iq lv b gy nv nw l nx ny">torcheck.enable()</span></pre></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="1c0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是开始使用torcheck所需的全部内容。更全面的介绍请参考其<a class="ae kv" href="https://github.com/pengyan510/torcheck" rel="noopener ugc nofollow" target="_blank"> GitHub页面</a>。</p><p id="c9e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于该软件包仍处于早期阶段，可能会有一些错误。请不要犹豫报告他们。欢迎任何投稿。</p><p id="a45a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望你觉得这个包有用，让你对你的黑盒模型更有信心！</p></div></div>    
</body>
</html>