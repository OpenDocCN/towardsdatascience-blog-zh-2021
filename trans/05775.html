<html>
<head>
<title>Troubleshooting Dask GroupBy Aggregation Performance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Dask GroupBy聚合性能故障排除</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/troubleshooting-dask-groupby-aggregation-performance-1c39599598c1?source=collection_archive---------27-----------------------#2021-05-23">https://towardsdatascience.com/troubleshooting-dask-groupby-aggregation-performance-1c39599598c1?source=collection_archive---------27-----------------------#2021-05-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fffb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何解决Dask GroupBy聚合的性能问题？对算法的深入研究。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6a81dca506a7204195d0dbe62b937e71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJOahX-rDQQJOUabSqzgYQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">示例分组任务图—Julia Signell<a class="kv kw ep" href="https://medium.com/u/b865b2668619?source=post_page-----1c39599598c1--------------------------------" rel="noopener" target="_blank">的courtsey</a></p></figure><p id="94d6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在Saturn Cloud，<a class="ae lt" href="https://www.saturncloud.io" rel="noopener ugc nofollow" target="_blank">我们管理着一个数据科学平台</a>，该平台提供Jupyter笔记本、Dask集群以及部署模型、仪表盘和作业的方法。因此，我们经常帮助客户排除Dask操作故障。GroupBys的问题经常出现。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="cd7b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Dask数据框架对于交互式探索大型数据集来说是惊人的。然而，在大型数据集上使用它们可能有点棘手。您可能已经在尝试进行分组时遇到了一个<code class="fe mb mc md me b">KilledWorker</code>异常。如果你还没有，你很快就会了！</p><p id="6b0e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本文的目标是为您提供一组选项，供您在GroupBy失败时尝试。首先，我们将深入了解数据帧分组聚合是如何实现的。这对于理解如何绕过你遇到的任何障碍是必要的。</p><h1 id="f044" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">Dask GroupBy聚合</h1><p id="406e" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">Dask GroupBy聚合使用<code class="fe mb mc md me b">apply_concat_apply()</code>方法，该方法对<code class="fe mb mc md me b">dask.DataFrame</code>应用3个函数，一个<code class="fe mb mc md me b">chunk()</code>、<code class="fe mb mc md me b">combine()</code>和一个<code class="fe mb mc md me b">aggregate()</code>函数。这是一个非常强大的范例，因为它使您能够通过提供这些函数来构建自己的自定义聚合。我们将在示例中引用这些函数。</p><ul class=""><li id="b1d3" class="nc nd iq kz b la lb ld le lg ne lk nf lo ng ls nh ni nj nk bi translated"><strong class="kz ir"> chunk </strong>:该方法应用于Dask数据帧的每个分区。</li><li id="1743" class="nc nd iq kz b la nl ld nm lg nn lk no lo np ls nh ni nj nk bi translated"><strong class="kz ir">合并</strong>:来自<code class="fe mb mc md me b">chunk()</code>步骤的输出被连接，然后与<code class="fe mb mc md me b">combine()</code>合并在一起。</li><li id="2560" class="nc nd iq kz b la nl ld nm lg nn lk no lo np ls nh ni nj nk bi translated"><strong class="kz ir">聚合</strong>:来自<code class="fe mb mc md me b">combine()</code>步骤的输出被连接，然后用<code class="fe mb mc md me b">aggregate()</code>聚合。这是最后一步。经过这个转换，你的结果就完成了。</li></ul><h1 id="2593" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">Dask GroupBy聚合:最简单的例子</h1><p id="aaa3" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">在这个例子中，我们将通过一个带有默认参数的Dask GroupBy来展示算法是如何工作的。我们使用一个虚拟数据集，它被分成4个分区。我们已经为<code class="fe mb mc md me b">score</code>选择了具有独立小数位的数值，以便在汇总数据时更加明显。</p><p id="ee31" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">此示例应用以下转换:</p><p id="92b9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Dask GroupBy聚合将算法分为<code class="fe mb mc md me b">chunk()</code>、<code class="fe mb mc md me b">combine()</code>和<code class="fe mb mc md me b">aggregate()</code>步骤。在这种情况下(最简单的一种)，我们只使用<code class="fe mb mc md me b">chunk()</code>和<code class="fe mb mc md me b">aggregate()</code>步骤。这种特殊的聚集是优雅的，因为这些步骤中的每一个都以相同的方式实现，通过按动物分组并对分数求和(<code class="fe mb mc md me b">df.groupby('animal')['zscore'].sum()</code>)。通过对分区求和，然后对这些和求和，我们可以计算出所需的结果。其他算法如<code class="fe mb mc md me b">var()</code>在不同的阶段需要不同的操作。该图展示了相关的操作，并向我们展示了每一步的数据情况。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/819e62f7a90fbb4113f495efd0566487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nUebFgL8deP7gPT_.jpg"/></div></div></figure><p id="7a05" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们的样本数据集被分成4个分区。<strong class="kz ir">步骤1 </strong>将<code class="fe mb mc md me b">chunk()</code>函数应用于每个分区。这是一个重要的步骤，因为它的输出是一个缩减，比原始分区小得多。<strong class="kz ir">步骤2 </strong>将<strong class="kz ir">步骤1 </strong>的输出连接成一个数据帧，然后对结果应用<code class="fe mb mc md me b">aggregate()</code>函数。</p><h2 id="2ace" class="nr mg iq bd mh ns nt dn ml nu nv dp mp lg nw nx mr lk ny nz mt lo oa ob mv oc bi translated">问题</h2><p id="2293" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">简单的情况是返回一个分区，其中包含整个结果。如果你的<code class="fe mb mc md me b">GroupBy</code>产生一个小的数据帧，这个方法很好。如果您的<code class="fe mb mc md me b">GroupBy</code>导致一个大的数据帧(如果您有大量的组)，您将耗尽内存，这通常在<code class="fe mb mc md me b">KilledWorker</code>异常中表现出来。</p><h1 id="9af3" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">处理记忆:分裂</h1><p id="2759" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">Dask提供两个参数<code class="fe mb mc md me b">split_out</code>和<code class="fe mb mc md me b">split_every</code>来控制数据流。<code class="fe mb mc md me b">split_out</code>控制生成的分区数量。如果我们设置<code class="fe mb mc md me b">split_out=4</code>，group by将产生4个分区，而不是1个。我们稍后会谈到<code class="fe mb mc md me b">split_every</code>。让我们用<code class="fe mb mc md me b">split_out=4</code>重做前面的例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/e3e8fe4769b63854dc68478f7e1108c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jhP6WP4tHNkIi3qZ.jpg"/></div></div></figure><p id="44e8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">第1步</strong>与上例相同。<strong class="kz ir">步骤1 </strong>(应用<code class="fe mb mc md me b">chunk()</code>函数)的输出是每个分区1个数据帧。<strong class="kz ir">步骤2 </strong>通过散列分组将这些数据帧中的每一个分成<code class="fe mb mc md me b">split_out=4</code>个数据帧。查看图表，您会看到每个分区的第n个数据帧中有相同的动物。这种一致性是哈希的目标。我们将每个组称为一个分片(分片1包含每个分区的第一个数据帧，分片2包含每个分区的第二个数据帧，依此类推)。<strong class="kz ir">步骤3 </strong>将组成每个碎片的所有数据帧连接起来(同样使用这种散列法),这样来自相同动物的数据就会出现在相同的数据帧中。然后应用<code class="fe mb mc md me b">aggregate()</code>功能。结果现在是一个由<code class="fe mb mc md me b">split_out=4</code>分区组成的Dask数据帧。</p><h1 id="ef81" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">高级选项:分割_每</h1><p id="18a6" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">在前面的示例中，<strong class="kz ir">步骤3，</strong> Dask为每个分区分片串接数据。默认情况下，Dask会一次为多达8个分区分片连接数据。因为我们的数据集只有4个分区，所以所有的数据都是一次性处理的。让我们用<code class="fe mb mc md me b">split_every=2</code>重新运行前面的例子。第二步之前的一切都是一样的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/2c238cfabc09da9bd3e0110893cb4d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KocAt_QsxQmGvGdk.jpg"/></div></div></figure><p id="9779" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用<code class="fe mb mc md me b">split_every=2</code>，我们一次连接两个数据帧，然后用<strong class="kz ir">步骤3 </strong>中的<code class="fe mb mc md me b">combine()</code>函数组合它们，而不是连接来自单个碎片的所有数据帧(在我们的例子中，每个碎片有4个数据帧)。<strong class="kz ir">步骤4 </strong>将这些结果连接起来，然后调用<code class="fe mb mc md me b">aggregate()</code>。用<code class="fe mb mc md me b">combine()</code>最后用<code class="fe mb mc md me b">aggregate()</code>的约简是一个树约简。因为我们只有4个分区，所以我们可以在1个<code class="fe mb mc md me b">combine()</code>步骤和1个<code class="fe mb mc md me b">aggregate()</code>步骤中完成这个操作。然而，如果我们有8个分区，将有2个<code class="fe mb mc md me b">combine()</code>步骤和1个<code class="fe mb mc md me b">aggregate()</code>步骤。<code class="fe mb mc md me b">aggregate()</code>永远是最后一步。</p><h1 id="7ee8" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">我们该怎么办</h1><p id="d251" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">真的只有两件事可以做。我知道这可能看起来有点反高潮，考虑到我们刚刚经历的关于算法如何工作的长度解释，然而理解算法对于理解如何调整它是重要的。</p><h1 id="51e0" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">调整拆分</h1><p id="516b" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated"><code class="fe mb mc md me b">split_out</code>参数可以传递给聚合函数。</p><p id="8867" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这一部分将有点近似和手动波动。最终，您需要对您的数据集进行实验，并找出哪些参数有效。这一节可能会为你提供一些如何思考这个问题的指导。</p><h2 id="28bd" class="nr mg iq bd mh ns nt dn ml nu nv dp mp lg nw nx mr lk ny nz mt lo oa ob mv oc bi translated">了解您的数据</h2><p id="4d2b" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">我将有几个小组？希望您对数据有足够的了解，能够大致估计出结果中的组数。如果不是，你可能需要以某种方式计算它。举个例子，我有一个包含5000万动物的数据集。我获取数据的一个子集，执行计算，观察到我的结果有500万只动物，占用500 mb内存。500万只动物是我在数据集中拥有的5000万只动物的1/10，所以我的最终结果大约是5GB。</p><h2 id="1b32" class="nr mg iq bd mh ns nt dn ml nu nv dp mp lg nw nx mr lk ny nz mt lo oa ob mv oc bi translated">分区大小</h2><p id="c312" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">分区大小是一个不同的主题，这里不讨论。一般来说，您应该调整分区的大小，以便一个工作线程可以容纳多个分区，但是理想的分区大小取决于您的工作线程有多少内存。</p><p id="325d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">假设我有8GB的工人。如果我的最终结果是5GB，我可以将<code class="fe mb mc md me b">split_out</code>设置为5，这样每个1GB的结果都适合这个工人。然而，默认的<code class="fe mb mc md me b">split_every</code>参数被设置为8。如果每个分区都是1GB，在最坏的情况下，我可能会连接8GB——这将耗尽我的8GB工作人员。相反，我选择<code class="fe mb mc md me b">split_out</code>为25，这样每个分区都是200MB。</p><p id="9eef" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现实不会这么精确。确切的内存使用将取决于您的数据如何在不同的机器之间布置，以及实际的pandas计算本身使用了多少内存。如果您的数据是按照groupby列排序的，那么您的内存使用量将接近理想值。如果您在每台机器上都有来自每个组的数据，那么您的内存使用将接近最坏的情况。但是这种方法可以作为选择<code class="fe mb mc md me b">split_out</code>的粗略指南。</p><p id="4931" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我不建议调<code class="fe mb mc md me b">split_every</code>。调整单个参数要容易得多，默认值8类似于您希望Dask workers有多少额外的内存空间。</p><h1 id="d476" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">请改用map_partitions</h1><p id="4176" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated"><code class="fe mb mc md me b">map_partitions()</code>是Dask数据帧上的一个方法(它也用于其他Dask集合),将一个函数应用于Dask数据帧的所有分区，然后在这些结果上构建另一个Dask数据帧。</p><p id="772b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果您的数据已经按照您希望分组的字段排序，那么使用<code class="fe mb mc md me b">map_partitions()</code>是一个好的策略。在这个示例数据集中，如果我的数据已经按动物排序，并且我知道所有的猫都在一个分区中，所有的狗都在另一个分区中，那么我知道我不需要来自其他分区的数据来计算每种动物的统计数据。这意味着我可以取代</p><pre class="kg kh ki kj gt of me og oh aw oi bi"><span id="217e" class="nr mg iq me b gy oj ok l ol om">ddf<strong class="me ir">.</strong>groupby<strong class="me ir">(</strong>'animal'<strong class="me ir">)[</strong>'scores'<strong class="me ir">].</strong>sum<strong class="me ir">()</strong></span></pre><p id="cec3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">随着</p><pre class="kg kh ki kj gt of me og oh aw oi bi"><span id="b0ab" class="nr mg iq me b gy oj ok l ol om">ddf<strong class="me ir">.</strong>map_partitions<strong class="me ir">(lambda</strong> x<strong class="me ir">:</strong> x<strong class="me ir">.</strong>groupby<strong class="me ir">(</strong>'animal'<strong class="me ir">)[</strong>'scores'<strong class="me ir">].</strong>sum<strong class="me ir">()</strong></span></pre><h2 id="f7e7" class="nr mg iq bd mh ns nt dn ml nu nv dp mp lg nw nx mr lk ny nz mt lo oa ob mv oc bi translated">不要对你的数据进行排序</h2><p id="e622" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">如果我的数据没有排序，我可以使用<code class="fe mb mc md me b">set_index()</code>或<code class="fe mb mc md me b">shuffle</code>进行排序。然后我可以申请<code class="fe mb mc md me b">map_partitions()</code>。这可能不值得。groupby聚合中的数据移动应该少于<code class="fe mb mc md me b">set_index()</code>中的数据移动，因为第一步的<code class="fe mb mc md me b">chunk()</code>操作会显著减少数据量。</p><h2 id="fabe" class="nr mg iq bd mh ns nt dn ml nu nv dp mp lg nw nx mr lk ny nz mt lo oa ob mv oc bi translated">不要使用GroupBy然后应用</h2><p id="3fac" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated"><code class="fe mb mc md me b">map_partition</code>是在数据已经排序的情况下，如何实现带有Apply的Dask GroupBy。这意味着我可以将我的聚合写成</p><p id="9b75" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这可能比原来的例子慢得多，纯粹是因为pandas groupby applys比groupby aggregations慢得多。</p><h1 id="cdc8" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">结论</h1><p id="7703" class="pw-post-body-paragraph kx ky iq kz b la mx jr lc ld my ju lf lg mz li lj lk na lm ln lo nb lq lr ls ij bi translated">为了在集群上实现GroupBy聚合，Dask做了很多工作。在大多数情况下，它开箱即用。如果没有，可以调优<code class="fe mb mc md me b">split_out</code>让Dask产生更小的块。如果您的数据已经排序，您可以使用<code class="fe mb mc md me b">map_partitions()</code>更有效地实现操作。实际的算法可能有点难以理解，但是理解它可以帮助您获得关于如何调整参数的直觉。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="4d8c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">声明:我是<a class="ae lt" href="https://www.saturncloud.io/s/home/" rel="noopener ugc nofollow" target="_blank">土星云</a>的CTO。我们让您的团队轻松连接云资源。想用Jupyter和Dask？部署模型、仪表板或作业？在笔记本电脑或4 TB Jupyter实例上工作？完全透明地了解谁在使用哪些云资源？我们做所有这些，甚至更多。</p><p id="3dd0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><em class="on">最初发布于</em><a class="ae lt" href="https://www.saturncloud.io/docs/reference/dask_groupby_aggregations/" rel="noopener ugc nofollow" target="_blank"><em class="on">https://www . Saturn cloud . io</em></a><em class="on">。</em></p></div></div>    
</body>
</html>