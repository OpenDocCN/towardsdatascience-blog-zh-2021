<html>
<head>
<title>Neural Search with Haystack — Semantic Search At Its Finest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Haystack神经搜索——语义搜索的极致</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-search-with-haystack-semantic-search-at-its-finest-5f39d07b992?source=collection_archive---------14-----------------------#2021-04-11">https://towardsdatascience.com/neural-search-with-haystack-semantic-search-at-its-finest-5f39d07b992?source=collection_archive---------14-----------------------#2021-04-11</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="8b17" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">一个快速简单的指南，用变形金刚和最少的设置建立你自己的搜索引擎</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/667c1a63659a3d465a4e175b45c5653d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oiibjk4i7PtGL_F1"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">卢卡·胡特在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b0ac" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">语义搜索在我们的日常生活中相当常见，尤其是我们使用谷歌作为大多数问题(如果不是所有问题)答案的媒介的次数。直到几年前，在没有大量计算资源的情况下构建一个相当不错的搜索引擎还是一件痛苦的事情。简而言之，这太难了，需要大量的高级NLP概念的专业知识。</p><blockquote class="lw lx ly"><p id="b06c" class="la lb lz lc b ld le jv lf lg lh jy li ma lk ll lm mb lo lp lq mc ls lt lu lv in bi translated">BERT transformer模型及其后继者的出现改变了这一点。虽然我们仍然需要一个好的GPU来微调这些模型，但一些令人敬畏的库，如<a class="ae kz" href="https://haystack.deepset.ai/" rel="noopener ugc nofollow" target="_blank"> Haystack </a>现在已经可以非常容易地围绕我们选择的数据集构建生产就绪的应用程序。</p></blockquote><p id="d5a5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在本文中，我将展示如何从公开可用的数据集(例如Kaggle)中快速构建自己的定制搜索引擎。</p><p id="2e76" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们开始吧！👇</p><h2 id="87bb" class="md me iu bd mf mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu mv bi translated">但首先，干草堆到底是什么？</h2><blockquote class="mw"><p id="969d" class="mx my iu bd mz na nb nc nd ne nf lv dk translated">简而言之，它是一个非常棒的库，可以用来构建生产就绪的、可伸缩的搜索系统和问题回答系统。</p></blockquote><p id="66bc" class="pw-post-body-paragraph la lb iu lc b ld ng jv lf lg nh jy li lj ni ll lm ln nj lp lq lr nk lt lu lv in bi translated">它利用了最新的transformer模型，因此对研究人员和开发人员来说都是最好的NLP工具包之一。</p><p id="dee7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">它提供了用于构建此类系统的不同组件，这些组件非常易于学习和实验。我将在本文中讨论其中一些，希望能给你一个好的起点！</p><h2 id="b81a" class="md me iu bd mf mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu mv bi translated">获取数据集</h2><p id="0d87" class="pw-post-body-paragraph la lb iu lc b ld nl jv lf lg nm jy li lj nn ll lm ln no lp lq lr np lt lu lv in bi translated">我们将使用来自Kaggle的数据集的子集<a class="ae kz" href="https://www.kaggle.com/Cornell-University/arxiv" rel="noopener ugc nofollow" target="_blank">。它包含大约170万篇来自STEM的arxiv研究论文，每篇论文都有不同的特征，如摘要、作者、发表日期、标题等。它是json格式的，我编译了一个更小的版本。</a></p><blockquote class="lw lx ly"><p id="ed0c" class="la lb lz lc b ld le jv lf lg lh jy li ma lk ll lm mb lo lp lq mc ls lt lu lv in bi translated">在我的GitHub repo上的这里有更小的版本。继续将<strong class="lc iv"> arxiv_short.csv </strong>下载到您的机器上。</p></blockquote><p id="92fd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了简单起见，我确保只保留50，000个文档和三列:</p><ul class=""><li id="a5c6" class="nq nr iu lc b ld le lg lh lj ns ln nt lr nu lv nv nw nx ny bi translated"><strong class="lc iv">作者</strong> —论文的作者</li><li id="e6be" class="nq nr iu lc b ld nz lg oa lj ob ln oc lr od lv nv nw nx ny bi translated"><strong class="lc iv">摘要</strong> —论文摘要</li><li id="eafc" class="nq nr iu lc b ld nz lg oa lj ob ln oc lr od lv nv nw nx ny bi translated"><strong class="lc iv">标题</strong> —论文标题</li></ul><p id="440d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">和熊猫一起读:</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="3f24" class="md me iu of b gz oj ok l ol om">import pandas as pd</span><span id="c7c0" class="md me iu of b gz on ok l ol om">df = pd.read_csv('arxiv_short.csv')<br/>df.head()</span></pre><p id="8d64" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们来看看数据:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oo"><img src="../Images/e23aeb5be65093d93f572066f139c8da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FVoCP3oacwqY4ZC3JSEyNg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">arxiv数据集标题行</p></figure><p id="2098" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们现在准备设置我们的haystack引擎。</p><h2 id="21fa" class="md me iu bd mf mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu mv bi translated">安装干草堆</h2><p id="17e9" class="pw-post-body-paragraph la lb iu lc b ld nl jv lf lg nm jy li lj nn ll lm ln no lp lq lr np lt lu lv in bi translated">这一步只需要两行代码。首先确保你处于虚拟环境中。</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="2230" class="md me iu of b gz oj ok l ol om">pip install git+https://github.com/deepset-ai/haystack.git</span><span id="d057" class="md me iu of b gz on ok l ol om">pip install sentence-transformers</span></pre><blockquote class="lw lx ly"><p id="d6c4" class="la lb lz lc b ld le jv lf lg lh jy li ma lk ll lm mb lo lp lq mc ls lt lu lv in bi translated">我们将使用haystack构建实际的搜索引擎，并使用句子转换器从我们的<strong class="lc iv"> <em class="iu">摘要</em> </strong>文本列创建句子嵌入，我们的搜索引擎将基于该文本列。</p></blockquote><p id="99db" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，让我们继续为我们的haystack搜索引擎构建不同的组件！</p><h2 id="a5f3" class="md me iu bd mf mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu mv bi translated">初始化文档存储和检索器</h2><blockquote class="lw lx ly"><p id="0615" class="la lb lz lc b ld le jv lf lg lh jy li ma lk ll lm mb lo lp lq mc ls lt lu lv in bi translated">一个<strong class="lc iv">文档存储库</strong>存储我们的可搜索文本及其元数据。</p></blockquote><p id="1c1b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">例如，这里我们的文本将是来自数据集的<strong class="lc iv">抽象</strong>列，其余两列— <strong class="lc iv">标题</strong>和<strong class="lc iv">作者</strong> —将由我们的元数据组成。</p><p id="1bea" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">初始化和构建相当简单:</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="1deb" class="md me iu of b gz oj ok l ol om">document_store_faiss = FAISSDocumentStore(faiss_index_factory_str="Flat", return_embedding=True)</span></pre><p id="a3fb" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><a class="ae kz" href="https://github.com/facebookresearch/faiss" rel="noopener ugc nofollow" target="_blank"> FAISS </a>是一个用于高效相似性搜索和密集向量聚类的库，因为它不需要额外的设置，所以我更喜欢在这里使用它而不是Elasticsearch。</p><p id="cb54" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在猎犬来了。</p><blockquote class="lw lx ly"><p id="8fbc" class="la lb lz lc b ld le jv lf lg lh jy li ma lk ll lm mb lo lp lq mc ls lt lu lv in bi translated">一个<strong class="lc iv">检索器</strong>是一个过滤器，它可以快速遍历整个文档库，并根据对给定查询相似性搜索，从中找出一组候选文档。</p></blockquote><blockquote class="mw"><p id="c72f" class="mx my iu bd mz na op oq or os ot lv dk translated">其核心是，我们正在构建一个语义搜索系统，因此从查询中获取相关文档是我们项目的核心。</p></blockquote><p id="39fe" class="pw-post-body-paragraph la lb iu lc b ld ng jv lf lg nh jy li lj ni ll lm ln nj lp lq lr nk lt lu lv in bi translated">初始化一个检索器也很简单:</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="718d" class="md me iu of b gz oj ok l ol om">retriever_faiss = EmbeddingRetriever(document_store_faiss, embedding_model='distilroberta-base-msmarco-v2',model_format='sentence_transformers')</span></pre><p id="ffeb" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在这里，<strong class="lc iv">distilloberta</strong>仅仅是一个transformer模型BERT模型的变体——我们在这里使用它来为我们的文本进行嵌入。它作为<strong class="lc iv">句子变形金刚</strong>套装的一部分提供。</p><p id="034f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，我们想将文档写入我们的文档存储。</p><h2 id="c46d" class="md me iu bd mf mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu mv bi translated">构建文档存储</h2><p id="8608" class="pw-post-body-paragraph la lb iu lc b ld nl jv lf lg nm jy li lj nn ll lm ln no lp lq lr np lt lu lv in bi translated">我们只需将数据帧的列传递给文档存储。</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="33f4" class="md me iu of b gz oj ok l ol om">document_store_faiss.delete_all_documents() # a precaution</span><span id="a51d" class="md me iu of b gz on ok l ol om"><br/>document_store_faiss.write_documents(</span><span id="31f9" class="md me iu of b gz on ok l ol om">df[['authors', 'title', 'abstract']].rename(columns={ </span><span id="447c" class="md me iu of b gz on ok l ol om">'title':'name',</span><span id="239f" class="md me iu of b gz on ok l ol om">'author' : 'author',</span><span id="d384" class="md me iu of b gz on ok l ol om">'abstract':'text'</span><span id="9d5f" class="md me iu of b gz on ok l ol om">}</span><span id="7008" class="md me iu of b gz on ok l ol om">).to_dict(orient='records'))</span></pre><p id="47d7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这里需要进行一点重命名，因为haystack希望我们的文档以这种格式编写:</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="348b" class="md me iu of b gz oj ok l ol om">{ 'text': DOCUMENT_TEXT, 'meta': {'name': DOCUMENT_NAME, ...}     }, ... and so on.</span></pre><p id="7b6f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">最后，在构建完成后，我们将文档存储提供给我们的检索器。</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="5c00" class="md me iu of b gz oj ok l ol om">document_store_faiss.update_embeddings(retriever=retriever_faiss)</span></pre><blockquote class="lw lx ly"><p id="2d7d" class="la lb lz lc b ld le jv lf lg lh jy li ma lk ll lm mb lo lp lq mc ls lt lu lv in bi translated">数据集越大，这两个步骤需要的时间就越长。</p></blockquote><p id="0b51" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们快完成了！剩下唯一要做的就是创建一个函数来检索与查询匹配的文档！</p><h2 id="eaad" class="md me iu bd mf mg mh dn mi mj mk dp ml lj mm mn mo ln mp mq mr lr ms mt mu mv bi translated">总结——获取结果并尝试</h2><p id="1e8b" class="pw-post-body-paragraph la lb iu lc b ld nl jv lf lg nm jy li lj nn ll lm ln no lp lq lr np lt lu lv in bi translated">我们定义了一个简单的函数来从我们的数据中获取10个相关的文档(研究论文摘要)。</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="afcf" class="md me iu of b gz oj ok l ol om">def get_results(query, retriever, n_res = 10):</span><span id="af38" class="md me iu of b gz on ok l ol om">    return [(item.text, item.to_dict()['meta']) for item in    retriever.retrieve(q, top_k = n_res)]</span></pre><p id="111c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">最后我们测试一下！</p><pre class="kk kl km kn gu oe of og oh aw oi bi"><span id="e9a0" class="md me iu of b gz oj ok l ol om">query = 'Poisson Dirichlet distribution with two-parameters'<br/></span><span id="aec9" class="md me iu of b gz on ok l ol om">print('Results: ')</span><span id="8660" class="md me iu of b gz on ok l ol om">res = get_results(query, retriever_faiss)</span><span id="6c4d" class="md me iu of b gz on ok l ol om">for r in res:<br/>    print(r)</span></pre><p id="cb19" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">您可以看到这样的结果:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ou"><img src="../Images/02ab532a29d67d7bdae1a7481188c7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6V-8lePStM5eUXVja-1RA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">搜索结果</p></figure><p id="d700" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这就是你要的——一个建立在你选择的数据集上的定制语义搜索引擎！</p><p id="dde5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">去玩吧！调整一些参数—例如，尝试更改检索器对象中的转换器模型。</p><p id="3435" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">完整的代码也可以在这里的笔记本上找到:</p><div class="ov ow gq gs ox oy"><a href="https://github.com/yashprakash13/haystack-search-engine" rel="noopener  ugc nofollow" target="_blank"><div class="oz ab fp"><div class="pa ab pb cl cj pc"><h2 class="bd iv gz z fq pd fs ft pe fv fx it bi translated">yashprakash 13/haystack-搜索引擎</h2><div class="pf l"><h3 class="bd b gz z fq pd fs ft pe fv fx dk translated">基于Kaggle的Arxiv数据集构建的语义搜索引擎。-yashprakash 13/haystack-搜索引擎</h3></div><div class="pg l"><p class="bd b dl z fq pd fs ft pe fv fx dk translated">github.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm kt oy"/></div></div></a></div><p id="954b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">感谢阅读！:)</p></div><div class="ab cl pn po hy pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="in io ip iq ir"><blockquote class="lw lx ly"><p id="2940" class="la lb lz lc b ld le jv lf lg lh jy li ma lk ll lm mb lo lp lq mc ls lt lu lv in bi translated">独自学习数据科学可能会很难，<a class="ae kz" href="https://medium.com/@ipom" rel="noopener">跟我来</a>，让我们一起让它变得有趣。保证。😎</p></blockquote><p id="d9fe" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">此外，这里是我所有数据科学故事的代码库。快乐学习！⭐️</p></div><div class="ab cl pn po hy pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="in io ip iq ir"><p id="9cd2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这是我的另一篇文章，你可能想读一读:</p><div class="ov ow gq gs ox oy"><a rel="noopener follow" target="_blank" href="/deploying-an-ml-model-with-fastapi-a-succinct-guide-69eceda27b21"><div class="oz ab fp"><div class="pa ab pb cl cj pc"><h2 class="bd iv gz z fq pd fs ft pe fv fx it bi translated">使用FastAPI部署ML模型——简明指南</h2><div class="pf l"><h3 class="bd b gz z fq pd fs ft pe fv fx dk translated">如何使用NLP模型作为API——智能的、生产就绪的方式。</h3></div><div class="pg l"><p class="bd b dl z fq pd fs ft pe fv fx dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="pu l pj pk pl ph pm kt oy"/></div></div></a></div></div></div>    
</body>
</html>