<html>
<head>
<title>Simple Linear and Polynomial Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单线性和多项式回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simply-linear-and-polynomial-regression-9c9624774f5a?source=collection_archive---------8-----------------------#2021-09-26">https://towardsdatascience.com/simply-linear-and-polynomial-regression-9c9624774f5a?source=collection_archive---------8-----------------------#2021-09-26</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="abdd" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">使用Statsmodels、Polyfit、线性回归和多项式特征</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/d5e29844bf50bbfad34646b400e051bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M6ew6C5MDOhHUFLo-Cpsrg.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图片来自<a class="ae kz" href="https://unsplash.com/photos/-Bq3TeSBRdE" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><blockquote class="la lb lc"><p id="c045" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated">介绍</p></blockquote><p id="a680" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">回归是预测分析和商业预测中最基本的课题之一。它可以通过线性方式和使用高阶多项式来实现。存在使用多元线性回归生成模型的实例，但是许多真实世界的情况在因变量和自变量之间具有非线性相关性。这就是为什么需要多项式回归。使用样条进行回归也有助于最小化多项式回归的缺点，例如不必要的波动。</p><blockquote class="la lb lc"><p id="e5e9" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">用Python实现</strong></p><p id="af58" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated">使用统计模型</p></blockquote><p id="7b03" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">为了用python实现，我将使用来自这个<a class="ae kz" href="https://online.stat.psu.edu/stat501/lesson/9/9.8" rel="noopener ugc nofollow" target="_blank">链接</a>的数据。这是按年龄与鱼长相关的数据。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="md me l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj mf"><img src="../Images/6ebdd6b0852b2cf97122df79bf281025.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*m6HSzRYSdM4ZKcs1wJxOyQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="b450" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">我们希望使用线性和多项式回归来拟合这些数据。使用statsmodels，可以部署普通最小二乘法(OLS)来拟合数据。我们可以看看拟合的结果。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="md me l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj mg"><img src="../Images/fa1cf0642d71ed930e3b711e6c50f368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LppenPPv7t33A4RpWId4Yg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="e2e1" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">R平方值决定拟合的好坏。最佳实践是绘制残差图来检查异方差，但这里我们将范围限制为仅检查R平方值。R平方值为0.735表示拟合良好，但不是很强。调整后的R平方值试图抵消添加更多因变量的影响。这里显示了因变量的系数和截距。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="md me l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj mh"><img src="../Images/e5e50c5c0bcd0be6fa04f5919168c0f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*-kXQ0O_kycB7WHWxlbCIkw.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="774f" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">为了合并高阶项aka多项式回归，我们需要实现以下模块。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="md me l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj mi"><img src="../Images/26207176703c745cfd78282a9498339a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjVaKa92HHQXuTvtvN6b3g.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="aab5" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">多项式回归的R平方值为0.801，比线性回归好。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj mf"><img src="../Images/e50fce8f0eeef4d548c6f8091d77822f.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*ZCCb3g9IIjBzwnl_250wow.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><blockquote class="la lb lc"><p id="ec43" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated">使用Polyfit</p></blockquote><p id="5841" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">使用numpy的polyfit类可以实现相同的回归。这种情况下的R平方值也是0.801。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="md me l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj mf"><img src="../Images/e50fce8f0eeef4d548c6f8091d77822f.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*ZCCb3g9IIjBzwnl_250wow.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><blockquote class="la lb lc"><p id="2fee" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated">使用线性回归和多项式特征</p></blockquote><p id="757e" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">使用sklearn的基本功能，可以实现线性和多项式回归。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="md me l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj mf"><img src="../Images/77f3fd365889d7a66b1612eae9d57f6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*vZqi16XMg5x9It3i0rAqyA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="b244" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">这种情况下的R平方值为0.735，与之前的方法(使用statsmodels)相同。对于高阶回归(非线性回归)，可以使用下面的代码块。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="md me l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj mf"><img src="../Images/e947ede3fdf15162f82b902571a21423.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*sKQerJz7uc22HFjmugCBUw.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="93a1" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">在这种情况下，R平方值也是0.801。</p><blockquote class="la lb lc"><p id="1a31" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated">结论</p></blockquote><p id="89e8" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">我们已经尝试了三种不同的方法来实现多项式回归，在所有情况下，我们都得到了相同的R平方值。对于python中的回归分析，所有这些方法都是相似的。对每次执行持续时间的简单测试表明，numpy的polyfit是最快的实现。因此，在处理大数据时，与其他实现相比，polyfit可能是更好的方法。</p></div></div>    
</body>
</html>