<html>
<head>
<title>Demystified: Wasserstein GANs (WGAN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭秘:瓦瑟斯坦·甘斯(WGAN)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystified-wasserstein-gans-wgan-f835324899f4?source=collection_archive---------5-----------------------#2021-09-17">https://towardsdatascience.com/demystified-wasserstein-gans-wgan-f835324899f4?source=collection_archive---------5-----------------------#2021-09-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="83d6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">什么是瓦瑟斯坦距离？用Wasserstein距离训练GANs背后的直觉是什么？是如何实现的？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b817dfe719307f93fd3ecf3690a15e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7eio04uWQyuP_IHnK-qpA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">图1:学习区分两个高斯函数时的最佳鉴别器和批判器[1]。</strong></p></figure><p id="1512" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我们将了解Wasserstein GANs。具体来说，我们将关注以下内容:I)什么是Wasserstein距离？，ii)为什么使用它？iii)我们如何使用它来训练GANs？</p><h1 id="a0bc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">瓦瑟斯坦距离</h1><p id="881a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">Wasserstein距离(推土机距离)是给定度量空间上两个概率分布之间的距离度量。直观上，它可以被视为将一种分布转换为另一种分布所需的最小功，其中功被定义为必须移动的分布的质量与移动距离的乘积。数学上，它被定义为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/9b3f2975523e002cd8c7954de72532d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bo6JYKzi6h2vNW3FxN56Rw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">情商。1:分布P_r和P_g之间的Wasserstein距离</strong></p></figure><p id="08d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Eq中。1，π(P_r，P_g)是在<strong class="ky ir"> x </strong>和<strong class="ky ir"> y </strong>上的所有联合分布的集合，使得边际分布等于P_r和P _ g。γ(x，y)可以被视为必须从x移动到y以将P _ r转换为P_g[1]的质量量。瓦瑟斯坦距离就是最优运输计划的成本。</p><h1 id="4bbe" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">瓦瑟斯坦距离与詹森-香农散度</h1><p id="d615" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">最初的GAN目标是Jensen-Shannon散度的最小化[2]。JS散度定义为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/5f44a79277ec1560fd9809d6a87f68fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyGiXiOGC78Djdwvn_YpNA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">情商。2:P _ r和P_g之间的JS背离P_m = (P_r + P_g)/2 </strong></p></figure><p id="6bcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与JS相比，Wasserstein距离具有以下优势:</p><ul class=""><li id="fdf0" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">Wasserstein距离是连续的，几乎处处可微，这允许我们将模型训练到最优。</li><li id="ce56" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">随着鉴别器变得更好，JS发散局部饱和，因此梯度变为零并消失。</li><li id="3c8d" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">Wasserstein距离是一个有意义的度量，即，当分布彼此接近时，它收敛到0，而当它们远离时，它发散。</li><li id="7c95" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">Wasserstein距离作为目标函数比使用JS散度更稳定。当使用Wasserstein距离作为目标函数时，也减轻了模式崩溃问题。</li></ul><p id="4387" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从图1中我们可以清楚地看到，最佳GAN鉴频器饱和并导致梯度消失，而优化Wasserstein距离的WGAN critic始终具有稳定的梯度。</p><p id="8a88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要获得数学证明和对这个话题更详细的了解，请点击这里查看论文<a class="ae nf" href="https://arxiv.org/pdf/1701.07875.pdf" rel="noopener ugc nofollow" target="_blank"/>！</p><h1 id="1021" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">瓦瑟斯坦·甘</h1><p id="725f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在可以清楚地看到，优化Wasserstein距离比优化JS散度更有意义，还需要注意的是，等式1中定义的Wasserstein距离非常难以处理[3]，因为我们不可能计算所有γ∈π(Pr，Pg)的下确界(最大下界)。然而，从Kantorovich-Rubinstein对偶来看，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/053ca014ed3ef9874282320b26d4df3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ERuZ0kLek8Q4VMgyLFohw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">情商。3:1-lip schitz条件下Wasserstein距离。</strong></p></figure><p id="8d60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们有W(P_r，P_g)作为所有1-Lipschitz函数f: X → R上的上确界(最低上界)</p><p id="48e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> K-Lipschitz连续:</strong>给定2个度量空间(X，d_X)和(Y，d_Y)，变换函数f: X → Y是K-Lipschitz连续的若</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/aab076ddda6b4b7486982a228657c6cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wNKZyfomrjejuhKSpS9iAQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">情商。3: K-Lipschitz连续性。</strong></p></figure><p id="1acd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中d_X和d_Y是它们各自度量空间中的距离函数。当函数是K-Lipschitz时，从等式。2，我们最后得到K ∙ W(P_r，P_g)。</p><p id="465f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，如果我们有一族K-Lipschitz连续的参数化函数{f_w}，其中w∈W，我们可以得到</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/8ad601e576fcf11ab4ba5be16871d01d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*td_Cl8eQWE6CuFGeUirTGA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">情商。4 </strong></p></figure><p id="c4a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">即w∈W最大化Eq。4给出Wasserstein距离乘以一个常数。</p><h2 id="a296" class="nj lt iq bd lu nk nl dn ly nm nn dp mc lf no np me lj nq nr mg ln ns nt mi nu bi translated">WGAN评论家</h2><p id="adb2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了达到这个效果，WGAN引入了一个批评家，而不是我们已经知道的GANs的歧视者。critic网络在设计上类似于鉴频器网络，但通过优化来预测Wasserstein距离，以找到将使等式4最大化的<strong class="ky ir"> w* </strong>。为此，评论家的客观职能如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/27f0b9640967382fb30cc63c33436d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4BHrbDUL0USZ6giQ1yvWQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">情商。5:批评家目标函数。</strong></p></figure><p id="e6ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，为了在函数f上加强Lipschitz连续性，作者求助于将权重w限制到紧空间。这是通过将砝码夹紧在一个小范围内(论文[1]中的[-1e-2，1e-2])来实现的。</p><p id="4936" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">鉴别器和鉴别器的区别在于，鉴别器被训练来正确地识别来自P_r的样本和来自P_g的样本，鉴别器估计P_r和P_g之间的Wasserstein距离。</p><p id="c806" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是训练评论家的python代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h2 id="0fab" class="nj lt iq bd lu nk nl dn ly nm nn dp mc lf no np me lj nq nr mg ln ns nt mi nu bi translated"><strong class="ak"> WGAN发生器目标</strong></h2><p id="dffc" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">自然，生成器的目标是最小化P_r和P_g之间的Wasserstein距离。生成器试图找到θ <strong class="ky ir"> * </strong>，使P_g和P_r之间的Wasserstein距离最小化。为此，生成器的目标函数如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/e691586252377bcba97c1fc03674732a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ii6g9bJyd6EPGTk-uY4_qA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">情商。6:发电机目标函数。</strong></p></figure><p id="4ca4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，WGAN发生器和标准发生器之间的主要区别还是WGAN发生器试图最小化P_r和P_g之间的Wasserstein距离，而标准发生器试图用产生的图像欺骗鉴别器。</p><p id="4e4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是训练生成器的python代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h1 id="2482" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">培训结果</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/4dde9b4fd8848191531582044f5a2d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*LfS8fAE_s6XYl4DCtvDTaQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图WGAN训练的早期结果[3]。</p></figure><p id="5aba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图2显示了训练WGAN的一些早期结果。<strong class="ky ir">请注意，图2中的图像是早期结果，一旦确认模型正在如预期那样训练，就停止训练。</strong></p><h1 id="ed69" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">密码</h1><p id="0f1d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">瓦塞尔斯坦甘的完整实现可以在这里找到<a class="ae nf" href="https://github.com/aadhithya/gan-zoo-pytorch" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"/></a><strong class="ky ir">【3】。</strong></p><h1 id="6f24" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="2b6d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">WGANs提供稳定的训练和有意义的训练目标。本文介绍并直观地解释了Wasserstein距离是什么，Wasserstein距离相对于标准GAN使用的Jensen-Shannon散度的优势，以及Wasserstein距离如何用于训练WGAN。我们还看到了训练批判者和生成器的代码片段，以及训练模型的早期阶段的大量输出。尽管WGAN相对于标准GAN有许多优势，但WGAN论文的作者明确承认，权重裁剪并不是增强Lipschitz连续性的最佳方式[1]。为了解决这个问题，他们提出了Wasserstein GAN梯度罚函数[4]，我们将在以后的文章中讨论。</p><p id="2476" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你喜欢这篇文章，看看这个系列的下一篇文章<a class="ae nf" href="https://asankar96.medium.com/demystified-wasserstein-gan-with-gradient-penalty-ba5e9b905ead" rel="noopener">关于</a><a class="ae nf" href="https://asankar96.medium.com/demystified-wasserstein-gan-with-gradient-penalty-ba5e9b905ead" rel="noopener"> WGAN-GP </a>！</p></div><div class="ab cl oa ob hu oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="ij ik il im in"><h1 id="be09" class="ls lt iq bd lu lv oh lx ly lz oi mb mc jw oj jx me jz ok ka mg kc ol kd mi mj bi translated">参考</h1><p id="174d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1] Arjovsky、Martin、Soumith Chintala和Léon Bottou。"沃瑟斯坦生成性对抗网络."<em class="om">机器学习国际会议</em>。PMLR，2017。</p><p id="5c83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]伊恩·古德费勒等，“生成性对抗性网络”<em class="om">美国计算机学会的通讯</em>63.11(2020):139–144。</p><p id="906d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]甘-动物园-py torch(<a class="ae nf" href="https://github.com/aadhithya/gan-zoo-pytorch" rel="noopener ugc nofollow" target="_blank">)https://github.com/aadhithya/gan-zoo-pytorch</a>)。</p><p id="aefc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] Gulrajani，Ishaan等，“改善wasserstein gans的训练”<em class="om"> arXiv预印本arXiv:1704.00028 </em> (2017)。</p></div></div>    
</body>
</html>