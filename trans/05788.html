<html>
<head>
<title>ConnectorX: The fastest library for loading your Python data frame</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ConnectorX:加载Python数据框最快的库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/connectorx-the-fastest-way-to-load-data-from-databases-a65d4d4062d5?source=collection_archive---------4-----------------------#2021-05-24">https://towardsdatascience.com/connectorx-the-fastest-way-to-load-data-from-databases-a65d4d4062d5?source=collection_archive---------4-----------------------#2021-05-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f18d" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="bc0c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">用一行代码将Pandas read_sql加速10倍</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f8f8355a58a490ad1339a64f391fee7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HYAd1aal5Et1A-Qzs6VAtQ.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@nasa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> NASA </a>在<a class="ae le" href="https://unsplash.com/s/photos/data-center?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="2504" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">ConnectorX旨在通过向开发人员提供高效、轻量级且易于使用的工具来加快从数据库加载数据的过程。在本文中，我们将通过回答以下问题为您简要介绍ConnectorX:</p><ul class=""><li id="ea9a" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated"><a class="ae le" href="#cb2e" rel="noopener ugc nofollow">什么是ConnectorX？</a></li><li id="c327" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><a class="ae le" href="#a4f5" rel="noopener ugc nofollow">如何使用ConnectorX？</a></li><li id="a43d" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><a class="ae le" href="#d086" rel="noopener ugc nofollow">为什么ConnectorX是更好的选择？</a></li><li id="4145" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">接下来会发生什么？</li></ul></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="cb2e" class="mw mx iq bd my mz na nb nc nd ne nf ng kf nh kg ni ki nj kj nk kl nl km nm nn bi translated">什么是ConnectorX？</h1><p id="1787" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">ConnectorX是一个开源库，可以加速将数据从数据库加载到像<em class="nt"> pandas这样的数据结构中。数据框</em>用于进一步处理和分析。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/b519206807574c8d3ca5e3c45d34504a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zFgMhhyQgHDMT9VgXKWuKw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">ConnectorX的高级工作流程示例</p></figure><p id="0db9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">ConnectorX由两个主要概念组成:<strong class="lh ja">源</strong>(例如<em class="nt"> PostgreSQL </em>)和<strong class="lh ja">目的地</strong>(例如<em class="nt">熊猫。数据帧</em>。ConnectorX会将用户给出的SQL查询转发给<strong class="lh ja">源</strong>，然后高效地将查询结果从<strong class="lh ja">源</strong>传输到<strong class="lh ja">目的地</strong>。上图显示了当前支持的源和目的地的示例。</p><p id="7908" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了同时提供<strong class="lh ja">高效的</strong>性能和<strong class="lh ja">强大的</strong>功能，ConnectorX中繁重的提升工作量被写成了Rust。它还有一个带有简单API的Python绑定，可以轻松地与Python中的其他数据科学库进行互操作。</p><p id="8017" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">接下来，让我们看看如何通过一行代码以不同的方式使用ConnectorX。</p><h1 id="a4f5" class="mw mx iq bd my mz nv nb nc nd nw nf ng kf nx kg ni ki ny kj nk kl nz km nm nn bi translated">如何使用ConnectorX？</h1><p id="3df4" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">步骤1:安装连接器x:</p><pre class="kp kq kr ks gt oa ob oc od aw oe bi"><span id="b3a9" class="of mx iq ob b gy og oh l oi oj">pip install connectorx</span></pre><p id="6bbd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二步:用<em class="nt"> read_sql </em>从数据库加载数据。使用连接字符串定义源，默认情况下目的地是<em class="nt"> pandas。数据帧</em>可以通过设置<a class="ae le" href="https://github.com/sfu-db/connector-x#parameters" rel="noopener ugc nofollow" target="_blank"> <em class="nt"> return_type </em> </a>来改变:</p><pre class="kp kq kr ks gt oa ob oc od aw oe bi"><span id="c186" class="of mx iq ob b gy og oh l oi oj">import connectorx as cx<br/><br/># source: PostgreSQL, destination: pandas.DataFrame<br/>df = cx.read_sql("postgres://postgres:postgres@localhost:5432/tpch", "SELECT * FROM lineitem")</span></pre><p id="028f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">查询结果将返回一只<em class="nt">熊猫。数据帧</em>如下所示:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/8d823840752f29f2367ec069d6020bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qJjgGYV2iRMIXK_lAV3Nvg.png"/></div></div></figure><p id="e5c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了进一步提高速度，ConnectorX支持通过对查询进行分区并并行执行分区查询来提高CPU和带宽资源的利用率。用户可以指定分区列，也可以手动定义分区查询:</p><pre class="kp kq kr ks gt oa ob oc od aw oe bi"><span id="46d5" class="of mx iq ob b gy og oh l oi oj"># specify the partition column and number of partitions<br/>df = cx.read_sql("postgres://postgres:postgres@localhost:5432/tpch", "SELECT * FROM lineitem", partition_on="l_orderkey", partition_num=4)<br/><br/># manually partition the query<br/># the partition bellow is equivalent with the one above<br/>df = cx.read_sql("postgres://postgres:postgres@localhost:5432/tpch", [<br/>    "SELECT * FROM lineitem WHERE l_orderkey &gt; 0 AND l_orderkey &lt;= 15000000",<br/>    "SELECT * FROM lineitem WHERE l_orderkey &gt; 15000000 AND l_orderkey &lt;= 30000000",<br/>    "SELECT * FROM lineitem WHERE l_orderkey &gt; 30000000 AND l_orderkey &lt;= 45000000",<br/>    "SELECT * FROM lineitem WHERE l_orderkey &gt; 45000000 AND l_orderkey &lt;= 60000000"<br/>])</span></pre><p id="540b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">ConnectorX将并行运行所有分区查询，并将所有查询结果连接成一个单独的<em class="nt"> pandas。数据帧</em>。至于分区，目前，对于SPJA查询，ConnectorX支持对整数列进行自动分区。下面是一个更复杂的查询示例:</p><pre class="kp kq kr ks gt oa ob oc od aw oe bi"><span id="ecaf" class="of mx iq ob b gy og oh l oi oj">query = f”””<br/>SELECT l_orderkey,<br/> SUM(l_extendedprice * ( 1 — l_discount )) AS revenue,<br/> o_orderdate,<br/> o_shippriority<br/>FROM customer,<br/> orders,<br/> lineitem<br/>WHERE c_mktsegment = ‘BUILDING’<br/> AND c_custkey = o_custkey<br/> AND l_orderkey = o_orderkey<br/> AND o_orderdate &lt; DATE ‘1995–03–15’<br/> AND l_shipdate &gt; DATE ‘1995–03–15’<br/>GROUP BY l_orderkey,<br/> o_orderdate,<br/> o_shippriority <br/>“””</span><span id="4d59" class="of mx iq ob b gy ol oh l oi oj">df = read_sql(“postgresql://postgres:postgres@localhost:5432/tpch”, query, partition_on=”l_orderkey”, partition_num=4)</span></pre><p id="9f70" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请查看我们的<a class="ae le" href="https://github.com/sfu-db/connector-x#detailed-usage-and-examples" rel="noopener ugc nofollow" target="_blank"> Github repo </a>获取更多用法和示例！</p><h1 id="d086" class="mw mx iq bd my mz nv nb nc nd nw nf ng kf nx kg ni ki ny kj nk kl nz km nm nn bi translated">为什么ConnectorX是更好的选择？</h1><p id="0ade" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">其他常用的Python库如<em class="nt"> Pandas </em>已经提供了类似的<em class="nt"> read_sql </em>函数，那么为什么还要使用ConnectorX呢？为了回答这个问题，让我们来看一个简单的基准测试，我们将ConnectorX与其他三个现有的解决方案(<a class="ae le" href="https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html" rel="noopener ugc nofollow" target="_blank"> Pandas </a>、<a class="ae le" href="https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html" rel="noopener ugc nofollow" target="_blank"> Modin </a>和<a class="ae le" href="https://docs.dask.org/en/latest/dataframe-sql.html#loading-from-sql-with-read-sql-table" rel="noopener ugc nofollow" target="_blank"> Dask </a>)进行了比较，这三个解决方案也能够将数据从数据库加载到数据框。</p><p id="1959" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们使用来自<a class="ae le" href="http://www.tpc.org/tpch/" rel="noopener ugc nofollow" target="_blank"> TPC-H </a>的<em class="nt"> LINEITEM </em>表，并将比例因子设置为10。该表包含60M记录x 16列，如果转储到CSV文件中，其大小为8 GB，在PostgreSQL中为11 GB。我们测量每个解决方案从数据库加载整个表并写入到<em class="nt"> pandas所需的时间。不同并行度(1到10核)和带宽条件下的DataFrame </em>。我们还测量了该过程中每种方法的峰值内存使用量。我们在这里展示的测试结果是在一个AWS <em class="nt"> r5.4xlarge </em>实例上进行的，我们在该实例上运行ConnectorX，并从运行在AWS RDS上的<em class="nt"> db.m6g.4xlarge </em>实例上的PostgreSQL加载数据。(有关其他数据库的更多基准测试结果，请点击查看<a class="ae le" href="https://github.com/sfu-db/connector-x/blob/main/Benchmark.md#benchmark-result-on-aws-r54xlarge-with-dbm6g4xlarge-rds" rel="noopener ugc nofollow" target="_blank">。)结果显示，在所有场景中，ConnectorX都是速度最快、内存效率最高的解决方案！</a></p><ol class=""><li id="66d0" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma om mh mi mj bi translated"><strong class="lh ja">更快的数据加载</strong></li></ol><p id="0325" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下图显示了使用4个CPU内核测试不同方法速度的结果。我们可以看到，ConnectorX是所有解决方案中速度最快的，在PostgreSQL上比<em class="nt"> Modin </em>、<em class="nt"> Pandas </em>、<em class="nt"> Dask </em>分别加快了<strong class="lh ja"> 3x </strong>、<strong class="lh ja"> 10x、</strong>和<strong class="lh ja"> 20x </strong>的数据加载速度！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/7e2ae1f97e77a9ff7d8d75fb399bca26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0J6hjMkgwiONaE-ZtdTqoA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">read_sql (4核)的时间比较</p></figure><p id="6d1c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们还改变了用于<em class="nt"> read_sql </em>的内核(分区)数量，从1到10不等，并在不同的网络条件和机器下进行了测试。(<em class="nt"> Dask </em>由于内存不足(OOM)无法使用完一个内核。Pandas不支持并行，所以我们只使用一个内核。)我们发现ConnectorX在所有设置中始终优于其他方法。</p><p id="7c0d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> 2。更小的内存占用</strong></p><p id="9e69" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">接下来，我们来看看每种方法的内存使用情况。这里我们绘制了4核设置的比较结果。我们可以看到ConnectorX使用的内存比其他方法少3倍。在不同的并行度下，结果是相同的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/7e47daa84fa4508df34f87c48dde9b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_kY5wbCoa37hui25qr-nzw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">read_sql的内存比较(4核)</p></figure><p id="5be9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">【ConnectorX是如何做到这一点的？</p><p id="30bc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">ConnectorX实现这一性能的三个主要原因是:</p><ol class=""><li id="9bd4" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma om mh mi mj bi translated"><strong class="lh ja">用原生语言编写:</strong>与其他库不同，ConnectorX是用Rust编写的，避免了用Python实现数据密集型应用的额外成本。</li><li id="3435" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma om mh mi mj bi translated"><strong class="lh ja">精确复制一次:</strong>当从数据库下载数据时，现有的解决方案或多或少会进行多次数据复制，而ConnectorX的实现遵循“零复制”原则。我们设法精确地复制数据一次，直接从<strong class="lh ja">源</strong>到<strong class="lh ja">目的地</strong>，即使是在并行的情况下。</li><li id="1c25" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma om mh mi mj bi translated"><strong class="lh ja"> CPU缓存高效:</strong>我们应用了多项优化，使ConnectorX CPU缓存友好。与“零拷贝”实现不同，ConnectorX中的数据处理是以流的方式进行的，以减少缓存缺失。另一个例子是，当我们在Python中构造字符串时，我们将一批字符串写入一个预先分配的缓冲区，而不是为每个字符串分配单独的位置。</li></ol><h1 id="8a79" class="mw mx iq bd my mz nv nb nc nd nw nf ng kf nx kg ni ki ny kj nk kl nz km nm nn bi translated">接下来会发生什么？</h1><p id="b818" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">到目前为止，ConnectorX支持广泛使用的<strong class="lh ja">源</strong>，包括PostgreSQL、MySQL、SQLite以及其他采用相同有线协议的数据库(例如，通过PostgreSQL的Redshift、通过MySQL的Clickhouse)。我们现在正致力于增加更多的<a class="ae le" href="https://github.com/sfu-db/connector-x/discussions/61" rel="noopener ugc nofollow" target="_blank">流行数据库和数据仓库</a>。我们还计划在未来支持以不同的文件格式(如CSV、JSON、Parquet)从数据存储(如<a class="ae le" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank">亚马逊S3 </a>)传输数据。</p><p id="c23d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">至于<strong class="lh ja">目的地</strong>，ConnectorX支持Python和Rust中所有流行的数据帧，包括<a class="ae le" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a>、<a class="ae le" href="https://arrow.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇箭头</a>、<a class="ae le" href="https://modin.readthedocs.io/en/latest/#" rel="noopener ugc nofollow" target="_blank">摩丁</a>、<a class="ae le" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"> Dask </a>和<a class="ae le" href="https://github.com/pola-rs/polars" rel="noopener ugc nofollow" target="_blank"> Polars </a>。已完成和正在进行的源和目的地的完整列表可在<a class="ae le" href="https://github.com/sfu-db/connector-x#supported-sources--destinations" rel="noopener ugc nofollow" target="_blank">这里</a>找到。让我们知道你是否有其他的建议！</p><p id="74c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">除了支持更多的源和目的地，该团队还在开发新功能，以帮助最大限度地减少数据加载的时间成本，例如维护一个<a class="ae le" href="https://github.com/sfu-db/connector-x/discussions/64" rel="noopener ugc nofollow" target="_blank">客户端数据缓存</a>。我们还对优化查询分区感兴趣，例如支持从数据库收集元数据的自动分区。您可以在Github上关注我们，了解我们的最新实施情况和下一步计划！</p></div></div>    
</body>
</html>