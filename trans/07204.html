<html>
<head>
<title>Stop using Grid Search Cross-Validation for Hyperparameter Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">停止使用网格搜索交叉验证进行超参数调整</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stop-using-grid-search-cross-validation-for-hyperparameter-tuning-b962160dd6ae?source=collection_archive---------12-----------------------#2021-06-30">https://towardsdatascience.com/stop-using-grid-search-cross-validation-for-hyperparameter-tuning-b962160dd6ae?source=collection_archive---------12-----------------------#2021-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0dbf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">各种基于交叉验证的超参数调优技术的基准时间数</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/94ecf6e12f4f3a9626671d377f997c88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjUNbaXFQH7MyhjiI6oB2A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，使用<a class="ae ky" href="https://pixlr.com/x/" rel="noopener ugc nofollow" target="_blank"> Pixlr </a>编辑</p></figure><p id="b598" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了训练健壮的机器学习模型，必须选择最合适的机器学习算法以及相应的超参数的最佳集合。为了找到最适合用例的方法，数据科学家需要用不同的超参数集手动训练数百个模型，以比较它们的性能。选择模型的手动搜索是一项繁琐的任务，并且会降低建模流水线的速度。</p><p id="cccb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">超参数调整是指为模型选择最佳参数集的过程。建议在超参数空间中搜索最佳交叉验证分数的估计量。各种交叉验证技术可用于优化估计量的超参数空间。网格搜索交叉验证是一种流行的技术，用于优化各种机器学习算法的超参数空间并选择稳健的模型。</p><p id="d915" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将讨论超参数优化何时以及为什么应该避免网格搜索交叉验证，并讨论各种其他类似的技术及其运行时基准时间数。在我的上一篇文章中，我们已经讨论了<a class="ae ky" rel="noopener" target="_blank" href="/7-hyperparameter-optimization-techniques-every-data-scientist-should-know-12cdebe713da"> 7超参数优化技术</a>，这里我们将比较时间</p><h1 id="dac4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">开始使用:</h1><p id="0c0a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">从<a class="ae ky" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载的信用卡欺诈检测数据集将用于比较每种交叉验证技术的运行时间，以优化超参数。我们将使用<strong class="lb iu">随机森林分类器模型</strong>和具有<strong class="lb iu"> 100个组件</strong>的超参数空间来训练所有交叉验证技术。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="c77d" class="mx lw it mt b gy my mz l na nb"><strong class="mt iu"><em class="nc"># Number of Components: 5*5*2*2 = 100</em></strong></span><span id="dd21" class="mx lw it mt b gy nd mz l na nb"><strong class="mt iu">param_grid </strong>= <br/><strong class="mt iu">{</strong>'<strong class="mt iu">n_estimator</strong>':[10,25,50,100,250],<br/>'<strong class="mt iu">max_depth</strong>':[5,10,25,50,None],<br/>'<strong class="mt iu">max_features</strong>':['auto',None],<br/>'<strong class="mt iu">min_sample_split</strong>':[2,5]<br/><strong class="mt iu">}</strong></span></pre><p id="6eb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将讨论和比较以下各项的运行时间:</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="82fb" class="mx lw it mt b gy my mz l na nb"><strong class="mt iu">CV based Hyperparameter Optimization Checklist:<em class="nc"><br/>1) Grid Search CV<br/>2) Randomized Search CV<br/>3) Halving Grid Search CV</em></strong></span></pre><blockquote class="ne nf ng"><p id="6249" class="kz la nc lb b lc ld ju le lf lg jx lh nh lj lk ll ni ln lo lp nj lr ls lt lu im bi translated"><em class="it">阅读</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank"><em class="it">sci kit-了解交叉验证的文档</em> </a> <em class="it">以便更好地理解。</em></p></blockquote></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="19a7" class="lv lw it bd lx ly nr ma mb mc ns me mf jz nt ka mh kc nu kd mj kf nv kg ml mm bi translated">1.网格搜索CV:</h1><p id="34af" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">网格搜索也可以称为手动超参数搜索的自动化版本。网格搜索CV在参数网格的所有组合上训练估计器，并返回具有最佳CV分数的模型。Scikit-Learn包附带了GridSearchCV实现。</p><p id="c306" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网格搜索交叉验证技术计算量很大。网格搜索CV的复杂性随着参数网格中参数数量的增加而增加。因此，网格搜索CV技术不推荐用于大尺寸数据集或具有大量组件的参数网格。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/c0577b2ceeaeb3c4823a84d916d48afa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZWcpI5p4th73ZEq7fPDJyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，网格搜索CV执行时间和测试信用卡欺诈检测数据集的各种样本的AUC-ROC分数</p></figure><blockquote class="ne nf ng"><p id="c5f2" class="kz la nc lb b lc ld ju le lf lg jx lh nh lj lk ll ni ln lo lp nj lr ls lt lu im bi translated">在这里找到<a class="ae ky" href="https://gist.github.com/satkr7/120ee68901164ceadc0447985daec259#file-gridsearchcv-py" rel="noopener ugc nofollow" target="_blank">的</a>代码片段来实现网格搜索CV。</p></blockquote><h1 id="27cf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.随机搜索简历:</h1><p id="a4e8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">随机化搜索CV克服了网格搜索CV的局限性(时间复杂度高)。超参数组合随机子集上的随机搜索训练模型。与网格搜索相比，随机搜索训练估计器的组合总数较少。</p><p id="344a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learn包还附带了随机搜索CV的实现。可以采样的参数设置数量可以通过调整<strong class="lb iu"> RandomizedSearchCV </strong>功能中的<code class="fe nx ny nz mt b"><strong class="lb iu">n_iter</strong></code> <strong class="lb iu"> </strong>参数来决定。<code class="fe nx ny nz mt b"><strong class="lb iu">n_iter</strong></code> <strong class="lb iu"> </strong>可以在解决方案的运行时间和性能之间进行权衡。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/96739476db3039d73f8927a9a3411cf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDyj_F4N_JhCWwOjxFn18g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，针对信用卡欺诈检测数据集的各种样本的随机搜索CV执行时间和测试AUC-ROC得分</p></figure><blockquote class="ne nf ng"><p id="ea9c" class="kz la nc lb b lc ld ju le lf lg jx lh nh lj lk ll ni ln lo lp nj lr ls lt lu im bi translated">在这里找到<a class="ae ky" href="https://gist.github.com/satkr7/f6ee02baec9bd6344ff1cdf2477a26c7#file-randomsearchcv-py" rel="noopener ugc nofollow" target="_blank">的</a>代码片段来实现网格搜索CV。</p></blockquote><h1 id="2a02" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.减半网格搜索CV:</h1><p id="ee3d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">网格搜索和随机搜索在全部数据的所有成分或成分的随机样本(参数网格的组合)上训练估计器，而等分网格搜索CV遵循连续等分方法。Scikit-Learn包附带了<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html" rel="noopener ugc nofollow" target="_blank">减半网格搜索CV实现</a>。</p><p id="8991" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将网格搜索(HGS) CV减半的步骤如下:</p><ol class=""><li id="9166" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">HGS将随机数据样本训练成超参数的组合。</li><li id="230e" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">选择性能最佳的候选参数。</li><li id="158b" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">一个相对较大的数据样本被训练在表现最好的候选人身上(来自步骤2)。</li><li id="07ee" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">重复上述3个步骤，直到最佳超参数集保持不变。</li></ol><blockquote class="ne nf ng"><p id="e357" class="kz la nc lb b lc ld ju le lf lg jx lh nh lj lk ll ni ln lo lp nj lr ls lt lu im bi translated">阅读我之前的文章，描述如何使用<a class="ae ky" rel="noopener" target="_blank" href="/20x-times-faster-grid-search-cross-validation-19ef01409b7c"> HGS将建模工作流程提高20倍</a>。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/0e61224f0780ccf342465bccda5003e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QO8NcjRKHc7iy9OuerKeuA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，将网格搜索CV执行时间减半，并测试信用卡欺诈检测数据集的各种样本的AUC-ROC分数</p></figure><p id="54ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用HGS，对于每个经过的迭代，参数分量在减少，而训练数据集在增加。由于该算法遵循连续减半的方法，因此与网格搜索CV相比，该算法的时间复杂度相对较小。</p><h1 id="463d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">基准性能:</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/c6b17ba693730e3453b4e3a9e947c766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*hsQwjqXJeRelv_iVvQYC0Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h1 id="1e62" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论:</h1><p id="09c3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本文中，我们讨论了各种基于交叉验证的超参数优化技术，并比较了它们的执行时间和ROC分数。</p><p id="0e01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上述基准数据中，我们可以得出结论，整个数据集(250000个样本)的测试AUC-ROC得分几乎相同。但是随机搜索CV的执行时间是网格搜索CV技术的五倍(T0)快(T1)，减半网格搜索是网格搜索CV技术的三倍(T3)。对于具有大量组件的大型数据集或参数格网，建议使用另一种讨论过的技术。</p><p id="63c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着参数网格组件数量的增加，对半网格搜索CV的性能将进一步提高。阅读<a class="ae ky" rel="noopener" target="_blank" href="/20x-times-faster-grid-search-cross-validation-19ef01409b7c">这篇文章</a>以获得更好的理解。</p><h1 id="25cf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考资料:</h1><p id="c22a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">[1]sci kit-学习文档:<a class="ae ky" href="https://scikit-learn.org/stable/modules/grid_search.html#" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/modules/grid_search.html</a></p><blockquote class="op"><p id="4674" class="oq or it bd os ot ou ov ow ox oy lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>