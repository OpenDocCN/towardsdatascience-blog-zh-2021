<html>
<head>
<title>Differentiable Hardware</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可区分硬件</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/differentiable-hardware-9bb03aad4563?source=collection_archive---------17-----------------------#2021-10-08">https://towardsdatascience.com/differentiable-hardware-9bb03aad4563?source=collection_archive---------17-----------------------#2021-10-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9cdadc5f42653d3da30b6c415dad7e13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-6DepegA2NVWRabhd1kTpw.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">保罗·范·科特姆在<a class="ae jd" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="31b5" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/notes-from-industry" rel="noopener" target="_blank">业内笔记</a></h2><div class=""/><div class=""><h2 id="b1fb" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">人工智能如何帮助恢复摩尔定律的良性循环</h2></div><p id="7774" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在<a class="ae jd" href="https://www.techrepublic.com/article/the-global-chip-shortage-what-caused-it-how-long-will-it-last/" rel="noopener ugc nofollow" target="_blank">全球芯片短缺</a>之后，据报道TSMC<a class="ae jd" href="https://www.wsj.com/articles/worlds-largest-chip-maker-to-raise-prices-threatening-costlier-electronics-11629978308?mod=djemalertNEWS" rel="noopener ugc nofollow" target="_blank">提高了芯片价格</a>和<a class="ae jd" href="https://www.digitimes.com/news/a20201231VL200.html" rel="noopener ugc nofollow" target="_blank">推迟了3纳米工艺</a>。不管它是否准确或预示着一种长期趋势，这种消息应该提醒我们注意摩尔定律衰落的日益恶化的影响，并迫使我们重新思考人工智能硬件。人工智能硬件会受到这种衰退的影响，或者帮助扭转这种局面吗？</p><p id="1ef2" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">假设我们想恢复摩尔定律的良性循环，即软件和硬件相互推动，让现代智能手机比过去十年占据仓库的超级计算机更强大。普遍接受的后摩尔良性循环是不可持续的，即更大的数据导致更大的模型需要更强大的机器。除非我们重新定义并行性，否则我们不能再指望缩小晶体管来构建越来越宽的并行处理器。我们也不能依赖特定领域架构(DSA ),除非它促进并适应软件的进步。</p><p id="fa5c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们不是要弄清楚哪个硬件是为AI这个前进的移动目标准备的，而是从AI的核心是可区分编程的角度来看待AI硬件。在这里，人工智能软件程序是一个计算图，由一起训练的计算节点组成，以实现端到端的目标。只要是可微分的，深度流水线DSA硬件可以作为计算节点。软件程序员可以自由地将可区分的硬件插入到计算图中，以获得高性能和创造性的问题解决方案，就像一个预先构建的可定制软件组件一样。人工智能硬件不再有“纯度”检查，现在可以包括可区分的硬件。</p><blockquote class="ma"><p id="ca06" class="mb mc jg bd md me mf mg mh mi mj lz dk translated">人工智能硬件不再有“纯度”检查，现在可以包括可区分的硬件。</p></blockquote><p id="a3c8" class="pw-post-body-paragraph le lf jg lg b lh mk kq lj lk ml kt lm ln mm lp lq lr mn lt lu lv mo lx ly lz ij bi translated">希望软件和硬件将再次通过良性循环并行前进，就像摩尔定律如火如荼时一样。</p><h1 id="7add" class="mp mq jg bd mr ms mt mu mv mw mx my mz kv na kw nb ky nc kz nd lb ne lc nf ng bi translated">人工智能硬件架构师的苦恼</h1><p id="89a0" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">在人工智能市场的众多GPU竞争者中，特斯拉推出了Dojo超级计算机。Dojo似乎是联网、集成和可伸缩性方面的杰作。另一方面，D1芯片，Dojo的构建块，很难说是架构上的突破。我们可以将GPU竞争者分为两个阵营，众核和众MAC。作为众核阵营的代表，D1是由许多CPU内核组成的“网格”。另一方面，Tesla FSD或Google TPU是多MAC阵营的缩影，拥有少量大型MM加速器，每个加速器都在“网格”中打包了许多乘法累加(MAC)单元正如我们所见，人工智能架构的争论是在网格和GPU之间进行的。</p><p id="42a4" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在制造芯片所需的巨大努力的压力下，人工智能硬件架构师必须紧张地跟踪媒体关于基准测试和会议的报道。旨在取代GPU的人工智能硬件经常难以运行基准测试和最新的神经网络模型，讽刺的是，在“老式”GPU上运行得很好。如下图所示，众核和GPU在交换数据上有本质区别。前者通过互连网格传递数据，而后者通过内存层次结构共享数据。这个区别和AI关系不大。众核处理器，如D1芯片，最终是否会超过GPU还有待观察。我稍后将介绍许多MAC。</p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/0401d76ae87026178e65364434da3fa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7FqCnrkfL5q576Lq"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">比较众核(左)和GPU(右)中的数据交换。(图片由作者提供)</p></figure><p id="4d78" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，让我们快速回顾一下高性能计算(HPC)中网格和GPU的共同根源。</p><h1 id="2188" class="mp mq jg bd mr ms mt mu mv mw mx my mz kv na kw nb ky nc kz nd lb ne lc nf ng bi translated">HPC的遗产</h1><p id="3cc8" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">HPC用于解决计算密集型军事研究问题、科学发现、石油和天然气勘探等。超级计算机，简称为Super，已经成为HPC的关键硬件解决方案。与处理指针丰富的数据结构(如树和链表)的通用程序相比，HPC程序主要花时间在“循环”中重复数据并行计算。</p><h2 id="6060" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">向量超级的兴衰</h2><p id="c960" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">从20世纪70年代到90年代，旨在通过展开向量中的数据并行循环来加速HPC程序的Vector Super主导了HPC市场。在那段时间里，一台超级计算机被默认为矢量超级计算机。</p><p id="67c4" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在20世纪90年代，当摩尔定律完全生效时，通过将许多现成的CPU排列成网状或某种类似的拓扑结构来构建超级计算机变得可行。这种趋势催生了分布式超级，HPC社区怀疑地称之为<a class="ae jd" href="https://www.nytimes.com/1991/05/06/business/the-attack-of-the-killer-micros.html" rel="noopener ugc nofollow" target="_blank">黑仔微处理器</a>的攻击，这里的“微”指的是微处理器。这种观点源于微处理器是片上CPU，而“CPU”通常是由分立元件组成的系统。最终，分布式超级计算机取代了矢量超级计算机，成为今天超级计算机的同义词。</p><h2 id="fded" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">GPGPU中向量超的回归</h2><p id="e1d1" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">在21世纪初，摩尔定律显示出老化的迹象，这停止了对CPU时钟速度的争夺，CPU时钟速度是单芯片计算性能的主要来源。业界的反应是在一个芯片上放置多个CPU内核，期望并行性成为新的主要性能来源。这一趋势导致了双核、四核，并最终导致了众核，实际上是分布式超级单芯片，通常将CPU内核排列成网状。众核的例子包括英特尔两次试图应对GPU的失败，Larrabee用于3D市场，Larrabee的后代<a class="ae jd" href="https://en.wikipedia.org/wiki/Xeon_Phi" rel="noopener ugc nofollow" target="_blank"> Xeon Phi </a>系列用于HPC。</p><p id="5d0b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">传统上，GPU会在顶点、三角形和像素等图形实体上展开“循环”。GPU架构师将这种能力扩展到了HPC应用中的循环，使GPU成为有效的矢量超级芯片。然后他们将GPU在HPC中的用法命名为通用GPU (GPGPU)。致命的是，当Vector Super在HPC市场上让位于分布式Super时，它化身为GPU来报复它的对手。我们可以看到GPU在顶级超级计算机中的商业成功，如橡树岭国家实验室的<a class="ae jd" href="https://www.olcf.ornl.gov/olcf-resources/compute-systems/titan/" rel="noopener ugc nofollow" target="_blank">泰坦超级计算机</a>和瑞士国家超级计算中心的<a class="ae jd" href="https://www.cscs.ch/computers/piz-daint/" rel="noopener ugc nofollow" target="_blank">Piz Daint</a>。</p><h2 id="5bdd" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">简单地</h2><ul class=""><li id="1ff7" class="oc od jg lg b lh nh lk ni ln oe lr of lv og lz oh oi oj ok bi translated">分布式超级计算将Vector踢出了HPC市场。</li><li id="fbe4" class="oc od jg lg b lh ol lk om ln on lr oo lv op lz oh oi oj ok bi translated">众核是分布式超级芯片，GPU是面向高性能计算的矢量超级芯片。</li></ul><h1 id="d9ab" class="mp mq jg bd mr ms mt mu mv mw mx my mz kv na kw nb ky nc kz nd lb ne lc nf ng bi translated">矩阵乘法和人工智能</h1><p id="7ad6" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">网格，计算机架构中的旧锤子，如何被重新命名和改造为人工智能的新钉子？</p><h2 id="4a93" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">MM和HPC</h2><p id="b01d" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">计算机体系结构中一个永恒的规则是，移动数据比计算数据更昂贵，这使得计算机体系结构必须对更少的数据进行更多的计算。幸运的是，HPC社区从几十年的实践中了解到，他们可以用MM来表达大多数HPC问题，MM具有很高的计算与通信比率，粗略地说，<em class="oq"> N </em> MAC对2 <em class="oq"> N </em>数据进行运算。如果实现得当，使用MM解决问题可以通过隐藏数据传输来实现高性能。所以一个HPC程序员只需要有一个超级计算机厂商提供的健全的MM库就可以了。当计算一个毫米时，今天的分布式超级可以充分利用分布在几十万平方英尺上的几十万个节点，有效地保持每个节点忙于计算。</p><h2 id="d168" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">MM在AI的崛起</h2><p id="604d" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">使用神经网络的机器学习(ML)是现代人工智能的特征。一个神经网络模型由多层最大似然核组成。在卷积神经网络(CNN)之前，最流行的神经网络(NN)是多层感知器(MLP)。MLP的基本ML内核是矩阵向量乘法(MVM ),它对<em class="oq"> N </em>个数据进行大约<em class="oq"> N </em>个MAC运算，几乎不重用数据。另一方面，当前CNN的主要原语是张量卷积(TC)。正如我在文章《<a class="ae jd" rel="noopener" target="_blank" href="/all-tensors-secretly-wish-to-be-themselves-1ccc836df41c?source=friends_link&amp;sk=1cd76e37df5602892a5f25268a37a15f">所有张量都暗暗希望自己是</a>中解释的那样，“MM和TC在数据移动和共享方面是结构等价的，所以我们经常互换使用张量和矩阵。</p><p id="81d8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">使用MM作为原语带来了HPC和AI的突破。CNN，主要使用MM，引发了人工智能在计算机视觉上的突破。同样广泛使用MM的<a class="ae jd" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" rel="noopener ugc nofollow" target="_blank">变形金刚</a>，点燃了自然语言理解(NLP)的AI突破。</p><p id="9b40" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于人工智能及其对MM的大量使用，计算机架构社区有了百年一遇的机会来专注于优化MM的锐利目标，同时对总体计算产生广泛影响——更物有所值。</p><p id="bfeb" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">众核可以运行为分布式超级计算开发的相同的MM算法。从某种意义上说，人工智能的众核可以追溯到它的HPC根源。</p><h2 id="8f4d" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">多MAC的潮流</h2><p id="c77a" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated"><a class="ae jd" href="https://course.ece.cmu.edu/~ece740/f13/lib/exe/fetch.php?media=kung_-_1982_-_why_systolic_architectures.pdf" rel="noopener ugc nofollow" target="_blank">脉动阵列</a>于1982年推出，用于加速MM和其他应用。如果在人工智能背景下加速MM像今天这样酷，脉动阵列研究人员甚至不会为除了MM之外的应用而烦恼。脉动阵列是一种比CPU内核更密集地封装MAC单元的机制。然而，缺点是我们不能在其他地方使用MM MAC单元。由于缺乏通用性，脉动阵列没有得到市场的认可，直到人工智能成为MM的杀手级应用，促使谷歌在TPU采用它作为MM加速器。从那时起，市场已经衍生出各种变体来改进原来的版本。在这里，我将原始脉动阵列及其变体都称为多MAC。为了处理非MM操作，Many-MAC增加了配套处理器。</p><p id="f805" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">另一方面，众核中的CPU核心，如D1芯片或GPU着色器核心，可以使用小得多的多MAC，有效地成为多MAC容器。</p><h2 id="bc7b" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">简单地</h2><ul class=""><li id="6e3a" class="oc od jg lg b lh nh lk ni ln oe lr of lv og lz oh oi oj ok bi translated">AI和HPC有交集，因为它们都由MM主导。</li><li id="88da" class="oc od jg lg b lh ol lk om ln on lr oo lv op lz oh oi oj ok bi translated">众核和众MAC并不比GPU更特定于人工智能。</li></ul><h1 id="d584" class="mp mq jg bd mr ms mt mu mv mw mx my mz kv na kw nb ky nc kz nd lb ne lc nf ng bi translated">域转移和特定域并行</h1><h2 id="ebad" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">暗硅和电源墙</h2><p id="59e2" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">2010年后不久，业界意识到，将并行度(计算性能的主要来源)翻倍，CPU内核翻倍，无法保持良性循环。每个CPU内核无法将其功耗降低一半，或者每瓦特并行度降低两倍。经过几次内核加倍的迭代，我们会看到在相同的功耗预算下，大多数内核仍然没有供电，从而导致暗硅，或者更准确地说，暗内核。如下面的概念图所示，当我们从2个内核到4个内核时，4个内核中只有3个可以供电，当我们从4个内核到8个内核时，只有4个可以供电。最后，16个内核中只有4个可以供电，从8个内核升级到16个内核没有任何好处。我们把这种现象称为碰壁。</p><p id="4582" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于这个原因，相当一部分计算机体系结构社区回避并行。此外，悲观主义者倾向于将并行性——贫瘠的指针丰富的计算作为主流，而将并行性——丰富的HPC作为利基。他们认为良性循环会过早地停止在阿姆达尔的天花板上，限制了并行性所能达到的程度。</p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/225c580ddc09c75aa769a6dc2cf238c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uEASXyAKeyFV7ANz"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">深色硅或深色核心。(图片由作者提供)</p></figure><h2 id="ba7b" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">人工智能拯救世界</h2><p id="05ec" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">巧合的是，艾正是在这种悲观情绪中出现的。根据斯坦福AI指数报告，AI一直在前进，就好像力量墙不存在一样！</p><p id="ca94" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">关键是主流软件中可能存在域转移，从而导致不同类型的并行性。如下面的概念图所示，当主流软件经历从指针丰富到数据并行计算的领域转变时，它将一个并行度重新定义为单指令多数据(SIMD)通道，而不是CPU核心。我们看到一条比CPU-核心曲线更高的曲线(标记为数据并行的SIMD通道)。接下来，当主流软件进入MM-heavy AI空间时，添加了一条更高的曲线(标记为MM-heavy的MM MAC)，一个MM MAC代表一个并行度。正如我们所看到的，通过探索更高效的特定于域的并行性和提高Amdahl的上限，计算性能在电源墙后继续增长。</p><p id="3d87" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对了，MM-heavy AI有自己的Amadhl的天花板。一个人工智能应用程序需要循环前端，以将MM操作分配给并行计算资源，并需要循环后端来收集串行操作(如规范化或softmax)的结果。当有足够多的MM MACs来加速MM时，Amdahl定律就会发挥作用，从而使循环前端和后端都成为瓶颈。</p><p id="608c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">此外，随着摩尔定律的衰落越来越严重，制造更宽的机器来加速MM是否能维持人工智能的良性循环也成了问题。为了解决这个问题并进一步提高Amdahl的上限，我们需要执行新的域转移并探索新的特定于域的并行性。换句话说，我们需要添加一条新的曲线(？？？)到下面的概念图。</p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/ae91d9d7de94c748c50a962aead46b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*buSKuj73Nf5pHR4w"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">不同域转换的并行性扩展概念图。(图片由作者提供)</p></figure><h2 id="2078" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">简单地</h2><ul class=""><li id="7019" class="oc od jg lg b lh nh lk ni ln oe lr of lv og lz oh oi oj ok bi translated">通过从指针丰富、数据并行到毫米级繁重计算的领域转换，我们一直呆在电源墙后面。</li></ul><h1 id="a038" class="mp mq jg bd mr ms mt mu mv mw mx my mz kv na kw nb ky nc kz nd lb ne lc nf ng bi translated">下一次域转移</h1><h2 id="943b" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">差分编程</h2><p id="5b52" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">英特尔的Raja Koduri说:“神经网络是新的应用。我们看到的是，每一个插座，[无论是CPU，GPU，[或] IPU，都会有矩阵加速。”</p><p id="c603" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">特斯拉的Ganesh Venkataramanan将他们的D1芯片描述为一台“纯粹的”ML机器，运行“ML内核”,没有遗留硬件。或许，他暗示GPU不像D1那样纯粹，因为它在人工智能处理期间有图形专用硬件闲置。</p><p id="f452" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">以上两种意见提出了两个问题。AI定义域转移是否应该止步于加速矩阵乘法？AI硬件是否排除遗留的特定领域设计？</p><p id="bd20" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，我们从人工智能的角度探索人工智能硬件的不同观点，人工智能的核心是<a class="ae jd" href="https://en.wikipedia.org/wiki/Differentiable_programming" rel="noopener ugc nofollow" target="_blank">可微分编程</a> (DP)。AI软件程序是一个计算图，如下图所示，由参数化的计算节点组成，每个节点将输入作为上游节点的输出，并将计算输出提供给下游节点。我们通过“训练”确定所有计算节点的参数，首先使用最终输出计算端到端损耗，然后计算该损耗的输出梯度。它进一步使用标准的微积分链规则重复计算中间梯度，遵循输出的相反方向。</p><p id="539a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">DP只要求一个计算节点是可微分的，允许与所有其他节点的联合优化，以通过梯度下降来最小化端到端损失。计算节点的可微性使其能够维持从其下游到其上游邻居的反馈路径，从而完成端到端的反馈回路。在DP下，计算节点不一定是传统的“ML内核”计算图可以是异构的，以包括非ML软件和硬件节点，只要它们满足可区分性要求。</p><h2 id="0845" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">计算图表</h2><p id="f142" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">我们在下面展示了一个计算图的概念图。</p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/276319db05ed4ceb53990216a1233270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ITooR7J-LGOqK5D0"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">概念计算图(图片由作者提供)</p></figure><p id="940b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">使用参数<em class="oq"> w </em>计算输出<em class="oq"> y </em>给定输入<em class="oq"> x </em>的计算节点评估并记忆用于计算输入梯度的输出/输入微分。蓝色曲线虚线表示反馈路径将输入梯度传播到上游节点。如果需要，它计算并记忆输出/参数微分，用于计算参数梯度以调整参数。让我们看一些例子。</p><h2 id="de55" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">可区分的图形在环</h2><p id="bba0" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">越来越多的神经网络模型具有异构计算节点，符合可微规划的定义。很好的例子就是那些解决逆图形问题的例子。与从3D场景参数生成2D图像的正向图形相反，反向图形从2D图像恢复场景参数。新兴的基于人工智能的反向图形解决方案通常包括可区分的图形渲染器，这不同于传统的渲染器。它将梯度反向传播到上游节点，参与梯度下降以最小化端到端损耗。具有可区分图形在环的反向图形管道的强大之处在于使反向图形“自我监督”，如下图所示。</p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/e390d74380a14c19668e3fe33896f8d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7-sRtlPkl38BiRw7"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="3135" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">重建神经网络从真实世界图像获得场景参数，而可微分图形从场景参数渲染虚拟世界图像。相同的两个下游神经网络准备真实世界和虚拟世界图像，以计算它们之间的端到端损耗。如果循环中没有可微分的图形，我们必须为场景参数准备3D地面事实。相反，真实世界的图像有效地充当了虚拟世界图像的基础事实，使得该过程自我监督。</p><p id="528a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当前的可区分渲染器，如<a class="ae jd" href="https://arxiv.org/abs/1904.01786" rel="noopener ugc nofollow" target="_blank">软光栅化器</a>、<a class="ae jd" href="https://arxiv.org/abs/1908.01210v2" rel="noopener ugc nofollow" target="_blank"> DIB-R </a>，以及那些在AI框架中使用的渲染器，如<a class="ae jd" href="https://pytorch3d.org/docs/renderer" rel="noopener ugc nofollow" target="_blank"> PyTorch3D </a>、<a class="ae jd" href="https://www.tensorflow.org/graphics/" rel="noopener ugc nofollow" target="_blank"> TensorFlow Graphics </a>，都是不使用图形专用硬件的软件渲染器。这种软件实现不像典型的ML内核那样是MM-heavy，因此不能利用MM加速。</p><p id="d4ec" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">另一方面，GPU架构师设计并提供具有足够深度的流水线的图形专用硬件，以便它们速度很快，很少成为瓶颈。现在，想象我们制造这样一个管道“可区分的硬件”软件程序员可以有效地使用计算图中的可区分硬件，类似于使用预构建的软件组件。由于图形专用硬件的深度流水线并行性，这种硬件图形在环应该比软件快得多。</p><h2 id="60da" class="nr mq jg bd mr ns nt dn mv nu nv dp mz ln nw nx nb lr ny nz nd lv oa ob nf jm bi translated">可区分的ISP在回路中</h2><p id="907d" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">除了使用差分硬件作为预构建的软件组件，我们还可以通过梯度下降调整其参数来对其进行“编程”，就像我们如何“训练”一个ML内核一样。例如，图像信号处理器(ISP)通过镜头捕捉图像，并在管道中处理它们，以产生供人类消费或下游图像理解(IU)任务(如对象检测或语义分割)的图片。传统的ISP具有充足的参数空间，需要专家调整以满足人们的需求。这个参数空间主要未被训练下游IU NN模型的专家开发。相反，专家使用ISP使用特定参数设置预先捕获和预处理的图像来训练NN模型。此外，捕获图像的透镜系统在制造和操作期间可能会有缺陷。如果没有ISP的联合优化和设备上的调整，IU NN模型的性能将不会令人满意。</p><p id="6025" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">已经出现了用NN模型代替某些ISP处理阶段的蓬勃发展的建议，这些建议在具有特定功率和实时约束的情况下不一定实用或更好。另一方面，已经出现了努力开发ISP的未开发参数空间的研究。以下是一些例子:</p><ol class=""><li id="8f0f" class="oc od jg lg b lh li lk ll ln or lr os lv ot lz ou oi oj ok bi translated"><a class="ae jd" href="https://www.cs.princeton.edu/~fheide/HardwareInTheLoop-ImageOptimization/" rel="noopener ugc nofollow" target="_blank">非微分ISP硬件在环</a>用于非ML优化的参数自动调整。</li><li id="50c6" class="oc od jg lg b lh ol lk om ln on lr oo lv op lz ou oi oj ok bi translated"><a class="ae jd" href="https://www.cs.princeton.edu/~fheide/proxyopt" rel="noopener ugc nofollow" target="_blank">一个经过训练的神经网络模型，模仿一个ISP作为一个可区分的代理</a>，使用ML进行参数自动调整。</li></ol><p id="d4b0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">上面的研究表明，通过为特定的IU任务设置端到端的目标，自动调优的ISP比没有自动调优的ISP表现更好。</p><p id="4a8c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">第一种方法不能与其他神经网络模型联合优化不可微ISP。另一方面，虽然使用可区分代理的第二种方法有助于训练，但它的缺点是我们需要在仔细控制的设置中单独训练这个代理。</p><p id="8a89" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，想象一下让一个ISP与众不同。我们可以利用ISP在回路中构建一个自适应传感管道，如下图所示。它可以在设备上与ISP前和ISP后的神经网络模型联合调整自身，以适应操作环境和UI任务。请注意，我们不会像GPU架构师不会指定图形着色器那样固定ISP前和ISP后的NN模型(参见我的文章<a class="ae jd" rel="noopener" target="_blank" href="/will-the-gpu-star-in-a-new-golden-age-of-computer-architecture-3fa3e044e313?source=friends_link&amp;sk=207ca541fd32dfe5c838e52622d31de4">GPU会在计算机架构的黄金时代开始吗</a>)。</p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/9a18a08cb70d6d763bdebadef90313fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8T47JyzbwO2sx95Y"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><h1 id="c6c7" class="mp mq jg bd mr ms mt mu mv mw mx my mz kv na kw nb ky nc kz nd lb ne lc nf ng bi translated">结论</h1><p id="aba5" class="pw-post-body-paragraph le lf jg lg b lh nh kq lj lk ni kt lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">我们已经通过环路中的图形和环路中的ISP的例子介绍了可区分硬件的概念。想象一下，我们已经有了一个可区分的ISP和一个可区分的GPU。我们还希望自我监督的反向图形和自我调整的传感。如下图所示，我们可以通过连接环路中的图形和环路中的ISP管道来构建新的管道。</p><figure class="nn no np nq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/f676017540d8dec66072ea1eaa8980a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EMUGSYm1LCjPQMhm"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="a140" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">正如我们所看到的，可区分的硬件单元在以下三个方面是可编程的:</p><ol class=""><li id="274d" class="oc od jg lg b lh li lk ll ln or lr os lv ot lz ou oi oj ok bi translated">人工智能程序员可以在计算图中使用它，因为他们在软件开发中使用预构建和可定制的软件组件。</li><li id="a355" class="oc od jg lg b lh ol lk om ln on lr oo lv op lz ou oi oj ok bi translated">人工智能程序员可以使用用于训练神经网络模型的相同ML框架来自动调整这些可区分的硬件单元参数。</li><li id="85d2" class="oc od jg lg b lh ol lk om ln on lr oo lv op lz ou oi oj ok bi translated">AI程序员可以自由选择各种NN模型来使用这种可区分的硬件单元，就像图形程序员可以自由编程不同类型的着色器一样。</li></ol><p id="3912" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">人工智能在主流软件中引入了一个领域转移到毫米级计算。软件程序员可以将各种各样的应用程序简化为ML内核。为了恢复摩尔定律的良性循环，我们将需要另一次领域转移。我们应该遵循人工智能的核心——差异化编程——来改变我们设计和使用计算硬件的方式，而不是找出哪个硬件适合人工智能这个前进的移动目标。人工智能硬件不再有“纯度”检查，现在可以包括可区分的硬件。</p><p id="86d1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">希望硬件可以在创新软件中延长其生命周期，软件可以利用硬件作为预构建和可定制的组件。两者可以在新的良性循环中互相推动，就像摩尔定律全面实施时一样。</p><blockquote class="ma"><p id="0508" class="mb mc jg bd md me mf mg mh mi mj lz dk translated">希望硬件可以在创新软件中延长其生命周期，软件可以利用硬件作为预构建和可定制的组件。两者可以在新的良性循环中互相推动，就像摩尔定律全面实施时一样。</p></blockquote></div></div>    
</body>
</html>