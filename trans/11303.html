<html>
<head>
<title>8 Hows of Augmented Reality</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">增强现实的8种方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/8-hows-of-augmented-reality-7eb01956401a?source=collection_archive---------25-----------------------#2021-11-05">https://towardsdatascience.com/8-hows-of-augmented-reality-7eb01956401a?source=collection_archive---------25-----------------------#2021-11-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="afc7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">构建模块/分解/解释</h2><div class=""/><div class=""><h2 id="7a64" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">AR要被广泛接受需要什么？</h2></div><p id="9b9b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">本文将研究“如何做？”这让<strong class="kt jd">有了“为什么？”</strong>列在我上一篇帖子里— <a class="ae ln" href="https://medium.com/the-shadow/10-whys-of-augmented-reality-1b71f4a101c5" rel="noopener"> <em class="lo">增强现实的10个为什么</em> </a>。强烈建议用上一篇文章中的视觉场景来刷新你的记忆，以便更好地理解下面列出的概念。</p><p id="9aff" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">免责声明:</strong>这是从我过去使用围绕<a class="ae ln" href="https://en.wikipedia.org/wiki/Extended_reality" rel="noopener ugc nofollow" target="_blank">扩展现实(XR) </a>的产品的经验中推断出来的解释:</p><ul class=""><li id="15b3" class="lp lq it kt b ku kv kx ky la lr le ls li lt lm lu lv lw lx bi translated"><a class="ae ln" href="https://developers.google.com/ar" rel="noopener ugc nofollow" target="_blank"> ARCore </a>，<a class="ae ln" href="https://developer.apple.com/augmented-reality/" rel="noopener ugc nofollow" target="_blank"> ARKit </a>，<a class="ae ln" href="https://immersiveweb.dev/" rel="noopener ugc nofollow" target="_blank"> WebXR </a>，<a class="ae ln" href="https://www.ptc.com/en/products/vuforia?cl1=AR_Vuforia_General_Google_CLC-cpc-ARBrandedxxxVuforia-38010&amp;cmsrc=Google&amp;cid=7015A000001oRiBQAU&amp;elqCampaignId=13184&amp;gclid=Cj0KCQiA3Y-ABhCnARIsAKYDH7tZhXpS3PH4x19ANdqTzb0Hw1oq_VZTfMzOA2f2UErXE9t5UwHvoQ8aAiocEALw_wcB" rel="noopener ugc nofollow" target="_blank"> Vuforia </a></li><li id="63b5" class="lp lq it kt b ku ly kx lz la ma le mb li mc lm lu lv lw lx bi translated"><a class="ae ln" href="https://en.wikipedia.org/wiki/Tango_(platform)" rel="noopener ugc nofollow" target="_blank"> Project Tango </a>，<a class="ae ln" href="https://en.wikipedia.org/wiki/Kinect" rel="noopener ugc nofollow" target="_blank"> Kinect </a>，<a class="ae ln" href="https://www.vuzix.com/" rel="noopener ugc nofollow" target="_blank"> Vuzix </a>，<a class="ae ln" href="https://www.ultraleap.com/" rel="noopener ugc nofollow" target="_blank"> LeapMotion now UltraLeap </a>，<a class="ae ln" href="https://gaming.tobii.com/" rel="noopener ugc nofollow" target="_blank"> Tobii </a>，<a class="ae ln" href="https://www.vive.com/us/" rel="noopener ugc nofollow" target="_blank"> Vive </a>，<a class="ae ln" href="https://www.oculus.com/" rel="noopener ugc nofollow" target="_blank"> Oculus </a>，<a class="ae ln" href="https://www.intel.com/content/www/us/en/architecture-and-technology/realsense-overview.html" rel="noopener ugc nofollow" target="_blank">英特尔实感技术</a>，<a class="ae ln" href="https://newsroom.intel.com/chip-shots/intel-unveils-project-alloy/#gs.qxnjh1" rel="noopener ugc nofollow" target="_blank">英特尔项目合金</a>，<a class="ae ln" href="https://en.wikipedia.org/wiki/Daqri" rel="noopener ugc nofollow" target="_blank"> Daqri </a>，<a class="ae ln" href="https://www.microsoft.com/en-us/hololens" rel="noopener ugc nofollow" target="_blank"> Hololens </a>和<a class="ae ln" href="https://www.magicleap.com/en-us" rel="noopener ugc nofollow" target="_blank"/></li></ul><p id="5e9c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">采用由外向内的方法，消费者对理想增强现实设备的明显要求将被广泛接受:</p><ul class=""><li id="e175" class="lp lq it kt b ku kv kx ky la lr le ls li lt lm lu lv lw lx bi translated">符合人体工程学的外形(重量轻，长期日常使用)</li><li id="363e" class="lp lq it kt b ku ly kx lz la ma le mb li mc lm lu lv lw lx bi translated">易于使用和开发</li><li id="4b67" class="lp lq it kt b ku ly kx lz la ma le mb li mc lm lu lv lw lx bi translated">增强内容与真实环境无缝融合</li></ul><p id="3ab4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了到达这里，我们需要什么？</p><h2 id="fd88" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">1.增强内容原地不动(本地SLAM和传感器)</h2><p id="ed08" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">随着我们真实视觉中最轻微的移动，一个增强的浮动面板应该保持固定，就像我们的沙发保持固定一样，当我们四处移动时，我们只能看到沙发的不同视角。</p><blockquote class="na nb nc"><p id="2ae0" class="kr ks lo kt b ku kv kd kw kx ky kg kz nd lb lc ld ne lf lg lh nf lj lk ll lm im bi translated">让我们做一个练习——先看你的左边，然后看你的右边，闭上你的眼睛。闭上眼睛，稍微移动一下，以确保远离最初的观察点。不要睁开眼睛，试着想象新地点的空间视角？最后打开&amp;比较。够近吗？</p></blockquote><p id="b5cd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们的耳朵不断地评估我们的运动，即使你在一个新的空间闭上眼睛，你也能粗略地评估我们的运动。当我们的眼睛睁开时，我们的运动感觉更加准确。</p><blockquote class="na nb nc"><p id="e9e1" class="kr ks lo kt b ku kv kd kw kx ky kg kz nd lb lc ld ne lf lg lh nf lj lk ll lm im bi translated"><a class="ae ln" href="https://en.wikipedia.org/wiki/Inertial_measurement_unit" rel="noopener ugc nofollow" target="_blank"> IMU </a>(陀螺仪、加速度计)代替耳朵，两个或两个以上超广角高刷新率摄像头代替我们的眼睛。一种基于<strong class="kt jd">轻量级</strong>传感器融合的<a class="ae ln" href="https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping" rel="noopener ugc nofollow" target="_blank"> SLAM </a>算法结合了来自两种技术的输入，构成了我们大脑评估我们周围空间运动的能力。</p></blockquote><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/b21e918d31b31b372e1c9f15630b053c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/1*ldV2xhiEuqCwq-IMnSQLwg.gif"/></div><p class="no np gj gh gi nq nr bd b be z dk translated">来自<a class="ae ln" href="https://github.com/IntelRealSense/librealsense/issues/3129" rel="noopener ugc nofollow" target="_blank"> github演示</a>的T265实感vSLAM模块—图片由作者提供</p></figure><p id="2f2e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们不需要理解我们周围的整个空间(地图)——只需要承认我们的微小运动。我们走得越远，随着时间的推移，我们可能积累的错误就越多。在这里，我们的记忆开始发挥作用，这种能力将在下一节中讨论。</p><h2 id="8392" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">2.将内容与环境相关联(全球SLAM)</h2><p id="fc7b" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">我们还需要一个强大的计算昂贵的slam来映射我们当前所处的各个空间，以周期性地关联心理地图。</p><blockquote class="na nb nc"><p id="58f4" class="kr ks lo kt b ku kv kd kw kx ky kg kz nd lb lc ld ne lf lg lh nf lj lk ll lm im bi translated">为了最大限度地减少我们轻量级可穿戴设备上的计算并延长电池寿命，我们可以通过与别处(远程)存储和处理的稀疏(非密集)地图进行交叉检查来纠正自己。就像购物中心里的地图，它就在购物中心里，我们不需要把它带回家。</p></blockquote><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ns"><img src="../Images/2800bfd088e8edcb17abda043a865b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*412cfs5szZMX7ifRoU3qVA.gif"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated"><a class="ae ln" href="https://github.com/raulmur/ORB_SLAM2" rel="noopener ugc nofollow" target="_blank"> ORBSLAM2 </a>和OpenVSLAM(EOL)演示——图片由作者提供</p></figure><p id="bbaf" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">视觉传感器可以定期向外部设备发送数据，以了解我们的位置，并纠正我们对空间的局部理解。</p><blockquote class="na nb nc"><p id="5cef" class="kr ks lo kt b ku kv kd kw kx ky kg kz nd lb lc ld ne lf lg lh nf lj lk ll lm im bi translated">想想轻量级本地slam(可穿戴设备上)与全球slam(如谷歌地图)在其他地方运行，而<strong class="kt jd">在我们所处的空间</strong>的前提下保持安全。为了解决隐私问题，全球地图由空间所有者维护，例如商场、商店、私人住宅或AR设备切换和连接的办公室，就像我们在星巴克接入wifi一样。</p></blockquote><h2 id="eccf" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">3.感知三维世界(深度感应)</h2><p id="4ccf" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">我们自然地感觉到深度——某物有多远，某物有多大或多小。让我们做另一个练习。</p><blockquote class="na nb nc"><p id="71d6" class="kr ks lo kt b ku kv kd kw kx ky kg kz nd lb lc ld ne lf lg lh nf lj lk ll lm im bi translated">闭上双眼，然后睁开一只眼睛，同时将拇指放在鼻子前面。观察大小、方向和一维拇指。然后睁开另一只眼睛，注意不同之处。你看到了什么？</p></blockquote><p id="30ce" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通过结合你左右眼的视差，我们可以感知深度，从而看到三维世界。AR设备也需要这种能力来估计物体的角度和遮挡——前面有什么，后面有什么，以及某物有多远；在我们的三维世界中进行直观的互动。想想粘在墙上或放在厨房台面上的浮动面板。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi nx"><img src="../Images/12018e8de31d8ad678cca87f605beb8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/0*jCT5LQnL80WJyL1D.gif"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">使用来自<a class="ae ln" href="https://youtu.be/HnXnBKaCqpU" rel="noopener ugc nofollow" target="_blank"> StereoLabs </a>的ZED演示进行空间制图</p></figure><p id="d71b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对我们周围的环境进行3D重建<a class="ae ln" href="https://en.wikipedia.org/wiki/3D_reconstruction" rel="noopener ugc nofollow" target="_blank">的想法</a>计算量很大，可以卸载到其他地方。AR设备仍然可以显示增强的内容，这损害了没有这种功能的可信度，使其介于必须拥有和最好拥有之间。</p><h2 id="13a7" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">4.与扩充内容交互(输入跟踪)</h2><p id="cd92" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">虽然技术本身没有限制，从视线跟踪、设备上的触摸板、基于语音的输入到输入控制器，但我们有权使用我们大多数人幸运地配备的东西——两只手！</p><p id="26e8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了无缝地跟踪我们灵活的伸出的手，我们可以利用现有的用于SLAM的宽视野摄像机。我们可以将实时使用的计算简化为:</p><ul class=""><li id="3ddb" class="lp lq it kt b ku kv kx ky la lr le ls li lt lm lu lv lw lx bi translated">基于深度的遮挡贴图(用于渲染和物理碰撞),无需完全跟踪手部骨骼关节(20)。</li><li id="19aa" class="lp lq it kt b ku ly kx lz la ma le mb li mc lm lu lv lw lx bi translated">跟踪接触点的5个图形提示并检测多帧手势</li></ul><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/1f173a7de57e3ec56906bb2002686f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*-e2THaFE3-j9nXLX.gif"/></div><p class="no np gj gh gi nq nr bd b be z dk translated">来自代码为的<a class="ae ln" href="https://paperswithcode.com/dataset/handnet" rel="noopener ugc nofollow" target="_blank">纸张的HandNet</a></p></figure><h2 id="b042" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">5.开发和渲染引擎(Unity和Unreal)</h2><p id="7fe6" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">两个领先的移动开发平台是Android (Java，Kotlin: SDK &amp; C/C++: NDK)和iOS (Objective-C &amp; Swift)。AR是一种视觉媒体，其中应用程序逻辑与三维渲染组件结合在一起，这是游戏引擎提供编写逻辑的功能，并将物理和照明考虑在内。它们还为图形处理单元(GPU)和CPU (Linux、macOS、Windows)上的操作系统调用提供了隐藏底层低级图形细节的抽象(<a class="ae ln" href="https://www.khronos.org/opengl/wiki/" rel="noopener ugc nofollow" target="_blank"> OpenGL </a>、<a class="ae ln" href="https://en.wikipedia.org/wiki/DirectX" rel="noopener ugc nofollow" target="_blank"> DirectX </a>、<a class="ae ln" href="https://www.khronos.org/vulkan/" rel="noopener ugc nofollow" target="_blank"> Vulkan </a>)。开发人员可以消除渲染计算机生成的图像所需的顶点、三角形和模拟光、暗、透明度和颜色的迷你程序(<a class="ae ln" href="https://en.wikipedia.org/wiki/Shader" rel="noopener ugc nofollow" target="_blank">着色器</a>)的本质细节，并专注于纯粹的应用体验。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi nz"><img src="../Images/bc81250e6c754a7d804ecd7439aa532d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*TPPQnKntdREKCSRJGcv6jA.gif"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">Unity和UE4游戏引擎演示——作者图片</p></figure><blockquote class="na nb nc"><p id="b631" class="kr ks lo kt b ku kv kd kw kx ky kg kz nd lb lc ld ne lf lg lh nf lj lk ll lm im bi translated">可穿戴AR设备上的计算越多，就会越重，越耗电，越发热。利用wifi6和5G的强大连接，随时随地卸载计算的优势，我们可以将AR设备简化为一个发送传感信息以在其他地方处理的编码器，一个解码返回到显示器的内容的解码器。</p></blockquote><p id="70ff" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">想象一下，开发人员可以自由地在任何现有的AppStore中部署AR应用程序，这些应用程序可以在任何有能力的设备上运行，但结果会以无线方式显示在AR设备上。</p><h2 id="8ec3" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">6.非应用程序逻辑组件即远程服务(微服务)</h2><p id="74af" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">在上一节中，我们主要讨论了前端(例如浏览器的网页)，那么后端(例如存储、算法)呢？随着在Kubernetes等编排系统中运行或在远程系统上的docker中简单运行的容器化微服务的流行，生态系统仍然可以在SLAM、AI和其他计算机视觉算法上进行创新，作为一种微服务，只向渲染引擎提交所需的结果，以实现注重用户体验的应用程序逻辑。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oa"><img src="../Images/1f998bcd2fdd6ff76065525fbb49fd08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XzAGENbC-h86q2Q3EoSE2g.png"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">软件和硬件组件—按作者分类的图片</p></figure><blockquote class="na nb nc"><p id="a7dc" class="kr ks lo kt b ku kv kd kw kx ky kg kz nd lb lc ld ne lf lg lh nf lj lk ll lm im bi translated"><strong class="kt jd">假设场景:</strong>想象一下，如果所有的行业参与者都可以自由地创新和发展他们已经擅长构建的组件，AR创新的步伐会有多快？显示器、CPU、GPU、操作系统、VPU、无线等都可以利用其现有的生态系统和市场来提供常见的增强现实消费产品。</p></blockquote><h2 id="d70f" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">7.增强显示技术</h2><p id="3bce" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">这是AR最难的部分——成本、功耗、显示分辨率、亮度、视野！要解释波导的现状(全息、衍射、偏振和反射)，还需要一篇很长的文章。这里有一篇由<a class="ob oc ep" href="https://medium.com/u/8e607bd33f68?source=post_page-----7eb01956401a--------------------------------" rel="noopener" target="_blank"> Kore </a>撰写的关于这一主题的有据可查的媒体文章:</p><p id="02e2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae ln" href="https://medium.com/hackernoon/fundamentals-of-display-technologies-for-augmented-and-virtual-reality-c88e4b9b0895" rel="noopener">https://medium . com/hacker noon/fundamentals-of-display-technologies-for-augmented-and-virtual-reality-c 88e 4b 9 b 0895</a></p><p id="6390" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">注意:</strong>在这个领域有更多的创新<br/>例如<a class="ae ln" href="https://www.ostendo.com/wearable-displays" rel="noopener ugc nofollow" target="_blank"> Ostendo </a>、<a class="ae ln" href="https://www.nreal.ai/" rel="noopener ugc nofollow" target="_blank"> nreal </a>、<a class="ae ln" href="https://www.nueyestech.com/" rel="noopener ugc nofollow" target="_blank"> nueyes </a></p><h2 id="cf50" class="md me it bd mf mg mh dn mi mj mk dp ml la mm mn mo le mp mq mr li ms mt mu iz bi translated">8.借助第三方技术增强AR</h2><p id="5caf" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">理想的AR体验的很大一部分可以通过与其他不能在设备本身上运行的技术合作来实现。</p><ul class=""><li id="ea70" class="lp lq it kt b ku kv kx ky la lr le ls li lt lm lu lv lw lx bi translated"><strong class="kt jd"> AI: </strong>从可以实时生成动态图像(可视化我们的想象力、deepfakes和虚拟化身代理)的GANs，到可以学习我们的动作以适应、推荐和优化我们日常任务的增强内容的网络。</li><li id="a2c6" class="lp lq it kt b ku ly kx lz la ma le mb li mc lm lu lv lw lx bi translated"><strong class="kt jd">物联网:</strong>智能空间的传感器不断生成可以在其他地方进行分析的数据，情境化的信息可以在我们的视野中得到增强，以更快地做出决策(预测性维护、交通信号灯、自主引导车辆和机械臂)</li><li id="ad27" class="lp lq it kt b ku ly kx lz la ma le mb li mc lm lu lv lw lx bi translated"><strong class="kt jd">云游戏:</strong>这可以扩展到直接在AR设备上消费OTA流媒体内容。</li></ul><h1 id="c2bf" class="od me it bd mf oe of og mi oh oi oj ml ki ok kj mo kl ol km mr ko om kp mu on bi translated">结论</h1><p id="0662" class="pw-post-body-paragraph kr ks it kt b ku mv kd kw kx mw kg kz la mx lc ld le my lg lh li mz lk ll lm im bi translated">你可能会注意到上述方法中的一种模式，其中5G ( <a class="ae ln" href="https://www.5gamericas.org/wp-content/uploads/2021/01/InDesign-3GPP-Rel-16-17-2021.pdf" rel="noopener ugc nofollow" target="_blank"> URLLC </a>，企业空间中的私有5G)，wifi6(小型个人空间中的多用户)，IoT(智能城市/工厂/工作场所/家庭)，分布式计算(从边缘到云的远程处理)，作为可扩展微服务交付的算法能力，应用体验的渲染引擎(Unity &amp; Unreal)都协同工作，以提供理想的AR体验。这项技术已经在回答<em class="lo">“增强现实被广泛接受需要什么？”但是这只是“我们如何实现目标”的众多观点之一</em></p><p id="fc27" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">给你留下我(2020年)DIY的早期原型树莓Pi 4 +轻量级T265 SLAM+ <a class="ae ln" href="https://en.wikipedia.org/wiki/Pepper%27s_ghost" rel="noopener ugc nofollow" target="_blank"> Pepper的幽灵效果</a>用于AR显示+Wifi+power bank+win 10 Unity上的远程处理+ WSL docker微服务希望解锁我上一篇帖子中总结的可能性<br/> <a class="ae ln" href="https://medium.com/the-shadow/10-whys-of-augmented-reality-1b71f4a101c5" rel="noopener"> <em class="lo">增强现实的10个为什么</em> </a> <em class="lo">。</em></p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oo"><img src="../Images/00310a3aed140da5e21e88d8a3ba986b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7obhdh_5fTyuVaFZnp5GQ.jpeg"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">DIY早期原型(个人项目)——作者图片</p></figure></div></div>    
</body>
</html>