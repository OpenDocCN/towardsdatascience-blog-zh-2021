<html>
<head>
<title>Wine data set: A Classification Problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">葡萄酒数据集:一个分类问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wine-data-set-a-classification-problem-983efb3676c9?source=collection_archive---------12-----------------------#2021-11-24">https://towardsdatascience.com/wine-data-set-a-classification-problem-983efb3676c9?source=collection_archive---------12-----------------------#2021-11-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="3503" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="b2e4" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">葡萄酒数据集由 13 个不同的葡萄酒参数组成，如酒精和灰分含量，共测量了 178 个葡萄酒样品。这些葡萄酒生长在意大利的同一地区，但来自三个不同的栽培品种；因此有三种不同等级的酒。这里的目标是找到一个模型，该模型可以在给定 13 个测量参数的情况下预测葡萄酒的类别，并找出三个不同类别之间的主要差异。这是一个分类问题，这里我将描述四个模型，并评估每个模型的准确性。此外，我将使用主成分分析来确定和探索这三类之间的差异。</p><p id="bbb6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">多项逻辑回归</strong></p><p id="549a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">由于葡萄酒有三个类别，我们必须使用多项式逻辑回归，而不是有两个类别时使用的逻辑回归。为了做到这一点，我使用了<strong class="kn ir"> <em class="lo"> nnet </em> </strong>包中的<strong class="kn ir"> <em class="lo"> multinom </em> </strong>函数。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="23b5" class="ly jo iq lu b gy lz ma l mb mc">&gt; dim(wine)</span><span id="629e" class="ly jo iq lu b gy md ma l mb mc">[1] 178 14</span><span id="23c2" class="ly jo iq lu b gy md ma l mb mc">&gt; attach(wine)</span><span id="3b28" class="ly jo iq lu b gy md ma l mb mc">&gt; test=sample(178,45)</span><span id="9375" class="ly jo iq lu b gy md ma l mb mc">&gt; library(nnet)</span><span id="75cb" class="ly jo iq lu b gy md ma l mb mc">&gt; LogReg=multinom(class~.,data=wine[-test,])</span><span id="3268" class="ly jo iq lu b gy md ma l mb mc">&gt; summary(LogReg)</span><span id="e789" class="ly jo iq lu b gy md ma l mb mc">&gt; Pre=predict(LogReg,wine[test,])</span><span id="457f" class="ly jo iq lu b gy md ma l mb mc">&gt; table(Pre,wine[test,]$class)</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi me"><img src="../Images/94a17b0105a6f4cf476cf2f5389215dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*csMthmU0tG7CQRpIXP3x0w.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">表 1。多项式逻辑回归模型的混淆矩阵</p></figure><p id="655e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">从表 1 可以看出，在 45 次观察中有 5 次分类错误；因此，多项式逻辑回归模型的准确率为 89%。</p><p id="5589" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">通过执行以下命令，我们可以多次重复上述过程，以获得对多项逻辑回归模型性能的更准确估计:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="e6ab" class="ly jo iq lu b gy lz ma l mb mc">&gt; Accuracy=rep(0,50)</span><span id="8146" class="ly jo iq lu b gy md ma l mb mc">&gt; for (i in 1:50) {</span><span id="903b" class="ly jo iq lu b gy md ma l mb mc">+ test=sample(178,45)</span><span id="fb25" class="ly jo iq lu b gy md ma l mb mc">+ LogReg=multinom(class~.,data=wine[-test,])</span><span id="e064" class="ly jo iq lu b gy md ma l mb mc">+ Pre=predict(LogReg,wine[test,])</span><span id="da43" class="ly jo iq lu b gy md ma l mb mc">+ Accuracy[i]=mean(Pre==wine[test,]$class)</span><span id="f18b" class="ly jo iq lu b gy md ma l mb mc">+ }</span><span id="69c5" class="ly jo iq lu b gy md ma l mb mc">&gt; sum(Accuracy)/50</span><span id="b681" class="ly jo iq lu b gy md ma l mb mc">[1] 0.944</span></pre><p id="ef42" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">线性判别分析</strong></p><p id="e988" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">当我们有两个以上的类，并且当观察数量很小时，LDA 是有用的。当预测值的分布在每一类中都是正态分布时，LDA 也更稳定。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="3b8b" class="ly jo iq lu b gy lz ma l mb mc">&gt; library(MASS)</span><span id="a5e0" class="ly jo iq lu b gy md ma l mb mc">&gt; lda.fit=lda(class~.,data=wine[-test,])</span><span id="fdb2" class="ly jo iq lu b gy md ma l mb mc">&gt; lda.fit</span></pre><p id="7089" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">最后一个命令将生成关于模型的更多细节，如表 2 所示。</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mm"><img src="../Images/552ecab15b644134e0d7174aeab3bc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*00TY4I-HBPOT3q4VAImXcw.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">表二。各类葡萄酒的 13 个预测指标的平均值</p></figure><p id="57e5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">然后，我们根据测试数据评估模型的性能:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="cdba" class="ly jo iq lu b gy lz ma l mb mc">&gt; lda.pred=predict(lda.fit,wine[test,])</span><span id="8dfb" class="ly jo iq lu b gy md ma l mb mc">&gt; table(lda.pred$class,wine[test,]$class)</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/7bab05992d3338c08c1c8a75c4309e1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*PQ5F4XWL_dQ9jY0um6T7PA.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">表 3。LDA 模型的混淆矩阵</p></figure><p id="3b77" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">从表 3 中我们可以看出，LDA 在预测测试数据类别方面具有 100%的准确性。</p><p id="1410" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们还可以使用下面的命令通过 LDA 可视化训练数据的分类，结果如图 1 所示:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="a28f" class="ly jo iq lu b gy lz ma l mb mc">&gt; plot(lda.fit)</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ms"><img src="../Images/801ec6cf93bbdd2eb45ca647e9f7f541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DkSOYllMSY0PDo_U9TL5wA.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">图一。通过 LDA 对训练数据进行分类(图片由作者提供)</p></figure><p id="cd88" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">由于数据集中有三个类，所以只需要两个线性判别式来对每个观察值进行分类。图 1 显示了 LD1 和 LD2 空间上的训练数据的图以及每个数据点的相应类别。基于 LDA 模型的系数计算 LD1 和 LD2 值。</p><p id="8d45" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">通过执行以下命令，我们可以多次重复上述过程，以获得对 LDA 模型性能的更准确估计:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="9395" class="ly jo iq lu b gy lz ma l mb mc">&gt; for (i in 1:50) {</span><span id="75fa" class="ly jo iq lu b gy md ma l mb mc">+ test=sample(178,45)</span><span id="4d86" class="ly jo iq lu b gy md ma l mb mc">+ lda.fit=lda(class~.,data=wine[-test,])</span><span id="ca4f" class="ly jo iq lu b gy md ma l mb mc">+ lda.pred=predict(lda.fit,wine[test,])</span><span id="6b47" class="ly jo iq lu b gy md ma l mb mc">+ Accuracy[i]=mean(lda.pred$class==wine[test,]$class)</span><span id="2f26" class="ly jo iq lu b gy md ma l mb mc">+ }</span><span id="92c1" class="ly jo iq lu b gy md ma l mb mc">&gt; sum(Accuracy)/50</span><span id="526c" class="ly jo iq lu b gy md ma l mb mc">[1] 0.9844444</span></pre><p id="4758" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">二次判别分析(QDA) </strong></p><p id="df78" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">另一个分类器是 QDA 模型，其语法与 r 中的 LDA 相似。我们可以多次运行该过程，以获得对 QDA 模型性能的更准确估计，如下所示:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="bfd0" class="ly jo iq lu b gy lz ma l mb mc">&gt; qda.fit=qda(class~.,data=wine[-test,])</span><span id="f509" class="ly jo iq lu b gy md ma l mb mc">&gt; qda.pred=predict(qda.fit,wine[test,])</span><span id="be80" class="ly jo iq lu b gy md ma l mb mc">&gt; table(qda.pred$class,wine[test,]$class)</span><span id="5a79" class="ly jo iq lu b gy md ma l mb mc">&gt; for (i in 1:50) {</span><span id="c724" class="ly jo iq lu b gy md ma l mb mc">+ test=sample(178,45)</span><span id="8665" class="ly jo iq lu b gy md ma l mb mc">+ qda.fit=qda(class~.,data=wine[-test,])</span><span id="1df5" class="ly jo iq lu b gy md ma l mb mc">+ qda.pred=predict(qda.fit,wine[test,])</span><span id="4a11" class="ly jo iq lu b gy md ma l mb mc">+ Accuracy[i]=mean(qda.pred$class==wine[test,]$class)</span><span id="9d73" class="ly jo iq lu b gy md ma l mb mc">+ }</span><span id="73a7" class="ly jo iq lu b gy md ma l mb mc">&gt; sum(Accuracy)/50</span><span id="09eb" class="ly jo iq lu b gy md ma l mb mc">[1] 0.9866667</span></pre><p id="4b92" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">K-最近邻(KNN) </strong></p><p id="ea20" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">KNN 是一种非参数方法，其中基于其 K-最近邻的类别对观测值进行分类。当决策边界是非线性时，这是一个有用的模型，但它不会告诉我们哪些预测是重要的。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="cbff" class="ly jo iq lu b gy lz ma l mb mc">&gt; library(class)</span><span id="a952" class="ly jo iq lu b gy md ma l mb mc">&gt; knn.pred=knn(wine[-test,2:14],wine[test,2:14],wine[-test,]$class,k=1)</span><span id="72fc" class="ly jo iq lu b gy md ma l mb mc">&gt; table(knn.pred,wine[test,]$class)</span><span id="f03f" class="ly jo iq lu b gy md ma l mb mc">&gt; mean(knn.pred==wine[test,]$class)</span><span id="05f3" class="ly jo iq lu b gy md ma l mb mc">[1] 0.7777778</span></pre><p id="c1b3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">通过执行以下命令，我们可以多次重复上述过程，以获得对 KNN 模型性能的更准确估计:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="d3dc" class="ly jo iq lu b gy lz ma l mb mc">&gt; for (i in 1:50){</span><span id="ab71" class="ly jo iq lu b gy md ma l mb mc">+ test=sample(178,45)</span><span id="7e35" class="ly jo iq lu b gy md ma l mb mc">+ knn.pred=knn(wine[-test,2:14],wine[test,2:14],wine[-test,]$class,k=1)</span><span id="7a1f" class="ly jo iq lu b gy md ma l mb mc">+ Accuracy[i]=mean(knn.pred==wine[test,]$class)</span><span id="0095" class="ly jo iq lu b gy md ma l mb mc">+ }</span><span id="6a79" class="ly jo iq lu b gy md ma l mb mc">&gt; sum(Accuracy)/50</span><span id="47eb" class="ly jo iq lu b gy md ma l mb mc">[1] 0.7435556</span></pre><p id="a884" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们可以对 k=2 到 5 重复相同的过程，结果显示在表 4 的中间栏中。</p><p id="fe01" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">从表 4 的中间一栏我们可以看出，KNN 模型的结果并不令人印象深刻。这是因为 KNN 模型使用欧几里德距离来测量两点之间的距离，如果要素具有不同的比例，它会影响模型。由于 13 个要素中的每一个都具有不同的比例，因此对数据进行归一化处理以使所有要素都具有相同的值范围非常重要。我们可以在缩放数据后重新运行 KNN 模型，如下所示:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="316f" class="ly jo iq lu b gy lz ma l mb mc">&gt; for (i in 1:50){</span><span id="c567" class="ly jo iq lu b gy md ma l mb mc">+ test=sample(178,45)</span><span id="89d6" class="ly jo iq lu b gy md ma l mb mc">+ knn.pred=knn(scale(wine[-test,2:14]),scale(wine[test,2:14]),wine[-test,]$class,k=1)</span><span id="4084" class="ly jo iq lu b gy md ma l mb mc">+ Accuracy[i]=mean(knn.pred==wine[test,]$class)</span><span id="4a4c" class="ly jo iq lu b gy md ma l mb mc">+ }</span><span id="4f70" class="ly jo iq lu b gy md ma l mb mc">&gt; sum(Accuracy)/50</span><span id="a908" class="ly jo iq lu b gy md ma l mb mc">[1] 0.9382222</span></pre><p id="fe2d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">表 4 总结了 KNN 模型的结果，我们可以看到缩放数据极大地提高了模型的性能。</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c45745f75475def0ae66d6e79b137651.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*lNn-5DfvUm_eP1yzAOS2rA.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">表 4。有无数据缩放的 KNN 模型的准确性</p></figure><h2 id="351c" class="ly jo iq bd jp mu mv dn jt mw mx dp jx kw my mz kb la na nb kf le nc nd kj ne bi translated"><strong class="ak">总结</strong></h2><p id="0e49" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">表 5 总结了不同分类模型对葡萄酒数据集的准确性。LDA 和 QDA 的精确度最高，其次是 KNN (k=5)模型。</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/1122111e426cef090f06c4bd7dc83def.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*agbThy0T5E_cchsnTcgZxQ.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">表 5。不同分类模型的准确性</p></figure><p id="9c71" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">主成分分析</strong></p><p id="8d3b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">上面描述的模型可以基于 13 个测量的预测值来预测葡萄酒的类别。然而，我们也有兴趣知道这三个类别之间的主要区别是什么，以及什么预测是重要的。为了做到这一点，我们可以执行主成分分析，这是一个探索性数据分析的有用工具。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="2074" class="ly jo iq lu b gy lz ma l mb mc">&gt; pr.out=prcomp(wine[,-1],scale=TRUE)</span><span id="2338" class="ly jo iq lu b gy md ma l mb mc">&gt; pr.out$rotation</span><span id="c04d" class="ly jo iq lu b gy md ma l mb mc">&gt; biplot(pr.out,scale=0)</span><span id="6e10" class="ly jo iq lu b gy md ma l mb mc">&gt; plot(pr.out$x[,1:2],col=wine$class)</span></pre><p id="b5e5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">前两个 PC 分数和相应的加载向量如图 2 所示。</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ng"><img src="../Images/ab00322a72a93c2208ee9fca4dc9bb6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yEzjCiH7IrB_eDXPJSpIgg.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">图二。葡萄酒数据集在前两台电脑上的投影。每个箭头表示顶部和右侧轴上的前两个 PCs 的加载向量。图上的每个数字代表该特定数据点的 PC1 和 PC2 得分(图片由作者提供)</p></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/75cc3c4ad8cec41287e4d5de37663a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*aPlWLqsl-Db4iM8yMQHNGQ.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">图 3。葡萄酒数据集的前两个 PC 分数。黑色代表 1 级，红色代表 2 级，绿色代表 3 级酒。(图片由作者提供)</p></figure><p id="790d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">图 2 和图 3 显示数据点被分成三个不同的组，对应于三种葡萄酒。1 班和 3 班的 PC2 分数相对相同，但 PC1 分数相差很大。另一方面，类 2 具有介于类 1 和类 3 之间的 PC1 分数，并且其 PC2 分数低于其他两个类。我们可以通过查看 PC 负载向量(图 2 中的箭头)来进一步检查每个类之间的差异。例如,“火山灰碱性”的方向是朝向 PC1 和 3 类数据点的高值。因此，我们可以预计，等级 3 具有较高的“灰分碱度”值，其次是等级 2 和等级 1。我们可以对其他 13 个预测因子进行类似的研究。这种调查的结果总结在表 6 和表 7 中，表 6 和表 7 显示了三种葡萄酒之间的主要差异。这些发现与表 2 所示的 LDA 结果一致。</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ni"><img src="../Images/2d45da3b003e9ba6118f0706bfbe4951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Suv0iZTtgQazmaVhgjLoAA.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">表 6。总结了 1 级和 3 级葡萄酒的主要区别。对于上述参数，等级 2 的值介于等级 1 和等级 3 之间。</p></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/dd19d9556fbfe70f377025b154417fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*ccOISoJHBjmufzndQoJFEg.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">表 7。2 级和 1/3 级葡萄酒的主要区别</p></figure><h1 id="049b" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">结论</strong></h1><p id="176e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用四种分类方法来评估每个模型在预测葡萄酒类别中的准确性。QDA 和 LDA 的精确度最高，其次是 KNN 和多项逻辑回归。在应用 KNN 模型进行准确分类之前，对数据进行归一化是非常重要的。主成分分析用于识别三类葡萄酒之间的主要差异。</p><h1 id="2b18" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">消息来源</strong></h1><p id="4d3e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><a class="ae nk" href="http://archive.ics.uci.edu/ml/datasets/Wine" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库:葡萄酒数据集</a>。<a class="ae nk" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank">知识共享署名 4.0 国际</a> (CC BY 4.0)许可”。</p><p id="70b7" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><a class="ae nk" href="https://www.statlearning.com/" rel="noopener ugc nofollow" target="_blank">统计学习导论(statlearning.com)</a></p></div></div>    
</body>
</html>