<html>
<head>
<title>Comprehensive Guide to Multiclass Classification With Sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Sklearn多类分类综合指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/comprehensive-guide-to-multiclass-classification-with-sklearn-127cc500f362?source=collection_archive---------1-----------------------#2021-06-06">https://towardsdatascience.com/comprehensive-guide-to-multiclass-classification-with-sklearn-127cc500f362?source=collection_archive---------1-----------------------#2021-06-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e3ce" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">模型选择、制定策略和选择评估标准</h2></div><p id="011f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">学习如何用Sklearn解决任何多类分类问题。本教程涵盖了如何选择模型选择策略、几个多类评估指标，以及如何使用它们完成超参数调整，以优化用户定义的指标。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/9ffad58ef10400d9c5362b30fcc93fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vlfX6cRLxZKhn4uN4MFHrg.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated"><strong class="bd lu">照片由</strong> <a class="ae lv" href="https://www.pexels.com/@sergiu-iacob-10475786?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd lu">塞尔吉奥·亚科布</strong> </a> <strong class="bd lu">上</strong> <a class="ae lv" href="https://www.pexels.com/photo/wave-dark-abstract-motion-7868341/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd lu">像素</strong> </a></p></figure><h2 id="bd3d" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">介绍</h2><p id="01b1" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">尽管多类分类并不常见，但它确实比二元分类问题提出了更大的挑战。你可以相信我的话，因为这篇文章是我写过的最有挑战性的文章(已经写了将近70篇)。</p><p id="406f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我发现多类分类这个话题很有深度，充满了细微差别。我读了那么多文章，读了多个StackOverflow线程，自己创建了几个，花了几个小时浏览Sklearn用户指南，做实验。多类分类的核心主题，例如</p><ul class=""><li id="3e79" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">选择将问题二值化的策略</li><li id="8736" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">选择基本模式</li><li id="9b3b" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">理解非常多的指标</li><li id="8dee" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">筛选出解决您业务问题的单一指标，并对其进行定制</li><li id="5538" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">为此定制度量调整超参数</li><li id="413a" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">最后用Sklearn把所有的理论付诸实践</li></ul><p id="4457" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">都分散在互联网黑暗肮脏的角落里。这足以得出结论，没有一个单一的资源显示了在互联网上处理多类分类问题的端到端工作流(也许，我错过了)。</p><p id="83be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">出于这个原因，本文将是一个关于如何使用Sklearn解决任何多类监督分类问题的综合教程。您将学习上述核心概念的理论和实现。这将是一个漫长而技术性的阅读，所以去喝杯咖啡吧！</p><div class="ni nj gp gr nk nl"><a href="https://ibexorigin.medium.com/membership" rel="noopener follow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd iu gy z fp nq fr fs nr fu fw is bi translated">通过我的推荐链接加入Medium-BEXGBoost</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">获得独家访问我的所有⚡premium⚡内容和所有媒体没有限制。支持我的工作，给我买一个…</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">ibexorigin.medium.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz lo nl"/></div></div></a></div><p id="43d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">获得由强大的AI-Alpha信号选择和总结的最佳和最新的ML和AI论文:</p><div class="ni nj gp gr nk nl"><a href="https://alphasignal.ai/?referrer=Bex" rel="noopener  ugc nofollow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd iu gy z fp nq fr fs nr fu fw is bi translated">阿尔法信号|机器学习的极品。艾总结的。</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">留在循环中，不用花无数时间浏览下一个突破；我们的算法识别…</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">alphasignal.ai</p></div></div><div class="nu l"><div class="oa l nw nx ny nu nz lo nl"/></div></div></a></div></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="9874" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">本地多类分类器</h2><p id="c3e7" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">根据你选择的模型，Sklearn以3种不同的方式处理多类分类问题。换句话说，Sklearn估计器根据其处理多类数据的策略分为3类。</p><p id="0118" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一组也是最大的一组估计器本身支持多类分类:</p><ul class=""><li id="6dc5" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB" rel="noopener ugc nofollow" target="_blank">naive_bayes.BernoulliNB</a></code></li><li id="0ab1" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" rel="noopener ugc nofollow" target="_blank">tree.DecisionTreeClassifier</a></code></li><li id="0326" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier" rel="noopener ugc nofollow" target="_blank">tree.ExtraTreeClassifier</a></code></li><li id="bf0f" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier" rel="noopener ugc nofollow" target="_blank">ensemble.ExtraTreesClassifier</a></code></li><li id="755d" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB" rel="noopener ugc nofollow" target="_blank">naive_bayes.GaussianNB</a></code></li><li id="31c2" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" rel="noopener ugc nofollow" target="_blank">neighbors.KNeighborsClassifier</a></code></li><li id="7bc2" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" rel="noopener ugc nofollow" target="_blank">svm.LinearSVC</a></code>(设置multi_class="crammer_singer ")`</li><li id="f59e" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" rel="noopener ugc nofollow" target="_blank">linear_model.LogisticRegression</a></code>(设置multi_class= "多项式")</li><li id="5194" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV" rel="noopener ugc nofollow" target="_blank">linear_model.LogisticRegressionCV</a></code>(设置multi_class= "多项式")</li></ul><p id="f8a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于一个N类问题，他们会产生N乘N <a class="ae lv" rel="noopener" target="_blank" href="/how-to-tune-models-like-a-puppet-master-based-on-confusion-matrix-fd488f9b5e65?source=your_stories_page-------------------------------------">的混淆矩阵</a>，大部分评估指标都是从中推导出来的:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/e596269eb3b91ff83d0a8ad0145abd59.png" data-original-src="https://miro.medium.com/v2/format:webp/1*wC5gxrcVy5j4OU-NxBwOrQ.png"/></div></figure><p id="e594" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将在教程的后面关注多类混淆矩阵。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="58fa" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">一对一(OVO)策略的二元分类器</h2><p id="e4f6" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">其他监督分类算法主要是为二进制情况设计的。然而，Sklearn实现了两种称为一对一(OVO)和一对其余(OVR，也称为一对所有)的策略，将一个多类问题转换为一系列二元任务。</p><p id="60c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">OVO将一个多类问题分解成每对类的一个二元分类任务。换句话说，对于每一对，将建立单个二元分类器。例如，一个具有4个类别(脑癌、肺癌、乳腺癌和肾癌)的目标使用6个单独的分类器将问题二值化:</p><ul class=""><li id="c8c8" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">分类器1:肺与乳房</li><li id="a978" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器2:肺对肾</li><li id="5f9e" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器3:肺对脑</li><li id="5d87" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器4:乳房对肾脏</li><li id="6c77" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器5:乳房对大脑</li><li id="5b0c" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器6:肾对脑</li></ul><p id="02a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Sklearn建议这些分类器最好与OVO方法一起使用:</p><ul class=""><li id="880b" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC" rel="noopener ugc nofollow" target="_blank"> svm。NuSVC </a></li><li id="a56a" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" rel="noopener ugc nofollow" target="_blank"> svm。SVC </a></li><li id="63bd" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier" rel="noopener ugc nofollow" target="_blank">高斯_过程。GaussianProcessClassifier </a>(设置multi_class = "one_vs_one ")</li></ul><p id="b7c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Sklearn还在<code class="fe oi oj ok ol b">sklearn.multiclass.OneVsOneClassifier</code>下提供了上述模型的包装器估算器:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="cdb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种策略的一个主要缺点是它的计算工作量。由于每对类都需要一个单独的二进制分类器，所以基数高的目标可能需要很长时间来训练。为了计算将为N类问题构建的分类器的数量，使用以下公式:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/6f840bedf8134a852a4285690df4d21f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*uU3BK3dicsDL6ajnpVX60Q.png"/></div></figure><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="c9cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在实践中，由于这个缺点，一对其余的策略是更可取的。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="1da4" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">一对一(OVR)策略的二元分类器</h2><p id="3339" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">或者，OVR策略为目标中的每个类创建一个单独的分类器。本质上，每个二进制分类器选择一个类，并将其标记为正，编码为1。其余的类被认为是负标签，因此用0编码。对4种癌症进行分类:</p><ul class=""><li id="d74d" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">分类器1:肺vs .[乳腺、肾、脑]——(肺癌，不是肺癌)</li><li id="09c8" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器2:乳房对[肺、肾、脑]——(乳腺癌，不是乳腺癌)</li><li id="d0c6" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器3:肾对[肺、乳房、脑]——(肾癌，不是肾癌)</li><li id="a499" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">分类器4:大脑vs .[肺、乳腺、肾]——(脑癌，不是脑癌)</li></ul><p id="362e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Sklearn建议这些分类器最好与OVR方法一起使用:</p><ul class=""><li id="d42f" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier" rel="noopener ugc nofollow" target="_blank">ensemble.GradientBoostingClassifier</a></code></li><li id="742d" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier" rel="noopener ugc nofollow" target="_blank">gaussian_process.GaussianProcessClassifier</a></code>(设置multi_class = "one_vs_rest ")</li><li id="a582" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" rel="noopener ugc nofollow" target="_blank">svm.LinearSVC</a></code>(设置multi_class="ovr ")</li><li id="7a9c" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" rel="noopener ugc nofollow" target="_blank">linear_model.LogisticRegression</a></code>(设置multi_class="ovr ")</li><li id="a2b2" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV" rel="noopener ugc nofollow" target="_blank">linear_model.LogisticRegressionCV</a></code>(设置multi_class="ovr ")</li><li id="5b39" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" rel="noopener ugc nofollow" target="_blank">linear_model.SGDClassifier</a></code></li><li id="e2fc" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><code class="fe oi oj ok ol b"><a class="ae lv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron" rel="noopener ugc nofollow" target="_blank">linear_model.Perceptron</a></code></li></ul><p id="6361" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者，您可以使用默认<code class="fe oi oj ok ol b">OneVsRestClassifier</code>的上述模型:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="345a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管这种策略显著降低了计算成本，但事实上只有一个类被认为是正面的，而其余的被认为是负面的，这使得每个二元问题成为一个不平衡的分类。对于目标中比例较低的班级，这个问题更加突出。</p><p id="2ae5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这两种方法中，根据传递的估计量，所有二元分类器的结果可以用两种方式总结:</p><ul class=""><li id="f26b" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">多数投票:每个二元分类器预测一个类别，从所有分类器中获得最多投票的类别被选择</li><li id="ce39" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">根据类成员概率分数的arg max:LogisticRegression等分类器计算每个类的概率分数(<code class="fe oi oj ok ol b">.predict_proba()</code>)。然后，选择分数总和的argmax。</li></ul><p id="bb43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将在本教程的后面部分详细讨论如何对这些策略进行评分。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="3838" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">样本分类问题和预处理流水线</h2><p id="316e" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">作为一个示例问题，我们将使用Kaggle的<a class="ae lv" href="https://www.kaggle.com/shivam2503/diamonds" rel="noopener ugc nofollow" target="_blank">钻石数据集</a>来预测钻石的质量:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/13b79ae0d34a22b2cd549e23fe23f420.png" data-original-src="https://miro.medium.com/v2/format:webp/1*a02DlZtoBCZCz3wMmqWKBw.png"/></div></figure><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/795fb008c690f18f7c6c4cee50f1be47.png" data-original-src="https://miro.medium.com/v2/format:webp/1*mHREJjp-hhv8f3JKOhDNqA.png"/></div></figure><p id="d536" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的输出显示了不同比例的特征，建议我们使用某种类型的归一化。这一步对于许多基于线性的模型的良好运行是必不可少的。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="c79f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集混合了数值和分类特征。我在我的上一篇文章中详细介绍了二进制分类的预处理步骤。您可以很容易地将这些想法应用到多类的情况中，所以我在这里将保持解释简洁明了。</p><p id="32c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">目标是“削减”，它有5个等级:理想、优质、非常好、良好和一般(质量递减)。我们将用OneHotEncoder对文本特征进行编码。</p><p id="747a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们快速浏览一下每个数字要素的分布，以决定使用哪种类型的归一化:</p><pre class="lf lg lh li gt oq ol or os aw ot bi"><span id="6e7f" class="lw lx it ol b gy ou ov l ow ox">&gt;&gt;&gt; diamonds.hist(figsize=(16, 12));</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/48cf8a5e81882c43e590623efafe9b95.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1bUMus_GdSwMjcLY1VAuzw.png"/></div></figure><p id="2d03" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">价格和克拉显示偏斜分布。我们将使用对数转换器使它们尽可能呈正态分布。对于其他的，简单的标准化就足够了。如果您不熟悉数字转换，请查看我的关于该主题的文章。同样，下面的代码包含了一个Sklearn管道的例子，你可以从<a class="ae lv" rel="noopener" target="_blank" href="/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d?source=your_stories_page-------------------------------------">这里</a>了解所有关于它们的内容。</p><p id="be90" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们开始工作:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="de08" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们管道的第一个版本使用了<code class="fe oi oj ok ol b">RandomForestClassifier</code>。让我们通过生成预测来查看它的混淆矩阵:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/84d99be3288483090be93bcc0095de08.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WKZVju7JsvEyu1TTG3ZSvg.png"/></div></figure><p id="36f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第8行和第9行，我们创建了矩阵并使用特殊的Sklearn函数来绘制它。<code class="fe oi oj ok ol b">ConfusionMatrixDisplay</code>也有<code class="fe oi oj ok ol b">display_labels</code>参数，我们将通过<code class="fe oi oj ok ol b">pipeline.classes_</code>属性访问的类名传递给它。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="86f2" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">解读N乘N混淆矩阵</h2><p id="0630" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">如果你读过我的另一篇关于二进制分类的文章，你就会知道混淆矩阵是监督分类问题的圣杯。在2乘2矩阵中，矩阵项易于解释和定位。</p><p id="1b5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管随着类别数量的增加，解释矩阵变得越来越困难，但是有一些万无一失的方法可以找到任何形状的矩阵。</p><p id="3c22" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一步是始终确定你的积极和消极类。这取决于你要解决的问题。作为珠宝店老板，我可能希望我的分类器能够比其他类型更好地区分理想钻石和优质钻石，使这些类型的钻石成为我的正面类别。其他类将被视为负面。</p><p id="c868" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在早期建立正类和负类对于评估模型性能和超参数调整非常重要。这样做之后，你应该定义你的真阳性、真阴性、假阳性和假阴性。在我们的案例中:</p><ul class=""><li id="4b2f" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated"><strong class="kk iu">阳性等级</strong>:理想和优质钻石</li><li id="cb0a" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">负等级</strong>:非常好，好，和公平的钻石</li><li id="0c39" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">真阳性，类型1 </strong>:实际理想值，预测理想值</li><li id="2f61" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">真阳性，类型2 </strong>:实际保费，预测保费</li><li id="3398" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">真阴性</strong>:其余钻石类型预测正确</li><li id="7b3f" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">假阳性</strong>:实际值属于3个阴性类别中的任何一个，但预测为理想值或溢价值</li><li id="97a0" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">假阴性</strong>:实际值为理想值或溢价值，但由3个阴性类别中的任何一个预测。</li></ul><p id="a102" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总是以这种方式列出矩阵的术语，你的工作流程的其余部分将会容易得多，正如你将在下一节看到的。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="5ed5" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">Sklearn如何计算多类分类指标— ROC AUC得分</h2><p id="5e47" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">这一节仅仅是关于Sklearn如何为多类分类计算公共度量的基本细节。具体来说，我们将探究4个最常见的指标:ROC_AUC、precision、recall和f1得分。尽管我将对每个指标做一个简要的概述，但我将主要关注在实践中使用它们。如果您想更深入地了解每个指标衡量的内容，请参考这篇<a class="ae lv" rel="noopener" target="_blank" href="/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2">文章</a>。</p><p id="4ee5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将讨论的第一个指标是ROC AUC得分或<em class="op">受试者工作特征曲线</em>下的面积。当我们想要测量一个分类器的性能来区分每一个类时，它是最常用的。这意味着ROC AUC更适合平衡分类任务。</p><p id="ee18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">实质上，ROC AUC分数用于二进制分类，并与可以基于某个阈值生成类别成员概率的模型一起使用。以下是计算二元分类ROC AUC步骤的简要概述:</p><ol class=""><li id="8a1f" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld oy na nb nc bi translated">一个二元分类器，可以用它的<code class="fe oi oj ok ol b">predict_proba</code>方法生成类成员概率，比如LogisticRegression。</li><li id="5546" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">选择接近0的初始决策阈值。例如，如果概率高于0.1，则预测该类为负，否则为正。</li><li id="5b67" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">使用该阈值，创建混淆矩阵。</li><li id="3903" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">发现真阳性率(TPR)和假阳性率(FPR)。</li><li id="8db9" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">选择新的阈值，并重复步骤3-4。</li><li id="c726" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">对0到1之间的各种阈值重复步骤2-5，以创建一组TPR和FPR。</li><li id="c124" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">绘制所有TPR与FPR的关系图，以生成接收器工作特性曲线。</li><li id="f217" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">计算这条曲线下的面积。</li></ol><p id="f16a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于多类分类，您可以使用OVO或OVR策略计算所有类的ROC AUC。由于我们一致认为OVR是一个更好的选择，以下是OVR分类的ROC AUC计算方法:</p><ol class=""><li id="a3de" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld oy na nb nc bi translated">使用OVR创建的每个二元分类器使用上述步骤找到其自身类别的ROC AUC分数。</li><li id="867c" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld oy na nb nc bi translated">然后使用以下两种方法之一对所有分类器的ROC AUC评分进行平均:</li></ol><ul class=""><li id="81f5" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">“宏观”:这只是分数的算术平均值</li><li id="02ee" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">“加权”:通过找到一个加权平均值，将阶级不平衡考虑在内。每个ROC AUC乘以其类别权重并求和，然后除以样本总数。</li></ul><p id="1d10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，假设目标中有100个样本—类别1 (45)，类别2 (30)，类别3 (25)。OVR创建了3个二元分类器，每个类别一个，它们的ROC AUC分数分别为0.75、0.68、0.84。所有类别的加权ROC AUC分数将为:</p><p id="bf7b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> ROC AUC(加权):((45 * 0.75)+(30 * 0.68)+(25 * 0.84))/100 = 0.7515</strong></p><p id="9d71" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是这一切在Sklearn中的实现:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="3c50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面，我们为我们的钻石分类问题计算了ROC AUC，得到了一个优秀的分数。使用<code class="fe oi oj ok ol b">roc_auc_score</code>时，不要忘记正确设置<code class="fe oi oj ok ol b">multi_class</code>和<code class="fe oi oj ok ol b">average</code>参数。如果您想要生成某个特定课程的分数，以下是您的操作方法:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="a52d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ROC AUC分数只是一个很好的衡量标准，可以看出分类器如何区分不同的类别。更高的ROC AUC分数不一定意味着更好的模型。最重要的是，我们更关心我们的模型对理想钻石和优质钻石进行分类的能力，因此ROC AUC这样的指标对我们的情况来说不是一个好的选择。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="7070" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">多类分类的精确度、召回率和F1分数</h2><p id="7ef1" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">衡量渠道绩效的更好指标是使用精确度、召回率和F1分数。对于二进制情况，它们易于理解且直观:</p><div class="lf lg lh li gt ab cb"><figure class="oz lj pa pb pc pd pe paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/5145e3503eb10a2744450f355bd74114.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*XH-bmDiJ50rWfqBR82NOdQ.png"/></div></figure><figure class="oz lj pf pb pc pd pe paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/47728affee0b0d893d662b2115fc36d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*KWZHeEuBGhDfw5CTE_PRfQ.png"/></div></figure><figure class="oz lj pg pb pc pd pe paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/a4b51160df3b3e695f518a738bde7f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*LmttOOk86tXBGlaC_73Xag.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk ph di pi pj translated">作者提供的图片</p></figure></div><p id="2d47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在多类的情况下，这3个度量是基于每类计算<em class="op">。例如，让我们再来看看混淆矩阵:</em></p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/84d99be3288483090be93bcc0095de08.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WKZVju7JsvEyu1TTG3ZSvg.png"/></div></figure><p id="506b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">精度告诉我们有多少比例的预测阳性是真正的阳性。如果我们想要计算理想钻石的精度，真正的阳性将是正确预测的理想钻石的数量(矩阵的中心，6626)。假阳性将是任何细胞计数的次数，我们的分类预测其他类型的钻石是理想的。这些单元格位于矩阵中心的上方和下方(1013 + 521 + 31 + 8 = 1573)。使用精度公式，我们将其计算为:</p><p id="e4a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">精度(理想)= TP/(TP+FP)= 6626/(6626+1573)= 0.808</strong></p><p id="019c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">召回的计算方法类似。我们知道真正阳性的数量——6626。假阴性将是对分类器预测属于任何其他阴性类别的钻石的理想类型的次数进行计数的任何单元。这些单元格位于矩阵中心的左右两侧(3 + 9 + 363 + 111 = 486)。使用回忆公式，我们计算出它是:</p><p id="f216" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">回忆(理想)= TP/(TP+FN)= 6626/(6626+486)= 0.93</strong></p><p id="3d8d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么，对于理想的类，我们如何在召回率和精确度之间进行选择呢？这取决于你试图解决的问题的类型。如果你想尽量减少其他更便宜的钻石被预测为理想钻石的情况，你应该优化精度。作为一个珠宝店老板，你可能会因为将便宜的钻石冒充昂贵的理想钻石出售而被起诉欺诈。</p><p id="1461" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，如果您想最大限度地减少意外低价出售理想钻石的情况，您应该优化理想类的召回。的确，你不会被起诉，但你可能会赔钱。</p><p id="9255" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第三个选择是拥有一个同样擅长上述两种场景的模型。换句话说，一个具有高精度和高召回率的模型。幸运的是，有一个指标可以衡量这一点:F1分数。F1得分取精确度和召回率的调和平均值，并产生一个介于0和1之间的值:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/c8bf2012a78edee60e7dc815336d9e84.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ii6xHPNkJXzj-lSl2803JA.png"/></div></figure><p id="33b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，理想班级的F1分数应该是:</p><p id="6ce2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> F1(理想)= 2 *(0.808 * 0.93)/(0.808+0.93)= 0.87</strong></p><p id="c4f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">至此，我们只计算了理想类的3个指标。但是在多类分类中，Sklearn为所有类计算它们。你可以用<code class="fe oi oj ok ol b">classification_report</code>来看这个:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="3d56" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以检查我们对理想类的计算是否正确。表格的最后一列— <code class="fe oi oj ok ol b">support</code>显示了每个类别有多少个样本。此外，最后两行显示了3个指标的平均分数。我们已经介绍了ROC AUC示例中的宏观平均值和加权平均值。</p><p id="c3c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于像这样的不平衡分类任务，你很少选择平均精度，F1分数的回忆。同样，选择一个指标来优化一个特定的类取决于您的业务问题。对于我们的情况，我们将选择优化理想和高级类的F1分数(是的，您可以同时选择多个类)。首先，让我们看看如何计算所有类别的加权F1:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="5071" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上与<code class="fe oi oj ok ol b">classification_report</code>的输出一致。要选择理想和高级课程的F1分数，请指定<code class="fe oi oj ok ol b">labels</code>参数:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="df99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，让我们看看如何通过超参数调优来优化这些指标。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="a453" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">调整超参数以优化自定义指标的模型性能</h2><p id="ac21" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">为一个指标优化模型性能几乎与我们为二进制情况所做的一样。唯一的区别是我们如何将评分函数传递给GridSearch这样的超参数调谐器。</p><p id="4db5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，我们一直使用RandomForestClassifier管道，因此我们将为此估计器创建一个超参数网格:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><blockquote class="pk pl pm"><p id="dba8" class="ki kj op kk b kl km ju kn ko kp jx kq pn ks kt ku po kw kx ky pp la lb lc ld im bi translated">不要忘记在每个超参数名称前面加上您在评估器管道中选择的步骤名称。当我们创建管道时，我们将RandomForests指定为“base”。更多信息见<a class="ae lv" href="https://stackoverflow.com/a/66344804/11922237" rel="noopener ugc nofollow" target="_blank">本</a>讨论。</p></blockquote><p id="6dfb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用HalvingGridSeachCV (HGS ),它比常规的网格搜索要快得多。你可以阅读这篇文章来看看我的实验:</p><div class="ni nj gp gr nk nl"><a rel="noopener follow" target="_blank" href="/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232ed0160155"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd iu gy z fp nq fr fs nr fu fw is bi translated">HalvingGridSearch将超参数调谐速度提高了11倍</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">编辑描述</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="pq l nw nx ny nu nz lo nl"/></div></div></a></div><p id="471d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们将上面的网格提供给HGS之前，让我们创建一个定制的评分函数。在二进制的情况下，我们可以传递字符串值作为我们想要使用的度量的名称，比如“precision”或“recall”但是在多类的情况下，这些函数接受额外的参数，如果我们将函数名作为字符串传递，我们就不能这样做。为了解决这个问题，Sklearn提供了<code class="fe oi oj ok ol b">make_scorer</code>功能:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="12de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我们在上一节中所做的，我们粘贴了<code class="fe oi oj ok ol b">average</code>和<code class="fe oi oj ok ol b">labels</code>参数的自定义值。</p><p id="c658" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，让我们初始化HGS，并通过三重交叉验证使其适合全部数据:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="926e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">搜索完成后，您可以分别使用<code class="fe oi oj ok ol b">.best_score_</code>和<code class="fe oi oj ok ol b">.best_estimator_</code>属性获得最佳得分和估计值。</p><p id="17ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你的模型的好坏取决于你选择用来评估它的标准。超参数调整将是耗时的，但假设您在此之前做了所有正确的事情，并且给出了足够好的参数网格，那么一切都会如预期的那样。如果没有，这是一个迭代过程，所以调整预处理步骤，重新审视您选择的指标，也许可以扩大您的搜索范围。感谢您的阅读！</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="b342" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">相关文章</h2><ul class=""><li id="ba0e" class="mu mv it kk b kl mp ko mq kr pr kv ps kz pt ld mz na nb nc bi translated"><a class="ae lv" rel="noopener" target="_blank" href="/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2">简化多类指标，第一部分:精度和召回率</a></li><li id="696b" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae lv" rel="noopener" target="_blank" href="/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1">简化多类指标，第二部分:F1-得分</a></li><li id="7dd6" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae lv" href="https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/" rel="noopener ugc nofollow" target="_blank">如何计算不平衡分类的精度、召回率和F-Measure</a></li></ul><h2 id="bbb0" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">讨论</h2><ul class=""><li id="265a" class="mu mv it kk b kl mp ko mq kr pr kv ps kz pt ld mz na nb nc bi translated"><a class="ae lv" href="https://stats.stackexchange.com/questions/210700/how-to-choose-between-roc-auc-and-f1-score" rel="noopener ugc nofollow" target="_blank">如何在ROC AUC和F1成绩之间做出选择？</a></li><li id="c906" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae lv" href="https://stats.stackexchange.com/questions/123036/what-are-the-differences-between-auc-and-f1-score" rel="noopener ugc nofollow" target="_blank">AUC和F1-score有什么区别？</a></li></ul><h2 id="fb58" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">API和用户指南</h2><ul class=""><li id="b368" class="mu mv it kk b kl mp ko mq kr pr kv ps kz pt ld mz na nb nc bi translated"><a class="ae lv" href="https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics" rel="noopener ugc nofollow" target="_blank">分类指标</a></li><li id="1172" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae lv" href="https://scikit-learn.org/stable/modules/multiclass.html" rel="noopener ugc nofollow" target="_blank">多类和多输出算法</a></li></ul></div></div>    
</body>
</html>