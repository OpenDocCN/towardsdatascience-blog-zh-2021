<html>
<head>
<title>Understanding the n_jobs Parameter to Speedup scikit-learn Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解n_jobs参数以加速scikit-learn分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-the-n-jobs-parameter-to-speedup-scikit-learn-classification-26e3d1220c28?source=collection_archive---------9-----------------------#2021-07-28">https://towardsdatascience.com/understanding-the-n-jobs-parameter-to-speedup-scikit-learn-classification-26e3d1220c28?source=collection_archive---------9-----------------------#2021-07-28</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="417c" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">数据分析</h2><div class=""/><div class=""><h2 id="9dc6" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">一个现成的代码，演示了如何使用n_jobs参数来减少训练时间</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/b045dbf773b6cbdf8d40b80fafbcd353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PprW8-w9ieOhDc-ZBCaiaQ.jpeg"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="2291" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">在本教程中，我说明了由<code class="fe mg mh mi mj b">scikit-learn</code>库的一些类提供的<code class="fe mg mh mi mj b">n_jobs</code>参数的重要性。根据官方的<code class="fe mg mh mi mj b">scikit-learn</code>库，<code class="fe mg mh mi mj b">n_jobs</code>参数描述如下:</p><blockquote class="mk ml mm"><p id="d460" class="lk ll mn lm b ln lo kg lp lq lr kj ls mo lu lv lw mp ly lz ma mq mc md me mf ip bi translated">为邻居搜索运行的并行作业的数量。除非在joblib.parallel_backend上下文中，否则None表示1。-1表示使用所有处理器。</p></blockquote><p id="be25" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">这意味着<code class="fe mg mh mi mj b">n_jobs</code>参数可以用来分配和利用本地计算机中所有可用的CPU。</p><p id="9b49" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">在本教程中，我通过将<code class="fe mg mh mi mj b">n_jobs</code>参数从1变化到CPU的最大数量，来评估适应scikit-learn库提供的所有默认分类数据集所需的时间。作为例子，我将尝试一个带有交叉验证的网格搜索的K-Neighbors分类器。</p><h1 id="417e" class="mr ms iw bd mt mu mv mw mx my mz na nb kl nc km nd ko ne kp nf kr ng ks nh ni bi translated">定义辅助变量</h1><p id="694c" class="pw-post-body-paragraph lk ll iw lm b ln nj kg lp lq nk kj ls lt nl lv lw lx nm lz ma mb nn md me mf ip bi translated">首先，我定义了所有分类数据集名称的列表，包含在<a class="ae no" href="https://scikit-learn.org/stable/datasets/toy_dataset.html" rel="noopener ugc nofollow" target="_blank"> sklearn.datasets包</a>中。</p><pre class="kv kw kx ky gu np mj nq nr aw ns bi"><span id="e63c" class="nt ms iw mj b gz nu nv l nw nx">datasets_list = ['iris', 'digits', 'wine', 'breast_cancer','diabetes']</span></pre><p id="d44e" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">然后，我计算系统中可用的CPU数量。我利用了<code class="fe mg mh mi mj b">os</code>包提供的<code class="fe mg mh mi mj b">cpu_count()</code>函数。</p><pre class="kv kw kx ky gu np mj nq nr aw ns bi"><span id="60cf" class="nt ms iw mj b gz nu nv l nw nx">import os<br/>  <br/>n_cpu = os.cpu_count()<br/>print("Number of CPUs in the system:", n_cpu)</span></pre><p id="2d88" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">就我而言。CPU的数量是4 ( <strong class="lm jg">一台相当旧的电脑，唉…我应该决定造一台更新的… </strong>)</p><p id="3691" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我还定义了网格搜索的所有参数。</p><pre class="kv kw kx ky gu np mj nq nr aw ns bi"><span id="ac57" class="nt ms iw mj b gz nu nv l nw nx">import numpy as np<br/>parameters = {  'n_neighbors'   : np.arange(2, 25),<br/>                'weights'       : ['uniform', 'distance'],<br/>                'metric'        : ['euclidean', 'manhattan', <br/>                                   'chebyshev', 'minkowski'],<br/>                'algorithm'     : ['ball_tree', 'kd_tree']<br/>            }</span></pre><h1 id="9990" class="mr ms iw bd mt mu mv mw mx my mz na nb kl nc km nd ko ne kp nf kr ng ks nh ni bi translated">定义主要功能</h1><p id="96e4" class="pw-post-body-paragraph lk ll iw lm b ln nj kg lp lq nk kj ls lt nl lv lw lx nm lz ma mb nn md me mf ip bi translated">现在，我准备定义main函数，它将用于测试训练所用的时间。我导入所有需要的函数和类:</p><pre class="kv kw kx ky gu np mj nq nr aw ns bi"><span id="cfaa" class="nt ms iw mj b gz nu nv l nw nx">from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.datasets import *<br/>import time</span></pre><p id="5f65" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我定义了<code class="fe mg mh mi mj b">load_and_train()</code>函数，它接收数据集名称作为输入。为了加载相应的dataaset，我利用了<code class="fe mg mh mi mj b">globals()</code>函数，它包含一个包含所有导入函数的表。因为我已经导入了scikit-learn提供的所有数据集，所以我可以将函数名传递给<code class="fe mg mh mi mj b">globals()</code>函数。语法是:<code class="fe mg mh mi mj b">globals()[&lt;function_name&gt;]()</code>。</p><pre class="kv kw kx ky gu np mj nq nr aw ns bi"><span id="a529" class="nt ms iw mj b gz nu nv l nw nx">def load_and_train(name):<br/>    dataset = globals()['load_' + name]()<br/>    X = dataset.data<br/>    y = dataset.target</span></pre><p id="dbc6" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">一旦加载了数据集，我就可以构建一个循环，通过改变CPU的数量来遍历CPU的数量并计算训练所用的时间。我构建了一个包含所有运行时间的列表，最终由函数返回。</p><pre class="kv kw kx ky gu np mj nq nr aw ns bi"><span id="a4b4" class="nt ms iw mj b gz nu nv l nw nx">    tdelta_list = []<br/>    for i in range(1, n_cpu+1):<br/>        s = time.time()<br/>        model = KNeighborsClassifier(n_jobs=i)<br/>        clf = GridSearchCV(model, parameters, cv = 10)<br/>        model.fit(X_train, y_train)<br/>        e = time.time()<br/>        tdelta = e - s <br/>        tdelta_list.append({'time' : tdelta, 'bin' : i})<br/>    return tdelta_list</span></pre><h1 id="335c" class="mr ms iw bd mt mu mv mw mx my mz na nb kl nc km nd ko ne kp nf kr ng ks nh ni bi translated">绘图结果</h1><p id="0a3f" class="pw-post-body-paragraph lk ll iw lm b ln nj kg lp lq nk kj ls lt nl lv lw lx nm lz ma mb nn md me mf ip bi translated">最后，我为所有数据集名称调用<code class="fe mg mh mi mj b">load_and_train()</code>函数，并绘制结果。</p><pre class="kv kw kx ky gu np mj nq nr aw ns bi"><span id="c53e" class="nt ms iw mj b gz nu nv l nw nx">import matplotlib.pyplot as plt<br/>import pandas as pd</span><span id="0460" class="nt ms iw mj b gz ny nv l nw nx">for d in datasets_list:<br/>    tdelta_list = load_and_train(d)<br/>    df = pd.DataFrame(tdelta_list)<br/>    plt.plot(df['bin'], df['time'], label=d)<br/>plt.grid()<br/>plt.legend()<br/>plt.xlabel('N Jobs')<br/>plt.ylabel('Time for fit (sec.)')<br/>plt.title('Time for fit VS number of CPUs')<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj nz"><img src="../Images/180ea13dbad6687dfb964d27b00c4916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4gfXbcTAZmr3J_BV3LhK2A.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="d39e" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">对于所有数据集，通过增加作业数量来减少对K近邻分类器执行具有交叉验证的网格搜索所花费的时间。为此，我强烈建议您使用<code class="fe mg mh mi mj b">n_jobs</code>参数。</p><p id="be33" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">具体来说，我建议设置<code class="fe mg mh mi mj b">n_jobs=n_cpus-1</code>，以免机器卡死。</p><h1 id="9007" class="mr ms iw bd mt mu mv mw mx my mz na nb kl nc km nd ko ne kp nf kr ng ks nh ni bi translated">摘要</h1><p id="cb7d" class="pw-post-body-paragraph lk ll iw lm b ln nj kg lp lq nk kj ls lt nl lv lw lx nm lz ma mb nn md me mf ip bi translated">在本教程中，我演示了如何使用<code class="fe mg mh mi mj b">n_jobs</code>参数来加速训练过程。</p><p id="5d4f" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">本教程的完整代码可以从<a class="ae no" href="https://github.com/alod83/data-science/blob/master/DataAnalysis/SpeedUp%20Scikit.ipynb" rel="noopener ugc nofollow" target="_blank">我的Github库</a>下载。</p><p id="4649" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">现在Medium提供了一个新特性，即它允许<strong class="lm jg">构建列表</strong>。<strong class="lm jg">如果您喜欢这篇文章，您可以将其添加到您的收藏列表</strong>，只需点击按钮，放在文章右上角的按钮:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj oa"><img src="../Images/68cfc28fd5ea4c3e0f1d35cb891ff80b.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/0*t_2ScMSERjWn-BUb.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="ff9e" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae no" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae no" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae no" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="bb70" class="mr ms iw bd mt mu mv mw mx my mz na nb kl nc km nd ko ne kp nf kr ng ks nh ni bi translated">相关文章</h1><div class="ob oc gq gs od oe"><a rel="noopener follow" target="_blank" href="/three-tricks-to-speed-up-and-optimise-your-python-d9b5d49d68a6"><div class="of ab fp"><div class="og ab oh cl cj oi"><h2 class="bd jg gz z fq oj fs ft ok fv fx jf bi translated">加快和优化Python的三个技巧</h2><div class="ol l"><h3 class="bd b gz z fq oj fs ft ok fv fx dk translated">关于我在六月份的阅读中发现的三个Python技巧的评论。</h3></div><div class="om l"><p class="bd b dl z fq oj fs ft ok fv fx dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="oo l op oq or on os le oe"/></div></div></a></div><div class="ob oc gq gs od oe"><a rel="noopener follow" target="_blank" href="/how-to-spend-your-time-when-you-are-waiting-for-a-data-analysis-output-e71b383f43cb"><div class="of ab fp"><div class="og ab oh cl cj oi"><h2 class="bd jg gz z fq oj fs ft ok fv fx jf bi translated">当你在等待数据分析结果时，你该如何打发时间</h2><div class="ol l"><h3 class="bd b gz z fq oj fs ft ok fv fx dk translated">当你的计算机正在运行你喜欢的算法，而你正在等待的时候，一些建议不要浪费你的时间…</h3></div><div class="om l"><p class="bd b dl z fq oj fs ft ok fv fx dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="ot l op oq or on os le oe"/></div></div></a></div><div class="ob oc gq gs od oe"><a rel="noopener follow" target="_blank" href="/how-to-speed-up-your-python-code-through-pyspark-e3296e39da6"><div class="of ab fp"><div class="og ab oh cl cj oi"><h2 class="bd jg gz z fq oj fs ft ok fv fx jf bi translated">如何通过PySpark加速您的Python代码</h2><div class="ol l"><h3 class="bd b gz z fq oj fs ft ok fv fx dk translated">关于如何安装和运行Apache Spark和PySpark以提高代码性能的教程。</h3></div><div class="om l"><p class="bd b dl z fq oj fs ft ok fv fx dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="ou l op oq or on os le oe"/></div></div></a></div></div></div>    
</body>
</html>