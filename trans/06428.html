<html>
<head>
<title>Why Using a Dummy Classifier is a Smart Move</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么使用虚拟分类器是明智之举</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-using-a-dummy-classifier-is-a-smart-move-4a55080e3549?source=collection_archive---------11-----------------------#2021-06-09">https://towardsdatascience.com/why-using-a-dummy-classifier-is-a-smart-move-4a55080e3549?source=collection_archive---------11-----------------------#2021-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="df66" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">建立基线，将您的模型性能与虚拟模型进行比较</em></h2></div><p id="e891" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di"> Y </span>你早上醒来，点燃你最喜欢的香味蜡烛，煮些咖啡和早餐，打开Spotify听些果酱，开始新的一天。在享受早晨的例行公事时，你突然有了一个想法:如果有一种方法可以在一首流行歌曲真正流行起来之前准确预测它，会怎么样？</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/008c50a674c58a6aeeb89e8b242a16a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IcxIQWa2Yeq4mFld"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">由<a class="ae mb" href="https://unsplash.com/@denesroland?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">拍摄的罗兰·德内斯</a>在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="9ad3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，像任何其他数据科学家一样，你打开笔记本电脑，从Spotify找到一些数据，在预处理数据后，建立一个随机森林模型。你很快扫了一眼你的初始模型的准确度分数，并不期望它很高——因为，让我们面对它，你什么时候第一次就有过一个伟大的模型——但是，那是什么？</p><pre class="lm ln lo lp gt mc md me mf aw mg bi"><span id="3a2f" class="mh mi iq md b gy mj mk l ml mm">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="cb12" class="mh mi iq md b gy mn mk l ml mm">#building Random Forest model<br/>clf_rf = RandomForestClassifier(random_state=42)<br/>clf_rf.fit(X_train, y_train)</span><span id="c2eb" class="mh mi iq md b gy mn mk l ml mm">#making predictions and printing accuracy score<br/>y_pred = clf_rf.predict(X_test)<br/>print(accuracy_score(y_test, y_pred)) #0.9371</span></pre><p id="52ee" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">哇，准确率高达93.7%！<strong class="ki ir"> </strong>牛逼！嗯…也许不是。当我们查看该模型的混淆矩阵(更多信息见下文)时，我们看到了我们最初期望看到的情况:我们的模型的预测能力没有那么强。该模型只在56%的情况下正确预测了一首流行歌曲，但它正确识别了99%的不受欢迎的歌曲。这就是为什么我们的准确性分数是倾斜的！</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/3c6a4f7b6102ac2924a094bbb349cf3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*1-3_lx9uz1SnwmzU_rk_wg.png"/></div></figure><p id="68c1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">让我们倒回去一分钟……</strong></p><p id="8aea" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">混淆矩阵是什么？它的目的是什么？还有，我们怎么知道56%的人气预测对我们掌握的数据不好？</p><p id="4b25" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">输入虚拟分类器(dun dunnnn…) </strong></p><p id="e3dc" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了能够真正理解并改进我们模型的性能，我们首先需要为我们拥有的数据建立一个基线。毕竟，如果我们不知道我们的模型相对于基线表现如何，我们如何改进它呢？</p><blockquote class="mp"><p id="5096" class="mq mr iq bd ms mt mu mv mw mx my lb dk translated"><em class="kf">“如果你不能衡量它，你就不能改进它”——开尔文爵士</em></p></blockquote><p id="15d3" class="pw-post-body-paragraph kg kh iq ki b kj mz jr kl km na ju ko kp nb kr ks kt nc kv kw kx nd kz la lb ij bi translated">这就是为什么建立一个基线模型，我们可以比较我们的模型的性能是如此重要，这就是虚拟分类器发挥作用的地方。</p><p id="c21b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">什么是虚拟分类器？</strong></p><p id="a1c3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">伪分类器就像它听起来的那样！它是一个分类器模型，无需尝试在数据中寻找模式即可做出预测。默认模型本质上是查看哪个标签在训练数据集中出现频率最高，并基于该标签进行预测。但是，在我们继续构建虚拟分类器之前，我们需要知道如何将手头的模型与虚拟分类器进行比较。</p><p id="a4fb" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">那么，我如何比较我的模型和虚拟分类器呢？</strong></p><p id="150e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们可以查看许多指标和图像来比较我们的模型与基线模型的性能。其中一个指标是准确性得分，这是我们之前兴奋不已的93.7%。</p><p id="0631" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">精度= TP+TN / (TP+FP+TN+FN) </strong></p><p id="49c9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">其他指标包括精确度、召回率和f1分数:</p><p id="7e06" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">精度= TP/(TP+FP) </strong></p><p id="b619" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">回忆= TP/(TP+FN) </strong></p><p id="4d99" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> F1 = 2*(召回率*精度)/(召回率+精度)</strong></p><p id="5e6c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">一般来说，您使用哪个分数取决于您试图回答的问题和您正在处理的数据类型。在这个预测歌曲流行度的例子中，我们主要关心正确识别流行歌曲，因此回忆分数变得更加重要。有关指标的更多信息，请参考此<a class="ae mb" rel="noopener" target="_blank" href="/accuracy-precision-recall-or-f1-331fb37c5cb9">文章</a>。所有这些指标及其组合平均值可从sklearn的分类报告中获得:</p><pre class="lm ln lo lp gt mc md me mf aw mg bi"><span id="f82f" class="mh mi iq md b gy mj mk l ml mm">from sklearn.metrics import classification_report</span></pre><p id="ee50" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">等等，你提到了视觉效果，但我看到的都是分数。你说的是混淆矩阵吗？</strong></p><p id="02cd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">是的。你可以使用的最容易理解的视觉效果之一(我推荐你使用)是混淆矩阵。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/671fb5d20c9119d87a486b1797eb5c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*FO9VGprQbLVN95korgCJbA.jpeg"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图片由memegenerator.net提供</p></figure><p id="201c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">混淆矩阵显示矩阵上模型预测的真阳性(TPs)、假阳性(FPs)、真阴性(TNs)和假阴性(FNs)的原始计数或百分比(您可以根据自己的喜好更改下面的normalize参数)。你可以使用scikit-learn的plot_confusion_matrix来创建这个视觉效果。这是我们初始模型的混淆矩阵:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/3c6a4f7b6102ac2924a094bbb349cf3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*1-3_lx9uz1SnwmzU_rk_wg.png"/></div></figure><p id="fdfe" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">正如我上面提到的，在这里我们可以看到，模型在99%的时间里正确预测了不受欢迎的歌曲(TNs，左上象限)，但对流行歌曲(TPs，右下象限)的预测为56%。</p><p id="3d32" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在我们知道了如何通过使用不同的度量和混淆矩阵来比较我们的模型和虚拟分类器，让我们构建一个虚拟分类器。</p><pre class="lm ln lo lp gt mc md me mf aw mg bi"><span id="1e44" class="mh mi iq md b gy mj mk l ml mm">from sklearn.dummy import DummyClassifier<br/>from sklearn.metrics import plot_confusion_matrix</span><span id="c880" class="mh mi iq md b gy mn mk l ml mm">clf_dummy = DummyClassifier(random_state=42) <br/>#establishing random_state for reproducibility</span><span id="71fd" class="mh mi iq md b gy mn mk l ml mm">clf_dummy.fit(X_train, y_train)<br/>y_pred = clf_dummy.predict(X_test)<br/>plot_confusion_matrix(estimator=clf_dummy, X=X_test, y_true=y_test,<br/>                      normalize=’true’, cmap=’Blues’)</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/586a49e1606dda9bdbe226b4c7f73729.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*Pkz5_tbVBDNAyHtSc4J4tg.png"/></div></figure><p id="06c8" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">好吧，我们的虚拟分类器似乎把我们的大部分数据归类为不受欢迎的。让我们看一下我们的数据的value_counts，看看我们是否能找出为什么会出现这种情况。</p><pre class="lm ln lo lp gt mc md me mf aw mg bi"><span id="5ab8" class="mh mi iq md b gy mj mk l ml mm">y_train.value_counts(normalize=True)</span><span id="a72e" class="mh mi iq md b gy mn mk l ml mm">#0 0.885503<br/>#1 0.114497<br/>#Name: is_popular, dtype: float64</span></pre><p id="a5c8" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">啊哈！在我们的数据集中，冷门歌曲比流行歌曲多得多，所以虚拟分类器预测冷门歌曲比流行歌曲多。</p><p id="e390" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这解释了为什么我们的随机森林分类器在正确识别不受欢迎的歌曲方面如此出色，但在识别流行歌曲方面却不太成功，而这正是我们最终要做的。</p><p id="087f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">那么，我们能做些什么来解决这个问题呢？</strong></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ng"><img src="../Images/0a99d13a5c0ef7631bb9bf7d442bad4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-m5nNWiJyCE4V12g"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">Elena Mozhvilo 在<a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="62d5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">出击救援！这个问题被称为“类不平衡问题”，解决这个问题的一种方法是使用SMOTE进行过采样。本质上，我们使用SMOTE创建与实际数据相似的合成样本来均衡我们的类。但是，因为我们的数据集中有分类列，所以使用SMOTENC会产生更好的结果。</p><pre class="lm ln lo lp gt mc md me mf aw mg bi"><span id="0dfd" class="mh mi iq md b gy mj mk l ml mm">from imblearn.over_sampling import SMOTE, SMOTENC</span><span id="107b" class="mh mi iq md b gy mn mk l ml mm">sm = SMOTENC(categorical_features=cat_cols, random_state=42)<br/>X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)<br/>y_train_sm.value_counts(normalize=True)</span><span id="f339" class="mh mi iq md b gy mn mk l ml mm">#1 0.5<br/>#0 0.5<br/>#Name: is_popular, dtype: float64</span></pre><p id="07df" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">阶级失衡根除了，现在怎么办？</strong></p><p id="9a3a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">完美！既然我们已经解决了类不平衡问题，让我们更新我们的虚拟分类器和随机森林分类器。更新虚拟分类器是必要的，因为我们使用它作为基线；它需要基于与我们所有其他模型相同的精确数据。</p><pre class="lm ln lo lp gt mc md me mf aw mg bi"><span id="440a" class="mh mi iq md b gy mj mk l ml mm">#updating Dummy Classifier with SMOTE’d data<br/>clf_dummy_sm = DummyClassifier(random_state=42)<br/>clf_dummy_sm.fit(X_train_sm, y_train_sm)<br/>y_pred = clf_dummy_sm.predict(X_test)</span><span id="df8c" class="mh mi iq md b gy mn mk l ml mm">#fitting RF Classifier to SMOTE’d data<br/>clf_rf = RandomForestClassifier(random_state=42)<br/>clf_rf.fit(X_train_sm, y_train_sm)<br/>y_pred = clf_rf.predict(X_test)</span></pre><p id="37e1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在，由于虚拟分类器，我们可以真正解释我们的模型的性能。这是并排的新混淆矩阵(左:虚拟分类器，右:随机森林)。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nh"><img src="../Images/30204a45903260e8b13cb71d8bc30a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fDj6cSyWQukcLKs3DaKHfw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">类别不平衡后虚拟分类器(左)和随机森林(右)的混淆矩阵用SMOTENC解决。</p></figure><p id="aaa2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们可以看到，与虚拟分类器相比，随机森林模型在预测不受欢迎的歌曲方面表现出48%的优势，在预测流行歌曲方面表现出8%的优势。似乎我们的随机森林模型过度拟合了(哈！有什么新鲜事？).</p><p id="eb1d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">但是，嘿，回去享受你的早晨吧；您可以调整您的随机森林模型，并在以后尝试一些其他模型！</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><p id="45db" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="np">如果你想查看我在这里作为例子使用的歌曲人气预测项目，你可以在</em><a class="ae mb" href="https://github.com/ebtezcan/dsc-phase-3-project" rel="noopener ugc nofollow" target="_blank"><em class="np">GitHub</em></a><em class="np">上查看。</em></p></div></div>    
</body>
</html>