<html>
<head>
<title>How to Train YOLOX On a Custom Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在自定义数据集上训练YOLOX</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-train-yolox-on-a-custom-dataset-bb2f94cdb038?source=collection_archive---------7-----------------------#2021-08-02">https://towardsdatascience.com/how-to-train-yolox-on-a-custom-dataset-bb2f94cdb038?source=collection_archive---------7-----------------------#2021-08-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/1d319c08041e7c293210ee4379468218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rKo_ZVKC_xDW802149nuRw.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">(<a class="ae kc" href="https://unsplash.com/photos/HynlII1AOkw" rel="noopener ugc nofollow" target="_blank">引用</a>)</p></figure><p id="1539" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">YOLO家族继续发展下一款产品:YOLOX。在本帖中，我们将介绍如何训练YOLOX识别<strong class="kf ir">自定义用例</strong>的对象检测数据。</p><p id="b210" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">出于本教程的目的，我们使用公共血细胞对象检测数据集。但是，您可以将自己的数据导入到Roboflow中，并将其导出以训练该模型来满足自己的需求。本教程使用的<a class="ae kc" href="https://colab.research.google.com/drive/1_xkARB35307P0-BTnqMy0flmYrfoYi5T#scrollTo=igwruhYxE_a7" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> YOLOX笔记本</strong> </a> <strong class="kf ir">可以在</strong> <a class="ae kc" href="https://colab.research.google.com/drive/1_xkARB35307P0-BTnqMy0flmYrfoYi5T#scrollTo=igwruhYxE_a7" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">这里</strong> </a> <strong class="kf ir">下载。</strong></p><p id="8477" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">感谢</em>旷视科技团队<em class="lb">发布了</em> <a class="ae kc" href="https://github.com/Megvii-BaseDetection/YOLOX" rel="noopener ugc nofollow" target="_blank"> <em class="lb">底层知识库</em> </a> <em class="lb">，这构成了我们笔记本的基础。</em></p><p id="7b96" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本指南中，我们采取了以下步骤:</p><ul class=""><li id="7a92" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">安装YOLOX依赖项</li><li id="3e27" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">通过Roboflow下载自定义YOLOX对象检测数据</li><li id="5570" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">下载YOLOX的预训练重量</li><li id="e856" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">运行YOLOX训练</li><li id="a54a" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">评估YOLOX性能</li><li id="7fd8" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">对测试图像运行YOLOX推理</li><li id="abf5" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">导出保存的YOLOX重量以供将来推断</li></ul><p id="70ea" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更喜欢YouTube？</p><figure class="lq lr ls lt gt jr"><div class="bz fp l di"><div class="lu lv l"/></div></figure><h1 id="3cfb" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">YOLOX有什么新功能？</h1><p id="7d0c" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">YOLOX是YOLO模型的最新版本，在速度和准确性方面都达到了极限。YOLOX最近赢得了流媒体感知挑战(CVPR 2021自动驾驶研讨会)。</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/5f722ba62f08c9f9e9220611b65c56c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/0*wQ1elOIkzWq1WuWi.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">相对于其他YOLO检测网络的YOLOX评估</p></figure><p id="8167" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最大的建模变化包括移除盒锚(提高模型到边缘设备的可移植性)和将YOLO检测头解耦到用于盒分类和盒回归的单独特征通道(提高训练收敛时间和模型准确性)。</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/1bcb39b28ceea35183e98accdd80b409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4baJXWpCsfmMo2NY.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://arxiv.org/pdf/2107.08430.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOX </a>中的分离头</p></figure><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/1e777c0c3e755a68fcc674aa59033338.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/0*5SyjPjFCI2HR2Rbf.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="nc">通过</em><a class="ae kc" href="https://arxiv.org/pdf/2107.08430.pdf" rel="noopener ugc nofollow" target="_blank"><em class="nc">YOLOX</em></a><em class="nc">中的历元加快训练时间。我们认为</em><a class="ae kc" href="https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"><em class="nc">yolov 5</em></a><em class="nc">时代更快(我们还没有运行任何直接的面对面测试)</em></p></figure><p id="c145" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">许多其他令人兴奋的训练和推理考虑都包括在论文中。你可以在YOLOX论文或这个视频中更深入地探究。</p><figure class="lq lr ls lt gt jr"><div class="bz fp l di"><div class="lu lv l"/></div></figure><h1 id="55ac" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">安装YOLOX依赖项</h1><p id="1c1c" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">为了设置我们的开发环境，我们将首先克隆基本的YOLOX库并下载必要的需求:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="cac5" class="ni lx iq ne b gy nj nk l nl nm">!git clone https://github.com/roboflow-ai/YOLOX.git %cd YOLOX !pip3 install -U pip &amp;&amp; pip3 install -r requirements.txt !pip3 install -v -e . !pip uninstall -y torch torchvision torchaudio # May need to change in the future if Colab no longer uses CUDA 11.0 !pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f <a class="ae kc" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a></span></pre><p id="a2d3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还将安装NVIDIA Apex和PyCocoTools，以使该存储库按预期工作:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="4bf9" class="ni lx iq ne b gy nj nk l nl nm">%cd /content/ !git clone https://github.com/NVIDIA/apex %cd apex !pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./ !pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</span></pre><h1 id="4475" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">下载自定义YOLOX对象检测数据</h1><p id="8795" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">在我们开始之前，您需要<a class="ae kc" href="https://blog.roboflow.com/p/971d35a0-6b91-4ff9-b7f8-a668fab6624d/app.roboflow.com" rel="noopener ugc nofollow" target="_blank">创建一个Roboflow帐户</a>。我们将使用<a class="ae kc" href="https://public.roboflow.com/object-detection/bccd/" rel="noopener ugc nofollow" target="_blank">这个血细胞数据集</a>，但是欢迎您使用任何数据集，无论是您自己加载到Roboflow的数据集还是其他公共数据集。</p><p id="956b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这个笔记本，我们将需要应用一些预处理步骤来确保数据能够与YOLOX一起工作。首先，<a class="ae kc" href="https://app.roboflow.com/" rel="noopener ugc nofollow" target="_blank">创建一个Roboflow </a>帐户(如果您还没有),然后派生数据集:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/3db6152a755e80f82df04620e2796f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MIvSMW5PFQM207rT.png"/></div></div></figure><p id="7161" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在分叉数据集之后，您将需要添加一个预处理步骤，将所有图像的大小调整为640 x 640:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/1e330c186b44d16c4e5c43aa53a8bf8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a7v99LVf61onH7Nt.PNG"/></div></div></figure><p id="d7e8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后简单地生成数据集的新版本，用“<strong class="kf ir"> Pascal VOC </strong>”导出。您将收到一个类似于以下内容的Jupyter笔记本命令:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/1d36e50525133a970530f1945f0de588.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/0*xEPoH2Xn5phG8nK8.PNG"/></div></figure><p id="f54e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">复制该命令，并用Roboflow提供的命令替换笔记本中的下面一行:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="d4e6" class="ni lx iq ne b gy nj nk l nl nm">!curl -L "[YOUR LINK HERE]" &gt; roboflow.zip; unzip roboflow.zip; rm roboflow.zip</span></pre><h1 id="f6ae" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">标注您的数据</h1><p id="58d6" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">如果你有自己的数据集，你可以在Roboflow 中标注<a class="ae kc" href="https://docs.roboflow.com/annotate" rel="noopener ugc nofollow" target="_blank">你的图像。</a></p><h1 id="a28b" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">下载YOLOX的预训练重量</h1><p id="2f48" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">YOLOX带有一些预训练的权重，以允许模型更快地训练并实现更高的精度。砝码有多种尺寸，但我们使用的砝码尺寸将基于小型YOLOX型号(YOLOX_S)。我们可以按如下方式下载:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="7fbf" class="ni lx iq ne b gy nj nk l nl nm">%cd /content/ !wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth %cd /content/YOLOX/</span></pre><h1 id="99be" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">运行YOLOX训练</h1><p id="7bff" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">为了训练模型，我们可以运行<code class="fe nq nr ns ne b">tools/train.py</code>文件:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="5879" class="ni lx iq ne b gy nj nk l nl nm">!python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 1 -b 16 --fp16 -o -c /content/yolox_s.pth</span></pre><p id="da7c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行该命令的参数包括:</p><ul class=""><li id="2186" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">经验文件:该文件允许我们在培训时更改基础模型的某些方面</li><li id="d9c4" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">设备:我们的模型将训练的GPU数量— 1是Colab提供的值1</li><li id="c79d" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">批量大小:每批图像的数量</li><li id="d0a7" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">预训练权重:指定您想要使用的权重的路径-这可以是我们下载的权重或您的模型的早期检查点</li></ul><p id="817a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经过大约90个时代的训练，我们得到了以下AP。</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nt"><img src="../Images/ac38747d530724776f2c43f3ce239662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ly3RRIxm1U2ZUtuf.PNG"/></div></div></figure><h1 id="ae8d" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">评估YOLOX性能</h1><p id="2464" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">要评估YOLOX的性能，我们可以使用以下命令:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="bcec" class="ni lx iq ne b gy nj nk l nl nm">MODEL_PATH = "/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar" !python3 tools/eval.py -n yolox-s -c {MODEL_PATH} -b 64 -d 1 --conf 0.001 -f exps/example/yolox_voc/yolox_voc_s.py</span></pre><p id="2dba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行评估后，我们得到以下结果:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/54a24d17ebc9d996e7c004f7762622ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6s3pPQMXyGsd0JEd.PNG"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">YOLOX模型的评估</p></figure><p id="989e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">性能看起来不错！</p><h1 id="8ebe" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">对测试图像运行YOLOX推理</h1><p id="5911" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">我们现在可以在测试图像上运行YOLOX并可视化预测。要在测试映像上运行YOLOX:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="3b2b" class="ni lx iq ne b gy nj nk l nl nm">TEST_IMAGE_PATH = "/content/valid/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg" !python tools/demo.py image -f /content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py -c {MODEL_PATH} --path {TEST_IMAGE_PATH} --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu</span></pre><p id="16d8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要在图像上可视化预测:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="d2b1" class="ni lx iq ne b gy nj nk l nl nm">from PIL import Image OUTPUT_IMAGE_PATH = "/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_07_31_00_31_01/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg" Image.open(OUTPUT_IMAGE_PATH)</span></pre><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/80d009346c1fed600f3fe7359fbe7404.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*oy3rNTrfOXJYuZoU.png"/></div></figure><p id="dd9e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看起来模型像预期的那样工作！</p><h1 id="44d8" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">导出保存的YOLOX重量以供将来推断</h1><p id="6e6a" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">最后，我们可以将模型导出到我们的Google Drive，如下所示:</p><pre class="lq lr ls lt gt nd ne nf ng aw nh bi"><span id="8e90" class="ni lx iq ne b gy nj nk l nl nm">from google.colab import drive drive.mount('/content/gdrive') %cp {MODEL_PATH} /content/gdrive/My\ Drive</span></pre><h1 id="d6f6" class="lw lx iq bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">结论</h1><p id="f025" class="pw-post-body-paragraph kd ke iq kf b kg mu ki kj kk mv km kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">YOLOX是一个令人难以置信的强大，最先进的对象检测模型。在本教程中，您可以学习如何:</p><ul class=""><li id="6779" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">准备YOLOX环境</li><li id="939b" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">使用Roboflow下载自定义对象检测数据</li><li id="692b" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">运行YOLOX培训流程</li><li id="8312" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">使用你训练过的YOLOX模型进行推理</li><li id="1a1f" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">将您的模型导出到Google Drive</li></ul><p id="9e76" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">快乐训练！</p></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="29af" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">原载于2021年8月2日</em><a class="ae kc" href="https://blog.roboflow.com/how-to-train-yolox-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"><em class="lb">【https://blog.roboflow.com】</em></a><em class="lb">。</em></p></div></div>    
</body>
</html>