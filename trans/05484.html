<html>
<head>
<title>Optimising your input pipeline performance with tf.data (part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用tf.data优化输入管道性能(第1部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimising-your-input-pipeline-performance-with-tf-data-part-1-32e52a30cac4?source=collection_archive---------6-----------------------#2021-05-15">https://towardsdatascience.com/optimising-your-input-pipeline-performance-with-tf-data-part-1-32e52a30cac4?source=collection_archive---------6-----------------------#2021-05-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2fb2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">提高您的输入管道效率和GPU利用率</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/eb02dbfedaf0b3562ed81d7cd35c1aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MGnZcLQgjXAy7tA88YvZSg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Tensorflow徽标。来源:<a class="ae kv" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/</a></p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="4016" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">tf.data的概念</h1><blockquote class="lv lw lx"><p id="f5d7" class="ly lz ma mb b mc md jr me mf mg ju mh mi mj mk ml mm mn mo mp mq mr ms mt mu ij bi translated">API使您能够从简单的、可重用的部分构建复杂的输入管道。<code class="fe mv mw mx my b">tf.data</code>也使处理大量数据成为可能，从不同的数据格式中读取，并执行复杂的转换</p></blockquote><p id="af81" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">要知道GPU和TPU可以显著减少训练一个模型所需的时间，这并不是什么大事情。然而，作为一名深度学习开发者，最糟糕的事情之一是看到你的GPU能力没有得到充分利用，CPU上的瓶颈——特别是如果你在不同的云平台上为这些服务支付大量资金。</p><p id="e5a3" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">因此，确保我们的输入管道实现最佳性能和效率至关重要。<code class="fe mv mw mx my b">tf.data</code> API直接处理这个问题——这也是我如此喜欢它的原因。</p><p id="744f" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">在这篇第1部分文章中，我将解释关于<code class="fe mv mw mx my b">tf.data</code>如何实现最佳行为的不同概念，在第2部分，我将比较<code class="fe mv mw mx my b">tf.data</code>和Keras <code class="fe mv mw mx my b">ImageDataGenerator</code>读取输入数据的性能。</p><p id="4854" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated"><code class="fe mv mw mx my b">tf.data</code>有几种方法可以降低计算开销，这些方法很容易在您的管道中实现:</p><ul class=""><li id="b628" class="nc nd iq mb b mc md mf mg mz ne na nf nb ng mu nh ni nj nk bi translated">预取</li><li id="9a12" class="nc nd iq mb b mc nl mf nm mz nn na no nb np mu nh ni nj nk bi translated">并行数据提取</li><li id="bc37" class="nc nd iq mb b mc nl mf nm mz nn na no nb np mu nh ni nj nk bi translated">并行数据转换</li><li id="7966" class="nc nd iq mb b mc nl mf nm mz nn na no nb np mu nh ni nj nk bi translated">贮藏</li><li id="d454" class="nc nd iq mb b mc nl mf nm mz nn na no nb np mu nh ni nj nk bi translated">矢量化映射</li></ul><h1 id="58c7" class="ld le iq bd lf lg nq li lj lk nr lm ln jw ns jx lp jz nt ka lr kc nu kd lt lu bi translated">天真的方法</h1><p id="a664" class="pw-post-body-paragraph ly lz iq mb b mc nv jr me mf nw ju mh mz nx mk ml na ny mo mp nb nz ms mt mu ij bi translated">在我们开始这些概念之前，我们必须首先理解当一个模型被训练时，朴素方法是如何工作的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/2a1623ddfe9248c7e530f49f7fbc36c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*NlsHwaUrEsGII-o4LAVWsQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">天真的方法。来源:<a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/data_performance</a></p></figure><p id="92f0" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">此图显示训练步骤包括打开文件、从文件中获取数据条目，然后使用数据进行训练。我们可以在这里看到明显的低效率，因为当我们的模型正在训练时，输入管道是空闲的，而当输入管道正在获取数据时，我们的模型是空闲的。</p><p id="91c6" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated"><code class="fe mv mw mx my b">tf.data</code>通过使用<code class="fe mv mw mx my b">prefetching</code>解决了这个问题。</p><h1 id="7925" class="ld le iq bd lf lg nq li lj lk nr lm ln jw ns jx lp jz nt ka lr kc nu kd lt lu bi translated">预取</h1><p id="7935" class="pw-post-body-paragraph ly lz iq mb b mc nv jr me mf nw ju mh mz nx mk ml na ny mo mp nb nz ms mt mu ij bi translated">预取解决了天真方法的低效率，因为它旨在重叠训练步骤的预处理和模型执行。换句话说，当模型执行训练步骤n时，输入管道将读取步骤n+1的数据。</p><blockquote class="lv lw lx"><p id="1f0b" class="ly lz ma mb b mc md jr me mf mg ju mh mi mj mk ml mm mn mo mp mq mr ms mt mu ij bi translated"><code class="fe mv mw mx my b">tf.data</code> API提供了<code class="fe mv mw mx my b">tf.data.Dataset.prefetch</code>转换。它可用于将数据产生的时间与数据消耗的时间分离开来。特别是，转换使用后台线程和内部缓冲区在请求元素之前从输入数据集中预取元素。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/efd4617f3e8b7b02fb80b414f8a0d6e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*PISwE0ow6bjhlNME_Uq6Yw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预取。来源:https://www.tensorflow.org/guide/data_performance<a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="d315" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">有一种观点认为预取转换需要预取的元素数量。然而，我们可以简单地利用tensorflow提供的<code class="fe mv mw mx my b">tf.data.AUTOTUNE</code>，它提示<code class="fe mv mw mx my b">tf.data</code> runtime在运行时动态地调整值。</p><h1 id="9b96" class="ld le iq bd lf lg nq li lj lk nr lm ln jw ns jx lp jz nt ka lr kc nu kd lt lu bi translated">并行数据提取</h1><p id="8c56" class="pw-post-body-paragraph ly lz iq mb b mc nv jr me mf nw ju mh mz nx mk ml na ny mo mp nb nz ms mt mu ij bi translated">在读取数据时将原始字节加载到内存中会产生计算开销，因为可能需要对读取的数据进行反序列化和解密。无论数据是存储在本地还是远程，都存在这种开销。</p><blockquote class="lv lw lx"><p id="9db9" class="ly lz ma mb b mc md jr me mf mg ju mh mi mj mk ml mm mn mo mp mq mr ms mt mu ij bi translated">为了处理这种开销，<code class="fe mv mw mx my b">tf.data</code>提供了<code class="fe mv mw mx my b">tf.data.Dataset.interleave</code>转换来并行数据加载步骤，交错其他数据集的内容。</p></blockquote><p id="af90" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">类似地，这种交错转换支持<code class="fe mv mw mx my b">tf.data.AUTOTUNE</code>，它将在<code class="fe mv mw mx my b">tf.data</code>运行时再次委托并行级别的决策。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/cca60b790ed56e2a35e276b25239e25a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*Amms5OWLomjOe0MJnnQpJw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">顺序交错。来源:https://www.tensorflow.org/guide/data_performance</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/26d0675bf95cced9fbd3c4c756e7b638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*JGSJ-Ax35uNHAQ9kQeSdQw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">并行交错。来源:https://www.tensorflow.org/guide/data_performance<a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="f574" class="ld le iq bd lf lg nq li lj lk nr lm ln jw ns jx lp jz nt ka lr kc nu kd lt lu bi translated">并行数据转换</h1><p id="0220" class="pw-post-body-paragraph ly lz iq mb b mc nv jr me mf nw ju mh mz nx mk ml na ny mo mp nb nz ms mt mu ij bi translated">在大多数情况下，在将数据集传递给模型进行训练之前，您必须对数据集进行一些预处理。<code class="fe mv mw mx my b">tf.data</code> API通过提供<code class="fe mv mw mx my b">tf.data.Dataset.map</code>转换来解决这一问题，该转换将用户定义的函数应用于输入数据集的每个元素。</p><blockquote class="lv lw lx"><p id="405e" class="ly lz ma mb b mc md jr me mf mg ju mh mi mj mk ml mm mn mo mp mq mr ms mt mu ij bi translated">由于输入元素相互独立，预处理可以在多个CPU内核上并行进行。</p></blockquote><p id="c56b" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">要利用多个CPU内核，您必须传入<code class="fe mv mw mx my b">num_parallel_calls</code>参数来指定您想要的并行级别。类似地，map转换也支持<code class="fe mv mw mx my b">tf.data.AUTOTUNE</code>，它将在<code class="fe mv mw mx my b">tf.data</code>运行时再次委托并行级别的决策。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/94ebf38f309600ec03192bc69f26eb35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*Sbk_IxtsPuUTCV9yQq1ZBA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">天真的映射。来源:<a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/data_performance</a></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/9a35220322ef674545370757193aa713.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*eKf7t8tUgZFIsmxNvuQA0w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">平行映射。来源:<a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/data_performance</a></p></figure><h1 id="67c8" class="ld le iq bd lf lg nq li lj lk nr lm ln jw ns jx lp jz nt ka lr kc nu kd lt lu bi translated">贮藏</h1><p id="8323" class="pw-post-body-paragraph ly lz iq mb b mc nv jr me mf nw ju mh mz nx mk ml na ny mo mp nb nz ms mt mu ij bi translated"><code class="fe mv mw mx my b">tf.data</code>还拥有<code class="fe mv mw mx my b">tf.data.Dataset.cache</code>转换的缓存能力。您可以在内存或本地存储中缓存数据集。经验法则是在内存中缓存小数据集，在本地存储中缓存大数据集。这样就避免了像文件打开和数据读取这样的操作在每个时期被执行——下一个时期将重用由<code class="fe mv mw mx my b">cache</code>转换缓存的数据。</p><p id="efc1" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">需要注意的一点是，您应该在预处理之后(尤其是当这些预处理函数计算量很大时)和增强之前进行缓存，因为您不希望存储任何来自增强的随机性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/31b6eb5fcd8cf69f73805d1a403dfb5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*Jt3WrFTO22qmKoj-eKO5xA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">缓存。来源:https://www.tensorflow.org/guide/data_performance<a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="5a21" class="ld le iq bd lf lg nq li lj lk nr lm ln jw ns jx lp jz nt ka lr kc nu kd lt lu bi translated">矢量化映射</h1><p id="8070" class="pw-post-body-paragraph ly lz iq mb b mc nv jr me mf nw ju mh mz nx mk ml na ny mo mp nb nz ms mt mu ij bi translated">当使用前面“并行化数据转换”中提到的<code class="fe mv mw mx my b">tf.data.Dataset.map</code>转换时，会有一些与调度和执行用户定义函数相关的开销。向量化这个用户定义的函数——让它一次对一批输入进行操作——并在<code class="fe mv mw mx my b">map</code>转换之前应用<code class="fe mv mw mx my b">batch</code>转换有助于改善这种开销。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1cb11a3c85b93545f3d052ab3e9d9bf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*wOa4Zv3S_bpZL4eLtBqH1g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">批处理前映射。来源:https://www.tensorflow.org/guide/data_performance</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/0eb6479f161379d3fd7611dcfa9a779c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*WwyRAkR305Tt-q0uN0FHqg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">批处理后映射。来源:https://www.tensorflow.org/guide/data_performance<a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="3267" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">从图中可以看出，开销只出现一次，从而提高了整体时间性能。因此，与对每个样本调用<code class="fe mv mw mx my b">map</code>转换相比，对一批样本调用<code class="fe mv mw mx my b">map</code>转换具有更好的性能。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="13a8" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">最后</h1><p id="009b" class="pw-post-body-paragraph ly lz iq mb b mc nv jr me mf nw ju mh mz nx mk ml na ny mo mp nb nz ms mt mu ij bi translated"><code class="fe mv mw mx my b">tf.data</code>tensor flow充分考虑了输入管道的性能，采用多种方式优化效率。</p><p id="00c1" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">总之，您可以使用<code class="fe mv mw mx my b">prefetch</code>转换来重叠管道(生产者)和模型(消费者)所做的工作，使用<code class="fe mv mw mx my b">interleave</code>转换来并行化数据读取，使用<code class="fe mv mw mx my b">map</code>转换来并行化数据转换，使用<code class="fe mv mw mx my b">cache</code>转换来在内存或本地存储中缓存数据，并且使用<code class="fe mv mw mx my b">batch </code>转换来矢量化您的<code class="fe mv mw mx my b">map</code>转换。</p><p id="1e87" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">正如开始时提到的，最糟糕的事情之一是看到你的GPU能力没有被充分利用，CPU上的瓶颈。有了<code class="fe mv mw mx my b">tf.data</code>，你很可能会对你的GPU利用率感到满意！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/60d375745fbffcf0883caa45f6afb3e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*xpgeqRfpvzXave2_ZHWDdg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GPU利用率。来源:来自本地机器的截图</p></figure><p id="e8c0" class="pw-post-body-paragraph ly lz iq mb b mc md jr me mf mg ju mh mz mj mk ml na mn mo mp nb mr ms mt mu ij bi translated">在第2部分中，我将演示如何将<code class="fe mv mw mx my b">tf.data</code>用于您的输入管道，并测量<code class="fe mv mw mx my b">tf.data</code>和Keras <code class="fe mv mw mx my b">ImageDataGenerator</code>之间的性能</p><div class="oj ok gp gr ol om"><a rel="noopener follow" target="_blank" href="/optimising-your-input-pipeline-performance-with-tf-data-part-2-9ee406451f93"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd ir gy z fp or fr fs os fu fw ip bi translated">使用tf.data优化输入管道性能(第2部分)</h2><div class="ot l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz kp om"/></div></div></a></div><h1 id="e5b6" class="ld le iq bd lf lg nq li lj lk nr lm ln jw ns jx lp jz nt ka lr kc nu kd lt lu bi translated">资源</h1><ol class=""><li id="9348" class="nc nd iq mb b mc nv mf nw mz pa na pb nb pc mu pd ni nj nk bi translated"><a class="ae kv" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/data_performance</a></li></ol></div></div>    
</body>
</html>