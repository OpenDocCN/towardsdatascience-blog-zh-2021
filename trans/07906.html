<html>
<head>
<title>Transfer learning with XGBoost and PyTorch: Hack Alexnet for MNIST dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用XGBoost和PyTorch进行迁移学习:破解Alexnet for MNIST数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-with-xgboost-and-pytorch-hack-alexnet-for-mnist-dataset-51c823ed11cd?source=collection_archive---------12-----------------------#2021-07-20">https://towardsdatascience.com/transfer-learning-with-xgboost-and-pytorch-hack-alexnet-for-mnist-dataset-51c823ed11cd?source=collection_archive---------12-----------------------#2021-07-20</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><figure class="gl gn jt ju jv jw gh gi paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="gh gi js"><img src="../Images/208c39694ea5e973ae372079ae08f617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vPFAkEV55vjUNBhX"/></div></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">马修·施瓦茨在<a class="ae kh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="ki kj kk"><p id="0998" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj io bi translated"><strong class="ko iw">更新</strong>:发现我关于渐变提升的新书<a class="ae kh" href="https://www.amazon.fr/dp/B0BJ82S916" rel="noopener ugc nofollow" target="_blank">实用渐变提升</a>。这是用python中的许多例子对渐变增强的深入探究。</p></blockquote><div class="lk ll gp gr lm ln"><a href="https://www.amazon.com/dp/B0BJ82S916" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab fo"><div class="lp ab lq cl cj lr"><h2 class="bd iw gy z fp ls fr fs lt fu fw iu bi translated">实用的渐变增强:深入探究Python中的渐变增强</h2><div class="lu l"><h3 class="bd b gy z fp ls fr fs lt fu fw dk translated">这本书的梯度推进方法是为学生，学者，工程师和数据科学家谁希望…</h3></div><div class="lv l"><p class="bd b dl z fp ls fr fs lt fu fw dk translated">www.amazon.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb kb ln"/></div></div></a></div><p id="8314" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">在处理深度学习时，训练一个模型总是很复杂:不仅是一项耗时且成本高昂的任务，还需要非常大的数据集。微调模型架构也相当繁琐，使用超参数调整/ AutoML仍然是一个开放的计算耗时的主题。</p><p id="8c51" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">希望有另一种选择:迁移学习。这种技术允许在新用例中重用预先训练好的模型，避免昂贵的培训。</p><p id="629c" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">在本文中，我们将展示如何将<a class="ae kh" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> XGBoost </em> </a>和<a class="ae kh" href="http://www.pytorch.org" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>结合起来，将<em class="kn"> Alexnet </em>获得的知识转移到一个新的应用程序中。</p></div><div class="ab cl mf mg hz mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="io ip iq ir is"><p id="3c4f" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">最初，Alexnet在1000个类别的子集上接受了ImageNet大规模视觉识别挑战(ILSVRC)的培训。给定一幅图像，这个网络能够将其分类到1000个类别中的一个。这些课程的完整列表可以在<a class="ae kh" href="https://gist.github.com/kayhman/8bb7bcc4563cf33664d9b03bb942acda" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="068d" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">原文值得一读，可以在这里找到<a class="ae kh" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="8528" class="mm mn iv bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">使用Alexnet</h1><p id="ff10" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">在转移Alexenet深度神经网络训练获得的知识之前，我们要提醒自己如何使用它。</p><p id="07af" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">让我们回忆一下，Alexenet是一个深度卷积网络，有5个卷积层和3个用于功能部分的池层。该分类使用3个密集层。Alex Krizhevsky带来的创新是为了证明网络的深度对表演至关重要。这是通过设计一种新的算法在GPU上运行训练来实现的。</p><p id="1d1f" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">我们将把这种预先训练好的架构应用到以下照片中，这些照片是在Unsplash上随机挑选的:</p><div class="lk ll gp gr lm ln"><a href="https://unsplash.com/photos/Sg3XwuEpybU" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab fo"><div class="lp ab lq cl cj lr"><h2 class="bd iw gy z fp ls fr fs lt fu fw iu bi translated">照片由理查德·布鲁图在Unsplash上拍摄</h2><div class="lu l"><h3 class="bd b gy z fp ls fr fs lt fu fw dk translated">下载这张由理查德·布鲁约(@richardbrutyo)拍摄的狗、动物、宠物和寻回犬的免费高清照片</h3></div><div class="lv l"><p class="bd b dl z fp ls fr fs lt fu fw dk translated">unsplash.com</p></div></div><div class="lw l"><div class="np l ly lz ma lw mb kb ln"/></div></div></a></div><p id="3555" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">多亏了<a class="ae kh" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> pytorch </a>，这可以用几行python代码完成:</p><figure class="nq nr ns nt gt jw"><div class="bz fp l di"><div class="nu nv l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">这几行代码加载图像并使用Alexnet对其进行分类。作者代码。</p></figure><p id="09a2" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">多亏了Pytorch，我们只需一行代码就可以访问预先训练好的模型。多方便啊！</p><p id="7f27" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">Alexnet的输出是一个1000维的概率数组，即类的数量。该列表将前5名列为最佳标签。</p><p id="166a" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">正如你在这段代码的最后一行看到的，深度神经网络识别图像，并使用狗的名字正确地标记它。注意<em class="kn">变换</em>函数，用于缩放输入图像并将其转换为PyTorch张量。</p><h1 id="abec" class="mm mn iv bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">转移Alexnet学习</h1><p id="9480" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">迁移学习的思想是将在深度神经网络(或任何其他类型的模型)的训练期间获得的知识应用于试图解决给定问题的另一个问题。</p><p id="e718" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">在Alexnet的情况下，该网络已经学会对ImageNet大规模视觉识别挑战(ILSVRC)的图像进行分类。如上所述，网络输出是1000个类别中每一个的概率数组。</p><p id="1617" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">为了执行这种分类，Alexnet使用与3个池层交织的5个卷积层来计算特征。该层堆栈的输出被送入3个密集层，以执行分类并生成最终的1000个概率。</p><p id="47bd" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">我们在这里想要做的是访问特征部分的输出，并从它的知识中获益。</p><p id="6c30" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">我们在本文中想要验证的假设是，为分类器训练的深度卷积神经网络足够通用，可以应用于另一个问题。</p><p id="c545" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">此外，出于兴趣和利益，我们将使用XGBoost替换密集神经网络分类器。</p><h1 id="e104" class="mm mn iv bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">入侵Alexnet来识别数字</h1><p id="83b8" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">为了验证我们的假设，<a class="ae kh" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>是一个非常好的候选者。这是Yann Lecunn广泛用于建立分类器以识别手写数字的数据库之一。再一次，<a class="ae kh" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>简化了我们的工作，因为它提供了对MNIST数据集的便捷访问。</p><p id="7c4c" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">该数据集包含60 000个数字，它们的标签在训练集中，另外10 000个标记的数字用于测试集。每个数字存储为灰度28x28图像。因此，我们不能将它们直接输入Alexnet。这将是必要的重新调整他们，并将其转换为RGB。</p><p id="cca2" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">在这一步，现在可以使用非常方便的<em class="kn"> extract_features </em>方法将图像输入Alexnet并获取特征。</p><p id="46d8" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">最后，由于我们计划使用XGBoost作为分类器，我们需要将输出存储为CSV文件，该文件可以作为Pandas Dataframe轻松加载。</p><p id="9cb5" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">所有这些转换都由下面的python清单处理:</p><figure class="nq nr ns nt gt jw"><div class="bz fp l di"><div class="nu nv l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">这个脚本对图像进行预处理，并将它们传送到Alexnet，这样我们就可以得到图像的特征。作者代码。</p></figure><p id="e10c" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">运行这个脚本会生成一个csv文件，其中每一行都包含给定数字的所有特征及其标签。我们所要做的就是用这些数据装配一个xgb分类器。预处理测试数据需要一个类似的脚本。</p><p id="2d6d" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">因为有大量的样本和特征，所以可以根据这些数据的子集进行训练，比如说10 000个样本。下面是如何做到这一点:</p><figure class="nq nr ns nt gt jw"><div class="bz fp l di"><div class="nu nv l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">从预处理数据中编写脚本训练XGBClassifier。作者代码。</p></figure><p id="81f3" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">最后几行远远没有给出该模型的完整评估，而是倾向于表明将来自深度神经网络和XGB分类器的预先学习的知识相结合是可行的。</p><p id="2d98" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">注意，由于训练可能需要一些时间，我们使用<em class="kn"> joblib </em>将模型存储为pkl。因此，在进行评估时，我们可以轻松地重新加载它。</p><p id="f694" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">下面几行更准确地评估了这个模型:</p><figure class="nq nr ns nt gt jw"><div class="bz fp l di"><div class="nu nv l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">评估模型性能。作者代码</p></figure><p id="8d7c" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">如混淆矩阵和分类报告所示，分类确实不错。</p><p id="71c2" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">我们也许可以做得更好，在XGB分类器上使用超参数调整，但它已经相当不错了。</p></div><div class="ab cl mf mg hz mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="io ip iq ir is"><h1 id="495b" class="mm mn iv bd mo mp nw mr ms mt nx mv mw mx ny mz na nb nz nd ne nf oa nh ni nj bi translated">结论</h1><p id="5b6b" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">重用预先训练好的模型是构建新模型的一种非常有效的方式，而没有执行完整训练的负担:收集数据、调整模型、训练模型、评估模型等等。所有这些步骤都可以通过迁移学习来避免。</p><p id="408e" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">我们还展示了结合不同类型的模型，利用它们各自的优势是可能的。这里，例如XGBoost是一种非常好的基于深度神经网络输出执行分类的方法。PyTorch非常适合操纵神经网络部分。</p><p id="6077" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">为了进一步说明这个例子，最好从卷积网络的第一层提取特征，看看学习如何从这些中间层转移。</p></div></div>    
</body>
</html>