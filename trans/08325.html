<html>
<head>
<title>Using fastai callbacks for efficient model training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用fastai回调进行高效的模型训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-fastai-callbacks-for-efficient-model-training-cb03160a5f17?source=collection_archive---------21-----------------------#2021-07-31">https://towardsdatascience.com/using-fastai-callbacks-for-efficient-model-training-cb03160a5f17?source=collection_archive---------21-----------------------#2021-07-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/fa5ddc3fede4b88942eab04c368d2e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lEzw9HFoTpcyWSbsrLAAEg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图像快门库</p></figure><div class=""/><div class=""><h2 id="791e" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">利用提前停止和模型保存回调的力量</h2></div><p id="c18f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">当你训练一个深度学习模型时，你想从你用来训练模型的资源中获得最大的收益。如果你使用像Paperspace Gradient这样的按小时付费的环境，时间就是金钱。如果你能在更短的时间内训练出你的模型，你就能省钱。即使你正在使用Colab，并且计价器没有运行，你自己的时间仍然是宝贵的，所以知道如何最大限度地利用你可用的时间和能力来训练你的深度学习模型是值得的。在本文中，我将描述两个回调，你可以在fastai中使用它们来确保你的模型训练尽可能高效。我在本文中描述的例子在我的Packt book<a class="ae lt" href="https://www.amazon.com/Deep-Learning-fastai-Cookbook-easy/dp/1800208103/ref=sr_1_1?dchild=1&amp;keywords=%22deep+learning+with+fastai+cookbook%22&amp;qid=1627678139&amp;sr=8-1" rel="noopener ugc nofollow" target="_blank">Deep Learning with fastai Cookbook</a>中有更详细的解释。</p><h2 id="5c0b" class="lu lv ji bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">训练深度学习模型的两个问题</h2><p id="1238" class="pw-post-body-paragraph kx ky ji kz b la mn kj lc ld mo km lf lg mp li lj lk mq lm ln lo mr lq lr ls im bi translated">fastai与Keras有一个共同的特点，Keras是另一个常用的深度学习高级框架。在这两个框架中，模型训练过程不是开箱即用的。默认情况下，模型训练过程存在以下问题:</p><ol class=""><li id="7b14" class="ms mt ji kz b la lb ld le lg mu lk mv lo mw ls mx my mz na bi translated">训练过程将按照您在fit语句中指定的次数继续进行，即使您想要优化的指标不再改进。</li><li id="fdb7" class="ms mt ji kz b la nb ld nc lg nd lk ne lo nf ls mx my mz na bi translated">您在训练过程结束时获得的模型具有来自最后一个时期的权重，即使存在其权重会导致模型具有更好性能的更早时期。</li></ol><p id="61e6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">幸运的是，fastai和Keras都以<strong class="kz jj">回调</strong>的形式包含了这两个问题的解决方案。在本文的剩余部分，我将解释fastai中的这些回调。关于如何使用回调来控制Keras中的模型训练过程的类似描述，请参见我的曼宁著作<a class="ae lt" href="https://www.amazon.com/Deep-Learning-Structured-Data-Mark/dp/1617296724/ref=sr_1_1?dchild=1&amp;keywords=%22deep+learning+with+structured+data%22&amp;qid=1627678682&amp;sr=8-1" rel="noopener ugc nofollow" target="_blank">的第6章“结构化数据深度学习</a>”。</p><h2 id="db8e" class="lu lv ji bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">基线:在没有回调的情况下训练模型</h2><p id="46e2" class="pw-post-body-paragraph kx ky ji kz b la mn kj lc ld mo km lf lg mp li lj lk mq lm ln lo mr lq lr ls im bi translated">为了查看fastai回调的影响，我们将从训练一个没有回调的模型开始。该模型在fastai策划的数据集ADULT_SAMPLE上进行训练，该数据集包含个人的详细信息，如受教育年限、婚姻状况和职业类别。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ng"><img src="../Images/28975b5737048986c8923ce4792261d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XAmAmFWUokQxbeb6L5ZmTg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">成人_样本数据集</p></figure><p id="87b4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">在成人样本数据集上训练的模型的目标是预测给定个人的工资是高于还是低于50 k。</p><p id="c9a7" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们首先训练没有回调的模型:</p><figure class="nh ni nj nk gt iv"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="f96b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">请注意对set_seed()的调用。我们这样做是为了在不同的训练运行之间的每个时期获得一致的结果。这使我们能够在训练运行之间进行比较，并强调回调的影响。如果我们不调用set_seed()，我们将在运行之间得到不一致的结果。例如，历元2上的精度对于每次训练运行将是不同的。</p><p id="2c97" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">以下是应用于不带回调的学习者对象的fit语句的输出:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/e0e63805d1f6bc834a87125c76e77733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*oIUe4uMVlZ2KJQe1n2cmww.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">没有回调的基线的fit语句的输出</p></figure><p id="4ce0" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">精确度增加到时段2，然后在时段3下降，并在剩余时段振荡直到时段9。当我们对学习者对象运行validate()时:</p><pre class="nh ni nj nk gt no np nq nr aw ns bi"><span id="35e5" class="lu lv ji np b gy nt nu l nv nw">learn.validate()</span></pre><p id="5a90" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">输出显示，在训练运行结束时，训练模型的精度是历元9:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e1a6eb1847e7f3b5f35fbcd7212c034f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*dnY3BHpfHiISJ1gCdrEZVA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不带回调的模型的validate()输出</p></figure><p id="448e" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">由于没有回调，我们遇到了本文开头提到的两个问题:在模型停止改进之后，训练运行继续进行，并且从训练运行中出来的经过训练的模型的性能比在训练运行期间看到的最佳性能差。</p><h2 id="80c9" class="lu lv ji bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">添加提前停止回调，以便在模型性能停止提高时停止训练运行</h2><p id="5b31" class="pw-post-body-paragraph kx ky ji kz b la mn kj lc ld mo km lf lg mp li lj lk mq lm ln lo mr lq lr ls im bi translated">现在我们已经建立了一个没有回调的基线，让我们添加一个早期停止回调，以便在模型性能停止提高时停止训练运行。</p><p id="bdad" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们将使用用于训练基线模型的相同的dataloaders对象，但是这一次我们将在fit语句中指定一个早期停止回调:</p><figure class="nh ni nj nk gt iv"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="6ef1" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">fit语句的输出现在显示，尽管指定了10个时期，但是训练运行只进行到时期5。耐心参数被设置为3，因此在每个高精度标记之后，训练过程得到3个时期的改进。如果在高水位标记后的3个时期内没有改善，训练过程将自动停止。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6ac09ff573f6ff4d4d9751c8919c0ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*gdZUqdl3gymLdy8M9EIGBw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">带有提前停止回调的fit语句的输出</p></figure><p id="eb15" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">在时段2中精度的高水位标记之后，精度没有变得更好，因此训练运行在3个时段之后，在时段5之后停止。</p><p id="8700" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">当我们在学习者对象上运行validate()时，输出显示训练过程产生的模型的精度再次是训练运行的最终时期的精度，即使更早的时期具有更高的精度:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/aa4b7af0365f139292333d5b90075c92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*YmYH5dgKcgoDCSpVLGa7Ew.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">通过提前停止回调训练的模型的validate()输出</p></figure><h2 id="7213" class="lu lv ji bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">保存训练过程中的最佳砝码组</h2><p id="9989" class="pw-post-body-paragraph kx ky ji kz b la mn kj lc ld mo km lf lg mp li lj lk mq lm ln lo mr lq lr ls im bi translated">添加早期停止回调是对基线的改进，因为在准确性不再提高后，我们没有运行那么多无效的时期。然而，在最终的训练模型中，我们仍然没有达到最佳精度，因此仍然有改进的空间。为了获得最佳的准确性，我们将添加一个模型保存回调，以确保经过训练的模型在训练过程中具有最佳的准确性。</p><p id="5911" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们将再次使用用于训练基线模型的相同的dataloaders对象，但是这次我们将在fit语句中指定两个回调。我们还会将学习者对象的路径设置为可写目录，以便在培训过程中保存模型:</p><figure class="nh ni nj nk gt iv"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="b0c4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">就像上一节中的模型一样，fit语句的输出显示，即使指定了10个时期，训练运行也只进行到时期5。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6ac09ff573f6ff4d4d9751c8919c0ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*gdZUqdl3gymLdy8M9EIGBw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">带有提前停止回调和模型保存回调的fit语句的输出</p></figure><p id="8e6b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">再次，由于提前停止回调，在精度在时段2中的高水位标记上停止提高之后，训练过程自动停止3个时段。</p><p id="14ca" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">训练结束时，训练好的模型的精度如何？对该模型的学习者对象运行validate()表明，精度不是来自训练运行的最终时期的精度。这一次，精确度与我们在纪元2的高水位标记中看到的一致。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ab757aa49e708c348c1fd26587e04626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*4sR_j8Z87NzR2FGoKyfD5g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">通过提前停止回调和模型保存回调训练的模型的validate()输出</p></figure><p id="db29" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">通过回调、提前停止和模型保存，我们解决了本文开头提到的两个问题:</p><ul class=""><li id="5aea" class="ms mt ji kz b la lb ld le lg mu lk mv lo mw ls ob my mz na bi translated">多亏了早期停止回调，我们避免了做一堆无效的时期，因为精度不再提高。</li><li id="f497" class="ms mt ji kz b la nb ld nc lg nd lk ne lo nf ls ob my mz na bi translated">由于模型保存回调，从训练过程中得到的训练模型具有我们在训练过程中看到的最佳准确性。</li></ul><h2 id="9d83" class="lu lv ji bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">结论</h2><p id="1f88" class="pw-post-body-paragraph kx ky ji kz b la mn kj lc ld mo km lf lg mp li lj lk mq lm ln lo mr lq lr ls im bi translated">通过使用fastai中的提前停止和模型保存回调，您可以从培训周期中获得最大收益。您将避免在模型没有改进的时期耗尽容量，并且您可以确保在训练周期结束时，您拥有具有最佳性能的模型。</p><p id="00e4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">以下是与本文相关的一些资源:</p><ul class=""><li id="196f" class="ms mt ji kz b la lb ld le lg mu lk mv lo mw ls ob my mz na bi translated">本文检查的代码:<a class="ae lt" href="https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook/blob/main/ch8/training_with_tabular_datasets_callbacks.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/packt publishing/Deep-Learning-with-fastai-Cookbook/blob/main/ch8/training _ with _ tabular _ datasets _ callbacks . ipynb</a></li><li id="d211" class="ms mt ji kz b la nb ld nc lg nd lk ne lo nf ls ob my mz na bi translated">预定地点:<a class="ae lt" href="https://www.packtpub.com/product/deep-learning-with-fastai-cookbook/9781800208100" rel="noopener ugc nofollow" target="_blank">https://www . packtpub . com/product/deep-learning-with-fastai-cookbook/9781800208100</a></li><li id="9428" class="ms mt ji kz b la nb ld nc lg nd lk ne lo nf ls ob my mz na bi translated">关于这个主题的视频:【https://youtu.be/qkRok0e3yvs T4】</li></ul></div></div>    
</body>
</html>