<html>
<head>
<title>Sentence Transformer Fine-Tuning (SetFit): Outperforming GPT-3 on few-shot Text-Classification while being 1600 times smaller</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">句子转换微调(SetFit):在少量文本分类方面优于GPT-3，但体积却小了1600倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sentence-transformer-fine-tuning-setfit-outperforms-gpt-3-on-few-shot-text-classification-while-d9a3788f0b4e?source=collection_archive---------3-----------------------#2021-12-14">https://towardsdatascience.com/sentence-transformer-fine-tuning-setfit-outperforms-gpt-3-on-few-shot-text-classification-while-d9a3788f0b4e?source=collection_archive---------3-----------------------#2021-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0474" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GPT-n系列在少数镜头NLP分类任务中表现出非常有前景的结果，并随着模型规模的增加而不断改进(GPT 3–175B)。然而，这些模型需要大量的计算资源，并且它们对训练提示的选择很敏感。在这项工作中，我们演示了句子转换器微调(SetFit)，这是一种简单有效的少量文本分类方法。该方法基于用特定于任务的数据来微调句子转换器，并且可以容易地用句子转换器库来实现。我们通过将SetFit应用于RAFT(真实世界少数镜头文本分类)基准测试来验证它，并显示它令人惊讶地优于GPT-3等模型，同时它的规模是1600倍，并缓解了对即时训练和使用未标记数据的需求。此外，我们的方法有助于缩小机器和人类性能之间的差距，只需提供50个实例进行训练。</p><p id="5bb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">简介</strong></p><p id="ec27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有监督神经网络在不同领域和领域的许多任务中表现出显著的性能，但是它们需要大量的标记训练数据。数据标记过程是劳动密集型和成本高昂的，并且阻碍了人工智能系统在行业中的部署。人工智能中的迁移学习(TL)对于低数据资源场景实现了相当大的鲁棒性。<a class="ae kl" href="https://ruder.io/state-of-transfer-learning-in-nlp/" rel="noopener ugc nofollow" target="_blank">NLP</a>(Ruder et al . 2019)中的TL涉及两个步骤:使用未标记数据训练的预训练语言模型(PLM)和针对特定任务的第二步微调。在BERT (Devlin等人，2019)等标准微调设置中，PLM顶部的通用分类头输出用于生成最终预测的表示。基于LM微调的<a class="ae kl" href="https://ruder.io/recent-advances-lm-fine-tuning/" rel="noopener ugc nofollow" target="_blank">文本到文本</a>【1】的最新进展实现了SOTA少数镜头性能，包括上下文学习和任务特定提示学习。</p><p id="6899" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">情境学习</strong>模型根据作为提示提供的输入-输出训练示例直接生成答案，而不改变其参数。GPT-3(布朗等人，2020年)利用上下文学习来证明在许多自然语言处理任务中优越的少数镜头能力。它的主要缺点是需要一个庞大的模型，只依赖于预先训练的知识，并且需要大量的快速工程。</p><p id="6442" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">任务特定提示学习</strong>将下游任务转换成屏蔽语言模型问题，由此在提供由任务特定模板定义的提示时，该模型生成作为屏蔽标记预测的文本响应。开拓性的模式开发训练(PET)方法(Schick &amp; Schutze 2021a，b)结合了这种模式，并被证明在使用小三个数量级的模型的少量学习中胜过GPT-3。然而，这种设置有几个限制:它需要多步训练，包括适应和几个PLM的集合；它利用特定任务的未标记数据；并且需要手工制作提示。ADAPET (Tam等人，2021年)通过利用更多的监督来训练模型，在没有任何未标记数据的情况下，在少量强力胶上的表现优于PET。LM-BFF (Gao等人，2021)通过将基于提示的微调(FT)与自动提示生成相结合，并动态选择任务示例作为输入上下文的一部分，提供了改进的少量微调性能。</p><p id="6b0f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，出现了几个针对NLP中少数镜头学习的基准，如RAFT (Alex等人，2021)，FLEX (Bragg等人，2021)，和CLUES (Mukherjee等人，2021)。RAFT是一个真实世界的少量文本分类基准，它只提供50个样本用于训练，没有验证集。它包括11个实际的现实世界的任务，如医疗案例报告分析和仇恨言论检测，其中更好的性能直接转化为更高的企业价值。该基准包括GPT-3产生的结果，成为比较的标准基线。在一篇相关的论文(Schick &amp; Schutze 2021c)中，研究表明，像PET这样基于提示的学习者在RAFT基准测试中表现出色，在11个任务中有7个任务的表现接近人类水平，而没有使用任何验证数据。</p><p id="075e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博客中，我们介绍了SetFit，一个经过调整的句子转换器模型，它通过少量数据进行微调，以解决现实世界中的文本分类挑战，如RAFT。也就是说，验证SetFit是文本分类的通用灵丹妙药超出了本研究的范围。博客是这样组织的:我们从句子变形金刚相关的背景开始，然后提供改编方法的详细描述。由于目标基准缺乏任何验证数据，我们不得不根据外部相关任务搜索最佳参数集。我们选择<a class="ae kl" href="https://paperswithcode.com/sota/sentiment-analysis-on-sst-2-binary" rel="noopener ugc nofollow" target="_blank"> SST-2 </a>作为我们的验证数据集，并进行评估以选择RAFT实验的最佳参数。下一步是为RAFT任务微调SetFit，并执行预测RAFT的测试数据，同时利用几种试探法和最佳实践。我们每项任务的表现都会在RAFT的排行榜网站上公布。在<a class="ae kl" href="https://huggingface.co/spaces/ought/raft-leaderboard" rel="noopener ugc nofollow" target="_blank">发表后</a> [2] SetFit排名第二，紧随人类基线之后，在11个任务中的7个任务中超过了GPT-3，尽管它比x1600小(见图1)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/20cb36cdcc46c6f46b4d90446036c420.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a-TB5eSOa2vDdOAkWNPUMA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">图1: F1对比:筏形基准</em>上塞特菲vs GPT-3<em class="lc"/></p></figure><p id="0a98" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">方法</strong></p><p id="7c3a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">句子转换器(ST) </strong>是一种非常流行的方法，用于语义搜索、语义相似性和聚类。其思想是基于句子的语义签名对句子的唯一向量表示进行编码。如图2所示，在对比训练期间，通过在Siamese架构中采用transformer模型来构建表示(Remiers &amp; Gurevych 2019)，旨在最小化语义相似的句子之间的距离，最大化语义遥远的句子之间的距离。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/9db2b210d74f57926a1c2e33c633eae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*2Hq1UHifOXdalGQWxgRRRA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">图2:连体BERT架构</em></p></figure><p id="7b00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当应用于句子对之间的大规模比较时，句子转换器产生非常有效的表示，这是信息检索任务中非常常见的情况。STs对于其他流行的NLP任务也是有效的，例如情感分析和命名实体识别，因为它们将文本转换为数值结构，然后很容易用现成的机器学习(ML)工具包和流行的NLP生产框架(例如<a class="ae kl" href="https://nlp.johnsnowlabs.com/" rel="noopener ugc nofollow" target="_blank">spark NLP</a>【3】)进行缩放、操作和处理。</p><p id="3349" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">sentence-transformers <a class="ae kl" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">库</a> [4]是ST表示的模型中枢，包括一个抽象API和代码示例，用于在生产中训练、微调和推理ST。</p><p id="4486" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">用于文本分类的ST</strong>使用ST进行文本分类的想法并不新颖，它包括一个编码步骤和一个分类步骤(如逻辑回归)。ST性能优于其他嵌入表示，但无法与交叉编码器(如BERT)分类相媲美(Remiers &amp; Gurevych 2019)。令人惊讶的是，我们没有发现任何以连体方式为文本分类执行端到端ST微调的工作。原因可能是STs是在语义相似性任务上预先训练的(即句子对传达相同/不同的意思),并且为了相同的目标而进一步调整它们是直观的。此外，直到最近，具有显著性能提升的新ST模型才作为语句转换器(例如基于<a class="ae kl" href="https://arxiv.org/abs/2004.09297" rel="noopener ugc nofollow" target="_blank"> MPNet </a>的具有大数据训练的模型)和其他模型(例如<a class="ae kl" href="https://arxiv.org/abs/2104.08821" rel="noopener ugc nofollow" target="_blank"> SimCSE </a>)的一部分发布，并且它们可能仍在为非相似性任务进行探索。</p><p id="c96e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> SetFit —句子转换器微调</strong>图3是SetFit的训练和推理阶段的框图。交互式代码示例可以在<a class="ae kl" href="https://colab.research.google.com/github/MosheWasserb/SetFit/blob/main/SetFit_SST_2.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>【5】找到。</p><p id="728d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练阶段的第一步是从句子-变形金刚[6]模型中枢中选择一个st模型。以下步骤是设置训练类、填充训练数据加载器和执行微调。为了更好地处理少数镜头场景中数量有限的标记训练数据，我们采用了一种经常用于图像相似性的对比训练方法(Koch et al. 2015):训练数据包括正面和负面句子对，其中正面对是从同一类中随机选择的两个句子，负面对是从不同类中随机选择的两个句子。句子对生成伪代码如图4所示。在每个句子对迭代中，我们生成2x <em class="le"> N </em>个训练对，其中<em class="le"> N </em>是每个任务的训练样本总数。生成的句子对用于微调(拟合)ST模型。</p><p id="629f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在微调步骤的最后，产生一个适应的ST。接下来，使用适应的ST对句子训练数据进行编码，然后为了简单起见，利用编码的数据来训练逻辑回归(LR)。在推理阶段，每个测试句子都用适应的st编码，然后用LR模型预测其类别。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lf"><img src="../Images/39939ffecd811ef063f864f070f4fa0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RcdvTMmCgCo6TRT88j_DPA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">图3: SetFit的示意图</em></p></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lg"><img src="../Images/967259dca82924c2b9e41c0f1b5f12f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sbzX2eOCmUigljzmtmoJrA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">图4:句子对生成伪代码</em></p></figure><p id="97f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">实验</strong></p><p id="a9bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">RAFT (Alex et al. 2021)是一个少数镜头分类基准，旨在通过将训练样本的数量限制为每个任务50个标记的示例，而不提供验证集，来匹配真实世界的场景。前者对于从业者来说是困难的，因为找到最佳的训练超参数集是具有挑战性的。影响SetFit性能的突出特征包括:</p><ol class=""><li id="3e65" class="lh li iq jp b jq jr ju jv jy lj kc lk kg ll kk lm ln lo lp bi translated">st的类型:句子-变形金刚模型中枢中的ST有很多种类型，问题是如何为给定的任务选择最佳的ST。</li><li id="b372" class="lh li iq jp b jq lq ju lr jy ls kc lt kg lu kk lm ln lo lp bi translated">输入数据选择:在一些RAFT任务中，提供了几个数据字段作为输入，例如标题、摘要、作者姓名、ID、数据等。这就产生了一个问题:哪些数据字段应该用作输入，以及如何组合它们？</li><li id="0be8" class="lh li iq jp b jq lq ju lr jy ls kc lt kg lu kk lm ln lo lp bi translated">超参数的选择:如何选择最佳的微调超参数集(例如#epochs，句子对生成迭代的次数)？</li></ol><p id="bdd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们应用简单的试探法和常识来选择ST模型、输入数据字段、超参数和序列长度。在接下来的部分中，我们将描述选择这些参数的最佳实践。</p><p id="ae58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ST models 句子变形库包含了大量可供选择的句子嵌入模型。模型名称对应于它们所基于的转换器的类型以及训练数据集。例如，“释义-mpnet-base-v2”模型使用释义相似性数据集用mpnet模型来训练。</p><p id="d5cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于如何为下游NLP任务选择最佳模型或训练数据集，没有明确的指导原则，尽管对于相似性任务存在一些经验法则。由于RAFT是一个文本分类数据集，我们假设它将受益于一个嵌入模型，该模型被训练来检测句子对之间的语义相似性，因为这有点类似于文本分类设置中类之间的相似性。因此，我们考虑嵌入使用“<a class="ae kl" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" rel="noopener ugc nofollow" target="_blank">所有</a>或“<a class="ae kl" href="https://www.sbert.net/examples/training/paraphrases/README.html" rel="noopener ugc nofollow" target="_blank">释义</a>训练数据集训练的模型，并将其设计为通用模型，我们排除了使用<a class="ae kl" href="https://paperswithcode.com/task/natural-language-inference" rel="noopener ugc nofollow" target="_blank"> NLI </a>或<a class="ae kl" href="https://paperswithcode.com/task/question-answering" rel="noopener ugc nofollow" target="_blank"> Q &amp; A </a>数据集训练的嵌入模型，这些数据集与文本分类任务非常不同。</p><p id="2dfc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们只瞄准尺寸与BERT-110M相当的型号。我们还测试了STs的蒸馏版本，如TinyBERT-80M和MiniLM-80M，但发现它们的性能与原始教师模型不可比(见附件A)。</p><p id="81cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑到以上所有因素，我们为验证步骤选择了以下三个候选模型。这些模型在句子变形器的<a class="ae kl" href="https://www.sbert.net/docs/pretrained_models.html" rel="noopener ugc nofollow" target="_blank">句子嵌入性能</a>中排名最高，如表1所示。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lv"><img src="../Images/1ab45904f60551923d963f6b7ba86a4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SHsVMVON9oAo9vCjrRoChg.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">表1:语义相似性任务的性能和被选择用于在SST-2数据集上验证SetFit的三个候选ST模型的大小</em></p></figure><p id="233c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">使用SST-2作为验证集</strong>我们在SST-2数据集上验证了SetFit，这是广泛使用的GLUE基准测试的一部分。SST-2是试探性选择的，因为它与大多数RAFT基准任务具有几个共同的品质，例如:</p><p id="60c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●相对较短的序列长度(&lt; 64)</p><p id="68a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●丰富的语义和句法结构，与其他分类器相比，Transformer具有较高的准确性</p><p id="a4dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●代表真实生活场景</p><p id="ffb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SST-2的选择不是RAFT的最佳选择，但可以作为替代验证集，因为RAFT不提供验证数据，也不为测试数据提供金标签。</p><p id="357b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过从完整的SST-2训练数据中为每个类别随机选择少量训练样本(16或50)来模拟少炮设置，以适应和训练ST。训练过程重复五次，每次使用不同的随机种子。通过对五次迭代的推理结果进行平均来产生最终的准确度。</p><p id="6c42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> ST模型选择</strong>表2显示了三个候选模型在ST模型微调(Fit)和不微调的情况下的性能，并与PET的性能进行了比较，PET使用RoBERTa和3进行了标准微调(高等人，2021年)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lw"><img src="../Images/7924be4c145ab00ebc94207ede6ccdbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ow-LICR5bkSPq-UHJYDCAA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">表2:SST-2数据集上不同ST模型的少量和完整训练集性能与基线的对比。*任务特定提示。* *标准微调。***上下文微调。据</em>报道(高等2021)。</p></figure><p id="5479" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如表2中所示，三个候选模型相当可比，具有50个训练样本的“释义-mpnet-base-v2”模型证明了略好的性能。因此，我们选择这个模型来评估我们的方法在RAFT基准上的性能。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lx"><img src="../Images/04c7cf63f4f5dcea03c7bfa38c737c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MnoYOE6XxDJiXzq9fGtsbg.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">图5:微调后(左)和微调前(右)在</em>paraphrase-MP net-base-v2<em class="lc">ST输出的二元分类任务的训练向量的2D表示。k代表每类训练样本的数量。蓝色圆点代表类别“0”，而橙色圆点代表类别“1”。</em></p></figure><p id="2d78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">少量的历元、句子对生成的五次迭代和ST微调足以达到收敛，并在2D向量空间(使用T-SNE建立)中产生良好的可分性。图5显示了训练数据的2D投影，有和没有ST微调。可以看出，与没有微调的相同模型相比，微调步骤显著提高了少量训练数据的可分离性，这导致SST-2测试的精确度更高。</p><p id="b3ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">超参数</strong> <strong class="jp ir">选择</strong>以下是基于SST-2数据集实验选择的参数。我们对所有的RAFT基准测试使用了相同的参数集，除了任务4(见表3 ),为了达到可接受的分离，我们将迭代次数增加到了10次。</p><p id="3136" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">● ST模型= '释义-mpnet-base-v2 '</p><p id="f497" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●train _ loss = CosineSimilarityLoss</p><p id="5b65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●#纪元数= 3</p><p id="9450" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●句子对生成迭代次数= 5</p><p id="a623" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●批量= 16</p><p id="5669" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●预热步骤= 10</p><p id="3a8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">数据字段选择</strong>RAFT基准测试中的任务3、7和8包含多个数据字段作为额外的元数据(如日期、个人姓名和职务)。在这些情况下，我们确保只保留一个主要的文本特征，该特征直观地包括用于正确分类句子的足够的上下文。表3显示了每个任务的可用数据字段，以及所选择的数据字段(以粗体显示)，以及(mean+std)/max文本长度。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ly"><img src="../Images/2e9fd700bf664c263e252405e1d0d03f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*isxeN-_0ULtt0Y1w7VbAHQ.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">表3: RAFT的数据字段和(均值+标准差)/最大文本长度</em></p></figure><p id="1354" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">序列长度选择</strong>如表3所示，任务3、4、7和8包括长文本序列(&gt; 256个标记)，这可能会导致意外结果(SetFit仅针对SST-2进行验证)和微调期间的内存分配错误(取决于您的硬件设置)。在这些情况下，我们将输入文本长度限制为128个标记，如下所示:对于任务4、7和8，我们选择了前128个标记，但是对于任务3，我们选择了后128个标记，因为我们注意到正确分类的相关上下文通常位于文本输入的最后部分。</p><p id="36e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">大量句子对生成迭代</strong>对SST-2数据集实验的分析表明，五次句子对生成迭代和ST微调足以实现代表不同类别训练样本的向量的2D投影之间的良好分离(见图5)。因此，我们对所有的RAFT任务使用了五次迭代，除了任务4，为了达到可接受的分离，我们将迭代次数增加到10次。</p><p id="0692" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">其他最佳实践</strong>没有对文本输入进行预处理。在RAFT数据集的任务2 (Banking_77)中，由于标签样本具有相当稀疏的表示(77个意图类别中只有36个在训练数据中包括至少一个样本)，我们将标签的名称作为输入样本添加到该类别。这是一个微不足道的附加，因为在文本分类任务中，类的名称(或它们的描述)是给定的。</p><p id="6d33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结果</strong>表4显示了RAFT排行榜的快照(2021年11月)。SetFit的总分是0.669，在人类基线之后排名第二，比GPT-3高出0.042分。令人惊讶的是，在基准测试的11个任务中，SetFit在7个任务中超过了GPT3，在NIS任务中，SetFit甚至超过了人类基线。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lz"><img src="../Images/d9af1af8d35f384587ee1cff46fb5998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I22UWmeMcbV5hbHr_4r0ZQ.png"/></div></div></figure><p id="4606" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="le">表RAFT排行榜快照(2021年11月)</em></p><p id="aabc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">讨论</strong></p><p id="e69e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是基于将SetFit应用于RAFT基准测试的结果的一些想法:</p><p id="9967" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●我们预计，ST模型的集合，以及基于RoBERTa large等大型模型的ST模型，最终将在RAFT上实现更好的整体性能(如附录A中SST-2所示)。</p><p id="003e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●对于NIS任务，将文本输入长度限制在最后128个字符似乎是一个好的实践，对性能有积极的影响。</p><p id="2c3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●将类别名称添加到Banking_77任务的训练数据中似乎非常有效，这可能导致比GPT-3更大的准确性优势(超过0.2点)。</p><p id="ae51" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●一个有趣的反常现象是，该表显示，一方面，在NIS和OSE任务中，SetFit远远超过GPT-3，甚至在NIS任务中超过了人类基线。另一方面，GPT-3在SOT任务中的表现远远超过SetFit这可能与SOT任务比其他任务需要更多事实知识的直觉有关。</p><p id="4394" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●通过将文本分类的一般问题解耦到句子嵌入生成和预测的两个阶段，实现了显著的准确性/效率提高，这乍一看似乎令人惊讶，但对于SOTA自然语言处理任务来说并不新鲜。事实表明，开放式问答的检索和阅读器架构(例如Lewis等人的RAG)能够使小得多的模型获得与T5–11B等较大模型相当的结果。总的来说，SetFit和RAG的分离带来了更高的健壮性(新数据/类别不需要重新训练)、可解释性和可伸缩性(更高级别的并行化)。</p><p id="504f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">●SetFit为SST-2数据集生成的结果(如附录A所示)，例如使用“all-roberta-large-v1”模型的完整训练集的准确度为95.4，这将使set fit在<a class="ae kl" href="https://paperswithcode.com/sota/sentiment-analysis-on-sst-2-binary" rel="noopener ugc nofollow" target="_blank"> SST-2排行榜</a> [7]上排名前20。这些基于句子表征的高质量结果与句子表征被认为仅传达浅层信息并因此导致准确度下降的常见假设相反。</p><p id="9773" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论和未来工作</strong></p><p id="2809" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们提出了SetFit，一种有效的少镜头文本分类方法，它基于流行的句子转换库，基于预先训练的ST表示和微调。SST-2数据集上的实验和RAFT基准上的提交结果证明了SetFit与大两到三个数量级的模型(如GPT-3和GPT-近地天体)相比的有效性，以及对比培训对进一步改进下游NLP任务的STs的重要性。在未来的工作中，我们打算探索如何用SetFit实现无监督学习，以及如何将其扩展到其他任务，特别是两句话文本分类，如<a class="ae kl" href="https://paperswithcode.com/task/natural-language-inference" rel="noopener ugc nofollow" target="_blank"> NLI </a>，<a class="ae kl" href="https://paperswithcode.com/task/question-answering" rel="noopener ugc nofollow" target="_blank"> Q &amp; A </a>。</p><p id="1e38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">致谢</strong></p><p id="73b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们非常感谢柳文欢·佩雷格(英特尔实验室)、尼尔斯·雷默斯(拥抱脸)、卢克·贝茨(UKP —达姆施塔特)富有成效的评论和更正。</p><p id="ee76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[1]<a class="ae kl" href="https://ruder.io/recent-advances-lm-fine-tuning/" rel="noopener ugc nofollow" target="_blank">https://ruder.io/recent-advances-lm-fine-tuning/</a></p><p id="0498" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2]最近，PET进入RAFT排行榜，在人类基线之后排名第一，PET基于比SetFit大x2的ALBERT模型(xxlarge，v2，235M参数)。</p><p id="57b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3]https://nlp.johnsnowlabs.com/<a class="ae kl" href="https://nlp.johnsnowlabs.com/" rel="noopener ugc nofollow" target="_blank"/></p><p id="8565" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4]https://www.sbert.net/<a class="ae kl" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank"/></p><p id="072d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[5]<a class="ae kl" href="https://colab.research.google.com/github/MosheWasserb/SetFit/blob/main/SetFit_SST_2.ipynb" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/github/MosheWasserb/set fit/blob/main/set fit _ SST _ 2 . ipynb</a></p><p id="aa65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[6]句子-默认情况下，变形金刚包括ST对象的微调选项。</p><p id="1c9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[7]<a class="ae kl" href="https://paperswithcode.com/sota/sentiment-analysis-on-sst-2-binary" rel="noopener ugc nofollow" target="_blank">https://papers with code . com/sota/opinion-analysis-on-SST-2-binary</a></p><p id="ed8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献</strong></p><p id="e93b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">汤姆·布朗、本杰明·曼、尼克·赖德、梅拉妮·苏比亚、贾里德·D·卡普兰、普拉富拉·达里瓦、阿尔温德·尼拉坎坦、普拉纳夫·希亚姆、吉里什·萨斯特里、阿曼达·阿斯凯尔、桑迪尼·阿加瓦尔、阿里尔·赫伯特沃斯、格雷琴·克鲁格、汤姆·海尼汉、雷文·蔡尔德、阿迪蒂亚·拉梅什、丹尼尔·齐格勒、杰弗里·吴、克莱门斯·温特、克里斯·黑塞、陈唐山、埃里克·西格勒、马特乌斯·利特温、斯科特·格雷、本杰明·切斯、杰克·克拉克、克里斯托弗·伯纳、萨姆·麦卡德里什、亚历克·拉德福德<a class="ae kl" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank">语言模型是一次性学习者</a>。NeurIPS 2020。</p><p id="9fe8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://aclanthology.org/people/s/sebastian-ruder/" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·鲁德</a>，<a class="ae kl" href="https://aclanthology.org/people/m/matthew-e-peters/" rel="noopener ugc nofollow" target="_blank">马修·e·彼得斯</a>，<a class="ae kl" href="https://aclanthology.org/people/s/swabha-swayamdipta/" rel="noopener ugc nofollow" target="_blank">斯瓦巴·斯瓦扬迪普塔</a>，<a class="ae kl" href="https://aclanthology.org/people/t/thomas-wolf/" rel="noopener ugc nofollow" target="_blank">托马斯·沃</a> lf。<a class="ae kl" href="https://aclanthology.org/N19-5004/" rel="noopener ugc nofollow" target="_blank">自然语言处理中的迁移学习</a>。NAACL 2019。</p><p id="fee1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">雅各布德夫林张明伟肯顿李克里斯蒂娜图塔诺瓦。<a class="ae kl" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT:用于语言理解的深度双向转换器的预训练</a>。NAACL 2019。</p><p id="40ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">提莫·希克和辛里奇·舒茨。2021a。<a class="ae kl" href="https://arxiv.org/abs/2001.07676" rel="noopener ugc nofollow" target="_blank">利用完形填空题进行少量文本分类和自然语言推理</a>。EACL 2021。</p><p id="5d13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">提莫·希克和辛里奇·舒茨。2021b。<a class="ae kl" href="https://arxiv.org/abs/2009.07118" rel="noopener ugc nofollow" target="_blank">重要的不仅仅是规模:小型语言模型也是很少尝试的学习者</a>。NAACL 2021。</p><p id="6e0f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">德里克·塔姆，拉克什·梅农，莫希特·班萨尔，沙尚克·斯里瓦斯塔瓦，科林·拉弗尔。<a class="ae kl" href="https://arxiv.org/abs/2103.11955" rel="noopener ugc nofollow" target="_blank">改进和简化花样拓展训练</a>。EMNLP 2021。</p><p id="250e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">提莫·希克和辛里奇·舒茨。2021c。<a class="ae kl" href="https://arxiv.org/abs/2111.13440" rel="noopener ugc nofollow" target="_blank">真正的带提示的少量学习——现实世界的视角</a>。</p><p id="1af7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尼尔斯·雷默斯和伊琳娜·古雷维奇。句子-伯特:<a class="ae kl" href="https://arxiv.org/abs/1908.10084" rel="noopener ugc nofollow" target="_blank">使用连体伯特网络的句子嵌入</a>。EMNLP 2019</p><p id="fa83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">格雷戈里·科赫，理查德·泽梅尔，鲁斯兰·萨拉胡季诺夫。<a class="ae kl" href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="noopener ugc nofollow" target="_blank">用于一次性图像识别的连体神经网络</a>。2015</p><p id="89f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">天宇高，亚当费舍尔，陈2021。<a class="ae kl" href="https://arxiv.org/abs/2012.15723" rel="noopener ugc nofollow" target="_blank">使预先训练的语言模型成为更好的少量学习者</a>。ACL 2021。</p><p id="a4aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Neel Alex、Eli Lifland、Lewis Tunstall、Abhishek Thakur、Pegah Maham、C. Jess Riedel、Emmie Hine、Carolyn Ashurst、Paul Sedille、l . Alexis Carlier、Michael Noetel、Andreas Stuhlmüller。<a class="ae kl" href="https://arxiv.org/pdf/2109.14076v1.pdf" rel="noopener ugc nofollow" target="_blank"> RAFT:一个真实世界的少镜头文本分类基准</a>。NeurIPS 2021，数据集和基准跟踪。</p><p id="c726" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">乔纳森·布拉格，阿尔曼·科汉，凯尔·洛伊兹·贝尔塔吉。<a class="ae kl" href="https://arxiv.org/abs/2107.07170" rel="noopener ugc nofollow" target="_blank"> FLEX:统一评估少镜头NLP </a>。NeurIPS 2021。</p><p id="bf39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">苏伯拉塔·慕克吉、、郑国庆、萨加尔·侯赛尼、格雷格·杨、克里斯多夫·米克、阿瓦达拉、高剑锋。<a class="ae kl" href="https://openreview.net/pdf?id=VhIIQBm00VI" rel="noopener ugc nofollow" target="_blank">线索:自然语言理解中的少量学习评价</a>。NeurIPS 2021，数据集和基准跟踪。</p><p id="8883" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Patrick Lewis、Ethan Perez、Aleksandra Piktus、Fabio Petroni、Vladimir Karpukhin、Naman Goyal、Heinrich Küttler、迈克·刘易斯、Yih Wen-tau、Tim rocktschel、Sebastian Riedel、Douwe Kiela。知识密集型自然语言处理任务的检索增强生成。NeurIPS 2020。</p><p id="6b2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">附录A </strong></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ma"><img src="../Images/4f069fb1abf8dbbd22f20a15750a96b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iglNtc2Cjq_QWH8XqarUdw.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">图6: SST-2对句子转换模型的评估。</em>* 3个模型的集合:<strong class="bd mb">释义-mpnet-base-v2、All-mpnet-base-v1和Stsb-mpnet-base-v2 </strong></p></figure></div></div>    
</body>
</html>