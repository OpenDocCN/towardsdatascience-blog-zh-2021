<html>
<head>
<title>Accelerated Python for general-purpose and scientific computationally expensive tasks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">针对通用和科学计算开销大的任务的加速Python</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/accelerated-python-for-general-purpose-and-scientific-computationally-expensive-tasks-55ac46f7f52b?source=collection_archive---------19-----------------------#2021-10-18">https://towardsdatascience.com/accelerated-python-for-general-purpose-and-scientific-computationally-expensive-tasks-55ac46f7f52b?source=collection_archive---------19-----------------------#2021-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4a14" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="f94f" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">借助强大的Numba CPU/CUDA目标编译，快速学习如何以最小的努力提高代码的性能。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/084463f49edc483d7d537eb2de268d91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWEfgdzQDMMtu7dQ9G2llg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@nasa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> NASA </a>在<a class="ae le" href="https://unsplash.com/s/photos/rocket?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="583d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">大家都喜欢Python </strong>。Python是一种解释型高级通用编程语言。它是动态类型的，并提供垃圾收集。Python支持多种范式，包括过程化、面向对象和函数式编程。</p><p id="2014" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，<a class="ae le" href="https://en.wikipedia.org/wiki/Guido_van_Rossum" rel="noopener ugc nofollow" target="_blank"> Guido Van Rossum </a>创造的语言带有简单易学的语法，并通过设计鼓励<strong class="lh ja">代码可读性</strong>，从而允许程序员编写干净的代码，即使对于大型生产级项目也是如此。</p><p id="50db" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所有这些漂亮的特性，一方面使Python如此吸引人，另一方面，不可避免地增加了执行速度的负担，这并不是它的强项。在本文中，我们将讨论如何使用<strong class="lh ja"> Numba和CUDA，不费吹灰之力或以最小的努力提高代码的<strong class="lh ja">性能。</strong></strong></p><p id="3337" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为此，我们准备了<strong class="lh ja">两种算法</strong>，我们将比较和测试使用和不使用Numba的不同实现。</p><p id="ef26" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们不是故意考虑<a class="ae le" href="https://cython.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja">Cython</strong></a><strong class="lh ja"/>的:虽然它提供了——至少在理论上——与静态编译语言相当的性能，但cy thon实际上是Python的扩展，对它的翻译需要相当大的努力来重写代码，遵循类似于c的静态类型语法</p><p id="1800" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意:下面显示的所有代码在这里都有:<a class="ae le" href="https://github.com/andrea-ci/misc-stuff/tree/master/numba-test" rel="noopener ugc nofollow" target="_blank">https://github . com/Andrea-ci/misc-stuff/tree/master/numba-test</a>。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="715d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">列表操作</h1><p id="ec13" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">我们要测试的第一个算法在列表上工作，列表是Python最常见的内置对象之一。一个函数接收一个字符列表，这些字符是从前五个字符(即A、B、C、D和E)中随机选择的，并为每个元素分配一个与字符在字母表中的位置相对应的整数。新的整数列表是函数的输出。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="0ac2" class="nk mj iq ng b gy nl nm l nn no">def translate_list_01(char_list):<br/>    """Working on a list.<br/>    Pure Python implementation."""</span><span id="2fad" class="nk mj iq ng b gy np nm l nn no">    num_list = []<br/>    for word in char_list:</span><span id="c23d" class="nk mj iq ng b gy np nm l nn no">        if word == 'A':<br/>            num = 1<br/>        elif word == 'B':<br/>            num = 2<br/>        elif word == 'C':<br/>            num = 3<br/>        elif word == 'D':<br/>            num = 4<br/>        else:<br/>            num = 5</span><span id="fd46" class="nk mj iq ng b gy np nm l nn no">    num_list.append(num)</span><span id="527e" class="nk mj iq ng b gy np nm l nn no">    return num_list</span></pre><p id="b581" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看这个简单函数对于不同大小的列表的执行时间，用2的幂来表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/42df5adc3c89341256544f2d2bb3adcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*7Wy5_oXc3UaSmNzxHj-meg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">简单实现的执行时间</p></figure><h1 id="660e" class="mi mj iq bd mk ml nr mn mo mp ns mr ms kf nt kg mu ki nu kj mw kl nv km my mz bi translated">输入数字</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/cb3e5c8578011da9f310655158068a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*05anKy5UUXQ3tkqEyzUAaA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Numba标志</p></figure><p id="ebee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们现在引入Numba，这是一个在Python代码上实现实时编译的库。来自Numba 的<a class="ae le" href="https://numba.readthedocs.io/en/stable/user/5minguide.html" rel="noopener ugc nofollow" target="_blank">官方主页:</a></p><blockquote class="nx ny nz"><p id="304f" class="lf lg oa lh b li lj ka lk ll lm kd ln ob lp lq lr oc lt lu lv od lx ly lz ma ij bi translated">Numba是一个针对Python的实时编译器，最适合使用NumPy数组和函数以及循环的代码。使用Numba最常见的方式是通过它的decoratorss集合，这些decorator可以应用到您的函数中来指示Numba编译它们。当一个Numba修饰的函数被调用时，它被编译成“实时”执行的机器代码，你的全部或部分代码随后可以以本机代码的速度运行！</p></blockquote><p id="3a3a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Numba的目标是针对CPU或CUDA内核进行编译，以实现大规模并行化(稍后将详细介绍)。</p><p id="548d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，第二个实现在我们的函数上添加了JIT编译。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="198b" class="nk mj iq ng b gy nl nm l nn no"><a class="ae le" href="http://twitter.com/jit" rel="noopener ugc nofollow" target="_blank">@jit</a>(nopython=True)<br/>def translate_list_02(char_list):<br/>    """Working on a list.<br/>    CPU-acceleration with Numba."""</span><span id="41c8" class="nk mj iq ng b gy np nm l nn no">    num_list = []<br/>    for word in char_list:</span><span id="b5c8" class="nk mj iq ng b gy np nm l nn no">        if word == 'A':<br/>            num = 1<br/>        elif word == 'B':<br/>            num = 2<br/>        elif word == 'C':<br/>            num = 3<br/>        elif word == 'D':<br/>            num = 4<br/>        else:<br/>            num = 5</span><span id="ed8d" class="nk mj iq ng b gy np nm l nn no">    num_list.append(num)</span><span id="5513" class="nk mj iq ng b gy np nm l nn no">    return num_list</span></pre><p id="e372" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">实际上，为了从JIT编译中获益，我们需要的唯一改变是添加Numba <code class="fe oe of og ng b">jit</code>装饰器。<code class="fe oe of og ng b">nopython=True</code>选项确保修饰函数将完全在没有Python解释器参与的情况下运行。这是从Numba获得最佳性能的推荐方法。</p><p id="1d50" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">无需任何重新编码，编译后的代码会立即快4到5倍。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/c749349af9fa1b7a13e2e4913456516d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*2db8X3ynUSlNppw5aIMO2Q.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">执行时间的比较</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/13c0bd7d554c27994928365ef4798853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*LJfKez-SgeNvvbz-jicnAg.png"/></div></figure><p id="3fc7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Numba并不支持所有的Python构造，所以在某些情况下，可能需要重新组织代码和/或在<code class="fe oe of og ng b">object mode</code>中编译，这是当<code class="fe oe of og ng b">nopython=True</code>未设置时<code class="fe oe of og ng b">jit</code>装饰器的一种备用模式。使用这种模式，Numba将识别它可以编译的部分，并在解释器模式下运行其余的代码，这对性能没有好处。</p><p id="da4b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你可以在这里找到Numba编译器支持的python特性。</p><h1 id="53cf" class="mi mj iq bd mk ml nr mn mo mp ns mr ms kf nt kg mu ki nu kj mw kl nv km my mz bi translated">科学计算</h1><p id="cc3c" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">Python还被广泛用于科学和数字任务，这要归功于一个强大的社区积极开发和支持的大量库。毕竟Python是机器学习的语言，仅举一例。</p><p id="afbd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">毫无疑问，Python科学生态系统的基础是<a class="ae le" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> Numpy </a>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/1783938343b6dc923ab6e99732dcef95.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*z9cCJjs9lD_9zdSDUUJ9nw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Numpy标志</p></figure><p id="3ecb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Numpy附带了一个丰富的工具集，其中的函数是为高效的矢量化而编译的，以便为需要在数组和矩阵上快速迭代的代码提供优化。其他高级语言也采用相同的方法，一个著名的例子是Matlab。</p><p id="d319" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Numba方面，<a class="ae le" href="https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html" rel="noopener ugc nofollow" target="_blank">声称是Numpy-friend </a>:</p><blockquote class="nx ny nz"><p id="497e" class="lf lg oa lh b li lj ka lk ll lm kd ln ob lp lq lr oc lt lu lv od lx ly lz ma ij bi translated">Numba的一个目标是与NumPy无缝集成。</p></blockquote><p id="682d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，使用Numba，我们在已经编译好的工具上增加了一个编译层。乍一看，这似乎<strong class="lh ja">有点令人困惑</strong>。</p><p id="8c12" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了更好地关注这个方面，我们要测试的第二个算法是在<strong class="lh ja"> Numpy 2D数组</strong>上进行的一系列元素操作:加法、减法、对数、指数、最小值、最大值、乘法和除法。</p><p id="fc10" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该算法的第一个实现仅使用Numpy。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="3932" class="nk mj iq ng b gy nl nm l nn no">def computing_01(A, B, a, b):<br/>    """Numpy operations with no acceleration."""</span><span id="2130" class="nk mj iq ng b gy np nm l nn no">    # Scalar multiplication and addition of matrices.<br/>    Y = a * A + b * B<br/>    # Scalar multiplication and subtraction of matrices.<br/>    Y -= a * A - b * B<br/>    # Element-wise logarithm.<br/>    Y += np.log(A) + np.log(B)<br/>    # Element-wise exponential.<br/>    Y -= np.exp(A) - np.exp(B)<br/>    # Element-wise minimum and maximum.<br/>    Y += (np.maximum(A, B) - np.minimum(A, B)) / 2<br/>    # Element-wise multiplication and division.<br/>    Y -= np.multiply(A, B) - np.divide(A, B)</span><span id="a4c7" class="nk mj iq ng b gy np nm l nn no">    return Y</span></pre><p id="3fd3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二个实现在上面添加了Numba编译。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="1e97" class="nk mj iq ng b gy nl nm l nn no"><a class="ae le" href="http://twitter.com/jit" rel="noopener ugc nofollow" target="_blank">@jit</a>(nopython=True)<br/>def computing_02(A, B, a, b):<br/>    """Numpy operations with Numba acceleration."""</span><span id="14b1" class="nk mj iq ng b gy np nm l nn no">    # Scalar multiplication and addition of matrices.<br/>    Y = a * A + b * B<br/>    # Scalar multiplication and subtraction of matrices.<br/>    Y -= a * A - b * B<br/>    # Element-wise logarithm.<br/>    Y += np.log(A) + np.log(B)<br/>    # Element-wise exponential.<br/>    Y -= np.exp(A) - np.exp(B)<br/>    # Element-wise minimum and maximum.<br/>    Y += (np.maximum(A, B) - np.minimum(A, B)) / 2<br/>    # Element-wise multiplication and division.<br/>    Y -= np.multiply(A, B) - np.divide(A, B)</span><span id="8e76" class="nk mj iq ng b gy np nm l nn no">    return Y</span></pre><p id="2548" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，第三实现避免了Numpy函数的任何使用，并且矩阵上的迭代是显式的。换句话说，<strong class="lh ja">我们完全依赖Numba </strong>来消耗循环的<em class="oa">。</em></p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="8d43" class="nk mj iq ng b gy nl nm l nn no"><a class="ae le" href="http://twitter.com/jit" rel="noopener ugc nofollow" target="_blank">@jit</a>(nopython=True)<br/>def computing_03(A, B, a, b):<br/>    """Numba acceleration, without Numpy."""</span><span id="c7df" class="nk mj iq ng b gy np nm l nn no">    # Matrix size.<br/>    N = A.shape[0]</span><span id="1b6d" class="nk mj iq ng b gy np nm l nn no">    # Init temporary matrices.<br/>    Y = np.empty((N,N))</span><span id="9728" class="nk mj iq ng b gy np nm l nn no">    for ii in range(N):<br/>        for jj in range(N):</span><span id="0228" class="nk mj iq ng b gy np nm l nn no">            # Scalar multiplication and addition of matrices.<br/>            Y[ii, jj] = a * A[ii, jj] + b * B[ii, jj]<br/>            # Scalar multiplication and subtraction of matrices.<br/>            Y[ii, jj] -= a * A[ii, jj] - b * B[ii, jj]<br/>            # Element-wise logarithm.<br/>            Y[ii, jj] += math.log(A[ii, jj]) + math.log(B[ii, jj])<br/>            # Element-wise exponential.<br/>            Y[ii, jj] += math.exp(A[ii, jj]) - math.exp(B[ii, jj])<br/>            # Element-wise minimum and maximum.<br/>            Y[ii, jj] += (max(A[ii, jj], B[ii, jj]) - min(A[ii, jj], B[ii, jj])) / 2<br/>            # Element-wise multiplication and division.<br/>            Y[ii, jj] -= A[ii, jj] * B[ii, jj] - A[ii, jj] / B[ii, jj]</span><span id="5bb0" class="nk mj iq ng b gy np nm l nn no">    return Y</span></pre><p id="6a8e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们最终可以针对不同的<em class="oa"> N </em>值测量这些实现的性能。<em class="oa"> N </em>是<em class="oa"> A、B </em>和<em class="oa"> Y </em>方阵的顺序。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/d3d7238724e293ff73aa9b12e882729a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*PRGYIK6YUnijhEPEdU-bPg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">执行时间的比较</p></figure><p id="24f3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们在这里注意到两件主要的事情。第一个是用Numba编译，我们得到了额外的优化，只针对Numpy。所以尽管引入了开销，Numba编译<strong class="lh ja">仍然是有益的</strong>。</p><p id="8c7c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二，令人惊讶的是，或者也许不那么令人惊讶的是，当我们让Numba做所有的迭代工作时，它的表现比Numpy好得多。</p><p id="cb84" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这种情况下，Numba的编译似乎比Numpy的矢量化更有效。</p><h1 id="be69" class="mi mj iq bd mk ml nr mn mo mp ns mr ms kf nt kg mu ki nu kj mw kl nv km my mz bi translated">输入CUDA</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/5f228d3887326e4a9746b3d44271c4f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*TWyVOuzirmWT3O8m.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">哈梅内伊索尔蒂斯，CC BY-SA 4.0，通过维基共享</p></figure><p id="6017" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后我们打出最后一张牌:<strong class="lh ja"> CUDA </strong>。CUDA(计算统一设备架构)是由Nvidia创建的并行计算平台。它提供了一个应用程序编程接口，允许软件使用图形处理单元(GPU)进行通用处理。</p><p id="f230" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Numba也支持CUDA编程。来自<a class="ae le" href="https://numba.pydata.org/numba-doc/dev/cuda/overview.html" rel="noopener ugc nofollow" target="_blank"> Numba文档</a>:</p><blockquote class="nx ny nz"><p id="2c87" class="lf lg oa lh b li lj ka lk ll lm kd ln ob lp lq lr oc lt lu lv od lx ly lz ma ij bi translated">Numba通过按照CUDA执行模型将Python代码的有限子集编译成CUDA内核和设备功能来支持CUDA编程。用Numba编写的内核似乎可以直接访问NumPy数组。NumPy数组在CPU和GPU之间自动传输。</p></blockquote><p id="4b9d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于Numba-CUDA支持的指令集进一步受到限制，所以在这里翻译代码需要稍微多做一些工作。</p><p id="b312" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了生成多维数组，CUDA的一般方法是让每个<strong class="lh ja"> GPU线程处理数组</strong>的单个元素，从而实现真正的并行计算。Numba前端管理主机(CPU)和设备(GPU)之间的<strong class="lh ja">同步</strong>。</p><p id="fe97" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是我们算法的CUDA实现。我们可以注意到在这个例子中使用了不同的装饰器。此外，为CUDA编译的函数不返回任何对象，因此处理结果作为输入参数包含在内。最后，在这个实现中没有使用Numpy方法。</p><pre class="kp kq kr ks gt nf ng nh ni aw nj bi"><span id="e119" class="nk mj iq ng b gy nl nm l nn no"><a class="ae le" href="http://twitter.com/cuda" rel="noopener ugc nofollow" target="_blank">@cuda</a>.jit<br/>def computing_04(Y, A, B, a, b, N, size):<br/>    """Operations accelerated with Cuda."""</span><span id="7c72" class="nk mj iq ng b gy np nm l nn no">    # Thread id in a 1D block<br/>    tx = cuda.threadIdx.x<br/>    # Block id in a 1D grid<br/>    ty = cuda.blockIdx.x<br/>    # Block width, i.e. number of threads per block<br/>    bw = cuda.blockDim.x<br/>    # Compute flattened index inside the array<br/>    pos = tx + ty * bw</span><span id="950e" class="nk mj iq ng b gy np nm l nn no">    if pos &lt; size:</span><span id="5b86" class="nk mj iq ng b gy np nm l nn no">        ii = int(math.floor( pos / N ))<br/>        jj = int(math.floor( (pos - ii * N) / N ))</span><span id="6fba" class="nk mj iq ng b gy np nm l nn no">        # Scalar multiplication and addition of matrices.<br/>        Y[ii, jj] = a * A[ii, jj] + b * B[ii, jj]<br/>        # Scalar multiplication and subtraction of matrices.<br/>        Y[ii, jj] -= a * A[ii, jj] - b * B[ii, jj]<br/>        # Element-wise logarithm.<br/>        Y[ii, jj] += math.log(A[ii, jj]) + math.log(B[ii, jj])<br/>        # Element-wise exponential.<br/>        Y[ii, jj] += math.exp(A[ii, jj]) - math.exp(B[ii, jj])<br/>        # Element-wise minimum and maximum.<br/>        Y[ii, jj] += (max(A[ii, jj], B[ii, jj]) - min(A[ii, jj], B[ii, jj])) / 2<br/>        # Element-wise multiplication and division.<br/>        Y[ii, jj] -= A[ii, jj] * B[ii, jj] - A[ii, jj] / B[ii, jj]</span></pre><p id="4220" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">CPU和CUDA实现之间的区别是不言自明的！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7910cac042a5bae32bf6d44afb32a5c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*pLCRJjd-1KkXKvDdO5wwxQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">CUDA增加了执行时间的比较</p></figure><h1 id="8005" class="mi mj iq bd mk ml nr mn mo mp ns mr ms kf nt kg mu ki nu kj mw kl nv km my mz bi translated">结论</h1><p id="5b4e" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">Numba是一个很棒的工具，它可以<strong class="lh ja">显著提升Python代码的</strong>性能，只需很少或者不需要重新编码。</p><p id="48a6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在矢量化数值运算的情况下，我们也可以从CUDA并行化中受益。在这种情况下，重新编码的成本肯定会更高，但是<strong class="lh ja">的性能提升是显著的</strong>。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="8c3b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">用于测试代码的机器是一台Windows机器，配备了Intel i7–10700k CPU、32 GB RAM和Nvidia GeForce 3060Ti。</p></div></div>    
</body>
</html>