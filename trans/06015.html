<html>
<head>
<title>Synthetic data — The panacea for Data Preserving AI?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">合成数据——数据保存人工智能的灵丹妙药？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/synthetic-data-the-panacea-for-data-preserving-ai-298b48ec3189?source=collection_archive---------27-----------------------#2021-05-29">https://towardsdatascience.com/synthetic-data-the-panacea-for-data-preserving-ai-298b48ec3189?source=collection_archive---------27-----------------------#2021-05-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c08e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">生成合成数据的不同技术的比较分析</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/15c6fa4be6e91367f3bf014db77a44b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BI8CGnqQBAD2v2Ft"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><a class="ae kw" href="https://unsplash.com/@matthewhenry?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马太·亨利</a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="934f" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated">介绍</h1><blockquote class="lp lq lr"><p id="da08" class="ls lt lu lv b lw lx jr ly lz ma ju mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><strong class="lv ir"> AI改变了世界</strong></p></blockquote><p id="210d" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">不管是好是坏，这完全是一个哲学上的争论，然而，上面的陈述几乎是真实的，是作为一个定律来陈述的。随着深不可测的数据量的无处不在的入侵，大量的ML算法，以及世界日益增加的复杂性，我们几乎处于这样一个点上，即我们快速增长的技术发展速度与计算要求的结合甚至可能使神圣的<a class="ae kw" href="https://www.technologyreview.com/2020/02/24/905789/were-not-prepared-for-the-end-of-moores-law/" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ir">摩尔定律过时</strong> </a>。</p><p id="6770" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">然而，正如每一次技术进步一样，我们现在正面临着来自数据爆炸性使用的迫在眉睫的威胁——数据隐私问题，它已经变得与被称为未来十年最重要的问题一样重要。通过这篇文章，我的目标是阐明数据隐私的综合含义，以及对当前技术的广泛观点，重点关注合成数据生成的方法，以及它们的定量-定性分析。尽管我已经尽力以一种简单的方式提出了我的发现，但我已经对人工智能领域有了一个总体的认识，并且通篇使用了其他专门的技术术语(主要是由于本文的简洁性质)。</p><h1 id="fcf2" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated"><strong class="ak"> <em class="kf">什么是数据隐私？</em>T19】</strong></h1><p id="286e" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">尽管对数据隐私的简明定义还没有明确的共识，但它被宽泛地定义为处理敏感的个人数据所涉及的一系列实践，通常与<a class="ae kw" href="https://en.wikipedia.org/wiki/Information_privacy" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ir">信息隐私</strong> </a>领域重叠。正如Patricia Thaine(联合创始人，私人AI)在她的<a class="ae kw" rel="noopener" target="_blank" href="/perfectly-privacy-preserving-ai-c14698f322f5"> <strong class="lv ir">文章</strong></a><strong class="lv ir"/>中提到的，数据隐私一般有<strong class="lv ir">四大支柱</strong>—</p><ol class=""><li id="5290" class="mx my iq lv b lw lx lz ma mp mz mq na mr nb mo nc nd ne nf bi translated"><strong class="lv ir">培训数据隐私- </strong>对培训数据进行不良逆向工程以确定个人身份的相关风险。</li><li id="565b" class="mx my iq lv b lw ng lz nh mp ni mq nj mr nk mo nc nd ne nf bi translated"><strong class="lv ir">输入隐私- </strong>与用户输入数据向外部参与者(包括模型创建者本身)泄露相关的风险。</li><li id="2b28" class="mx my iq lv b lw ng lz nh mp ni mq nj mr nk mo nc nd ne nf bi translated"><strong class="lv ir">输出隐私- </strong>与用户输出数据向用户本身以外的外部行为者泄露相关的风险。</li><li id="7e6b" class="mx my iq lv b lw ng lz nh mp ni mq nj mr nk mo nc nd ne nf bi translated"><strong class="lv ir">模型隐私- </strong>与恶意方窃取模型相关的风险。</li></ol><p id="1fab" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">显而易见，对数据隐私的完整分析包括仔细分析与传统数据/模型管道的所有步骤相关的风险。自然，在人工智能的情况下，隐私问题不仅延伸到软件考虑，也延伸到硬件规范，这带来了自己的威胁。这篇文章将其讨论限制在训练数据隐私的领域，这是一个被认为与人工智能算法领域最兼容的概念。</p><h1 id="e009" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated"><strong class="ak">数据隐私和人工智能</strong></h1><p id="47f1" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">随着利用数据得出有意义结论的方法日益增多，定量执行这些计算的算法也日益增多。从简单的统计方法到监督算法领域，再到强大的深度学习领域，计算能力和得出的结论今天继续以非常高的速度增长。自然，随着这些算法的计算能力的提高，它使模型创建者能够使用比以往任何时候都多得多的数据特征，甚至有可能在一个算法中增加到数百万个特征。因此，这导致了恶性循环，如下所述。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nl"><img src="../Images/00f7aee4999be81a4b96d2ddae46d403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2cRBS3ij6ijyK6bkkSHJA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">技术的恶性循环(作者图片)</p></figure><p id="d06a" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">虽然从训练集和参数中获取敏感信息比简单的输入/输出相对更困难，但研究中有明确的证据表明逆向工程模型和重建数据的实际可能性。</p><p id="7859" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">例如，[1] Carlini和Wanger在他们的研究中表明，一个模型在一个训练集中记忆罕见的信息是可能的。特别是，他们设计了一种算法，当在不考虑这种记忆的模型上实现时，可以很容易地从中提取稀有信息。暴露度量量化了信息的暴露，这在某种意义上显示了模型有多脆弱。</p><p id="691c" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">给定一个<strong class="lv ir">金丝雀s[r] </strong>，一个带<strong class="lv ir">参数θ </strong>的模型，和<strong class="lv ir">随机性空间R </strong>，s[r]的曝光度为:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nm"><img src="../Images/122bfa76993093c84c10aa5c1c3ac32a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*am19F3aoyFf9Jkpq-5Ierw.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><p id="97c3" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">等级是真实秘密(金丝雀)在所有可能秘密中的索引。虽然这里没有给出详细的分析，但是该度量与测试集的损失最小时暴露达到峰值的事实是一致的。</p><h1 id="14dc" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated"><strong class="ak">差分隐私</strong> <strong class="ak">来救援？</strong></h1><p id="6671" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">自然，为了防止这种数据泄漏，许多研究已经进入设计防止这种泄漏的方法，其中差分隐私的方法似乎是最有前途的一种。[2] Dwork、Nissim、McSherry和Smith表明，如果某个校准(统计)噪声被引入数据集，那么几乎不可能到达数据集的发起者，因此在该方法中包含了设计隐私的概念。更具体地说，对于每个输出O，任何对手都无法区分相差一个输入的两个数据集D1和D2，即它们总是受到ε的度量的限制，如下所示。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nn"><img src="../Images/e9c5ab584dc5d1c7fc9fc6370a09a609.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v0EZnGtAipJbY0-WChoayA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><p id="99ad" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">Pr=概率，E =ε(一个小的正实体)</p><p id="6115" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">尽管大肆宣传，差分隐私本身并不是一个完美的解决方案。关于什么是/不是私有的问题，该方法无法精确地在大型数据集上工作的问题还没有完全回答。</p><p id="be7c" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">虽然<strong class="lv ir">匿名数据</strong>本身似乎是一个不错的选择，但它仍然容易遭到黑客攻击。臭名昭著的<a class="ae kw" href="https://www.securityfocus.com/news/11497" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ir">用户身份识别事件</strong> </a>当网飞向其提供匿名用户评级时，却发现它已被去匿名化，这向我们展示了与之相关的风险。因此，可以有把握地说<strong class="lv ir">匿名化永远不够</strong>。</p><h1 id="27c9" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated"><strong class="ak">合成数据——新范式</strong></h1><p id="a8ab" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">合成数据生成技术的出现极大地促进了数据隐私领域的发展。合成数据概念的历史根源可以追溯到Little (1993年)构想的部分同情数据概念，Rubin (1993年)首先将其付诸实践，他使用多重插补生成十年一次的人口普查的合成版本。</p><p id="4835" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">虽然早期的方法使用参数建模，但根据开发精确模型的复杂程度，也使用非参数方法，即装袋、随机森林等。然而，正如我们前面提到的，就像预测完全被深度学习模型重新想象一样，这些模型现在也在生成合成数据方面发挥着重要作用。在本文中，我将讨论限制在合成数据的四种主要方法上。这些如下所述-</p><h2 id="b7d0" class="no ky iq bd kz np nq dn ld nr ns dp lh mp nt nu lj mq nv nw ll mr nx ny ln nz bi translated"><strong class="ak">重击</strong></h2><p id="3029" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated"><strong class="lv ir">合成少数过采样(SMOTE) </strong>是一种生成合成数据的方法，主要用于分类。[3] Chawla、Boyle、Hall和Kegelmeyer在2003年引入了这一概念，以处理不平衡数据集，这种数据集往往会在数据集中引入隐含偏差。虽然它是其他深度学习方法的例外，但它的各种版本仍在使用，在实现中引入了轻微的修改。</p><p id="e313" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">在一个非常基本的方式中，它可以被概念化如下-</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/50cb45ac1b11423ce5765099fbfe7494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*C_GsfNm71arnnn3tRTq-3g.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><p id="916d" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated"><em class="lu">考虑数据点的k个邻居，其中y是0到1之间的随机数。</em></p><h2 id="8502" class="no ky iq bd kz np nq dn ld nr ns dp lh mp nt nu lj mq nv nw ll mr nx ny ln nz bi translated"><strong class="ak"> VAE </strong></h2><p id="89e4" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated"><strong class="lv ir">可变自动编码器(VAE) </strong>是自动编码器的最新增强版本，这是一种基于神经网络的合成数据生成方法。它是一个前馈神经网络，其中数据集最初由编码器压缩为压缩表示，然后由解码器尝试解压缩。它使用瓶颈的概念来压缩数据，这实质上涉及到限制信息流。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ob"><img src="../Images/360d44e05c5089803a805ef3861f42db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S2pwkCqvSS5cgjpecfH-QA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><h2 id="b829" class="no ky iq bd kz np nq dn ld nr ns dp lh mp nt nu lj mq nv nw ll mr nx ny ln nz bi translated"><strong class="ak">甘</strong></h2><p id="e868" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">也许没有算法比Ian Goodfellow和他的同事引入的生成式对抗网络(GAN)在人工智能领域产生的影响更大[4]。这些算法通常通过查看非常精细的级别来学习测试数据集的分布，以生成合成数据集。它们的本质是其中存在两个相互竞争的神经网络，称为生成器和鉴别器。他们采用了一种两人游戏理论方法，即生成器从噪声中模拟数据分布，鉴别器根据真实数据鉴定生成的数据是真实的还是虚假的，因此随着适应性的增加，当生成器在模拟真实数据方面变得越来越好时，鉴别器在鉴别它方面变得越来越好，从而生成看起来非常真实的合成数据集。</p><h2 id="fbe3" class="no ky iq bd kz np nq dn ld nr ns dp lh mp nt nu lj mq nv nw ll mr nx ny ln nz bi translated"><strong class="ak"> WGAN和WCGAN </strong></h2><p id="ea5f" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated"><strong class="lv ir"> Wasserstein GAN </strong>和<strong class="lv ir">Wasserstein Conditional GAN</strong>是GAN模型的最新扩展，其中用作鉴别器函数的正常<a class="ae kw" href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ir"> JS散度</strong> </a>矩阵被Wasserstein矩阵替代，wasser stein矩阵在某种意义上测量概率分布之间的距离，从而提供某种质量测量。当WGAN进一步以C类为条件以产生一个以上的标签时，WCGAN开始生效，这进一步提高了进一步学习的质量，这是对通过早期方法产生的合成数据的显著改进。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oc"><img src="../Images/707a43981c1d072ef32ada71428dfc3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x45o8f46a7P-hFmmYwqa7A.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><p id="4c35" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated"><strong class="lv ir"> <em class="lu">边注</em> - </strong>上述算法的实现可以通过Tensorflow和Keras来完成。对于WGAN的工作实现，请查看本文<a class="ae kw" href="https://pub.towardsai.net/how-to-generate-synthetic-data-4ae4ff156344" rel="noopener ugc nofollow" target="_blank"><strong class="lv ir">。</strong></a></p><h1 id="7942" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated"><strong class="ak">合成数据和数据隐私？</strong></h1><p id="809a" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">一开始，合成数据似乎是处理数据隐私的最有前途的方法。然而，要注意陈述，需要严格开发<strong class="lv ir">质量</strong>和<strong class="lv ir">隐私</strong>的参数，以给出明确的结论性事实。在质量领域，<strong class="lv ir">成对皮尔逊系数</strong>可用于确定合成数据与真实数据的质量【5】。该公式可以表述为-</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi od"><img src="../Images/633256ca1690633af6c1a26b8b563db7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rTGk6c6lqabc-KPGVHUSQw.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><p id="c35b" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">差异越小，合成数据就越接近真实数据。关于哪种模型最适合生成合成数据的问题需要解释一下。一般来说，已经观察到模型的选择取决于数据集。更正式地说，为了找出哪个模型效果最好，我们可以<strong class="lv ir">设计一个系统</strong>，它通过所有四个模型检查合成数据的质量和隐私，并以系统的方式得出结论。但是纯粹从隐私的角度来说，GANs是最突出的。简单的原因是，与VAE和SOTE不同，GAN不需要真实数据集作为核心输入，即它们的生成器完全与真实数据集分离。随着WGAN和WCGAN的进一步改进，我们可能会朝着正确的方向快速解决数据隐私问题。</p><h1 id="2728" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated"><strong class="ak">结论</strong></h1><p id="8192" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">尽管合成数据集的调整可能是朝着正确方向迈出的重要一步，但仅靠它们并不能完全防止隐私泄露。真正的解决方案必须是各种技术的理想组合，如<strong class="lv ir"><em class="lu">【WCGAN+差分隐私</em>。尽管该研究领域还处于起步阶段，但是已经出现了许多新的解决方案，这些方案综合了学术界和工业界的关注。例如，<a class="ae kw" href="https://syntheticdata.community/" rel="noopener ugc nofollow" target="_blank"><strong class="lv ir">Synthetic data . community</strong></a>，一个开源社区提供了像WGAN、Time Synthetic GAN这样的工作深度学习模型来生成合成数据。不仅如此，学术研究也在迅速赶上。虽然速度令人印象深刻，但这些技术层必须足够强大，以允许我们处理隐私的软件和硬件方面，并维护所谓的四个基本支柱(如上所述)。</strong></p><blockquote class="lp lq lr"><p id="52bc" class="ls lt lu lv b lw lx jr ly lz ma ju mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">总之，虽然人工智能可能使我们能够扮演上帝之手，但数据的隐私需要得到确保，以便我们不会最终烧伤自己的手。</p></blockquote><h2 id="dd13" class="no ky iq bd kz np nq dn ld nr ns dp lh mp nt nu lj mq nv nw ll mr nx ny ln nz bi translated"><strong class="ak">参考文献</strong></h2><p id="4631" class="pw-post-body-paragraph ls lt iq lv b lw ms jr ly lz mt ju mb mp mu me mf mq mv mi mj mr mw mm mn mo ij bi translated">[1] Carlini，Nicholas等，<em class="lu">秘密分享者:评估和测试神经网络中的非故意记忆(2019) </em>，第28届USENIX安全研讨会(USENIX安全19)。</p><p id="2b68" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">[2] Dwork C .，McSherry F .，Nissim K .，Smith A. (2006) <em class="lu">在私有数据分析中校准噪声对灵敏度</em>。载于:Halevi S .，Rabin T .(编辑)密码学理论。TCC 2006。计算机科学讲义，第3876卷。斯普林格，柏林，海德堡。<a class="ae kw" href="https://doi.org/10.1007/11681878_14" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/11681878_14</a></p><p id="2dc9" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">[3]舒拉、鲍耶、霍尔和凯格尔迈耶(2002年)。<em class="lu"> SMOTE:合成少数过采样技术</em>。《人工智能研究杂志》<em class="lu">第16期</em>，第321至357页。</p><p id="f90f" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">[4]古德费勒等人(2014)。生成对抗网络。<em class="lu">神经信息处理系统进展</em>，第2672至2680页。</p><p id="f539" class="pw-post-body-paragraph ls lt iq lv b lw lx jr ly lz ma ju mb mp md me mf mq mh mi mj mr ml mm mn mo ij bi translated">[5] Beaulieu-Jones，Wu等，(2019) <em class="lu">隐私保护的生成式深度神经网络支持临床数据共享，</em>心血管质量与结果杂志<a class="ae kw" href="https://doi.org/10.1161/CIRCOUTCOMES.118.005122" rel="noopener ugc nofollow" target="_blank">、</a></p></div></div>    
</body>
</html>