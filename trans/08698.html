<html>
<head>
<title>Evaluation Metrics: Assessing the quality of NLG outputs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评价指标:评估NLG产出的质量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluation-metrics-assessing-the-quality-of-nlg-outputs-39749a115ff3?source=collection_archive---------13-----------------------#2021-08-11">https://towardsdatascience.com/evaluation-metrics-assessing-the-quality-of-nlg-outputs-39749a115ff3?source=collection_archive---------13-----------------------#2021-08-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5a88" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用评估指标自动化NLG输出的评估流程，以节省时间并增加评分实例的容量。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d74ff2b69c30bd29adcfe062f29c1ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tKs-DHjujYYMGjZO"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">詹妮弗·伯克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c9e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们开始之前；对于那些想直接跳到计算中并在他们的语料库上看到结果的人；最近，我们开源了一个用于评估NLG系统的Python包“Jury”。要为您的NLG模型计算指标，并对它们进行比较，您可以看看这个项目，并且您可以用几行代码轻松地进行设置:)。也可以阅读评审团的<a class="ae kv" href="https://medium.com/codable/jury-evaluating-performance-of-nlg-models-730eb9c9999f" rel="noopener">官方博文。</a></p><p id="6821" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">评委:<a class="ae kv" href="https://github.com/obss/jury" rel="noopener ugc nofollow" target="_blank">https://github.com/obss/jury</a>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="1955" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在机器学习领域，就像在最不相关的领域一样，我们需要某种评估。你可以想到一个学生参加考试，一辆汽车进行碰撞测试，一个web服务器进行负载测试，以及在AI中对一个模型进行性能评估。这些领域中的评估方法不同，进化标准设计也不尽相同。此程序主要用于评估模型输出的质量，以及在不同模型或不同设置之间进行比较等。</p><p id="8494" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自然语言生成(NLG)是自然语言处理(NLP)的一个领域，是人工智能的一个应用子领域，其目标是产生文本输出。它有大量的子任务，如机器翻译(MT)、问题回答(QA)、摘要、问题生成(QG)等。这里，讨论是围绕输出为文本的模型的性能。NLG主要是文本到文本，但一些NLG度量也可以应用并已经被采用，例如，评估语音到文本模型(如音素级别的编辑距离)。</p><p id="1d15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然像[3]、[4]和[6]这样的早期作品是自动化评估度量发展的先驱，但它们是原始和简单的度量，还不能捕捉语言特征的一些复杂方面。他们开创的时代很快带来了改进的度量标准，其中一些被许多NLG任务广泛采用，但仍有关于它们是否足够的讨论。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="7e2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有两种常见的方法来评估生成文本的质量(实际上有三种根据<a class="ae kv" href="https://en.wikipedia.org/wiki/Natural-language_generation#Evaluation" rel="noopener ugc nofollow" target="_blank">这篇</a>维基百科的文章):</p><p id="eb8d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人工评估:由人工评定者对生成的文本的质量进行评定的过程。通常，生成的输出被分发给一组人类评定者以增加多样性。</p><p id="0b13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ii)度量:</strong>通过自动度量对生成的文本进行评级的过程，这可能需要在创建之前进行人工干预(我稍后会谈到这一点)。虽然它们中的许多都是针对特定的任务(如机器翻译)，但它们普遍适用于其他NLG任务。</p><p id="2429" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这两种方法的主要区别在于保真度和努力/时间之间的权衡。人工评估是衡量生成文本质量的一种更好的方法，但它的成本很高。另一方面，度量具有成本效益，可以应用于大量生成的语料库，尽管它们可能不如人工评估好，并且还需要正确的参考语料库来比较生成的文本。</p><p id="7f2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由[13]提出的NLG评估指标的一个很好的分类法(如果你想深入研究一篇调查论文，我强烈推荐你看一下这篇论文)，其中任务不可知的或任务相关的指标也被区分如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lz"><img src="../Images/8c07d0c084e4b50d7f5ee50de8b43168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8NWfX75K6pFeKXgV4aEIvg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">自动评估指标的分类[13]。</p></figure><p id="b4d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，在这里，我将评估指标分为4组，以进行总结并保持易读性:</p><ul class=""><li id="c11f" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated">字符串度量</li><li id="b89b" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">基于n元语法的度量</li><li id="8a69" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">基于嵌入的度量</li><li id="603b" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">学习功能</li></ul><h2 id="f18b" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated"><strong class="ak"> 1。字符串度量</strong></h2><p id="9337" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">这些是人工智能领域中用于文本输出的最早的度量标准。他们在字符或音素水平上工作。通常，这些指标属于<a class="ae kv" href="https://en.wikipedia.org/wiki/Edit_distance" rel="noopener ugc nofollow" target="_blank">编辑距离</a>系列。这一组中的大多数指标利用了编辑距离的三个主要组成部分:插入(I)、删除(D)和替换(S)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/73ab803ecaa3df6b4d746d00ab309376.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*Fi_2ECU78-xAM3JjYcfPdA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">编辑将“裁缝”转换为“帆船”，ED = 4。</p></figure><p id="702a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的例子被广泛称为Levenshtein距离[6]。如果指标不使用替换，那么替换将计为2次操作，替换为序列删除和插入(反之亦然)，参见最长公共子序列(LCS)距离。</p><p id="4e31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该组指标的早期版本基本上不考虑流畅性、句法和语义完整性，仅考虑词汇一致性。然而，改进的版本试图通过考虑短语转换、释义、同义词等来填补这一空白。</p><p id="69f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多利用编辑操作的推导，Wagner-Fischer算法[11]，Levenshtein距离[6]，Hamming距离[3]等。除了在文本到文本的任务中使用之外，这些指标也被语音识别应用程序所采用。您可以看到一个<a class="ae kv" href="https://en.wikipedia.org/wiki/String_metric#List_of_string_metrics" rel="noopener ugc nofollow" target="_blank">字符串指标列表</a>。</p><h2 id="c69c" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">2.基于n元语法的度量</h2><p id="565e" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">这些度量使用<a class="ae kv" href="https://en.wikipedia.org/wiki/N-gram" rel="noopener ugc nofollow" target="_blank"> n-grams </a>在生成的文本和参考语料库之间进行计算。这一组中广泛使用和众所周知的例子是BLEU，它在参考语料库中寻找n元语法的对应，但是不考虑句法完整性和语法正确性。例如，BLEU使用n元语法的顺序参数来计算n元语法的精度。作者提出简短惩罚来近似人类对短句的判断。</p><p id="d8b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为这个集合中的一个示例成员，您可以看到候选项2的二元模型精度的计算，这是计算n元文法顺序≥ 2的bleu分数所需要的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/e17e15e5ce1e196f4a8bedc036e17314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*j_NhsRpJ6-BuLptY.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://present5.com/cs-388-natural-language-processing-machine-translation-raymond/" rel="noopener ugc nofollow" target="_blank">https://present 5 . com/cs-388-自然语言-处理-机器翻译-raymond/ </a></p></figure><p id="fda0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">早期的实验表明，BLEU是许多NLG任务的良好指标，因为它与人类的判断密切相关。然而，目前人们认为BLEU可能会带来误导性的结果。<a class="ae kv" rel="noopener" target="_blank" href="/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213">这里</a>是一篇详细的文章，聚焦于BLEU引起的潜在副作用，并提到了<a class="no np ep" href="https://medium.com/u/703b09baff4e?source=post_page-----39749a115ff3--------------------------------" rel="noopener" target="_blank"> Rachael Tatman </a>提出的替代方法。</p><p id="48b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个群体的一些成员有BLEU [10]，METEOR [1]，ROUGE [7]，NIST [2]，单词错误率(WER)[19]，翻译编辑率(TER) [16]，TER-Plus (TERP) [17]等。虽然像WER和TER这样的度量标准是从编辑距离中派生出来的，但它们是在单词级别上工作的，而不是在字符或音素级别上。</p><h2 id="7d5f" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">3.基于嵌入的度量</h2><p id="3433" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">这组指标利用语言模型(LM)表示来计算相似性或不相似性的得分。通过LM获得生成的文本和参考语料库的嵌入，然后使用余弦相似性或相似性度量来计算相似性或不相似性。使用合适的LM可以在字符、单词、句子、段落或语料库级别上获得嵌入。人们可以简单地创建带有嵌入和某种相似或相异度量的定制计算。</p><p id="b118" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于嵌入和LMs的众多级别，该组中的指标相当多样化。通过不同级别嵌入和不同LMs的组合，可以设计通用的度量或用于特定的任务。</p><p id="9612" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这组中的几个度量是嵌入平均[5]，贪婪匹配[12]，BERTscore [20]，YiSi [8]。这一组中常用的成员是BERTScore，它使用BERT单词嵌入来计算候选单词和参考单词相对于候选单词和参考单词彼此的相似性(余弦相似性)。以这种方式可以看出，它类似于F1分数。我不打算在这里深入讨论细节，但简单地说，它还可以选择使用逆文档频率(IDF)对每个单词嵌入的余弦相似性得分进行加权。这意味着对稀有单词的匹配奖励更多，对常用单词的匹配奖励更少。BERTScore计算阶段如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/e3f88a28d33b4933360f6e100fea30ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uzIIqZSnpvYKpp8Z.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://github.com/Tiiiger/bert_score</p></figure><blockquote class="nr ns nt"><p id="d509" class="kw kx nu ky b kz la jr lb lc ld ju le nv lg lh li nw lk ll lm nx lo lp lq lr ij bi translated"><strong class="ky ir">一艘</strong>宇宙飞船是<strong class="ky ir">一艘</strong>被设计用来在外层空间飞行的运载工具或机器。<strong class="ky ir">一种</strong>类型的人造卫星，宇宙飞船被用于<strong class="ky ir">一</strong>多种用途，包括通讯、地球观测、气象、导航、太空殖民、行星<strong class="ky ir">探索</strong>以及运输人类和货物。</p><p id="c6fe" class="kw kx nu ky b kz la jr lb lc ld ju le nv lg lh li nw lk ll lm nx lo lp lq lr ij bi translated">来源:<a class="ae kv" href="https://en.wikipedia.org/wiki/Spacecraft" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Spacecraft</a></p></blockquote><p id="495d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，单词<em class="nu">“a”</em>由于经常出现而具有低权重，而单词<em class="nu">“exploration”</em>由于很少出现在语料库中而具有较高权重。</p><h2 id="37f8" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">4.学习功能</h2><p id="8405" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">这组指标的目的是找到一个映射<em class="nu"> f: (P，R)&gt;人类评级</em>，其中<em class="nu"> P </em>是预测(或生成的文本)，R是引用<em class="nu">。</em>这些通过预训练回归模型提供预测和参考的端到端评估。</p><p id="6c0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些模型的输入可以有很大的不同，有些使用单词或文本嵌入，有些使用提取的统计数据和/或简单的指标(准确性、F1等。)来自预测和参考等等。</p><p id="8ed5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个群体的一些成员有格勒乌[9]，比尔[18]，鲁斯[15]，布莱特[14]等。例如，啤酒使用其他单词级别的指标，如召回率、精确度和F1分数，将生成的文本映射到人类评级。另一方面，RUSE使用预测和参考的句子级嵌入来计算分数。BLEURT是一个预训练的BERT模型，顶部有一个线性层。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/968a09bce8e061ee51a6d319519df7e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/0*5CrBqgS7bZ3zb-7q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://ai.googleblog.com/2020/05/evaluating-natural-language-generation.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2020/05/evaluating-natural-language-generation . html</a></p></figure><p id="09af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所看到的，BLEURT有两个预训练阶段，然后在公共人类评级上进行微调。可选地，它可以针对应用特定的人工评级进行微调，以用于手边的特定任务。下面，你可以看到BLEURT评价的几个候选句子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/2cc91470dbf5ba66b1355c4a34753580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/0*R35BC33mxTz_urtK.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://ai.googleblog.com/2020/05/evaluating-natural-language-generation.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2020/05/evaluating-natural-language-generation . html</a></p></figure><h1 id="43b6" class="oa mp iq bd mq ob oc od mt oe of og mw jw oh jx mz jz oi ka nc kc oj kd nf ok bi translated">最后的话</h1><p id="6cdb" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">我试图总结用于NLG系统的评估指标。到目前为止，我们涵盖了4个主要类别，它们(在某种意义上)是按时间顺序排列的。尽管这些度量标准简化了评估过程并减少了工作量，但是您应该使用相对更适合您的任务的度量标准。[13]举例说明了一些任务中几个指标的用法，如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d5b7dc350f966889ad442b3489e7b403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*ItCktGSoMYagcqUaq1QURA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">任务间自动评估度量的使用。[13]</p></figure><h2 id="5a66" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">承认</h2><p id="3c58" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">特别感谢<a class="no np ep" href="https://medium.com/u/e16ae3a11a91?source=post_page-----39749a115ff3--------------------------------" rel="noopener" target="_blank"> Cemil Cengiz </a>的宝贵反馈，以及所有obss ml团队的讨论和支持。</p><h1 id="c811" class="oa mp iq bd mq ob oc od mt oe of og mw jw oh jx mz jz oi ka nc kc oj kd nf ok bi translated"><strong class="ak">参考文献</strong></h1><p id="3693" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">班纳吉，s .，&amp;拉维，A. (2005年6月)。METEOR:一种与人类判断有改进相关性的机器翻译评估的自动度量。在<em class="nu">关于机器翻译和/或摘要的内在和外在评估措施的acl研讨会会议录</em>(第65–72页)。</p><p id="8341" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">多丁顿，G. (2002年3月)。基于n元语法共现统计的机器翻译质量自动评估。第二届人类语言技术研究国际会议论文集<em class="nu">(第138-145页)。</em></p><p id="efa3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【3】</strong>海明，R. W. (1950)。错误检测和纠错码。<em class="nu">贝尔系统技术期刊</em>，<em class="nu"> 29 </em> (2)，147–160。</p><p id="f22f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【4】</strong>亨特，M. J. (1990)。评估连接词识别器的品质因数。<em class="nu">言语交际</em>，<em class="nu"> 9 </em> (4)，329–336。</p><p id="e0a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【5】</strong>兰道尔，t . k .&amp;杜迈斯，S. T. (1997)。柏拉图问题的解决方案:知识的获取、归纳和表征的潜在语义分析理论。<em class="nu">心理复习</em>，<em class="nu"> 104 </em> (2)，211。</p><p id="0d5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【6】</strong>Levenshtein，V. I. (1966年2月)。能够纠正删除、插入和反转的二进制代码。在<em class="nu">苏联物理学多克拉迪</em>(第10卷第8期第707–710页)。</p><p id="9ab0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">林春燕(2004年7月)。Rouge:一个自动评估摘要的包。在<em class="nu">中，文本摘要分支出</em>(第74-81页)。</p><p id="a649" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【8】</strong>Lo，C. K. (2019，8月)。YiSi --一个统一的语义机器翻译质量评估和估计标准，适用于具有不同级别可用资源的语言。在<em class="nu">第四届机器翻译会议论文集(第二卷:共享任务论文，第一天)</em>(第507–513页)。</p><p id="841b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【9】羊肉，a，德拉斯，m，万，s，&amp;戴尔，R. (2007，6月)。GLEU:句子级流利度自动评测。在<em class="nu">计算语言学协会第45届年会的会议录</em>(第344-351页)。</p><p id="b602" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【10】</strong>帕皮尼，k，鲁科斯，s，沃德，t，&amp;朱，W. J. (2002年7月)。Bleu:一种自动评估机器翻译的方法。计算语言学协会第40届年会论文集(第311-318页)。</p><p id="55dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">罗伯特·a·瓦格纳和迈克尔·j·费舍尔。1974.<em class="nu">串对串校正问题</em>。《美国计算机学会杂志》第21卷，第1期(1974年1月)，第168-173页。DOI:https://DOI . org/10.1145/321796.321811</p><p id="26ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【12】</strong>俄罗斯，v .&amp;林泰恩，M. (2012年6月)。使用单词到单词的相似性度量对自然语言学生输入的最佳评估。在<em class="nu">智能教学系统国际会议上</em>(第675–676页)。斯普林格，柏林，海德堡。</p><p id="81fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【13】</strong>赛，A. B .，莫汉库马尔，A. K .，&amp;哈普拉，M. M. (2020)。用于NLG系统的评价标准综述。arXiv预印本arXiv:2008.12009 </p><p id="7260" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【14】</strong>t . Sellam，d . Das，&amp; Parikh，A. P. (2020)。BLEURT:学习文本生成的健壮度量。arXiv预印本arXiv:2004.04696 </p><p id="8145" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【15】</strong>岛中香，h .，Kajiwara，t .，&amp;小牧，M. (2018，10月)。Ruse:使用句子嵌入进行自动机器翻译评估的回归器。在<em class="nu">第三届机器翻译会议论文集:共享任务论文</em>(第751–758页)。</p><p id="6f41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"><strong class="ky ir"/>斯诺弗，m .，多尔，b .，施瓦茨，r .，米丘拉，l .，&amp;马霍尔，J. (2006年)。有针对性人工标注的翻译编辑率研究。在<em class="nu">美洲机器翻译协会第七届会议论文集:技术论文</em>(第223–231页)。</strong></p><p id="2e7d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"/>斯诺弗，马修&amp;马德纳尼，尼廷&amp;多尔，邦妮&amp;施瓦茨，理查德。(2009).TER-Plus:翻译编辑率的释义、语义和对齐增强。机器翻译。23.117–127.10.1007/s 10590–009–9062–9。</p><p id="4235" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"><em class="nu"/></strong>斯塔诺耶维奇，m .&amp;西玛安，K. (2014年6月)。啤酒:作为排名更好的评价。第九届统计机器翻译研讨会论文集(第414-419页)。</p><p id="1559" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">，[19]，</strong>苏桂英，吴明伟，&amp;常建生(1992)。机器翻译系统的一种新的定量质量度量。载于【1992年第2卷:第14届计算语言学国际会议。</p><p id="128e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【20】</strong>张，t，基肖尔，v，吴，f，温伯格，k . q .&amp;阿奇，Y. (2019)。bertscore:用Bert评估文本生成。<em class="nu"> arXiv预印本arXiv:1904.09675 </em>。</p></div></div>    
</body>
</html>