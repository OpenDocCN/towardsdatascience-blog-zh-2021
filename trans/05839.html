<html>
<head>
<title>Inside Quantization Aware Training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">内部量化感知训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/inside-quantization-aware-training-4f91c8837ead?source=collection_archive---------10-----------------------#2021-05-25">https://towardsdatascience.com/inside-quantization-aware-training-4f91c8837ead?source=collection_archive---------10-----------------------#2021-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="c88c" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="54c7" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">深入理解高效模型优化技术的指南</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/e88da62b5a58fb61db7eff32c066ef40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*L0CHszJp7v-8CKg7"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@ikukevk?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">凯文·Ku</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="6282" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">介绍</h1><p id="b789" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">随着我们学习利用人工智能来完成各种简单和复杂的任务，深度神经网络的现实世界应用日益增加。然而，深度神经网络的问题是它们涉及太多参数，由于这些参数，它们需要强大的计算设备和大容量存储器。这使得它几乎不可能在Android等计算能力较低的设备和其他低功耗边缘设备上运行。量化等优化技术可以用来解决这个问题<strong class="lz ja">。</strong>借助不同的量化技术，我们可以将参数的精度从float降低到int8等较低精度，从而实现高效的计算和更少的存储量。最佳量化技术之一是量化感知训练。在本帖中，我们将详细了解它的机制。</p><h1 id="2c33" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">什么是量化感知训练？</h1><p id="f024" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">当我们从浮点型转换到较低精度时，我们通常会注意到精度显著下降，因为这是一个有损耗的过程。借助quant-aware培训，这种损失可以降至最低。所以基本上，quant-aware训练模拟前向传递中的低精度行为，而后向传递保持不变。这导致了一些量化误差，该误差在模型的总损失中累积，因此优化器试图通过相应地调整参数来减少该误差。这使得我们的参数对量化更加鲁棒，使得我们的过程几乎无损。</p><h1 id="576c" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">是如何表现的？</h1><p id="cab6" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">我们首先决定一个量化方案。这意味着决定我们要包含哪些因素，以便在信息损失最小的情况下将浮点值转换为精度较低的整数值。在本文中，我们将使用[1]中使用的量化方案作为参考。为此，我们引入了两个新参数:标度和零点。顾名思义，scale参数用于将低精度值调整回浮点值。它以完全精确的方式存储，以获得更高的准确性。另一方面，零点是表示量化值的低精度值，该量化值将表示真实值0。零点的好处是，即使对于斜张量，我们也可以有更宽的整数值范围。因此，实值(r)可以通过以下方式从量化值(q)中导出:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/203dd4a9e7a245d95e62dbb9ad121edb.png" data-original-src="https://miro.medium.com/v2/resize:fit:204/format:webp/1*vADAUBtg1zFSbu9u1FztWA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式1</p></figure><p id="4a23" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">这里S和Z分别代表刻度和零点。</p><p id="d3a3" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">在涉及计算的每个操作之后，我们在我们的模型中引入一种叫做FakeQuant的节点，以获得我们所要求的精度范围内的输出。FakeQuant节点基本上是量化和反量化操作的组合。</p><h2 id="2574" class="mz lg iq bd lh na nb dn ll nc nd dp lp mg ne nf lr mk ng nh lt mo ni nj lv iw bi translated">量化操作</h2><p id="9014" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">它的主要作用是将张量的浮点值转换为低精度整数值。这是基于上面讨论的量化方案完成的。标度和零点按以下方式计算:</p><p id="e093" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">比例的主要作用是将浮动范围内的最低和最高值映射到量化范围内的最高和最低值。在8位量化的情况下，量化范围将是[-128，127]。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/0bc99b644c9f2308d00c4554b8f2e12c.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*K8I-xgSuPe0v9pqYhPODbQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式2</p></figure><p id="2153" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">这里fₘₐₓ和fₘᵢₙ代表浮点精度的最大值和最小值，qₘₐₓ和qₘᵢₙ代表量化范围的最大值和最小值。</p><p id="a4c5" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">同样，我们可以通过在浮点极值和量化值之间建立线性关系来找到零点。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/f02775480cb944916d309db4a92cae49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NU8twLrUjRt7e8VVv1lyhg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图一。从浮点域到量化域的缩放表示。来源:作者图片</p></figure><p id="b4c8" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">考虑到我们有一条直线上两点的坐标(qₘᵢₙ,fₘᵢₙ)和(qₘₐₓ,fₘₐₓ)，我们可以以y = mx +c的形式得到它的方程，x是量化值，y是实数值。所以为了得到量化域中0的映射，我们只需找到y=0时x的值。解决这个问题后，我们会得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/cb4e618f0123a81ec1f39444948246dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*wd2URTjDOB_C01ASOfjDUw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式3</p></figure><p id="4b10" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">但是如果0不在fₘₐₓ和fₘᵢₙ之间，我们的零点会超出量子化范围。为了克服这一点，我们可以将z设置为qₘₐₓ或qₘᵢₙ，这取决于它位于哪一侧。</p><p id="eac8" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">现在我们有了量化操作的一切，我们可以使用以下等式从浮点值获得量化值:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/af22e8d3be52300c4edb5d967d4aad69.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/format:webp/1*iHAgwbZrwnBWr6Dx9NmOMg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式4</p></figure><p id="3811" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">此外，我们将使用去量化操作将其转换回浮点域，以逼近原始值，但这会导致一些小的量化损失，我们将使用这些损失来优化模型。</p><h2 id="ca78" class="mz lg iq bd lh na nb dn ll nc nd dp lp mg ne nf lr mk ng nh lt mo ni nj lv iw bi translated">去量化操作</h2><p id="ee7d" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">为了获得真实值，我们将量化值放入等式1中，因此变为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi no"><img src="../Images/8d0fb335524c53a47bc0c73e4407f14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*1VsdfDyVdeQ06qS11Fl9dQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式5</p></figure><h2 id="1407" class="mz lg iq bd lh na nb dn ll nc nd dp lp mg ne nf lr mk ng nh lt mo ni nj lv iw bi translated">创建训练图</h2><p id="caff" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">现在我们已经定义了FakeQuant节点，我们需要确定将它们插入图中的正确位置。我们需要使用以下规则对权重和激活进行量化操作:</p><ul class=""><li id="6616" class="np nq iq lz b ma mu md mv mg nr mk ns mo nt ms nu nv nw nx bi translated">权重需要在与输入相乘或卷积之前进行量化。</li><li id="9b9e" class="np nq iq lz b ma ny md nz mg oa mk ob mo oc ms nu nv nw nx bi translated">我们的图表应该显示训练时的推理行为，因此BatchNorm层必须折叠，必须删除遗漏。关于BatchNorm折叠的详细信息可在<a class="ae le" href="https://scortex.io/batch-norm-folding-an-easy-way-to-improve-your-network-speed/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</li><li id="3b73" class="np nq iq lz b ma ny md nz mg oa mk ob mo oc ms nu nv nw nx bi translated">在将类似Relu的激活层应用于每一层之后，每一层的输出通常被量化，这是有益的，因为大多数优化的硬件通常具有与主操作融合的激活功能。</li><li id="4abb" class="np nq iq lz b ma ny md nz mg oa mk ob mo oc ms nu nv nw nx bi translated">我们还需要量化像Concat和Add这样的层的输出，其中几个层的输出被合并。</li><li id="5d26" class="np nq iq lz b ma ny md nz mg oa mk ob mo oc ms nu nv nw nx bi translated">我们不需要在训练期间量化偏差，因为我们将在推断期间使用int32偏差，并且稍后可以使用使用权重和激活的量化获得的参数来计算该偏差。我们将在这篇文章的后面讨论这个问题。</li></ul><p id="8042" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">天平和砝码零点的测定方法与上一节所讨论的一样简单。为了确定激活的标度和零点，我们需要在浮点域中保持激活的最大值和最小值的指数移动平均值，以便在从许多图像获得的数据上平滑我们的参数。</p><p id="42c0" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">因此，伪量化操作被插入到下图中，如下所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/9b0bfd1c5296ec5b03e0e2a8fbd44ace.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m6kx2S7nUELQWOmWBl0G7g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图二。量子感知训练图的可视化表示。来源:作者图片</p></figure><p id="dbaa" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">现在我们的图表已经准备好了，我们需要为训练做准备。在训练时，我们必须仅在前向通道中模拟量化行为以引入量化误差，后向通道保持不变，并且在训练期间仅更新浮点权重。为了在TensorFlow中实现这一点，我们可以借助@custom_gradient装饰器。这个装饰器帮助我们为任何操作定义自己的自定义渐变。</p><h2 id="fe35" class="mz lg iq bd lh na nb dn ll nc nd dp lp mg ne nf lr mk ng nh lt mo ni nj lv iw bi translated">创建评估或推理图</h2><p id="6e19" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">既然我们已经完成了我们的训练，并且我们的参数现在被调整用于更好的低精度推断，我们需要从获得的训练图中获得低精度推断图，以在优化的硬件设备上运行它。</p><ul class=""><li id="726f" class="np nq iq lz b ma mu md mv mg nr mk ns mo nt ms nu nv nw nx bi translated">首先，我们需要从上述模型中提取量化的权重，并将量化操作应用于在quant-aware训练期间获得的权重。</li><li id="c0dd" class="np nq iq lz b ma ny md nz mg oa mk ob mo oc ms nu nv nw nx bi translated">由于我们的优化函数将只接受低精度输入，我们还需要量化我们的输入。</li></ul><p id="d516" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">现在让我们来推导如何使用这些量化参数来获得量化结果。</p><p id="a62f" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">假设我们假设卷积是点运算。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/932310b858f144dd82c9b4a79531c2c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:148/format:webp/1*TC6Dffu8_bRiRu__iZI7OQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式6</p></figure><p id="b093" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">利用等式1，它也可以写成:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/8b9d8f0158f19d4b952951a7f347fa6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*JOcTMqP1MYDF16Dju6_2Sg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式7</p></figure><p id="5af3" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">为了获得量化值q₃，我们将等式重新排列为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi og"><img src="../Images/820d53be5e3de8f35e0ec0b46ac9aba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*kR_dy0fdA_2S3oPfoPqs5Q.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式8</p></figure><p id="e447" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">在这个等式中，我们可以在推理开始之前离线计算S₁S₂)/S₃，这可以用一个乘数m来代替</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/d4f6e777cb0370e90f9b24b1d8a4c321.png" data-original-src="https://miro.medium.com/v2/resize:fit:164/format:webp/1*7k-FfujTnAX3fQt7cp3LlQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式9</p></figure><p id="9d8d" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">现在，为了进一步将其简化为纯整数运算，我们尝试将M分解为两个整数值。m总是介于0和1之间，所以可以分解成这种形式。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/431782259012775037ec955f0c019bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:188/format:webp/1*iJmc6bzVYNMHuz9zkTB8RA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式10</p></figure><p id="1492" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">使用这个等式，我们可以获得M₀和n的整数值，它们将分别作为乘法器和逐位移位器的值。显然，如果我们可以在硬件上执行浮点乘法，就不需要这一步。</p><p id="6191" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">此外，我们需要相应地修改我们的偏见，因为我们的乘数也会影响它。因此，我们可以使用以下等式获得int32量化偏差以进行推断:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/58c9b26a21aa38283fe8358f9333f81d.png" data-original-src="https://miro.medium.com/v2/resize:fit:194/format:webp/1*Qa1FX6mKmtgek1_uP7p5NA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式11</p></figure><p id="7e5c" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">现在我们已经有了所有的成分，我们可以创建我们的低精度推理图，看起来像这样。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/6c74042c7cee69b056b53e50e086a3c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R0DUNIJ7UmdM4vBRy3_oVQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图3。量子推理图的表示。来源:作者图片</p></figure><p id="dedc" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">我们想把量子化的范围作为有符号的还是无符号的，这取决于我们。在上图中，它被认为是无符号的。</p><h1 id="c36a" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">量化感知训练值得努力吗？</h1><p id="51c1" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">我们已经知道了量化的重要性，也知道后量化有时会有很大的损失，量化感知培训是我们最好的选择。下表显示了使用一些流行和复杂的神经网络架构进行Quant-Aware训练的结果。我们可以观察到，在这种量化模式下，精度下降可以忽略不计。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/39ff8214036d3e03cf8e4d4e1dd367a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJzwDiKxRdmWZJQ40n5MUQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图4。量化感知训练的性能比较。来源:作者图片，数据来自<a class="ae le" href="https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html" rel="noopener ugc nofollow" target="_blank"> Tensorflow博客</a></p></figure><p id="1ba7" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">此外，我们不需要担心自己实现如此复杂的机制，因为Tensorflow为此提供了一个定义良好的API。你可以从<a class="ae le" href="https://www.tensorflow.org/model_optimization/guide/quantization/training" rel="noopener ugc nofollow" target="_blank">这里</a>了解一下。</p><h1 id="a5d1" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">参考</h1><p id="e724" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">[1] Benoit Jacob，Skirmantas Kligys，，Menglong Zhu，，，Hartwig Adam和Dmitry Kalenichenko，用于高效整数算术推理的神经网络的量化和训练[2017]</p><p id="8b7c" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">[2]<a class="ae le" href="https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html" rel="noopener ugc nofollow" target="_blank">https://blog . tensor flow . org/2020/04/quantization-aware-training-with-tensor flow-model-optimization-toolkit . html</a></p><p id="b219" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">[3]<a class="ae le" href="https://intellabs.github.io/distiller/algo_quantization.html#:~:text=This%20means%20that%20zero%20is,this%20exact%20quantization%20of%20zero" rel="noopener ugc nofollow" target="_blank">https://Intel labs . github . io/distiller/algo _ quantization . html #:~:text = This % 20 means % 20 that % 20 zero % 20 is，This % 20 exact % 20 quantization % 20 of % 20 zero</a></p><p id="2d75" class="pw-post-body-paragraph lx ly iq lz b ma mu ka mc md mv kd mf mg mw mi mj mk mx mm mn mo my mq mr ms ij bi translated">[4]<a class="ae le" href="https://scortex.io/batch-norm-folding-an-easy-way-to-improve-your-network-speed/" rel="noopener ugc nofollow" target="_blank">https://scortex . io/batch-norm-folding-an-easy-way-to-improve-your-network-speed/</a></p></div></div>    
</body>
</html>