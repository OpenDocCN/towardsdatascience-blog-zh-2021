<html>
<head>
<title>Increase model stability using Bagging in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中使用Bagging提高模型稳定性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/increase-model-stability-using-bagging-in-python-d407233d2d93?source=collection_archive---------31-----------------------#2021-10-18">https://towardsdatascience.com/increase-model-stability-using-bagging-in-python-d407233d2d93?source=collection_archive---------31-----------------------#2021-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c29d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们看看如何使用bagging技术增加模型的稳定性</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1447eff0a381771c371307a91bdf2ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mwPlo_dOuLX76WG4.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">装袋示例。作者图片</p></figure><p id="b65e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据科学家通常会寻找一个尽可能精确的模型。然而，他们还应该关注另一个术语，即稳定性。在这篇文章中，我解释了它是什么以及如何使用一种叫做“装袋”的技术来增加它。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="6e40" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">偏差-方差权衡</h1><p id="1944" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在机器学习中，预测误差可以分解为3部分:偏差的平方、方差和不可约误差。偏差是预测值与真实值相差多远的度量，方差衡量我们的模型在根据数据集的原始分布创建的样本上进行重新训练时的稳定性，不可约误差是无法消除的噪声项。研究这些术语并试图减少它们被称为偏差-方差权衡。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/9f663c08d46fb572a6a8ff16eb571725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*N40AQAHm8rcs5gN6.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0218" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下图更清楚地展示了偏差和方差是如何工作的。灰色目标是真实值，而红色叉号是使用训练数据集的不同重采样进行的预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/299a0a538b0570456796bba6e7436cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gnR0wpKmzxEhNqHG.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e488" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的目标是达到低偏差-低方差的情况，在这种情况下，我们的模型对再训练是稳定的，并且它的预测是正确的。然而，具有低偏差的模型(如XGBoost)往往会随着时间的推移而变得不稳定(高方差)，而具有低方差的模型(如随机森林)往往不太准确(低偏差)。数据科学家必须知道，他们是想创建一个不稳定的精确模型(需要频繁的重新训练)，还是创建一个更稳定的不太精确的模型。</p><p id="a34f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于模型训练是一项非常复杂和困难的任务，我更喜欢使用低方差的模型，以便随着时间的推移，以较低的性能为代价，获得更稳定的模型。</p><p id="892a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了减少偏差，可以使用一种称为升压的技术。为了减少差异，我们可以使用一种叫做装袋的技术。后者是本文的主题。</p><h1 id="ef3c" class="mb mc it bd md me na mg mh mi nb mk ml jz nc ka mn kc nd kd mp kf ne kg mr ms bi translated">装袋的工作原理</h1><p id="717f" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">装袋工作遵循<a class="ae nf" href="https://www.yourdatateacher.com/2021/04/19/the-bootstrap-the-swiss-army-knife-of-any-data-scientist/" rel="noopener ugc nofollow" target="_blank">自举</a>的统计原理。让我们考虑数据集的所有记录和所有特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/7fc56056608dbe42ccb2d8b9f52191c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2pLiopMKOb30tLzH.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="334f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们考虑我们的训练数据集的一些随机选择的样本，通过替换对我们的记录进行采样，并考虑列的随机子集。通过这种方式，我们可以创建不同的训练数据集来训练我们的模型，预先设置相同的超参数值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b0b5b3c3f14133f3dd9f15335b57660c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*R8BP_-m651mNN3RD.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="8dbc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，该模型集合可用于进行最终预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/f6cf49732e34b470ab30b8f0f643a172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4PBLo9t4Hd_wGAMg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="f1c9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于回归问题，通常使用模型预测的平均值。对于分类，软投票是首选。</p><p id="a3a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Bagging在数学上减少了我们模型的方差(即当我们在原始训练数据集的不同重新样本上训练我们的模型时，平均性能值周围的波动的度量)。最常见的bagging模型是随机森林，但是我们可以将bagging概念应用于每一个可能的模型。</p><p id="8070" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一些bagging技术使用没有替换的采样，并且样本的大小可以小于原始训练数据集的大小。因此，bagging引入了4个新的超参数:样本数、列数、要使用的记录分数、是否使用替换抽样。</p><p id="553a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们看看如何在Python中应用bagging进行回归和分类，并证明它实际上减少了方差。</p><h1 id="1290" class="mb mc it bd md me na mg mh mi nb mk ml jz nc ka mn kc nd kd mp kf ne kg mr ms bi translated">蟒蛇皮装袋</h1><p id="7345" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">现在让我们看看如何在Python中使用bagging。完整的代码可以在我的GitHub <a class="ae nf" href="https://github.com/gianlucamalato/collinearity/blob/main/Bagging.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="84ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们首先导入我们的数据集，即乳腺癌和糖尿病数据集。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="9b68" class="nn mc it nj b gy no np l nq nr">from sklearn.datasets import load_breast_cancer,load_diabetes</span></pre><p id="5f62" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们导入一个回归和一个分类模型。对于回归，我们将使用线性回归。对于分类，我们将使用高斯朴素贝叶斯模型。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="3eb0" class="nn mc it nj b gy no np l nq nr">from sklearn.linear_model import LinearRegression <br/>from sklearn.naive_bayes import GaussianNB</span></pre><p id="489c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了应用bagging，我们必须使用元估计器，将这种集成技术应用于给定的模型。在sklearn中，我们有打包分类器和开始分类器。让我们导入它们，让我们导入cross_val_score，以便计算方差。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="4e34" class="nn mc it nj b gy no np l nq nr">from sklearn.ensemble import BaggingClassifier,BaggingRegressor <br/>from sklearn.model_selection import cross_val_score</span></pre><p id="49e9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">先说分类。我们可以导入我们的数据集，训练我们的模型，并在10次交叉验证中计算一些性能指标的方差(比如平衡精度)。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="2d50" class="nn mc it nj b gy no np l nq nr">X,y = load_breast_cancer(return_X_y=True) </span><span id="e400" class="nn mc it nj b gy ns np l nq nr">nb = GaussianNB() </span><span id="585a" class="nn mc it nj b gy ns np l nq nr">cross_val_score(nb,X,y,scoring="balanced_accuracy",cv=10).var() <br/># 0.0011182285777794419</span></pre><p id="6299" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个方差是模型稳定性的度量。</p><p id="ed63" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们使用10个模型和原始列数的一半来应用bagging。在实际项目中，您希望使用像<a class="ae nf" href="https://www.yourdatateacher.com/2021/05/19/hyperparameter-tuning-grid-search-and-random-search/" rel="noopener ugc nofollow" target="_blank">网格搜索</a>这样的超参数调整技术来优化这些值。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="01d6" class="nn mc it nj b gy no np l nq nr">model = BaggingClassifier(GaussianNB(),n_estimators = 10, max_features = 0.5,random_state = 0, n_jobs = -1)</span></pre><p id="3f95" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，方差是:</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="6ebf" class="nn mc it nj b gy no np l nq nr">cross_val_score(model,X,y,scoring="balanced_accuracy",cv=10).var() <br/># 0.000944202642795715</span></pre><p id="fc9c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们看到的，它低于原始方差。因此，装袋减少了方差，使我们的模型更加稳定。</p><p id="a22b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们也可以将同样的概念应用于回归。让我们使用线性回归模型和R平方度量。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="2e72" class="nn mc it nj b gy no np l nq nr">X,y = load_diabetes(return_X_y=True) lr = LinearRegression() </span><span id="de92" class="nn mc it nj b gy ns np l nq nr">cross_val_score(lr,X,y,scoring="r2",cv=10).var() <br/># 0.021605440351612316</span></pre><p id="53b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们将BaggingRegressor应用于我们的模型，并计算新的方差:</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="aac3" class="nn mc it nj b gy no np l nq nr">model = BaggingRegressor(LinearRegression(),n_estimators = 10, max_features = 0.5,random_state = 0, n_jobs = -1) </span><span id="4da7" class="nn mc it nj b gy ns np l nq nr">cross_val_score(model,X,y,scoring="r2",cv=10).var() <br/># 0.013136832268767986</span></pre><p id="8d64" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它是原值的一半。所以，我们创造了一个更稳定的模型。</p><h1 id="c948" class="mb mc it bd md me na mg mh mi nb mk ml jz nc ka mn kc nd kd mp kf ne kg mr ms bi translated">结论</h1><p id="1b62" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">装袋是一种非常有用的技术，它从数学上增加了模型的稳定性。我认为，当您知道将来无法再次训练您的模型，并且希望构建一个随着时间推移而稳定的模型时，应该首选boosting。当然，监控模型性能对于机器学习项目的成功至关重要，但随着时间的推移，正确使用boosting会使您的模型更加稳定和健壮，但代价是性能下降。有时，增加模型的稳定性可能比增加其准确性更可取，bagging就是这样工作的。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><p id="6794" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nt"> Gianluca Malato是一名数据科学家，在</em><a class="ae nf" href="http://www.yourdatateacher.com/" rel="noopener ugc nofollow" target="_blank"><em class="nt"/></a><em class="nt">上教授机器学习和数据科学。</em></p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><p id="cc08" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nt">原载于2021年10月18日https://www.yourdatateacher.com</em><em class="nt">的</em> <a class="ae nf" href="https://www.yourdatateacher.com/2021/10/18/increase-model-stability-using-bagging-in-python/" rel="noopener ugc nofollow" target="_blank"> <em class="nt">。</em></a></p></div></div>    
</body>
</html>