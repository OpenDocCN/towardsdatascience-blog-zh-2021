<html>
<head>
<title>How To Change The Column Names Of PySpark DataFrames</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何更改PySpark数据帧的列名</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-change-the-column-names-of-pyspark-dataframes-46da4aafdf9a?source=collection_archive---------7-----------------------#2021-08-20">https://towardsdatascience.com/how-to-change-the-column-names-of-pyspark-dataframes-46da4aafdf9a?source=collection_archive---------7-----------------------#2021-08-20</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="4c1f" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">讨论PySpark数据框架中改变列名的5种方法</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/84dc6a99f611e912c5f06b0549c7b606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JNcXmHupRHORtgXrSQlTJQ.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://unsplash.com/@dreamsoftheoceans?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Linus Nylund </a>在<a class="ae kz" href="https://unsplash.com/s/photos/change?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="b740" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">介绍</h2><p id="ffc0" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在今天的简短指南中，我们将讨论在Spark数据帧中更改列名的4种方法。具体来说，我们将使用以下工具来探索如何做到这一点:</p><ul class=""><li id="a25e" class="mp mq iu ly b lz mr mc ms lj mt ln mu lr mv mo mw mx my mz bi translated"><code class="fe na nb nc nd b">selectExpr()</code>方法</li><li id="e8ca" class="mp mq iu ly b lz ne mc nf lj ng ln nh lr ni mo mw mx my mz bi translated"><code class="fe na nb nc nd b">withColumnRenamed()</code>方法</li><li id="52b2" class="mp mq iu ly b lz ne mc nf lj ng ln nh lr ni mo mw mx my mz bi translated"><code class="fe na nb nc nd b">toDF()</code>法</li><li id="9568" class="mp mq iu ly b lz ne mc nf lj ng ln nh lr ni mo mw mx my mz bi translated">别名</li><li id="faa2" class="mp mq iu ly b lz ne mc nf lj ng ln nh lr ni mo mw mx my mz bi translated">Spark会话和Spark SQL</li></ul><p id="88b9" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">并一次重命名一列或多列。</p></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><p id="4a62" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">首先，让我们创建一个示例PySpark数据帧，我们将在本指南中引用它来演示一些概念。</p><pre class="kk kl km kn gu nt nd nu nv aw nw bi"><span id="3042" class="la lb iu nd b gz nx ny l nz oa">&gt;&gt;&gt; from pyspark.sql import SparkSession</span><span id="43f2" class="la lb iu nd b gz ob ny l nz oa"># Create an instance of spark session<br/>&gt;&gt;&gt; spark_session = SparkSession.builder \<br/>    .master('local[1]') \<br/>    .appName('Example') \<br/>    .getOrCreate()</span><span id="1aec" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df = spark_session.createDataFrame(<br/>    [<br/>       (1, 'a', True, 1.0),<br/>       (2, 'b', False, 2.0),<br/>       (3, 'c', False, 3.0),<br/>       (4, 'd', True, 4.0),<br/>    ],<br/>    ['colA', 'colB', 'colC', 'colD']<br/>)</span><span id="05f2" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df.show()<br/><em class="oc">+----+----+-----+----+                                                          <br/>|colA|colB| colC|colD|<br/>+----+----+-----+----+<br/>|   1|   a| true| 1.0|<br/>|   2|   b|false| 2.0|<br/>|   3|   c|false| 3.0|<br/>|   4|   d| true| 4.0|<br/>+----+----+-----+----+</em></span><span id="fd90" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df.printSchema()<br/><em class="oc">root<br/> |-- colA: long (nullable = true)<br/> |-- colB: string (nullable = true)<br/> |-- colC: boolean (nullable = true)<br/> |-- colD: double (nullable = true)</em></span></pre></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><h2 id="e033" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用selectExpr()</h2><p id="2263" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">第一个选项是<code class="fe na nb nc nd b"><a class="ae kz" href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.selectExpr.html" rel="noopener ugc nofollow" target="_blank">pyspark.sql.DataFrame.selectExpr()</a></code>方法，它是接受SQL表达式的<code class="fe na nb nc nd b"><a class="ae kz" href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.select.html#pyspark.sql.DataFrame.select" rel="noopener ugc nofollow" target="_blank">select()</a></code>方法的变体。</p><pre class="kk kl km kn gu nt nd nu nv aw nw bi"><span id="be98" class="la lb iu nd b gz nx ny l nz oa"><strong class="nd iv">&gt;&gt;&gt; df =  df.selectExpr(<br/>    'colA AS A',<br/>    'colB AS B',<br/>    'colC AS C',<br/>    'colD AS D',<br/>)</strong></span><span id="d0be" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df.show()<br/><em class="oc">+---+---+-----+---+<br/>|  A|  B|    C|  D|<br/>+---+---+-----+---+<br/>|  1|  a| true|1.0|<br/>|  2|  b|false|2.0|<br/>|  3|  c|false|3.0|<br/>|  4|  d| true|4.0|<br/>+---+---+-----+---+</em></span></pre><p id="075d" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">但是请注意，当您需要重命名大多数列，并且还必须处理相对较少的列时，这种方法最适合。</p><p id="57c4" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">此时，您可能还想回忆一下Spark中<code class="fe na nb nc nd b">select()</code>和<code class="fe na nb nc nd b">selectExpr()</code>的区别:</p><div class="od oe gq gs of og"><a rel="noopener follow" target="_blank" href="/select-vs-selectexpr-in-spark-412a59416615"><div class="oh ab fp"><div class="oi ab oj cl cj ok"><h2 class="bd iv gz z fq ol fs ft om fv fx it bi translated">Spark中的select()与selectExpr()</h2><div class="on l"><h3 class="bd b gz z fq ol fs ft om fv fx dk translated">讨论Spark中select()和selectExpr()方法的区别</h3></div><div class="oo l"><p class="bd b dl z fq ol fs ft om fv fx dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="oq l or os ot op ou kt og"/></div></div></a></div></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><h2 id="5833" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用withColumnRenamed()</h2><p id="c705" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">重命名PySpark数据帧列的第二个选项是<code class="fe na nb nc nd b"><a class="ae kz" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.withColumnRenamed.html" rel="noopener ugc nofollow" target="_blank">pyspark.sql.DataFrame.withColumnRenamed()</a></code>。此方法通过重命名现有列来返回新的DataFrame。</p><pre class="kk kl km kn gu nt nd nu nv aw nw bi"><span id="8c3e" class="la lb iu nd b gz nx ny l nz oa"><strong class="nd iv">&gt;&gt;&gt; df = df.withColumnRenamed('colA', 'A')</strong></span><span id="6c23" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df.show()<br/><em class="oc">+---+----+-----+----+<br/>|  A|colB| colC|colD|<br/>+---+----+-----+----+<br/>|  1|   a| true| 1.0|<br/>|  2|   b|false| 2.0|<br/>|  3|   c|false| 3.0|<br/>|  4|   d| true| 4.0|<br/>+---+----+-----+----+</em></span></pre><p id="2b5c" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">当您需要一次重命名一列时，这种方法最合适。如果您需要一次性重命名多个列，那么本文中讨论的其他方法会更有帮助。</p></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><h2 id="da24" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用toDF()方法</h2><p id="ebae" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">方法使用新的指定列名返回一个新的DataFrame。</p><pre class="kk kl km kn gu nt nd nu nv aw nw bi"><span id="ade8" class="la lb iu nd b gz nx ny l nz oa"><strong class="nd iv">&gt;&gt;&gt; df = df.toDF('A', 'colB', 'C', 'colD')</strong></span><span id="2df7" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df.show()<br/><em class="oc">+---+----+-----+----+<br/>|  A|colB|    C|colD|<br/>+---+----+-----+----+<br/>|  1|   a| true| 1.0|<br/>|  2|   b|false| 2.0|<br/>|  3|   c|false| 3.0|<br/>|  4|   d| true| 4.0|<br/>+---+----+-----+----+</em></span></pre><p id="d572" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">当您需要<strong class="ly iv">同时重命名多个列</strong>时，这种方法很有用。</p><p id="9352" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">请注意，如果您有一个包含新列名的列表，那么下面的代码也应该可以完成这个任务:</p><pre class="kk kl km kn gu nt nd nu nv aw nw bi"><span id="d923" class="la lb iu nd b gz nx ny l nz oa">&gt;&gt;&gt; new_col_names = ['A', 'colB', 'C', 'colD']<br/>&gt;&gt;&gt; <strong class="nd iv">df = df.toDF(*new_col_names)</strong></span></pre></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><h2 id="e2d0" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用别名</h2><p id="2663" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">我们的另一个选择是使用<code class="fe na nb nc nd b"><a class="ae kz" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.alias.html" rel="noopener ugc nofollow" target="_blank">alias</a></code>方法，返回一个带有别名集的新数据帧。</p><pre class="kk kl km kn gu nt nd nu nv aw nw bi"><span id="9781" class="la lb iu nd b gz nx ny l nz oa">&gt;&gt;&gt; from pyspark.sql.functions import col</span><span id="06f9" class="la lb iu nd b gz ob ny l nz oa"><strong class="nd iv">&gt;&gt;&gt; df = df.select(<br/></strong><strong class="nd iv">    col('colA').alias('A'), <br/>    col('colB'),<br/>    col('colC').alias('C'),<br/>    col('colD')<br/></strong><strong class="nd iv">)</strong></span><span id="46b8" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df.show()<br/><em class="oc">+---+----+-----+----+<br/>|  A|colB|    C|colD|<br/>+---+----+-----+----+<br/>|  1|   a| true| 1.0|<br/>|  2|   b|false| 2.0|<br/>|  3|   c|false| 3.0|<br/>|  4|   d| true| 4.0|<br/>+---+----+-----+----+</em></span></pre><p id="ce77" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated">同样，当需要重命名多个列并且不需要处理大量列时，应该使用这种方法，否则这会变得非常冗长。</p></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><h2 id="2872" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用Spark SQL</h2><p id="83fd" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">最后，您可以使用Spark SQL对存储为表的数据帧使用传统的SQL语法来重命名列。举个例子，</p><pre class="kk kl km kn gu nt nd nu nv aw nw bi"><span id="afc7" class="la lb iu nd b gz nx ny l nz oa">&gt;&gt;&gt; df.createOrReplaceTempView('test_table')<br/>&gt;&gt;&gt; df = spark_session.sql(<br/>    <!-- -->'SELECT colA AS A, colB, colC AS C, colD FROM test_table'<br/>)</span><span id="9d4e" class="la lb iu nd b gz ob ny l nz oa">&gt;&gt;&gt; df.show()<br/><em class="oc">+---+----+-----+----+<br/>|  A|colB|    C|colD|<br/>+---+----+-----+----+<br/>|  1|   a| true| 1.0|<br/>|  2|   b|false| 2.0|<br/>|  3|   c|false| 3.0|<br/>|  4|   d| true| 4.0|<br/>+---+----+-----+----+</em></span></pre></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><h2 id="7208" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">最后的想法</h2><p id="5154" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在今天的简短指南中，我们讨论了如何以多种不同的方式重命名PySpark数据帧的列。根据您是否需要重命名一个或多个列，您必须选择最适合您的特定用例的方法。</p></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><p id="4e93" class="pw-post-body-paragraph lw lx iu ly b lz mr jv mb mc ms jy me lj nj mg mh ln nk mj mk lr nl mm mn mo in bi translated"><a class="ae kz" href="https://gmyrianthous.medium.com/membership" rel="noopener"> <strong class="ly iv">成为会员</strong> </a> <strong class="ly iv">阅读媒介上的每一个故事。你的会员费直接支持我和你看的其他作家。</strong></p></div><div class="ab cl nm nn hy no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="in io ip iq ir"><h2 id="676e" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">你可能也喜欢</h2><div class="od oe gq gs of og"><a rel="noopener follow" target="_blank" href="/sparksession-vs-sparkcontext-vs-sqlcontext-vs-hivecontext-741d50c9486a"><div class="oh ab fp"><div class="oi ab oj cl cj ok"><h2 class="bd iv gz z fq ol fs ft om fv fx it bi translated">spark session vs spark context vs SQLContext vs hive context</h2><div class="on l"><h3 class="bd b gz z fq ol fs ft om fv fx dk translated">SparkSession、SparkContext HiveContext和SQLContext有什么区别？</h3></div><div class="oo l"><p class="bd b dl z fq ol fs ft om fv fx dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ov l or os ot op ou kt og"/></div></div></a></div><div class="od oe gq gs of og"><a rel="noopener follow" target="_blank" href="/how-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3"><div class="oh ab fp"><div class="oi ab oj cl cj ok"><h2 class="bd iv gz z fq ol fs ft om fv fx it bi translated">加快PySpark和Pandas数据帧之间的转换</h2><div class="on l"><h3 class="bd b gz z fq ol fs ft om fv fx dk translated">将大火花数据帧转换为熊猫时节省时间</h3></div><div class="oo l"><p class="bd b dl z fq ol fs ft om fv fx dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ow l or os ot op ou kt og"/></div></div></a></div><div class="od oe gq gs of og"><a rel="noopener follow" target="_blank" href="/distinct-vs-dropduplicates-in-spark-3e28af1f793c"><div class="oh ab fp"><div class="oi ab oj cl cj ok"><h2 class="bd iv gz z fq ol fs ft om fv fx it bi translated">Spark中的distinct()与dropDuplicates()</h2><div class="on l"><h3 class="bd b gz z fq ol fs ft om fv fx dk translated">Spark中distinct()和dropDuplicates()有什么区别？</h3></div><div class="oo l"><p class="bd b dl z fq ol fs ft om fv fx dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ox l or os ot op ou kt og"/></div></div></a></div></div></div>    
</body>
</html>