<html>
<head>
<title>Using Word Embeddings to Identify Company Names and Stock Tickers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用单词嵌入识别公司名称和股票代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-word-embeddings-to-identify-company-names-and-stock-tickers-f194e3648a66?source=collection_archive---------16-----------------------#2021-07-13">https://towardsdatascience.com/using-word-embeddings-to-identify-company-names-and-stock-tickers-f194e3648a66?source=collection_archive---------16-----------------------#2021-07-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="220d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="2ab4" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ir">项目目标:</strong>使用单词嵌入从自然文本中识别公司名称和股票代码。</p><p id="33b0" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">假设:</strong>股票行情和公司名称在类似的自然文本中被使用，比如红迪网帖子或推特。</p><p id="cf4a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在这种假设下，单词嵌入应该很适合于识别这些目标单词，因为单词嵌入是根据单词所处的语境来训练的。</p><h2 id="8924" class="lo jo iq bd jp lp lq dn jt lr ls dp jx kw lt lu kb la lv lw kf le lx ly kj lz bi translated">计划:</h2><ol class=""><li id="a08c" class="ma mb iq kn b ko kp ks kt kw mc la md le me li mf mg mh mi bi translated">在股票市场相关的Reddit帖子上训练一个Word2Vec模型。</li><li id="97a6" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li mf mg mh mi bi translated">创建一个可用于表示目标矢量的矢量(详见下文)。</li><li id="654a" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li mf mg mh mi bi translated">使用代表向量从红迪帖子中识别目标词。</li></ol><p id="d6bd" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在这篇文章中，我将跳过描述什么是单词嵌入，以及Word2Vec算法是如何工作的。<a class="ae mo" href="https://github.com/brianward1428/word-embeddings-for-reddit-extraction/blob/master/project_writeup.pdf" rel="noopener ugc nofollow" target="_blank">我已经就同一项目</a> <a class="ae mo" href="https://github.com/brianward1428/word-embeddings-for-reddit-extraction/blob/master/project_writeup.pdf" rel="noopener ugc nofollow" target="_blank">写了一篇更详细的论文，可以在这里</a>找到。在本文中，我详细解释了什么是单词嵌入，以及Word2Vec算法是如何工作的。我还通过朴素贝叶斯进行详细的情感分析。在这篇文章中，我将以节略的形式展示代码。</p><p id="8d6a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><a class="ae mo" href="https://github.com/brianward1428/word-embeddings-for-reddit-extraction" rel="noopener ugc nofollow" target="_blank">完整报告见本页面。</a></p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="d4d6" class="jn jo iq bd jp jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk bi translated"><strong class="ak">数据导入</strong></h1><p id="571a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用了两种不同的数据源。这两个都是我在卡格尔网站上找到的来自r/wallstreetbets子网站的Reddit帖子的集合。</p><ul class=""><li id="8654" class="ma mb iq kn b ko lj ks lk kw nb la nc le nd li ne mg mh mi bi translated">Gabriel Preda，“Reddit WallStreetBets邮报”Kaggle，2021，<a class="ae mo" href="https://www.kaggle.com/gpreda/reddit-wallstreetsbets-posts/" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/gpreda/reddit-wallstreetsbets-posts</a>/</li><li id="89fb" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li ne mg mh mi bi translated">拉斐尔·丰特斯，“Reddit-r/wallstreet bets”。卡格尔，2021年。<a class="ae mo" href="https://www.kaggle.com/unanimad/reddit-rwallstreetbets" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/unanimad/reddit-rwallstreetbets</a></li></ul><p id="0c25" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在第一步中，我们将导入这些数据并提取每个句子。在其中一个数据集上，我们提取了Reddit标题，而另一个数据集上，我们提取了文本的正文，并进行拆分分开句子。<strong class="kn ir">注</strong> : Gensim的Word2Vec模型是基于句子进行训练的。</p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h1 id="1d14" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">字符串处理</h1><p id="d6cf" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下一步是在我们使用文本训练模型之前对其进行预处理。我们将执行以下操作:</p><ul class=""><li id="3d5e" class="ma mb iq kn b ko lj ks lk kw nb la nc le nd li ne mg mh mi bi translated">小写字母</li><li id="a3c1" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li ne mg mh mi bi translated">删除标点符号、数字和表情符号</li><li id="0360" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li ne mg mh mi bi translated">清除空白</li><li id="7588" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li ne mg mh mi bi translated">标记化</li><li id="be1a" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li ne mg mh mi bi translated">找到大人物</li><li id="3b52" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li ne mg mh mi bi translated">查找三元组</li></ul><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="f9dd" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在让我们看看我们处理过的一个句子:</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/3fd82dadcb2cfcb2cb5e5058745b5149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LBryAPThj9o9dmuuI0XRwA.png"/></div></div></figure><p id="fbd4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">太好了，我们现在大约有120万个句子来训练我们的模型。</p><h1 id="4316" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">模特培训</h1><p id="a26f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在我们准备训练或Word2Vec模型。Text 8是一个来自维基百科的数据转储，它非常适合标准化单词向量。我鼓励你比较有和没有这些额外训练数据的模型，看看它有多大帮助。<a class="ae mo" href="http://mattmahoney.net/dc/textdata" rel="noopener ugc nofollow" target="_blank">更多关于text8的信息可以在这里找到。</a></p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="90a7" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在，我们可以使用Gensim的<code class="fe nt nu nv nw b">most_similar()</code>功能来查看词汇表中与目标单词(如“gme ”)最相似的单词。</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nx"><img src="../Images/89c0eee845fd86693e5538bdf09d97f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-_kilBLKysA7lrIdw8i23A.png"/></div></div></figure><p id="8d61" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">完美，所以我们可以看到，至少前10个最相似的词也是公司或股票代号。这给了我们希望，我们的假设是正确的。</p><h2 id="f16c" class="lo jo iq bd jp lp lq dn jt lr ls dp jx kw lt lu kb la lv lw kf le lx ly kj lz bi translated">创建代表性向量</h2><p id="40c0" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们需要一个有代表性的向量来和词汇表中的其他单词进行比较。我们可以使用这个向量和一些相似度阈值来识别帖子中的目标词。</p><p id="0f2b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">不幸的是，<a class="ae mo" href="https://radimrehurek.com/gensim/models/word2vec.html" rel="noopener ugc nofollow" target="_blank"> Gensim </a>没有从其他向量创建平均向量的方法。所以我从Gensim的<code class="fe nt nu nv nw b">most_similar()</code>函数中提取了一些代码，以获得我正在寻找的功能。我还创建了一个余弦相似度方法，我们将使用它来比较任何两个向量。余弦相似性是一种比较两个非零向量的方法(两个相同的向量的余弦相似性= 1.0)。</p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="b827" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">太棒了，现在我们可以用它从一些精选的目标单词中创建我们自己的向量。</p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="5941" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在让我们继续使用我们创建的向量，看看我们的模型词汇表中最相似的向量。<strong class="kn ir">注:</strong>数字是项和代表向量的余弦相似度。</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi ny"><img src="../Images/8c3b6fcbebaf39a2131e691e5c5d1013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ubzPtxVB0b0qNLrqOLYWdA.png"/></div></div></figure><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nz"><img src="../Images/1b4d136876320df50fd83c400e2454dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lHgYG9TkYp0tUl2go4V7Og.png"/></div></div></figure><p id="e749" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我对这里的结果很满意。如果你跟随你应该探索所有这些500强，几乎所有的似乎是股票代号或公司名称。我们还可以看看向量与词汇表中每个单词的相似度的分布。</p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi oa"><img src="../Images/c87507747f4dbd59c91db1455873cdc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*btTkeXej9Nnk6ZgVQu9f_w.png"/></div></div></figure><p id="3b83" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我在0.55处添加了一条垂直线，这是我最终选择的相似度阈值。该行右边的任何单词都将被识别为目标。基于这个数字，看起来阈值可能应该大于0.55。这一选择是参数分析的结果，并有望随着更可靠的地面实况而增加。以下是更多相关信息。</p><h1 id="e241" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">模型检验</h1><p id="d7db" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在我们需要一些方法来测试我们的模型。我随机选择了1000个Reddit帖子，然后手动提取任何公司名称或股票代码。它看起来是这样的:</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi ob"><img src="../Images/4c9f2714310763842a3dfb437f3553c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-sxBeUsGnD1mECiZP46BwA.png"/></div></div></figure><p id="453e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在让我们继续测试它。有几个不同的方法来评分，我选择了一个简单的方法平均一个错过的分数和一个分数。</p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="be4a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">太好了，让我们开始工作吧。</p><h1 id="615d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参数分析</h1><p id="ff5a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Gensim的Word2Vec模型有几个我有兴趣系统测试的参数。我选择关注4个不同的参数:</p><ol class=""><li id="ac4e" class="ma mb iq kn b ko lj ks lk kw nb la nc le nd li mf mg mh mi bi translated">相似性阈值:[0.5，0.55，0.6，0.65]</li><li id="b381" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li mf mg mh mi bi translated">n-Gram:[一元，二元，三元]</li><li id="37c9" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li mf mg mh mi bi translated">窗口大小:[1，2，3，4，5]</li><li id="99e8" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li mf mg mh mi bi translated">向量大小:[100，200，300，400]</li></ol><p id="a91b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">注意</strong>:以下是关于这些参数的更多信息。</p><p id="515b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们可以迭代所有这些参数，并根据我们的实际情况进行测试。</p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="b37e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这显然需要很长时间，因为我们最终不得不训练模型60次。我只是让它运行了一夜。让我们来看看结果。</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi oc"><img src="../Images/9034d56ac224a82799be65d9ec322d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kpe86afIDMU-o9U95iFxwg.png"/></div></div></figure><p id="a2b8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在，我们可以单独考虑这些参数，看看我们是否发现了任何趋势。</p><h2 id="8d70" class="lo jo iq bd jp lp lq dn jt lr ls dp jx kw lt lu kb la lv lw kf le lx ly kj lz bi translated">相似性阈值</h2><p id="2fe6" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">相似性阈值是我们用来确定一个单词是否被提取的阈值:</p><pre class="nf ng nh ni gt od nw oe of aw og bi"><span id="8c60" class="lo jo iq nw b gy oh oi l oj ok">If cosineSimilarity(word, myVector) &gt;= similarity_threshold:<br/>       extract(word)<br/>Else : <br/>       continue</span></pre><p id="1aab" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">经过反复试验，我选择为这些测试考虑4个不同的阈值。在比较其他参数时，我还选择了包括这四个阈值中每个阈值的图形，因为这些参数在不同的阈值下可能会有不同的效果。</p><h2 id="d259" class="lo jo iq bd jp lp lq dn jt lr ls dp jx kw lt lu kb la lv lw kf le lx ly kj lz bi translated">n元语法</h2><p id="862a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">虽然N-Gram不是word2vec模型的一个参数，但它是对输入模型的数据进行预处理的一个重要步骤，对我们试图完成的任务有很大的影响。</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi ol"><img src="../Images/a74ebc61bdcf5c0ae0d9fa13c640ec81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5UM1bEXObWTC1Th1TUG2xw.png"/></div></div></figure><p id="0df7" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们看到每个阈值的趋势并不相同。我选择继续使用bigrams，因为它既是中间立场，也允许我们将bigram公司名称放在一起(例如“home_depot”)。</p><h2 id="de8a" class="lo jo iq bd jp lp lq dn jt lr ls dp jx kw lt lu kb la lv lw kf le lx ly kj lz bi translated">窗口大小</h2><p id="a602" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">窗口大小是Word2vec模型的一个参数，它指定了我们将考虑作为上下文单词的目标单词左右的单词数(<a class="ae mo" href="https://github.com/brianward1428/word-embeddings-for-reddit-extraction/blob/master/project_writeup.pdf" rel="noopener ugc nofollow" target="_blank">更多细节可以在项目描述</a>中找到)。这对嵌入有很大的影响，特别是对于像Reddit帖子这样的结构化程度较低的文本。</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi om"><img src="../Images/06dd81c0923c8314edc2f200d4b62d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yv5yeFEx9QqiwVyjxdCRKA.png"/></div></div></figure><h2 id="2296" class="lo jo iq bd jp lp lq dn jt lr ls dp jx kw lt lu kb la lv lw kf le lx ly kj lz bi translated">向量大小</h2><p id="d485" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">向量大小是word2vec模型的另一个参数。向量大小是我们正在创建的单词嵌入的长度或维度(<a class="ae mo" href="https://github.com/brianward1428/word-embeddings-for-reddit-extraction/blob/master/project_writeup.pdf" rel="noopener ugc nofollow" target="_blank">更多细节可以在项目描述</a>中找到)。选择正确的向量大小确实需要通过测试来完成。我们将考虑4个不同的选项。</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi on"><img src="../Images/961f3317f616d61c8eeb303b9da8d813.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DkI1jj9sH-MNO5AZpFyNPQ.png"/></div></div></figure><p id="b7ac" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">一旦确定了最佳参数:[n-gram=bigrams，window=1，vector-size=100，threshold=5.5]我们就能够在我们的地面真实数据上获得89%的总体准确率。我对这个简单的参数分析的结果非常满意。现在，我们可以继续使用该模型来提取公司。</p><h1 id="7d95" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">提取公司和股票代码</h1><p id="e6da" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">提取函数非常简单。我们基本上只需要将每个单词与我们的代表向量进行比较。我们之所以将它包装在try语句中，是因为我们模型的库不会有每一个可能的术语(word2vec模型中的param:<code class="fe nt nu nv nw b">min_count=25</code>)。</p><figure class="nf ng nh ni gt nj"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="ec57" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">当用一个<code class="fe nt nu nv nw b">threshold = 0.6</code>应用于我们的Reddit帖子的原始数据集时，这种方法能够从近30万个帖子中提取公司。在相同的阈值下，提取了800个独特的公司/报价机。以下是一些提取的公司/证券交易所及其数量的子集。</p><figure class="nf ng nh ni gt nj gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi oo"><img src="../Images/c5f933e6420bfd59072cbcb29b924c17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dt_7OiuqHypxRfxpDFER-g.png"/></div></div></figure><h1 id="47fb" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">后续步骤</h1><p id="97f7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我想指出的第一件事是，这个项目中的主要因素，<strong class="kn ir">代表向量</strong>，被掩盖了。这是因为在我做这个项目的时间里，我不认为我能实现一个创建这个向量的系统方法。我认为<strong class="kn ir">有很多</strong>可以让这个算法更加精确。首先需要做的是创建一个更大的地面真相，最好是从Twitter或其他形式的社交媒体中获取。有了一个更强大的基础事实来测试，我们可能会想出一些很酷的方法来学习一个更好的代表性向量。几个想法:</p><ul class=""><li id="a560" class="ma mb iq kn b ko lj ks lk kw nb la nc le nd li ne mg mh mi bi translated"><strong class="kn ir">简单的方法</strong>:获取公司名称/代码的子集，根据实际情况系统地测试不同的组合。</li><li id="8244" class="ma mb iq kn b ko mj ks mk kw ml la mm le mn li ne mg mh mi bi translated"><strong class="kn ir">更高级的方法:</strong>尝试实现某种梯度下降，它可以学习一个向量，这个向量将更好地执行我们现在令人敬畏的地面真理。</li></ul><p id="e268" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我也认为字符串的处理可以做得更多。在这个实现中，我选择删除数字和表情符号。我认为这是在抛出很多丰富的信息，尤其是表情符号。我确信我们的目标词与数字和表情符号都有上下文关系。如果我有任何想法，我一定会更新这篇文章。</p><h1 id="9255" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">包裹</h1><p id="aeb1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果您有任何建议、问题或意见，请告诉我，我是一名学生，正在学习所有这些工具。在整个项目中，我还使用朴素贝叶斯来确定不同公司/证券交易所的情绪。您可以在<a class="ae mo" href="https://github.com/brianward1428/word-embeddings-for-reddit-extraction/blob/master/project_writeup.pdf" rel="noopener ugc nofollow" target="_blank">中阅读更多相关内容，完整记录在此处</a>，您也可以在此处查看<a class="ae mo" href="https://github.com/brianward1428/word-embeddings-for-reddit-extraction" rel="noopener ugc nofollow" target="_blank">完整回购。感谢阅读。</a></p></div></div>    
</body>
</html>