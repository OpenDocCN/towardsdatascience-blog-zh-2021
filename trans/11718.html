<html>
<head>
<title>Interpret your black-box ML model with Permutation Feature Importance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用排列特征重要性解释你的黑盒 ML 模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/interpret-your-black-box-ml-model-with-permutation-feature-importance-fc2b2a14ca7c?source=collection_archive---------11-----------------------#2021-11-21">https://towardsdatascience.com/interpret-your-black-box-ml-model-with-permutation-feature-importance-fc2b2a14ca7c?source=collection_archive---------11-----------------------#2021-11-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="15c6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为训练过估计器计算全局特征重要性</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5d78500ebd24f6e0de8688eb61e32bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4KfGshATITG5KzmF90YW-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3037639" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/tayebmezahdia-4194100/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3037639" rel="noopener ugc nofollow" target="_blank"> Tayeb MEZAHDIA </a>提供</p></figure><p id="602f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">建模是数据科学模型开发管道的重要组成部分。它使用机器学习算法来拟合训练处理过的数据，以便对看不见的点进行预测。一些模型(如 Logistics Regression 和 k-NN)很容易表示，但大多数数据科学模型都是臭名昭著的黑盒模型，因为很难理解和解释任何预测的见解和原因。</p><p id="1f1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习模型的解释是指解释做出任何预测的原因。模型解释使得风险承担者和业务领导更容易理解有助于做出任何预测的因素。一些机器学习模型更容易解释，但对于其他算法，有各种技术和开源包来解释。一些软件包包括:</p><ul class=""><li id="4ac3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae ky" href="https://eli5.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> ELI5 </a></li><li id="ab90" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">石灰</a></li><li id="2f16" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank"> MLXTEND </a></li><li id="1ff1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://shap.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> SHAP </a></li></ul><p id="9070" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些软件包都涉及到各种算法来解释算法。一种流行的模型解释算法是基于排列的特征重要性。在本文中，我们将讨论如何使用排列特征重要性来解释该模型，以及它如何优于标准的 scikit-learn 特征重要性函数。</p><h1 id="15b8" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">什么是排列特征重要性？</h1><p id="7878" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">排列特征重要性是一种模型检查/解释技术，可用于解释任何拟合的黑盒机器学习模型。它为训练有素的估计器计算数据集的全局要素重要性，并帮助数据科学家了解高重要性要素和低重要性要素。</p><p id="6d5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">置换特征重要性算法通过任何特定特征的变化来测量模型性能的变化。有两种使用置换技术计算特征重要性的算法:</p><h2 id="86b8" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">方法 1:特征移除和再训练:</h2><ol class=""><li id="cb79" class="lv lw it lb b lc nb lf nc li ns lm nt lq nu lu nv mb mc md bi translated">在训练数据集上拟合估计量并计算性能。</li><li id="da04" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">从训练数据中移除一个特征并重新计算性能。</li><li id="1c69" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">测量步骤 1 和步骤 2 中模型性能的退化。</li><li id="befc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">添加步骤 2 中删除的特征。</li><li id="a37b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">对所有特征重复步骤 2、3 和 4。</li></ol><p id="425c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">删除某个功能后出现的性能下降决定了该功能的重要性。这种技术是昂贵的，因为需要为具有 n 个特征的数据集训练 n 个估计量。</p><p id="3588" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有另一种置换特征重要性可解释性技术，它对测试数据的特征值进行置换，并且只训练估计器。</p><h2 id="91f9" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">方法 2:特征值重组:</h2><ol class=""><li id="e299" class="lv lw it lb b lc nb lf nc li ns lm nt lq nu lu nv mb mc md bi translated">在训练数据集上拟合估计量并计算性能。</li><li id="c889" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">使用步骤 1 中的拟合估计值来计算测试数据的性能。</li><li id="e41d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">从测试数据集中随机抽取特定特征的特征值。</li><li id="ceb2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">使用步骤 1 中的拟合估计量来计算步骤 2 中的混洗测试数据集的性能。</li><li id="3ea6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">根据步骤 2 和步骤 4 的结果计算性能下降。</li><li id="31a9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">恢复步骤 3 中执行的随机更改。</li><li id="2d5f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu nv mb mc md bi translated">对数据集中的要素重复步骤 2、3、4 和 5。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/688a3487080e24d9831bfb3e581fe093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yfTT2_ltJ4wKCwLwzZSfFQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，特征重排示例:平均半径</p></figure><p id="7129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用方法 2，通过测量测试数据的性能恶化来计算特征重要性。这种技术的成本相对较低，因为它只适合估计器一次，并对测试数据和混洗测试数据进行 n+1 次预测。我们看到性能大幅下降的特性可以被视为重要特性，而性能几乎没有变化的特性可以被视为不太重要的特性。</p><h1 id="ee0c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">实施:</h1><p id="e878" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">Scikit-learn 和 ELI5 库在一行 Python 代码中提供了置换特征重要性算法的实现。</p><blockquote class="nx ny nz"><p id="8b54" class="kz la oa lb b lc ld ju le lf lg jx lh ob lj lk ll oc ln lo lp od lr ls lt lu im bi translated"><strong class="lb iu">数据集:</strong>sci kit-learn 库开源的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer" rel="noopener ugc nofollow" target="_blank">乳腺癌数据集</a>将用于执行排列特征重要性的演示。</p></blockquote><p id="a0e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">scikit-learn 包中的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance" rel="noopener ugc nofollow" target="_blank"> permutation_importance </a>可用于实现该算法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="74eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">置换特征重要性算法在第 8 行实现。<code class="fe og oh oi oj b"><strong class="lb iu">n_repeats</strong></code>参数代表置换特征的次数。</p><h1 id="49ba" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结果:</h1><p id="f6a2" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在让我们比较随机森林分类器的排列特征重要性和基于杂质的特征重要性。scikit-learn 中随机森林分类器的实现带有基于杂质的特征重要性，该特征重要性是根据从训练数据集导出的统计数据计算的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/ce9f932918fe44f51b2d814abd4b1c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aXE-ZVhN5CzDKXlLW-PPDw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，基于杂质的技术和基于排列的技术之间的特征重要性图的比较</p></figure><h1 id="f28d" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论:</h1><p id="1306" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">置换特征重要性是一种全局特征解释技术，可用于解释表格数据集中的任何拟合估计量。这项技术通过打乱测试数据的特征值来衡量性能的下降。这是一个非常方便的技术来解释任何黑盒估计器，并解释这个特性对于一个特定的模型是多么重要。</p><p id="eb1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于多共线数据集，排列特征重要性可能无法解释相关特征。阅读<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn 文档</a>以了解在使用排列特征重要性解释模型时如何处理多重共线性的情况。</p><h1 id="5196" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">参考资料:</h1><p id="8223" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">[1] Scikit-learn 文档:<a class="ae ky" href="https://scikit-learn.org/stable/modules/permutation_importance.html#outline-of-the-permutation-importance-algorithm" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/permutation _ importance . html # outline-of-the-permutation-importance-algorithm</a></p></div><div class="ab cl ol om hx on" role="separator"><span class="oo bw bk op oq or"/><span class="oo bw bk op oq or"/><span class="oo bw bk op oq"/></div><div class="im in io ip iq"><p id="0dae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oa">喜欢这篇文章吗？成为</em> <a class="ae ky" href="https://satyam-kumar.medium.com/membership" rel="noopener"> <em class="oa">中等会员</em> </a> <em class="oa">继续无限制学习。如果你使用下面的链接，我会收到你的一小部分会员费，不需要你额外付费。</em></p><div class="os ot gp gr ou ov"><a href="https://satyam-kumar.medium.com/membership" rel="noopener follow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd iu gy z fp pa fr fs pb fu fw is bi translated">加入我的推荐链接-萨蒂扬库马尔媒体</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">satyam-kumar.medium.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj ks ov"/></div></div></a></div><blockquote class="pk"><p id="15f2" class="pl pm it bd pn po pp pq pr ps pt lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>