<html>
<head>
<title>Deep neural networks: How to define?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度神经网络:如何定义？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-neural-networks-how-to-define-73d87bf36421?source=collection_archive---------31-----------------------#2021-09-29">https://towardsdatascience.com/deep-neural-networks-how-to-define-73d87bf36421?source=collection_archive---------31-----------------------#2021-09-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8a04" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">正确定义什么使神经网络变得更深很重要。这篇文章提出了深度神经网络的另一种定义。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c418e18f99ee4085e6b280dc4d55c693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ZG2iekZrG_WCVVelaws9A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Jonathan Borba 在Unsplash上拍摄的照片。</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><p id="d545" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在人工智能(AI)的成功，基本上是得益于深度学习(DL)及其相关模型。DL是机器学习(ML)的一个子领域，其中一组算法试图利用几个处理层对高级数据抽象进行建模，其中每种类型的层都有特定的用途。</p><p id="3748" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然而，深度神经网络(DNNs)，如深度卷积神经网络(<a class="ae kv" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">CNN</a>)，是基于多层感知器(MLP)，这是一类已经使用了相当长时间的前馈人工神经网络，甚至在1989年<a class="ae kv" href="https://ieeexplore.ieee.org/document/6795724" rel="noopener ugc nofollow" target="_blank">第一个CNN </a>出现之前。因此，问题来了:什么时候一个模型/网络被认为是“深”而不是“浅”？</p><h1 id="2498" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">浅层x深层神经网络</h1><p id="01b1" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">传统上，浅层神经网络(SNN)是具有一个或两个隐藏层的网络。因此，深度神经网络(DNN)是具有两个以上隐藏层的网络。这是最被接受的定义。下面，我们展示了一个SNN和DNN的例子(隐藏层是红色的)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/0fcb376b88494dfc6f0c5d7231afc514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P2ukL6wXmFZAoURb0qlsfw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="0072" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">但是，只考虑隐藏层的数量是一个好方法吗？正确定义什么使一个模型变得深刻，对于明确理解这个概念是很重要的，特别是从行业采用DL的角度来看。在这篇文章中，我们提出了DNNs的另一种定义。我们建议，被视为“深度”的模型不仅应考虑隐藏层的数量，还应考虑:</p><p id="bbb2" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">a.)考虑训练和/或评估它所需的时间；</p><p id="e29d" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">b.)考虑到计算平台(例如GPU)方面的需求。</p><p id="0150" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">经典基准数据集(如CIFAR-10、ImageNet)和标准环境/平台(Google Colab、kaggle)可用于获得这些度量。为了支持对另一个定义的需求，我们将使用两个传统数据库:修改后的国家标准与技术研究所(<a class="ae kv" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>)和<a class="ae kv" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a> <a class="ae kv" href="https://www.cs.toronto.edu/~kriz/cifar.html]." rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="393d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">MNIST数据库</h1><p id="cac5" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">关于MNIST数据库，我们考虑了三个神经网络:Aviv Shamsian的SNN500、T2的CNN3L、T4的Nutan、T5和Bolla Karthikeya的LeNet-5。SNN500是一个包含500个神经元的单隐层SNN。CNN3L也被认为是SNN，因为它有两个隐藏(卷积)层和输出层。第三个网络是经典的LeNet-5，有五层，其中四层是隐藏层。让我们看看代码(<a class="ae kv" href="https://github.com/vsantjr/DeepLearningMadeEasy/blob/temp_23-09/PyTorch_MNIST.ipynb" rel="noopener ugc nofollow" target="_blank">访问这里</a>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/0e6b368d78365bd85612056fd94cf032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VV0YIvEkUnmlMiN9Rt-AIg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="b1b2" class="nd ma iq mz b gy ne nf l ng nh"><strong class="mz ir">import</strong> <strong class="mz ir">torch</strong><br/><strong class="mz ir">import</strong> <strong class="mz ir">torch.nn</strong> <strong class="mz ir">as</strong> <strong class="mz ir">nn</strong><br/><strong class="mz ir">import</strong> <strong class="mz ir">torchvision.datasets</strong> <strong class="mz ir">as</strong> <strong class="mz ir">dsets</strong><br/><strong class="mz ir">import</strong> <strong class="mz ir">torchvision.transforms</strong> <strong class="mz ir">as</strong> <strong class="mz ir">transforms</strong><br/><strong class="mz ir">from</strong> <strong class="mz ir">torch.autograd</strong> <strong class="mz ir">import</strong> Variable<br/><strong class="mz ir">from</strong> <strong class="mz ir">prettytable</strong> <strong class="mz ir">import</strong> PrettyTable<br/><strong class="mz ir">import</strong> <strong class="mz ir">matplotlib.pyplot</strong> <strong class="mz ir">as</strong> <strong class="mz ir">plt</strong><br/><strong class="mz ir">import</strong> <strong class="mz ir">time</strong></span><span id="bbcc" class="nd ma iq mz b gy ni nf l ng nh"><em class="nj"># This function obtains the number of trainable parameters of the </em><br/><em class="nj"># model/network.</em><br/><strong class="mz ir">def</strong> count_parameters(model):<br/>    table = PrettyTable(["Modules", "Parameters"])<br/>    total_params = 0<br/>    <strong class="mz ir">for</strong> name, parameter <strong class="mz ir">in</strong> model.named_parameters():<br/>        <strong class="mz ir">if</strong> <strong class="mz ir">not</strong> parameter.requires_grad: <strong class="mz ir">continue</strong><br/>        param = parameter.numel()<br/>        table.add_row([name, param])<br/>        total_params+=param<br/>    print(table)<br/>    print(f"Total trainable params: <strong class="mz ir">{</strong>total_params<strong class="mz ir">}</strong>")<br/>    <strong class="mz ir">return</strong> total_params</span><span id="c71c" class="nd ma iq mz b gy ni nf l ng nh"><em class="nj"># Just visualising some images</em><br/><strong class="mz ir">def</strong> visualise_images(img, lab, t):<br/>   fig = plt.figure()<br/>   <strong class="mz ir">for</strong> i <strong class="mz ir">in</strong> range(6):<br/>     plt.subplot(2,3,i+1)<br/>     plt.tight_layout()<br/>     plt.imshow(img[i][0], cmap='gray', interpolation='none')<br/>     plt.title("<strong class="mz ir">{}</strong> - class: <strong class="mz ir">{}</strong>".format(t,lab[i]))<br/>     plt.xticks([])<br/>     plt.yticks([])</span></pre><p id="31c7" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，我们定义类的数量和一些超参数。请注意，批量大小为100。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="b825" class="nd ma iq mz b gy ne nf l ng nh">num_classes = 10 <em class="nj"># Number of output classes, discrete range [0,9]</em><br/><br/><em class="nj"># Hyper-parameters</em><br/>num_epochs = 20 <em class="nj"># Number of epochs</em><br/>batch_size = 100 <em class="nj"># The size of input data took for one iteration</em><br/>lr = 1e-3 <em class="nj"># Learning rate</em></span></pre><p id="f06b" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们下载并处理MNIST数据集。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="c42d" class="nd ma iq mz b gy ne nf l ng nh"><em class="nj"># Downloading MNIST dataset</em><br/>train_data = dsets.MNIST(root = './data', train = <strong class="mz ir">True</strong>,<br/>                        transform = transforms.ToTensor(), download = <strong class="mz ir">True</strong>)<br/><br/>test_data = dsets.MNIST(root = './data', train = <strong class="mz ir">False</strong>,<br/>                       transform = transforms.ToTensor())<br/><br/>print('#'*20)<br/>print('Training dataset: ', train_data)<br/>print('Test dataset: ', test_data)</span><span id="2923" class="nd ma iq mz b gy ni nf l ng nh"><em class="nj"># Wrap an iterable around the dataset to enable easy access to the samples.</em><br/>train_gen = torch.utils.data.DataLoader(dataset = train_data,<br/>                                        batch_size = batch_size,<br/>                                        shuffle = <strong class="mz ir">True</strong>)<br/><br/>test_gen = torch.utils.data.DataLoader(dataset = test_data,<br/>                                       batch_size = batch_size, <br/>                                       shuffle = <strong class="mz ir">False</strong>)<br/><br/><br/>device = torch.device("cuda:0" <strong class="mz ir">if</strong> torch.cuda.is_available() <strong class="mz ir">else</strong> "cpu")<br/>print('Device is: ', device)</span></pre><p id="d217" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">只是快速浏览一下训练数据集。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="9904" class="nd ma iq mz b gy ne nf l ng nh">batch_train = enumerate(train_gen)<br/>batch_idx, (batch_train_data, batch_train_classes) = next(batch_train)<br/>print('One batch - training dataset:', batch_train_data.shape)<br/><br/>print('<strong class="mz ir">\n</strong>Each image of the batch:')<br/><strong class="mz ir">for</strong> i <strong class="mz ir">in</strong> range(batch_train_classes.shape[0]):<br/>  print('Image: <strong class="mz ir">{}</strong> - Input shape: <strong class="mz ir">{}</strong> - Class: <strong class="mz ir">{}</strong>'.format(i, batch_train_data[i].shape, batch_train_classes[i]))<br/>  <strong class="mz ir">if</strong> i == (batch_train_classes.shape[0]-1):<br/>    print('The "image" itself: ', batch_train_data[i])<br/><br/>visualise_images(batch_train_data, batch_train_classes, 'Training')</span></pre><p id="d3dd" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">注意一批的形状是:[100，1，28，28]。这意味着一批100个图像，一个通道(MNIST的图像是灰度的)，每个图像的尺寸为28 x 28像素。现在，我们定义三个神经网络。基于测试数据集的准确性来测量它们的性能。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="fe54" class="nd ma iq mz b gy ne nf l ng nh"><strong class="mz ir">class</strong> <strong class="mz ir">SNN500</strong>(nn.Module):<br/>  <strong class="mz ir">def</strong> __init__(self, input_sz, hidden_sz, num_clas):<br/>    super(SNN500,self).__init__()<br/>    self.fc1 = nn.Linear(input_sz, hidden_sz)<br/>    self.relu = nn.ReLU()<br/>    self.fc2 = nn.Linear(hidden_sz, num_clas)<br/>  <br/>  <strong class="mz ir">def</strong> forward(self,x):<br/>    out = self.fc1(x)<br/>    out = self.relu(out)<br/>    out = self.fc2(out)<br/>    <strong class="mz ir">return</strong> out</span><span id="99c7" class="nd ma iq mz b gy ni nf l ng nh"><strong class="mz ir">class</strong> <strong class="mz ir">CNN3L</strong>(nn.Module):<br/>    <strong class="mz ir">def</strong> __init__(self, num_clas):<br/>        super(CNN3L, self).__init__()<br/>        self.conv1 = nn.Sequential(         <br/>            nn.Conv2d(<br/>                in_channels=1,              <br/>                out_channels=16,            <br/>                kernel_size=5,              <br/>                stride=1,                   <br/>                padding=2,                  <br/>            ),                              <br/>            nn.ReLU(),                      <br/>            nn.MaxPool2d(kernel_size=2),    <br/>        )<br/>        self.conv2 = nn.Sequential(         <br/>            nn.Conv2d(16, 32, 5, 1, 2),     <br/>            nn.ReLU(),                      <br/>            nn.MaxPool2d(kernel_size=2),                <br/>        )<br/>        <em class="nj"># Fully-connected layer</em><br/>        self.out = nn.Linear(32 * 7 * 7, num_clas)<br/>    <strong class="mz ir">def</strong> forward(self, x):<br/>        x = self.conv1(x)<br/>        x = self.conv2(x)<br/>        <em class="nj"># Flatten the output of conv2 to (batch_size, 32 * 7 * 7)</em><br/>        x = x.view(x.size(0), -1)       <br/>        output = self.out(x)<br/>        <strong class="mz ir">return</strong> output</span><span id="82f1" class="nd ma iq mz b gy ni nf l ng nh"><strong class="mz ir">class</strong> <strong class="mz ir">LeNet5</strong>(nn.Module):          <br/>    <strong class="mz ir">def</strong> __init__(self, num_clas):     <br/>        super(LeNet5, self).__init__()<br/>        <em class="nj"># Convolution </em><br/>        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=<strong class="mz ir">True</strong>)<br/>        <em class="nj"># Max-pooling</em><br/>        self.max_pool_1 = nn.MaxPool2d(kernel_size=2)<br/>        <em class="nj"># Convolution</em><br/>        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=<strong class="mz ir">True</strong>)<br/>        <em class="nj"># Max-pooling</em><br/>        self.max_pool_2 = nn.MaxPool2d(kernel_size=2) <br/>        <em class="nj"># Fully-connected layers</em><br/>        self.fc1 = nn.Linear(16*5*5, 120)   <em class="nj"># convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)</em><br/>        self.fc2 = nn.Linear(120, 84)       <em class="nj"># convert matrix with 120 features to a matrix of 84 features (columns)</em><br/>        self.fc3 = nn.Linear(84, num_clas)        <em class="nj"># convert matrix with 84 features to a matrix of 10 features (columns)</em><br/>        <br/>    <strong class="mz ir">def</strong> forward(self, x):<br/>        <em class="nj"># Convolve, then perform ReLU non-linearity</em><br/>        x = nn.functional.relu(self.conv1(x))  <br/>        <em class="nj"># Max-pooling with 2x2 grid </em><br/>        x = self.max_pool_1(x) <br/>        <em class="nj"># Convolve, then perform ReLU non-linearity</em><br/>        x = nn.functional.relu(self.conv2(x))<br/>        <em class="nj"># Max-pooling with 2x2 grid</em><br/>        x = self.max_pool_2(x)<br/>        <em class="nj"># First flatten 'max_pool_2_out' to contain 16*5*5 columns</em><br/>        x = x.view(-1, 16*5*5)<br/>        <em class="nj"># FC-1, then perform ReLU non-linearity</em><br/>        x = nn.functional.relu(self.fc1(x))<br/>        <em class="nj"># FC-2, then perform ReLU non-linearity</em><br/>        x = nn.functional.relu(self.fc2(x))<br/>        <em class="nj"># FC-3</em><br/>        x = self.fc3(x)<br/>        <strong class="mz ir">return</strong> x</span></pre><p id="368f" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，我们可以选择其中一个模型/网络进行训练和评估。我们还定义了损失函数、优化器，并显示了所选模型的可训练参数的数量。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="38d0" class="nd ma iq mz b gy ne nf l ng nh">loss_function = nn.CrossEntropyLoss()<br/>optimizer = torch.optim.Adam(net.parameters(), lr=lr)<br/><br/>print('Checking trainable parameters: <strong class="mz ir">{}</strong>'.format(count_parameters(net)))</span></pre><p id="53c5" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，我们可以训练模型了。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="474b" class="nd ma iq mz b gy ne nf l ng nh">train_losses = []<br/>train_acc = []<br/>train_time_init = time.time()<br/><strong class="mz ir">for</strong> epoch <strong class="mz ir">in</strong> range(num_epochs):<br/>  net.train() <br/>  running_loss = 0.0<br/>  running_corrects = 0<br/>  <strong class="mz ir">for</strong> images,labels <strong class="mz ir">in</strong> train_gen: <em class="nj"># Iterate over data: begin</em><br/>    <strong class="mz ir">if</strong> opt == '1':<br/>      images = Variable(images.view(-1,28*28)).to(device) <em class="nj"># Send to GPU</em><br/>    <strong class="mz ir">elif</strong> (opt == '2') <strong class="mz ir">or</strong> (opt == '3'):<br/>      images = Variable(images).to(device) <em class="nj"># Send to GPU</em><br/>    <br/>    labels = Variable(labels).to(device) <em class="nj"># Send to GPU</em><br/>    optimizer.zero_grad()<br/>    <strong class="mz ir">with</strong> torch.set_grad_enabled(<strong class="mz ir">True</strong>):<br/>        outputs = net(images)<br/>        _, preds = torch.max(outputs, 1)<br/>        loss = loss_function(outputs, labels)<br/>        loss.backward()<br/>        optimizer.step()<br/>    <br/>    running_loss += loss.item() * images.size(0)<br/>    running_corrects += torch.sum(preds == labels.data)<br/>  <em class="nj"># Iterate over data: end</em><br/><br/>  epoch_loss = running_loss / len(train_data)<br/>  epoch_acc = running_corrects.double() / len(train_data)  <br/>  print('Epoch [<strong class="mz ir">%d</strong>/<strong class="mz ir">%d</strong>], Loss: <strong class="mz ir">%.4f</strong>, Accuracy: <strong class="mz ir">%.4f</strong>'<br/>                 %(epoch+1, num_epochs, epoch_loss, epoch_acc))<br/>  <br/>  train_losses.append(epoch_loss)<br/>  train_acc.append(epoch_acc) <br/><br/>train_time_end = time.time() - train_time_init</span></pre><p id="dbe3" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在推理阶段，我们测量所选模型的性能。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="49ad" class="nd ma iq mz b gy ne nf l ng nh">am_training = net.training<br/>print('Am I training? ', am_training)<br/>net.eval()<br/>am_training = net.training<br/>print('Am I training? ', am_training)<br/>inference_loss = 0.0<br/>inference_corrects = 0<br/><br/>infer_time_init = time.time()<br/><strong class="mz ir">with</strong> torch.no_grad():<br/>  <strong class="mz ir">for</strong> images,labels <strong class="mz ir">in</strong> test_gen: <em class="nj"># Iterate over data: begin</em><br/>      <strong class="mz ir">if</strong> opt == '1':<br/>        images = Variable(images.view(-1,28*28)).to(device) <em class="nj"># Send to GPU</em><br/>      <strong class="mz ir">elif</strong> opt == '2' <strong class="mz ir">or</strong> opt == '3':<br/>        images = Variable(images).to(device) <em class="nj"># Send to GPU</em><br/>      <br/>      labels = labels.to(device) <em class="nj"># Send to GPU</em><br/>      outputs_infer = net(images)<br/>      _, preds_infer = torch.max(outputs_infer,1)<br/>      loss_infer = loss_function(outputs_infer, labels)<br/><br/>      inference_loss += loss_infer.item() * images.size(0)<br/>      inference_corrects += torch.sum(preds_infer == labels.data)<br/>  <em class="nj"># Iterate over data: end</em><br/><br/>final_inference_loss = inference_loss / len(test_data)<br/>final_inference_acc = inference_corrects.double() / len(test_data)<br/><br/>infer_time_end = time.time() - infer_time_init<br/>print('<strong class="mz ir">\n</strong>Training and inference in <strong class="mz ir">{:.0f}</strong>m <strong class="mz ir">{:.0f}</strong>s  OR  <strong class="mz ir">{:.0f}</strong>s'.format(<br/>        (train_time_end + infer_time_end) // 60, <br/>        (train_time_end + infer_time_end) % 60,<br/>         train_time_end + infer_time_end))<br/><br/>print('<strong class="mz ir">\n</strong>Loss of <strong class="mz ir">{}</strong>: <strong class="mz ir">{:.4f}</strong>'.format(opt_name, final_inference_loss))<br/>print()<br/>print('Accuracy of <strong class="mz ir">{}</strong>: <strong class="mz ir">{:.4f}</strong>'.format(opt_name, final_inference_acc))</span></pre><p id="cd37" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">因此，我们将三个模型中的每一个运行20个时期，并测量所需的总时间(train_time_end + infer_time_end)。注意总时间只包括这两个阶段)以秒为单位，如下所示。时间和准确度是三次运行的平均值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/22c48f0c22a9ec437310a84a3a542694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*scBWwZFkLAsZTPGXZh0F9g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MNIST:结果。图片作者。</p></figure><p id="9601" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">请注意，即使CNN3L具有最少数量的可训练参数(#Train Par)，它也需要更多的时间来运行(训练和评估)。CNN3L也是所有型号中最好的(即使精度非常接近)。下面，我们展示了通过带有PyTorch Profiler的TensorBoard插件获得的GPU概要(此处<a class="ae kv" href="https://github.com/vsantjr/DeepLearningMadeEasy/blob/temp_23-09/PyTorch_MNIST_Profiler.ipynb" rel="noopener ugc nofollow" target="_blank">访问</a>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/5588bcc4af4c3122ee26b04ccdcb0b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iy834Ut9DTaNggZ_4tgg2w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MNIST: GPU总结。图片作者。</p></figure><p id="4973" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在所有模型中，GPU利用率都非常低。不过注意，CNN3L的GPU利用率最高(4.57%)。底线是，根据经典定义，SNN (CNN3L)比DNN (LeNet-5)需要更多的运行时间，获得更高的准确性，并利用更多的GPU。</p><p id="9c93" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">值得一提的是，GPU利用率越高越好。但是，由于我们在这里比较的模型具有相同的配置(相同的批量大小，相同数量的DataLoader构建工人等等)，GPU利用率较高的模型可能会被解释为比其他模型需要更多的计算资源。我们预计较深的模型比较浅的模型需要更高的GPU利用率。</p><h1 id="1059" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">CIFAR-10数据库</h1><p id="c499" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">CIFAR-10数据库包含32 x 32幅彩色图像(三个波段)。这里，我们使用了前面三个模型中的两个:由<a class="ae kv" href="https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118" rel="noopener"> Nutan </a>开发的CNN3L和在<a class="ae kv" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank">训练分类器</a> PyTorch教程中介绍的LeNet-5。为了正确处理CIFAR-10图像，我们对这两个模型做了一些小的修改。优化器，学习率是相同的，但现在批量大小是4，我们运行每个模型三次，10个时期。<a class="ae kv" href="https://github.com/vsantjr/DeepLearningMadeEasy/blob/temp_23-09/PyTorch_CIFAR-10.ipynb" rel="noopener ugc nofollow" target="_blank">在这里访问代码</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/b167c2c9107e51dc8fecaea7b50e2376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_gnvrNuLBZ_FutoK41duw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="16e6" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在下图(表格)中，时间和准确度是三次运行的平均值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/382075b9587315ac433af4277186d72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xtTJUQm9NCygy6ZetdBW6Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CIFAR-10:结果。图片作者。</p></figure><p id="012d" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，我们有了一个更“自然”的情况。换句话说，LeNet-5有更多的可训练参数，需要更多的时间来运行。但是，同样，CNN3L取得了更好的性能。通过带有PyTorch Profiler的TensorBoard插件获得的GPU摘要如下所示(<a class="ae kv" href="https://github.com/vsantjr/DeepLearningMadeEasy/blob/temp_23-09/PyTorch_CIFAR-10_Profiler.ipynb" rel="noopener ugc nofollow" target="_blank">访问此处</a>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/38d38582aef8ae06a1bb5611eb2f0fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zEDlSPsJeqtE-a0uKjfDhw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="004f" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">同样，CNN3L(浅层)比LeNet-5(深层)显示了更多的GPU利用率。</p><h1 id="e6a1" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">结论</h1><p id="e924" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">在这篇文章中，我们建议用另一种定义来看待DNN模型。我们认为，一个不仅包含隐藏层数量，而且包含训练和/或评估模型所需时间以及计算平台要求的定义可能更合适。</p></div></div>    
</body>
</html>