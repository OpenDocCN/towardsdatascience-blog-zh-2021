<html>
<head>
<title>Detection of vertebral column pathologies using decision trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用决策树检测脊柱病变</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detection-of-vertebral-column-pathologies-using-decision-trees-ad4e47ae58c2?source=collection_archive---------19-----------------------#2021-07-12">https://towardsdatascience.com/detection-of-vertebral-column-pathologies-using-decision-trees-ad4e47ae58c2?source=collection_archive---------19-----------------------#2021-07-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0a5b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用Scikit-learn库构建决策树</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/cf01e087aff176e0d0357d16aff19a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eDQ_EbkfBAVdw-nr"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@moonshadowpress" rel="noopener ugc nofollow" target="_blank"> Joyce McCown </a>在<a class="ae kv" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="630b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人工智能在医疗保健领域有着巨大的潜力，并且在过去几年中一直在这一领域不断发展。<strong class="ky ir">医疗行业正在利用人工智能做出更智能、更准确的决策。</strong>机器学习在医疗保健领域的应用非常广泛，从疾病诊断和识别到机器人手术，在大多数情况下都提供了超出人类能力的结果。</p><p id="4688" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，您将学习如何使用<strong class="ky ir">决策树</strong>构建<strong class="ky ir">二元分类模型</strong>来检测脊柱病变患者。这些模型是使用<strong class="ky ir"> Python </strong>特别是<strong class="ky ir"> Scikit-learn库</strong>构建的；然而，重要的是要强调，许多其他编程语言也有可用于轻松构建分类模型的库(例如R和Java)。</p><p id="4e56" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了便于理解文章的内容，<strong class="ky ir">每一节都包含理论介绍和解释性插图</strong>。它们支持更容易地理解用于构建和评估分类模型的编程代码。❤️</p><h1 id="0ce4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据集</h1><p id="aac6" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">本文使用的数据集可在<strong class="ky ir">加州大学欧文分校机器学习知识库</strong>和<strong class="ky ir"> </strong>中获得，包含<strong class="ky ir">六个生物力学特征</strong>，用于将患者分为<strong class="ky ir">两组</strong> : (1)正常，和(2)异常。类别<code class="fe mp mq mr ms b">NO</code>(正常)包括100名没有脊柱疾病的患者，而类别<code class="fe mp mq mr ms b">AB</code>(异常)包括210名患有脊柱问题的患者。</p><p id="217f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://archive.ics.uci.edu/ml/datasets/Vertebral+Column" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets/Vertebral+Column</a></p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="d579" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">开源代码库</h1><p id="4a77" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这个项目的代码可以从GitHub上的Jupyter笔记本中获得。</p><div class="nf ng gp gr nh ni"><a href="https://github.com/amandaiglesiasmoreno" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">amandaiglesiasmoreno -概述</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">阻止或报告7月8月9月10月11月12月1月2月3月4月5月6月7日周一周三Fri amandaiglesiasmoreno没有活动…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">github.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw kp ni"/></div></div></a></div></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="254f" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">数据读取和清理</h1><p id="fb70" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">分析的第一步包括<strong class="ky ir">使用<code class="fe mp mq mr ms b">pandas.read_csv</code>函数读取和存储Pandas数据帧中的数据</strong>。在<strong class="ky ir"> UCI存储库</strong>中可用的<strong class="ky ir"> CSV文件</strong>不包含指示列名的标题，因此它们必须用参数<code class="fe mp mq mr ms b">names</code>手动指定。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="fe8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集包含<strong class="ky ir"> 6个独立变量</strong>，表示脊柱的生物力学属性:(1) <code class="fe mp mq mr ms b">pelvic_incidence</code>、(2) <code class="fe mp mq mr ms b">pelvic_tilt</code>、(3) <code class="fe mp mq mr ms b">lumbar_lordosis_angle</code>、(4) <code class="fe mp mq mr ms b">sacral_slope</code>、(5) <code class="fe mp mq mr ms b">pelvic_radius</code>、(6) <code class="fe mp mq mr ms b">degree_spondylolisthesis</code>。列<code class="fe mp mq mr ms b">class</code>表示患者是否患有脊柱疾病。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/b0cce9c654c1045d45af83f8cfe1f3ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mt1b0raxDcGatWQhBDPUVg.png"/></div></div></figure><p id="321d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">目标是使用所有生物力学特征建立一个模型，以预测脊柱病理的存在。</strong>在这个特殊的例子中，我们将只使用<strong class="ky ir">决策树算法</strong>来构建模型；然而，一个更深思熟虑的分析将包括使用更多的监督学习算法，目的是找到具有更大预测能力的模型。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="717d" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated"><strong class="ak">探索性数据分析</strong></h1><p id="6d75" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><strong class="ky ir">探索性数据分析</strong>包括分析数据集的主要特征，通常采用<strong class="ky ir">可视化方法</strong>和<strong class="ky ir">汇总统计</strong>。目标是理解数据，发现模式和异常，并在执行进一步评估之前检查假设。</p><p id="d61b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在EDA之初，我们希望了解尽可能多的关于数据的信息，这就是<code class="fe mp mq mr ms b">pandas.DataFrame.info</code>方法派上用场的时候。该方法打印数据帧的<strong class="ky ir">简明摘要，包括列名及其数据类型、非空值的数量以及数据帧使用的内存量。</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/6cdbc7fd07f321e8524a68e6afdc81fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*hbbCcamKk5MA9mRIc2Yipw.png"/></div></figure><p id="d18d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如前所示，<strong class="ky ir">数据集不包含空值，所有数据类型都是正确的</strong>；因此，该数据无需额外修改即可用于分类模型的构建。</p><p id="f6e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在EDA过程中，可视化变量的分布以及它们之间的相关性也很有趣。配对图是快速探索这两种事物的简单方法。他们在图的主对角线提供<strong class="ky ir">直方图，以检查数值变量的分布。此外，主对角线之外的位置提供了数字变量</strong>的<strong class="ky ir">散点图，以便于分析它们之间的关系。</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/66fcc58a01f5396952a566d98c9fd4c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jxFgE3adERskE-nW5EkKkg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者用seaborn生成的图像</p></figure><p id="fce9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看配对图，我们可以得出结论，当患者有脊柱问题时，属性<code class="fe mp mq mr ms b">degree_spondylolisthesis</code>呈现高值，并且根据直方图，预期该属性在对患者进行分类时具有巨大的重要性。</p><p id="fbd8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于其他属性，低<code class="fe mp mq mr ms b">pelvic_radius</code>的患者更容易出现脊柱异常；然而，当患者是健康的并且没有遭受任何脊柱病变时，其余的属性呈现较低的值。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="ca17" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated"><strong class="ak">数据拆分:训练集和测试集</strong></h1><p id="178d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">建立模型的第一步是<strong class="ky ir">将数据分成两组</strong>，通常称为<strong class="ky ir">训练和测试集</strong>。机器学习算法使用训练集来构建模型。测试集包含不属于学习过程的样本，用于评估模型的性能。使用看不见的数据来评估模型的质量以保证客观的评估是很重要的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/0877657bcf270cbe744135f50830f4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5CQPX3ZUsS4XFegSRglfGA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练集和测试集(图片由作者创建)</p></figure><p id="1537" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们创建一个变量X来存储<strong class="ky ir">独立属性</strong>(生物力学特征)。类似地，我们创建一个变量y，只包含目标变量(类)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="3249" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以使用<code class="fe mp mq mr ms b">sklearn.model_selection</code>包中的<code class="fe mp mq mr ms b">train_test_split</code>函数来创建训练集和测试集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="de00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">默认拆分百分比将75%的观察值分配给训练集，25%分配给测试集</strong>；然而，我们可以使用参数<code class="fe mp mq mr ms b">train_size</code>和<code class="fe mp mq mr ms b">test_size</code>来表示不同的分布。在这种情况下，我们使用默认的分割百分比75/25。</p><p id="fd43" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">参数<code class="fe mp mq mr ms b">shuffle</code>决定数据在分割前是否应该洗牌。建议<strong class="ky ir">随机分割数据</strong>，以确保目标变量的<strong class="ky ir">分布在两个数据集</strong>(训练和测试集)中相似，这意味着两个数据集都具有代表性。默认情况下，参数<code class="fe mp mq mr ms b">shuffle</code>的值为<code class="fe mp mq mr ms b">True</code>；但是也可以显式指定，表示<code class="fe mp mq mr ms b">shuffle=True</code>。</p><p id="1873" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">重要的是要记住，我们每次运行代码得到的结果都是一样的，因为参数<code class="fe mp mq mr ms b">random_state</code>被设置为40，而不是无(默认值)。该参数<strong class="ky ir">控制分割前应用于数据</strong> <strong class="ky ir">的混洗将始终相同。</strong></p><p id="db0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分割数据后，建议检查目标变量是否在两组数据中均匀分布。如下所示，<strong class="ky ir">在训练和测试组中，脊柱病变患者的百分比相似</strong>(约65%)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/75d2a7d109c8f7ee0c6d5b45bc69b1a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*MtvxpGyc6Deim_5KHaCK5w.png"/></div></figure></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="d682" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated"><strong class="ak">决策树算法—理论</strong></h1><h2 id="e78c" class="oe lt iq bd lu of og dn ly oh oi dp mc lf oj ok me lj ol om mg ln on oo mi op bi translated">元素</h2><p id="396c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">决策树是基于一系列分层问题的监督机器学习算法。这些问题会把空间分成多个线性空间来预测结果。响应可以是离散的(一类)或连续的(一个实数)。</p><p id="9782" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">决策树是由<strong class="ky ir">的三个元素</strong>组成的:节点、树枝和树叶。<strong class="ky ir">节点</strong>描述了一个属性的测试条件，而<strong class="ky ir">分支</strong>代表了基于该测试条件的结果。<strong class="ky ir">叶</strong>，也称为终端节点，代表决策路径(响应)的终点，与内部节点不同，它们不再进一步分裂。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/5b3075be11dbb9b72b205051976febd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UNkj77sNifkiTRERn0SkYg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">决策树的组成部分(图片由作者创建)</p></figure><p id="4571" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，重要的是要提到决策树算法是递归的，这意味着数据被分成更小的块，直到所有的叶子都是纯的(如果没有实施预修剪技术)。</p><h2 id="0642" class="oe lt iq bd lu of og dn ly oh oi dp mc lf oj ok me lj ol om mg ln on oo mi op bi translated">优点和缺点</h2><p id="f267" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">与神经网络等其他机器学习算法相比，决策树的<strong class="ky ir">主要优势在于获得的<strong class="ky ir"> </strong>模型是<strong class="ky ir">高度可解释的</strong>。神经网络在准确性方面比决策树取得更好的结果；然而，它们并没有提出一个容易理解的模型。无法解释决策是如何根据网络的权重做出的。相比之下，即使是非技术人员，决策树也很容易可视化和理解。</strong></p><p id="700f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个优势是决策树<strong class="ky ir">不需要密集的预处理任务</strong>，例如数据的标准化。存在对变量范围高度敏感的机器学习算法，例如K-means。K-means受属性比例的影响，因为是一种基于距离的算法。在这种情况下，规范化是非常必要的。如果没有实现，具有更高值的特征将主导学习过程，并且获得的聚类将是错误的。然而，决策树是基于规则而不是距离的。因此，<strong class="ky ir">它们不受变量范围的影响，也不需要标准化</strong>。此外，当处理分类特征时，<strong class="ky ir">决策树不需要创建虚拟变量</strong>。</p><p id="d72b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">决策树是一种强大易用的机器学习算法；然而，它们也存在<strong class="ky ir">缺点</strong>。决策树的主要问题是<strong class="ky ir">过拟合</strong>。决策树<strong class="ky ir">对训练集过于敏感，</strong>学习数据中存在的噪声。如果训练数据存在大量噪声，则获得的树将非常复杂，难以跟踪。幸运的是，大多数机器学习库中已经实现了两种机制来避免过度拟合:预修剪和后修剪技术。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/df60e6dc62bc9b2ab81fbcbac1c0625d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eEKBqNzRZPbEMzt7H-caeg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">决策树的优缺点(图片由作者创作)</p></figure><h2 id="f66b" class="oe lt iq bd lu of og dn ly oh oi dp mc lf oj ok me lj ol om mg ln on oo mi op bi translated">分割标准</h2><p id="77a8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">构建决策树有不同的<strong class="ky ir">分裂标准</strong>。Scikit- learn库有两个用于测量杂质的标准:(1)基尼指数(默认选项)和(2)熵。</p><p id="e849" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">基尼系数</strong>标准是基于最小化错误分类的可能性。指数<strong class="ky ir"> 0代表完美的分裂</strong>，这意味着所有的观察都属于同一个类别。相反，<strong class="ky ir">指数0.5代表可能的最高紊乱(在二元分类中)</strong>。当所有类别的概率都相同时，就会出现这种情况。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/ecc888f71dd8327a5b55c83adfbc0e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/0*rbUgSFk6Lwh5RbID"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基尼指数公式</p></figure><p id="af98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在二叉决策树中，分裂的<strong class="ky ir">基尼指数是通过将子节点(左右)的基尼指数乘以每个节点的案例比例来计算的。选择具有最大<strong class="ky ir">基尼系数</strong>(父基尼系数减去分割基尼系数)的属性作为分割属性。</strong></p><p id="634b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">熵标准</strong>也常用于在构建决策树时分割数据。如下所示，<strong class="ky ir">这个标准的范围是从0到1 </strong>，其中0代表完美分裂(纯节点)，就像基尼标准一样。然而，熵的最大值是1，而基尼系数的值是0.5。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/a8ebf1167a52089c1be9543eb82b6fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/0*qLJML2Hlv0u6z3aX"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">熵公式</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/5d9e59915e07175256ec4a3727d1645d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*srg-uFTkIiRcz62fWjLWBA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">熵(作者创建的图像)</p></figure><p id="82b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在每个阶段，数据将根据呈现更多<strong class="ky ir">信息增益</strong>(父节点的熵减去子节点的加权平均熵)的属性进行拆分。</p><p id="461c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">需要指出的是<strong class="ky ir">基尼系数和熵值这两种分割方法哪个更合适</strong>并没有确定的规则。事实上，在实践中，两者产生的结果是相似的。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="ffa3" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">用Scikit-learn构建决策树</h1><p id="bfa2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在这个简短的理论解释之后，是时候使用Scikit-learn库构建第一个决策树了。</p><div class="nf ng gp gr nh ni"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">sk learn . tree . decision tree classifier-sci kit-learn 0 . 24 . 2文档</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">决策树分类器。了解更多信息。参数标准{"gini "，"熵" }，default="gini "该函数用于…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">scikit-learn.org</p></div></div><div class="nr l"><div class="ov l nt nu nv nr nw kp ni"/></div></div></a></div><p id="b7c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们将使用来自<code class="fe mp mq mr ms b">tree</code>模块的<code class="fe mp mq mr ms b">DecisionTreeClassifier</code>类。这个类接受几个参数作为输入(所有参数都有一个默认值)。在这种特殊情况下，我们使用熵作为构建树的分裂方法；因此，我们必须设置参数<code class="fe mp mq mr ms b">criterion='entropy'</code>，因为默认的分割方法是基尼系数。一旦定义了决策树，我们就调用fit方法来训练算法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="b7cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以用<code class="fe mp mq mr ms b">tree</code>模块中的<code class="fe mp mq mr ms b">export_graphviz</code>函数来可视化得到的决策树。该函数以<strong class="ky ir">点格式</strong>导出决策树，可被<code class="fe mp mq mr ms b">graphviz</code>库用来生成<strong class="ky ir"> png图像</strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/4134a03b73ad99017c3ebe9068937709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_oIOnXnYywKx33q0MwTlsQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有默认参数的决策树</p></figure><p id="6b16" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">没有预修剪，<strong class="ky ir">树会长到所有的叶子都是纯净的</strong>。正如你所观察到的，所有树叶的熵都等于0。这给出了一个树，其中训练集的所有实例都被正确分类。如果我们不限制树的深度，我们就冒着获得复杂模型的风险，这种模型不能正确地推广到新数据。在接下来的部分中，我们将应用<strong class="ky ir">预剪枝方法来降低树</strong>的复杂度，从而在不损失性能的情况下获得更加简单的决策树。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="ce9c" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">特征重要性</h1><p id="af28" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">特征重要性表示特征在区分不同类别时的相关程度。在Scikit-learn中，我们可以用<code class="fe mp mq mr ms b">feature_importances_</code>属性获得每个特性的相对重要性。特征的重要性计算为该特征带来的杂质的(标准化)总减少量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/cf0f2a300eeba7c898a465f33d198c1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*ngY2KncOZ6Fjjcby5FGFLQ.png"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/28378a054f5af3b0d4e1c609098f916c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*7athC6N_4Nqj43dEcEzOOg.png"/></div></figure><p id="70f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数字越大，特性的重要性越大。如上所示，当预测患者是否有脊柱问题时，属性<code class="fe mp mq mr ms b">degree_spondylolisthesis</code>表现出更高的重要性。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="20d0" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">混淆矩阵</h1><p id="e080" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><strong class="ky ir">混淆矩阵</strong>，也称为误差矩阵，用于<strong class="ky ir">通过检查正确和错误分类的观察值数量来评估机器学习模型</strong>的性能。<strong class="ky ir">矩阵的每一列包含预测类别，而每一行代表实际类别，反之亦然</strong>。在完美的分类中，除了对角线之外，混淆矩阵将全为零。<strong class="ky ir">主对角线之外的所有元素代表错误分类。</strong>重要的是要记住，混淆矩阵允许我们观察错误分类的模式(错误分类的类别和程度)。</p><p id="eab1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<strong class="ky ir">二元分类问题</strong>中，<strong class="ky ir">混淆矩阵</strong>是一个由4个元素组成的<strong class="ky ir"> 2乘2矩阵</strong>:</p><ul class=""><li id="61a2" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir"> TP(真阳性)</strong>:被正确归类为患病的脊柱问题患者人数。</li><li id="22cf" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir"> TN(真阴性)</strong>:被正确分类为健康的无病变患者的数量。</li><li id="a5fa" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir"> FP(假阳性)</strong>:被错误归类为患病的健康患者人数。</li><li id="445e" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir"> FN(假阴性)</strong>:被误分类为健康的脊柱疾病患者数量。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/f49d8d8d0da56bc67b13ef2fdc65823d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B4wGIPd9QsfpeBTeLGqDuQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者创造的形象</p></figure><p id="10e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">既然模型已经训练好了，是时候使用测试集来评估它的性能了。</strong>首先，我们使用之前的模型(决策树)来预测测试数据的类别标签(使用<code class="fe mp mq mr ms b">predict</code>方法)。然后，我们使用来自<code class="fe mp mq mr ms b">sklearn.metrics</code>包的<code class="fe mp mq mr ms b">confusion_matrix</code>函数构建混淆矩阵，以检查哪些观察值被正确分类。输出是一个NumPy数组，其中<strong class="ky ir">行表示真实值</strong>而<strong class="ky ir">列表示预测类</strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi po"><img src="../Images/1c991546c9bfa294dda1b767b43ee98b.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*V2J6_RGVaWYf7dS4fIiOJw.png"/></div></figure><p id="f600" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上所示，测试数据的65个观察值被模型正确分类(45个真阳性和20个真阴性)。相反，我们可以观察到13个错误分类(7个假阴性和6个假阳性)。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="ed07" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">评估指标</h1><p id="27c3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">评估模型的质量是机器学习过程的基本部分。最常用的<strong class="ky ir">绩效评估指标</strong>基于混淆矩阵的元素进行计算。</p><ul class=""><li id="089b" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir">准确性:</strong>表示预测被正确分类的比例。准确性是最常用的评估指标；但是，请务必记住，在处理不平衡的数据集时，准确性可能会产生误导。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/c32f7b0279f637a4cb0af462b2970613.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/0*T5rRRA2OjnyKd_U8"/></div></figure><ul class=""><li id="f1fd" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir">灵敏度:</strong>表示被识别为阳性样本(患病患者)的比例。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/67a236160ae8956602e1aa904f92d504.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/0*ETRiaD6uhUzW6FPY"/></div></figure><ul class=""><li id="1b6a" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir">特异性:</strong>表示阴性样本(健康患者)的比例。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/649299518b639ace12546446fbb56104.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/0*9mKN79V_B5F70Pl1"/></div></figure><ul class=""><li id="4e19" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir">精度:</strong>它代表实际正确的正面预测的比例。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/5da3050919c12e9731805a044a2c06bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/0*vpEF5n1Ns63nWG9a"/></div></figure><p id="ef89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以使用混淆矩阵的数字来手动计算评估指标。或者，Scikit-learn已经实现了函数<code class="fe mp mq mr ms b">classification_report</code>，该函数为<strong class="ky ir">提供了关键评估指标</strong>的摘要。分类报告包含每个类别达到的精度、灵敏度、f1值和支持度(样本数)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/d87cfb0d0ee38321d9a81eb12b9fd522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*ZmzrhxN-0Nedtsj-OTZIMg.png"/></div></figure><p id="3467" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上所示，我们获得了0.87 (45/(45+7))的灵敏度<strong class="ky ir">和0.77 (20/(20+6))的特异性。所获得的模型更准确地预测患有脊柱病变的患者。这不应该让我们感到惊讶，因为<strong class="ky ir">决策树通常偏向于有更多观察的类</strong>(在这个例子中是<code class="fe mp mq mr ms b">AB</code>)。</strong></p><p id="c557" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可能已经注意到，之前的总结不包含分类的准确性。然而，这可以使用<code class="fe mp mq mr ms b">metrics</code>模块中的函数<code class="fe mp mq mr ms b">accuracy_score</code>轻松计算。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/7b8b66eecd9b11b65d98d1d6cf8d81d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*mX7uKGG4XafWU6_QSgW22g.png"/></div></figure><p id="890e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型做出正确预测的比例为<strong class="ky ir"> 83.33%。</strong></p><h1 id="93c0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">预修剪决策树</h1><p id="dea5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">决策树容易过拟合，为此，通常应用修剪技术来防止树过拟合数据中的噪声。这些技术可以分为两组:</p><ul class=""><li id="a1e6" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir">预修剪:</strong>这种方法根据给定的条件阻止树继续生长。</li><li id="3466" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir">后期修剪</strong>:树长到所有的叶子都是纯净的。然后，不重要的分支被转换成叶子。</li></ul><p id="ef36" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的<strong class="ky ir">预剪枝方法</strong>可以应用于<code class="fe mp mq mr ms b">DecisionTreeClassifier</code>构造函数，防止树继续生长:</p><ul class=""><li id="7028" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir">用参数<code class="fe mp mq mr ms b">max_depth</code>限制树的最大深度</strong>。此参数采用缺省值None，这意味着树将一直增长，直到所有训练数据的观察结果都被正确分类。注意该参数的限制是很重要的，因为低值容易产生拟合不足的模型(过于笼统)。</li><li id="d5cb" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir">用参数<strong class="ky ir"> </strong> <code class="fe mp mq mr ms b">max_leaf_nodes</code>限制最大叶片数</strong>。此参数设置决策树可以拥有的最终节点的最大数量。默认情况下，它的值为None。</li><li id="d47a" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir">用参数<code class="fe mp mq mr ms b">min_samples_split</code>确定一个节点中继续分裂的最小观察次数</strong>。该参数采用默认值2，因为具有两个样本的节点可以被分成两个节点(每个节点具有一个样本)。</li></ul><p id="2051" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的代码创建了一个带有预修剪的<strong class="ky ir">决策树模型。在这种情况下，决策树的<strong class="ky ir">最大层数</strong>被设置为8。8轮吐槽后决策树就要停止生长了。由于这个原因，期望一个比以前简单得多的树，因为没有预修剪，决策树的层数超过8。</strong></p><p id="736c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如下所示，带有预修剪的评估指标与之前获得的非常相似。模型做出正确预测的比例为<strong class="ky ir"> 82.05%。</strong>和以前一样，决策树更准确地预测脊柱病变患者(灵敏度高于特异性)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/eef7cc4ecef548e2df0e52e1ca242dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*qedsbkuBO4a38jiP-6hjrQ.png"/></div></figure><p id="67d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，带有预修剪的决策树更简单，也更容易理解，如下图所示。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pw"><img src="../Images/631f85ee0b253cb29aac2157e84bb6cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMj6o50m9b0zKWzro_6iBw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">带有预剪枝的决策树</p></figure><p id="372b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，<strong class="ky ir">决策树并不完全符合训练数据</strong>。有些树叶的熵大于0。因此，得到的树比前面的树更容易解释。</p><p id="05a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">预剪枝</strong>方法比<strong class="ky ir">后剪枝</strong>技术更有效(时间复杂度更低)，因为不需要生成整个树，然后删除不能为模型提供更高精度的分支。然而，正如您可能已经想到的，预修剪方法有一个缺点。通常很难精确估计何时停止树木的生长。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="dbc9" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">加权决策树</h1><p id="676b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在一些分类问题中，<strong class="ky ir">存在比其他</strong>更严重的特定错误。在医学诊断问题中，通常更糟糕的是犯下假阴性错误分类，因为这表示将患者诊断为健康，而实际上她/他患有疾病(在这种情况下是脊柱问题)。</p><p id="6524" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">成本矩阵</strong>允许克服这个问题，更严厉地针对代价高昂的误分类(在这种情况下是假阴性)。它基本上<strong class="ky ir">使一些错误分类比其他分类更昂贵</strong>。成本矩阵是n*n矩阵(n等于类的数量)，其中主对角线的所有元素都等于零，因为它们代表正确的分类(真阳性和真阴性)。其余元素将大于零，其中一个非对角线权重大于另一个，以便更严重地惩罚一种类型的错误分类(在这种情况下为假阴性)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi px"><img src="../Images/74b8d4a228cfe9f45d40e4240ee5c662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HsYMxt3cR3smzF15RQJokQ.png"/></div></div></figure><p id="4486" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以通过参数<code class="fe mp mq mr ms b">class_weight</code>在Scikit-learn中实现<strong class="ky ir">成本敏感决策树</strong>。该参数是一个字典，其中<strong class="ky ir">键</strong>是<strong class="ky ir">类标签</strong>，而<strong class="ky ir">值</strong>是成本矩阵的<strong class="ky ir">权重。</strong></p><p id="cc27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在构建决策树时，算法将考虑<strong class="ky ir">错误成本</strong>而不是<strong class="ky ir">信息增益</strong>。在下面的例子中，<strong class="ky ir">假阴性的误分类成本比假阳性的误分类成本大4倍</strong>。</p><p id="c897" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，加权决策树比以前的模型呈现出<strong class="ky ir">更高的灵敏度(90%) </strong>。在这种情况下，我们可以更有效地检测出患病的患者，只有5例假阴性。消极的一面是特异性的降低。现在，我们检测出表现较差的健康患者。</p><p id="90da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型甚至更偏向于具有更多观察值的类别(<code class="fe mp mq mr ms b">AB</code> -具有脊柱病理的患者)，这与我们想要以更高的准确度预测的类别相匹配。重要的是要记住，在医疗保健领域，假阴性比假阳性要糟糕得多。告诉病人健康可能会危及生命，因为他们无法接受所需的治疗。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi py"><img src="../Images/a2df73af08a3529bc179c31831fad200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*xYYNRiPABvnEPXK3C83tdQ.png"/></div></figure></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="4cc0" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">选择超参数—网格搜索</h1><p id="ebb5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><strong class="ky ir">超参数的选择会极大地影响机器学习模型的性能</strong>。网格搜索是寻找最佳超参数的常用方法。使用这种技术，我们分析超参数的所有组合，并最终选择性能最佳的组合。我们可以使用<code class="fe mp mq mr ms b">sklearn.model_selection</code>包中的<code class="fe mp mq mr ms b">GridSearchCV</code>类在Scikit-learn中轻松实现<strong class="ky ir">网格搜索</strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pz"><img src="../Images/cd54dece57c23380b9de8ba03cd484ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4-hF6e-bypWdzdWn6d7fA.png"/></div></div></figure><p id="1619" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们使用字典(<code class="fe mp mq mr ms b">grid_parameters</code>)指定<strong class="ky ir">参数值集</strong>，其中<strong class="ky ir">键</strong>是<strong class="ky ir">超参数</strong>，而<strong class="ky ir">值</strong>是我们想要评估的<strong class="ky ir">选项集</strong>。然后，我们定义了用于尝试不同参数组合的<code class="fe mp mq mr ms b">GridSearchCV</code>对象。该类将以下参数(以及其他默认值)作为输入:</p><ul class=""><li id="39bf" class="oz pa iq ky b kz la lc ld lf pb lj pc ln pd lr pe pf pg ph bi translated"><strong class="ky ir">估计器:</strong>用于超参数调整的机器学习算法。</li><li id="baaf" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir"> param_grid: </strong>包含超参数名称和值的字典。</li><li id="86f0" class="oz pa iq ky b kz pi lc pj lf pk lj pl ln pm lr pe pf pg ph bi translated"><strong class="ky ir">评分:</strong>我们希望最大化的绩效策略。</li></ul><p id="e470" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">拟合网格对象后，我们可以使用<code class="fe mp mq mr ms b">best_params_</code>属性获得<strong class="ky ir">最佳参数</strong>。在这种特殊情况下，我们希望最大化灵敏度(<strong class="ky ir">回忆分数</strong>)，因为我们希望专注于正确预测患者的病理状态。我们不想把任何生病的病人送回家。</p><p id="48fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们使用<code class="fe mp mq mr ms b">GridSearchCV</code>对象使用最佳参数进行预测({'class_weight': {'AB': 4，' NO': 1}，' criterion': 'gini '，' max_depth': 3})。如上所示，该模型的<strong class="ky ir">灵敏度为96% </strong>(远大于之前获得的灵敏度)。然而，该模型对无脊柱病变患者的预测准确性较低(特异性为54%)。</p><p id="8154" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">网格搜索是一种广泛使用的超参数调整方法；然而，这种技术有一个主要的缺点——时间复杂性。为每个超参数组合构建一个模型(决策树)(在本例中为2*9*3=54个模型)。如果超参数和值的数量非常大，那么要评估的模型数量也会相应增加。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="262d" class="ls lt iq bd lu lv na lx ly lz nb mb mc jw nc jx me jz nd ka mg kc ne kd mi mj bi translated">重要考虑因素——随机性</h1><p id="144a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在Scikit-learn中，当两个分裂并列时，<code class="fe mp mq mr ms b">DecisionTreeClassifier</code>将<strong class="ky ir">随机选择一个特性，这意味着它们的改进标准是相同的。这就是为什么<strong class="ky ir">不同的代码运行可能提供不同的结果</strong>。因此，如果您重新运行代码并获得与本文中提供的结果不同的结果，请不要担心。为了保证每次代码运行时都有相同的结果，我们应该使用<code class="fe mp mq mr ms b">random_seed</code>参数设置一个随机种子(在初始化<code class="fe mp mq mr ms b">DecisionTreeClassifier</code>构造函数时)。</strong></p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><p id="3540" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用Scikit-learn构建分类模型是一个简单明了的过程。这是因为已经实现了大量的算法和评估指标，使得构建分类模型的过程非常顺利。决策树不提供深度学习算法所提供的准确性；然而，它们很容易被非技术用户理解。所获得的结果可以帮助医生和研究人员了解哪些特征对脊柱病理影响最大，从而提高他们的检测能力。</p><p id="4936" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢你阅读❤️</p><p id="85c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">阿曼达·伊格莱西亚斯</p></div></div>    
</body>
</html>