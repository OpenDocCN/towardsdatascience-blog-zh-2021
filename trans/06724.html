<html>
<head>
<title>Scalable Machine Learning with Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Spark的可扩展机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scalable-machine-learning-with-spark-807825699476?source=collection_archive---------12-----------------------#2021-06-17">https://towardsdatascience.com/scalable-machine-learning-with-spark-807825699476?source=collection_archive---------12-----------------------#2021-06-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b1ed" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">分布式算法、Map-Reduce范式、在单机上使用Spark MLlib的可扩展ML、带有Docker的AWS EMR集群&amp; Nvidia RAPIDS。</em></h2></div><p id="5b59" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">自21世纪初以来，由于谷歌、网飞、Youtube、亚马逊、脸书等互联网巨头的出现，收集的数据量大幅增加。临近<strong class="ki ir"> 2010 </strong>，当<strong class="ki ir">手机</strong>大受欢迎时，另一个“数据浪潮”已经到来。到2020年，我们预计当<strong class="ki ir">物联网设备</strong>变得无孔不入时，数据将会再次呈指数级增长。在这种背景下，构建可扩展的系统成为机器学习解决方案的必要条件。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/efc911649a22510af8aa894b7f21d64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QSfsBPDBCRdtPV0Gwh4JNw.jpeg"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">Spark中的机器学习:从零到英雄版</p></figure><p id="5f0f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">任何解决方案都主要取决于这两种类型的任务:</p><p id="0824" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> a)计算量大:</strong>在2000年之前，被称为“超级计算机”的并行处理箱在计算量大的任务中很流行。在2005年之前，像<strong class="ki ir"> MPI和PVM这样的并行处理库在计算繁重任务</strong>中很流行，TensorFlow就是基于这种并行处理库设计的。</p><p id="ac09" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> b)数据量大:</strong>基于关系代数的数据库是在20世纪70年代设计的，当时硬盘存储非常昂贵。因此，该设计的<strong class="ki ir">目的是通过将较大的表格分成较小的表格，并使用关系(<strong class="ki ir">规范化)将它们链接起来，从而减少数据冗余</strong>。</strong></p><p id="4a31" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，传统的数据库如mySQL、PostgreSQL、Oracle等。不是为扩展而设计的，尤其是在上面提到的数据爆炸的环境中。因此，NoSQL数据库是为满足不同情况而设计的:</p><ol class=""><li id="fab8" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated">用于存储文本文档</li><li id="a8cf" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir"> Redis，Memcache: </strong>用于快速键值查找的分布式哈希表</li><li id="cffe" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir">弹性搜索:</strong>搜索文本文档</li><li id="597e" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir"> HBase和Cassandra: </strong>柱状商店</li><li id="1733" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir"> Neo4j和Grakn: </strong>图形数据库。</li></ol><p id="1ee2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然而，大型数据集上的机器学习和深度学习解决方案是<strong class="ki ir">计算密集型和数据密集型</strong>。因此，为了制造可扩展的AI/ML解决方案，解决方案必须同时满足这两种需求。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/ae647ba6f9e0bcac5701a7ae5b20c3eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/1*7gkJbSzg4sdteb1auVSfDQ.gif"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图一。作者使用MPI并行实现光子映射</p></figure><p id="d3ee" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">2004年，<em class="md"> Jeff Dean等人</em>发表了开创性的MapReduce论文来处理数据繁重的任务[2]。2006年，<strong class="ki ir"> Hadoop实现了MapReduce </strong>并设计了一个名为<strong class="ki ir"> HDFS </strong>的分布式文件系统，将单个大文件拆分存储在多台电脑的磁盘中。这个想法是将巨大的数据库分散在多个主板的硬盘上，每个主板都有独立的CPU、RAM、硬盘等，通过一个快速局域网互连。</p><p id="6ab6" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然而，<strong class="ki ir"> Hadoop将所有中间数据存储到磁盘</strong>，因为它是在2000年代设计的，当时硬盘价格暴跌，而RAM价格仍然很高。在2010年，当RAM价格下降时，<strong class="ki ir"> Spark </strong>诞生了一个大的设计变化<strong class="ki ir">将所有中间数据存储到RAM，而不是磁盘。</strong></p><p id="91c1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">火花对双方都有好处，</p><p id="f1fd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> i)数据密集型任务:</strong>因为它使用HDFS &amp;</p><p id="1db6" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> ii)计算繁重的任务:</strong>因为它使用RAM而不是磁盘来存储中间输出。<strong class="ki ir">例如:</strong>迭代求解</p><p id="1527" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">由于Spark可以利用RAM，它<strong class="ki ir">成为机器学习</strong>中迭代任务的有效解决方案，如随机梯度下降(<strong class="ki ir"> SGD </strong>)。所以是这个原因，<strong class="ki ir"> Spark MLlib </strong>变得如此受机器学习欢迎，与Hadoop的Mahout形成对比。</p><p id="426c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">此外，要使用TF进行分布式深度学习，您可以使用，</p><ol class=""><li id="0537" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated">多个GPU在<strong class="ki ir">同一个盒子上</strong> <em class="md">(或)</em></li><li id="3c90" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir">不同机箱</strong>上的多个GPU(GPU集群)</li></ol><p id="1989" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">虽然今天的超级计算机使用<strong class="ki ir"> GPU集群来执行计算密集型任务</strong>，但您可以在这样的集群中安装Spark，使其适用于分布式深度学习<strong class="ki ir">等任务，这些任务都是计算和数据密集型的</strong>。</p><h1 id="8eb8" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">Hadoop和Spark简介</h1><p id="2374" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">Hadoop中主要有两个组件，</p><ol class=""><li id="565c" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated"><strong class="ki ir"> Hadoop分布式文件系统(HDFS): </strong>一个容错的分布式文件系统，Hadoop和Spark都使用。HDFS支持将一个大文件分割成“n”个块，保存在“n”个节点中。当访问文件时，必须通过LAN跨节点访问不同的数据块。</li><li id="ac01" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir"> Map-Reduce: </strong>给定一个跨大量数据、分布在多个节点上的任务，必须进行大量的数据传输，并且需要分布处理。让我们详细研究一下这个问题。</li></ol><h1 id="6643" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated"><strong class="ak">地图简化范例</strong></h1><p id="97b7" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">考虑在900 GB的大型分布式文件中查找词频的任务。HDFS将支持将大文件拆分为3个区块，分别位于P1、P2和P3，每个区块300 GB，并在3个节点中各保留一个。</p><p id="160c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">任何Hadoop代码都会有<strong class="ki ir"> 3个阶段:</strong></p><ol class=""><li id="d1c4" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated"><strong class="ki ir"> Map </strong> : Mapper函数会通过数据，存储在各个节点的磁盘中，并递增输出字典中的字数。它将在每个分布式机器上独立执行<strong class="ki ir">。</strong></li></ol><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/5a75caa92dcc148f8c88a94fc637255d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uKA6Kc3ZCnkoeT52m_LidQ.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图二。字数统计图-简化工作流程(图片由作者提供)</p></figure><p id="0771" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 2。Shuffle: </strong> Hadoop自动在局域网内移动数据，这样相同的键就被组合在一个盒子里。</p><p id="a632" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 3。Reduce: </strong>一个函数，它将使用字典并将相同关键字的值相加(以计算总数)。</p><p id="f5e2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">要在Hadoop中实现一个函数，只需要编写Map &amp; Reduce函数。请注意，Hadoop中的每个Map-Reduce 操作之间都有<strong class="ki ir">磁盘I/O。然而，几乎所有的ML算法都是迭代工作的。SGD[下面的等式]中的每个迭代步骤对应于一个Map-Reduce操作。<em class="md">在每个迭代步骤之后，中间权重将被写入磁盘</em>，占总收敛时间的90%。</strong></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/678bcc5acc8c30479db85ab167491383.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*Ey2vXS74vWMviUUMQaFw2w.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated"><strong class="bd nh">等式</strong>:ML&amp;DL迭代中的权重更新公式</p></figure><p id="4908" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">作为解决方案，<strong class="ki ir"> Spark </strong>诞生于2013年<strong class="ki ir"> </strong>即<strong class="ki ir">将磁盘I/O操作替换为内存操作。</strong>借助<strong class="ki ir">Mesos——分布式系统内核</strong>——<strong class="ki ir"/>Spark缓存每次迭代后的中间数据集。因为每次迭代的输出都存储在RDD中，所以只需要一次磁盘读写操作就可以完成SGD的所有迭代。</p><p id="cb34" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">Spark建立在<strong class="ki ir">弹性分布式数据集(RDD)之上，</strong>存储在主内存中的容错不可变分布式数据集集合。在RDD <strong class="ki ir">之上，DataFrame API </strong>被设计为抽象掉它的复杂性，并简化在Spark上进行机器学习。</p><p id="0bb0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">RDDs支持<strong class="ki ir">两种类型的操作:</strong></p><ol class=""><li id="958e" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated"><strong class="ki ir"> <em class="md">转换:</em> </strong> <em class="md"> </em>从现有数据集创建新的数据集<br/><strong class="ki ir">映射:</strong>通过<em class="md">函数</em><br/><strong class="ki ir">reduce by key:</strong>使用<em class="md">函数</em><br/><strong class="ki ir">过滤器:</strong>仅选择那些使用<em class="md">函数的元素</em></li><li id="e7a9" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir"> <em class="md">动作:</em> </strong>对数据集运行计算后返回值<br/><strong class="ki ir">减少:</strong>使用某个<em class="md">函数</em><br/><strong class="ki ir">收集:</strong>返回输出数据集的所有元素<br/><strong class="ki ir">SaveAsTextFile:</strong>将数据集的元素作为文本文件写入。</li></ol><p id="533d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="md">Spark中的所有转换都是惰性的，</em>也就是说，它们只在“动作”需要结果时才被计算。在下面的代码中，由于懒惰，没有立即计算<em class="md">行长度</em>。只有当“reduce”运行时，Spark才会将计算分解为在不同机器上运行的任务，以计算总长度。</p><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="ef47" class="nn mf iq nj b gy no np l nq nr">lines = sc.textFile("data.txt")<br/>lineLengths = lines.map(lambda s: len(s))<br/>totalLength = lineLengths.reduce(lambda a, b: a + b)</span></pre><p id="1bb7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">下面是一个简单的数据转换示例，用于计算存储在3个分区的<strong class="ki ir">分布式RDD中的键的出现次数:</strong></p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">计算字母“a”和“b”的出现次数</p></figure><h1 id="276b" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">作为Map简化逻辑回归</h1><p id="d0a4" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">SGD迭代中最昂贵的操作是跨越所有数据点的梯度操作<em class="md">[公式。</em>【以上】。如果数据集很大，比如说“n”亿个数据点，那么我们可以将梯度计算分布在“k”个不同的盒子中。</p><ul class=""><li id="52f8" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated"><strong class="ki ir">贴图阶段:</strong>每个盒子将计算<em class="md"> n </em> /k个亿点的梯度</li><li id="0bab" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated"><strong class="ki ir">简化阶段:</strong>使用相同的键对每个框中的部分总和求和</li><li id="cd12" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">所有点的损失梯度= ∑部分和</li><li id="1117" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">因此，很容易计算w_new并存储在每个节点的存储器中</li></ul><p id="d2f4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这就是你如何分发任何基于优化的ML算法。然而，对于分布式LR实现，请参见Hadoop与Spark的性能比较。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c50a1a6738f84b7e24741b837caddbe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*ozdrKx4n0H-oDxlm.jpg"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图三。运行时间对比:Hadoop vs Spark [3]</p></figure><p id="471d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">由于Spark RDDs允许在内存中执行多种映射操作，因此不需要将临时数据集写入磁盘，因此速度提高了100倍。注意，<strong class="ki ir">第一次</strong>迭代花费的时间几乎相同，因为Hadoop和Spark都必须从磁盘读取。但是<strong class="ki ir">在后续的迭代中，Spark的内存读取只需要6秒，而Hadoop的磁盘读取需要127秒</strong>。</p><p id="64ab" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">此外，一个ML科学家不需要编码映射和简化函数。大多数ML算法包含在<strong class="ki ir"> Spark MLlib </strong>中，所有数据预处理都是使用<strong class="ki ir"> Spark SQL </strong>完成的。</p><h1 id="58a9" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">火花安装和设置</h1><p id="cd76" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">您可以在其中任何一个中设置Spark，</p><ol class=""><li id="7415" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated">您的本地机顶盒(或)</li><li id="0b81" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated">使用AWS EMR或Azure Databricks的托管集群</li></ol><p id="edb9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">下面我们将看到两种方式。首先，在完成Spark本地系统设置之后，我们将在您的个人机器上运行一些普通的并行任务。然后我们会拿一个更复杂的ML项目，在Spark Docker、AWS EMR &amp; Spark Rapids中运行。</p><h2 id="ed66" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">Spark:本地系统设置</h2><ol class=""><li id="c13f" class="lo lp iq ki b kj mw km mx kp oh kt oi kx oj lb lt lu lv lw bi translated"><em class="md">docker pull jupyter/pyspark-notebook</em></li><li id="0ea4" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated">docker run-it-p 8888:8888 jupyter/pyspark-notebook</li><li id="548b" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated">单击带有Auth-Token的链接或转到<a class="ae ok" href="http://localhost:8888/" rel="noopener ugc nofollow" target="_blank"> http://localhost:8888/ </a>并复制粘贴令牌</li><li id="bb17" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated">现在，您可以在Jupyter或终端中执行Spark代码。要在docker中执行，只需运行<strong class="ki ir"><em class="md">spark-submit pi-code . py</em></strong></li></ol><h2 id="7429" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">任务1:估计圆周率(π)的值</h2><p id="2482" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">取一个单位圆，考虑一个外接该圆的正方形。</p><ul class=""><li id="5315" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">单位正方形的面积= 1</li><li id="2884" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">因为是单位圆，所以圆的面积= π</li><li id="ae2f" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">四分之一圆弧的面积= π/4</li><li id="bd36" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">因此，π = 4 *四分之一圆弧的面积</li></ul><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/ada5a7c62ed29d32b9bd9cbaf464ab04.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*hFG_YRQyV0LyD16JzvriFA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图4。圆的面积=红色点数/总点数。(图片由作者提供)</p></figure><p id="215b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">四分之一圆弧的面积可以通过下式计算:</p><ol class=""><li id="db8e" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated"><strong class="ki ir">数值方法:</strong>使用积分</li><li id="ea87" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated"><strong class="ki ir">蒙特卡罗方法</strong>:使用随机抽样寻找答案</li></ol><p id="492c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在蒙特卡罗方法中，</p><ul class=""><li id="58a0" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">取(x，y)点的<em class="md">均匀分布</em>从0到1(即正方形内)</li><li id="8b17" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">四分之一区域的面积= <strong class="ki ir"> %圆内的点，</strong>即𝑥+𝑦&lt;1<br/>T9】eg:在1000个随机点中，如果“k”个点在圆内，那么阴影区域的面积= k/1000</li></ul><p id="ec2a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这些操作<strong class="ki ir">是可并行化的</strong>,因为为了检查一个点是否落在圆内，节点之间没有依赖性。在pyspark代码下面，一旦在spark本地设置上运行，<em class="md">将输出更接近π=3.14的值，因为我们增加了随机点数</em> (NUM_SAMPLES)</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="2854" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">随机函数将生成一个0到1之间的数字。</li><li id="b934" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">“inside”函数运行一百万次，只有当随机点在圆内时才返回“True”。</li><li id="3907" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">sc.parallelize()将创建一个分解为k=10个实例的RDD。</li><li id="0e14" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">过滤器将应用传递的函数。</li></ul><h2 id="f8c5" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">任务2:计算字数</h2><p id="1ae4" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">要在大型分布式文件中查找词频，只需将下面代码中的本地文件路径替换为HDFS文件路径。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="3623" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">map函数将创建一个列表列表&amp; flatMap将列表合并成一个列表。</p><h2 id="bf0a" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">任务3:数据预处理</h2><p id="c7e5" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">大多数数据预处理可以通过DataFrame API使用Spark SQL来完成。在Spark数据帧上执行的Spark SQL查询将在Spark中执行之前转换为Map和Reduce ops。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><h1 id="f0a5" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">Spark MLLib和ML管道简介</h1><p id="9d6f" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">Spark MLLib是一个受sklearn启发的库，它包含了<strong class="ki ir">流行ML算法</strong>的<strong class="ki ir">分布式</strong>实现。与sklearn的主要区别是使用sc.parallelize()函数将数据拆分到多个框中。</p><p id="c33e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">将磁盘上的原始数据转换成最终模型所需的所有步骤称为ML管道。Pipeline()依次包含<em class="md">输入和输出级。</em>例如，<em class="md">记号赋予器</em> → <em class="md">计数矢量化器</em> → <em class="md">逻辑回归</em>流水线序列可以编码为:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="94fe" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，训练数据首先被馈入tokenizer，然后馈入CV，然后馈入LR。若要测试模型，请调用model.transform()。您还可以进行<strong class="ki ir">分布式超参数调整，</strong>即在具有不同超参数的多个机器上运行相同的架构。然而，将一个大模型分布存储和训练在不同盒子中的GPU的VRAM中是稍微复杂的。</p><h1 id="cb30" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">Spark中的ML算法:自定义实现</h1><p id="1d1b" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">只有当一个算法可以被分成独立的子任务时，它才可以被并行化。具体来说，<strong class="ki ir">双字节排序</strong>可以并行，因为操作序列<strong class="ki ir">与数据无关，</strong>与合并排序无关。类似地，一些ML算法是平凡的可并行化的，而另一些则不是。</p><p id="88f3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> a)琐碎并行:</strong>以<strong class="ki ir">KNN</strong>(k-最近邻)为例。</p><ul class=""><li id="c0fb" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">将数据集D分成“n”个盒子。<strong class="ki ir">例如</strong> : 40K分4盒</li><li id="cadb" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">从每个框中的每个10K点中找出前k个最近的点</li><li id="f269" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">将所有4k个点转移到1个盒子中，并找到前k个最近的点。</li></ul><p id="df25" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> b)非平凡的平行:</strong>以GBDT <strong class="ki ir"> </strong>为例。在<strong class="ki ir"> GBDT </strong>中的每一棵决策树都是基于先前决策树的剩余部分构建的。因此，训练<strong class="ki ir"> GBDT本质上是一个顺序操作，而不是并行的。</strong></p><p id="434f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然而，我们可以并行构建每个决策树，因为用于左右子树的数据集是独立的。因此，xgboost在树级并行化，即左右子树在2个节点上独立训练。</p><h1 id="8b64" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">基于随机森林的时间序列预测</h1><p id="ae04" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">让我们在独立、Spark本地&amp;集群模式下解决一个ML问题<strong class="ki ir">。</strong></p><p id="a741" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">问题陈述:</strong>从1990 ~ 2020年代记录一个地点的每日<em class="md">气温、风、降雨和湿度</em>。鉴于这些特征，<strong class="ki ir">建立时间序列模型预测2021年的湿度。</strong>为了验证模型，使用2020Q4湿度值进行比较，使用公制。</p><p id="87ee" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">下面实验的<strong class="ki ir">完整源代码</strong>可以在<a class="ae ok" href="https://github.com/AdroitAnandAI/Scalable-ML-with-Spark" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">这里</strong> </a> <strong class="ki ir">找到。</strong></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi om"><img src="../Images/39790a624bd4abbf3ad659e926716538.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*21pxYrYVhKPkEqJrhEq5xA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated"><em class="kf">图五。输入数据集特征</em></p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi on"><img src="../Images/bf5d81a08ab4040ffaf52be570d38120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YcUsy0J-UWQd07jbXjjyDA.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated"><em class="kf">图六。</em>湿度值的时间序列性质清晰可见</p></figure><p id="6a46" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">首先，转换数据以获得对预测湿度有用的新特征。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/30db130462c1f4efb36bb1975a178b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*ZK4IEl1i9xOm1xhO3jVKDQ.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图7。新功能:日、周和规模=温度*降雨量</p></figure><h2 id="90cc" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">A.独立实现</h2><p id="ab26" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">现在我们可以用上述特征训练sklearn的随机森林回归器。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="8d3a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">预测湿度值和实际湿度值过于接近(如下图所示)</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi op"><img src="../Images/f3955d7fce18fcb3d9e1d79841a10487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x35MIjr2QKS7LjyZ7b66Qg.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图8。2020Q4湿度:蓝红线表示实际和预测湿度(独立)</p></figure><h2 id="3b11" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">B.Spark本地实施</h2><p id="c89e" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">首先，你需要做上面提到的<strong class="ki ir"> Spark本地系统设置</strong>步骤。然后，你可以用PySpark的RandomForestRegressor做上面同样的事情。</p><p id="1b11" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">要在Spark MLlib中为机器学习模型提供功能，您需要使用Spark ML库中的VectorAssembler模块将多个列合并为一个向量列。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oq"><img src="../Images/ddd591c7bb5aa2330075d0295468953d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KJwtKR07VN90L7wiHYhoYA.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图九。使用VectorAssembler组合特征</p></figure><p id="8b2e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然后，您可以运行类似于独立解决方案的训练和测试模块。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi or"><img src="../Images/966071be6b7f93d5aff67417ae557d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*V4cF-R0wCi7dWkDsG8l3TA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图10。预测回归值(湿度)</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi os"><img src="../Images/7f981c61f04666545680910d72817f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pIyDQZ5ZLsfAXqkjZG1wfg.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图11。2020Q4湿度:实际和预测(局部火花)</p></figure><p id="91f0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">PySpark中的分布式随机森林回归器实现似乎也遵循这一趋势，尽管均方误差值稍高一些。即便如此，在64G RAM的四核系统上，spark本地实现的运行时间还是快了<em class="md">3倍。</em></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/2c1e61120bcd815c15ece946a2578f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*gJEl-LZI7dPVtG0i3YJVfg.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图12。独立:2.14秒。Spark Local: 0.71秒用于随机森林回归训练</p></figure><h2 id="30b2" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">C.火花簇:AWS弹性贴图Reduce + Docker</h2><p id="971d" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">为了获得计算和数据规模的双重优势，上述解决方案需要跨多个机器部署。然而，使用本地机器用Spark设置集群是很耗时的。</p><p id="5521" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">相反，您可以使用Amazon EMR创建一个集群，负载运行在Amazon EC2实例上。亚马逊EMR是一个托管集群平台，简化了运行大数据框架，如Apache Hadoop和Spark。</p><p id="4e75" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">从Amazon EMR 6.0.0开始，您可以使用<em class="md"> Docker容器来处理库依赖关系</em>，而不是将其安装在每个EC2集群实例上。但是您需要在AWS EMR中的“集群创建”期间配置Docker注册表并定义附加参数。</p><ol class=""><li id="e160" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated"><strong class="ki ir">创建一个docker图像(或修改一个Docker图像)</strong></li></ol><p id="d5c2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">创建一个目录和一个requirements.txt文件。requirements.txt文件应该包含Spark应用程序所需的所有依赖项。</p><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="8b7e" class="nn mf iq nj b gy no np l nq nr">mkdir pyspark<br/>vi pyspark/requirements.txt<br/>vi pyspark/Dockerfile</span><span id="f142" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">Sample requirements.txt:</strong><br/><br/>python-dateutil==2.8.1<br/>scikit-image==0.18.1<br/>statsmodels==0.12.2<br/>scikit-learn==0.23.2</span></pre><p id="2924" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在目录中创建一个Dockerfile文件，包含以下内容。安装了特定的numpy版本，以从EMR笔记本确认docker执行。</p><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="4c12" class="nn mf iq nj b gy no np l nq nr"><strong class="nj ir">FROM amazoncorretto:8</strong></span><span id="f799" class="nn mf iq nj b gy ou np l nq nr">RUN yum -y update<br/>RUN yum -y install yum-utils<br/>RUN yum -y groupinstall development</span><span id="b2e9" class="nn mf iq nj b gy ou np l nq nr">RUN yum list python3*<br/>RUN yum -y install python3 python3-dev python3-pip python3-virtualenv python-dev</span><span id="e1f1" class="nn mf iq nj b gy ou np l nq nr">RUN python -V<br/>RUN python3 -V</span><span id="af2a" class="nn mf iq nj b gy ou np l nq nr">ENV PYSPARK_DRIVER_PYTHON python3<br/>ENV PYSPARK_PYTHON python3</span><span id="8e10" class="nn mf iq nj b gy ou np l nq nr">RUN pip3 install --upgrade pip<br/>RUN pip3 install 'numpy==1.17.5'</span><span id="9aad" class="nn mf iq nj b gy ou np l nq nr">RUN python3 -c "import numpy as np"</span><span id="2424" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">WORKDIR /app</strong></span><span id="3e16" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">COPY requirements.txt requirements.txt</strong><br/><strong class="nj ir">RUN pip3 install -r requirements.txt</strong></span></pre><p id="890e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">使用以下命令构建docker映像。</p><p id="b014" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 2。创建ECR存储库。</strong>标记并将本地构建的图像上传至ECR。</p><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="28f4" class="nn mf iq nj b gy no np l nq nr"><strong class="nj ir">sudo docker build</strong> -t local/pyspark-example pyspark/<br/><strong class="nj ir">aws ecr create-repository</strong> --repository-name emr-docker-examples</span><span id="2dc5" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">sudo docker tag</strong> local/pyspark-example 123456789123.dkr.ecr.us-east-1.amazonaws.com/emr-docker-examples:pyspark-example</span><span id="4882" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">sudo aws ecr get-login </strong>--region us-east-1 --no-include-email |<!-- --> <strong class="nj ir">sudo docker login</strong> -u AWS -p &lt;password&gt; https://123456789123.dkr.ecr.us-east-1.amazonaws.com</span><span id="aead" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">sudo docker push</strong> 123456789123.dkr.ecr.us-east-1.amazonaws.com/emr-docker-examples:pyspark-example</span></pre><p id="dca2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">也可以上传到Docker Hub，给<em class="md">' Docker . io/account/Docker-name:tag '</em>代替上面的AWS ECR图像URI。</p><p id="68a1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 3。在EMR中创建带火花的集群</strong></p><p id="7165" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">打开亚马逊电子病历控制台<em class="md">(参考</em> <a class="ae ok" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-launch.html" rel="noopener ugc nofollow" target="_blank"> <em class="md">此处</em> </a> <em class="md"> ) </em></p><p id="05df" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">点击“进入高级选项”而不是“快速选项”来启用，</p><ul class=""><li id="a768" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated"><strong class="ki ir"> Jupyter企业网关:</strong>代表远程笔记本帮助启动内核的网络服务器。</li><li id="a4ad" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated"><a class="ae ok" href="https://jupyterhub.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir"> JupyterHub </strong> </a>:托管Jupyter笔记本服务器的多个实例。</li><li id="f056" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated"><strong class="ki ir"> Apache Livy: </strong>支持通过REST接口与Spark集群交互的服务。</li></ul><p id="be82" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">根据所需的并行度，选择每种节点类型的<strong class="ki ir">的节点数量</strong></p><ul class=""><li id="60a7" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated"><strong class="ki ir">主节点:</strong>通过协调其他节点之间的数据和任务分配来管理集群</li><li id="c55e" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated"><strong class="ki ir">核心节点:</strong>在HDFS运行任务和存储数据(多节点至少一个)</li><li id="0c2c" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated"><strong class="ki ir">任务节点:</strong>只运行任务&amp;不在HDFS存储数据(可选)</li></ul><p id="7650" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，核心节点增加了数据和计算并行性，而任务节点仅增加了计算并行性。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ov"><img src="../Images/d637a74b8ed2cfb0acecdea6b7f61809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*eG2D5oDoPFAbdQQG22r_tA.gif"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图13。如何使用AWS EMR创建Spark集群</p></figure><p id="2844" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 4。进入“软件设置”下的<em class="md">配置</em></strong></p><p id="91a9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了避免userid错误，请在下面的JSON中设置“livy.impersonation”</p><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="d221" class="nn mf iq nj b gy no np l nq nr">[<br/>  {<br/>    "Classification": "container-executor",<br/>    "Configurations": [<br/>        {<br/>            "Classification": "<strong class="nj ir">docker</strong>",<br/>            "Properties": {<br/>                "docker.trusted.registries": "local,centos,<strong class="nj ir">123456789123.dkr.ecr.us-east-1.amazonaws.com"</strong>,<br/>                "docker.privileged-containers.registries": "local,centos,<strong class="nj ir">123456789123.dkr.ecr.us-east-1.amazonaws.com</strong>"<br/>            }<br/>        },<br/>    ]<br/>  },<br/>  {<br/>      "Classification":<strong class="nj ir">"livy-conf"</strong>,<br/>      "Properties":{<br/>         <strong class="nj ir">"livy.impersonation.enabled": "true"</strong>,<br/>         "livy.spark.master":"yarn",<br/>         "livy.spark.deploy-mode":"cluster",<br/>         "livy.server.session.timeout":"16h"<br/>      }<br/>   },<br/>   {<br/>    "Classification": "core-site",<br/>    "Properties": {<br/>      "hadoop.proxyuser.livy.groups": "*",<br/>      "hadoop.proxyuser.livy.hosts": "*"<br/>    }<br/>   },<br/>   {<br/>      "Classification":"hive-site",<br/>      "Properties":{<br/>         "hive.execution.mode":"container"<br/>      }<br/>   },<br/>   {<br/>      "Classification":<strong class="nj ir">"spark-defaults"</strong>,<br/>      "Properties":{<br/>         "spark.executorEnv.YARN_CONTAINER_RUNTIME_TYPE":"<strong class="nj ir">docker</strong>",<br/>         "spark.yarn.am.waitTime":"300s",<br/>         "spark.yarn.appMasterEnv.YARN_CONTAINER_RUNTIME_TYPE":"<strong class="nj ir">docker</strong>",<br/>         "spark.executorEnv.YARN_CONTAINER_RUNTIME_DOCKER_CLIENT_CONFIG":<strong class="nj ir">"hdfs:///user/hadoop/config.json"</strong>,<br/>         "spark.executorEnv.YARN_CONTAINER_RUNTIME_DOCKER_IMAGE":<strong class="nj ir">"123456789123.dkr.ecr.us-east-1.amazonaws.com/scalableml:s3spark"</strong>,</span><span id="c3d8" class="nn mf iq nj b gy ou np l nq nr">"spark.executor.instances":"2",<br/>         "spark.yarn.appMasterEnv.YARN_CONTAINER_RUNTIME_DOCKER_CLIENT_CONFIG":<strong class="nj ir">"hdfs:///user/hadoop/config.json"</strong>,<br/>         "spark.yarn.appMasterEnv.YARN_CONTAINER_RUNTIME_DOCKER_IMAGE":<strong class="nj ir">"123456789123.dkr.ecr.us-east-1.amazonaws.com/scalableml:s3spark"</strong><br/>      }<br/>   }<br/>]</span></pre><p id="feb4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 5。从纱线启用ECR访问</strong></p><p id="91aa" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了使YARN能够从ECR访问图像，我们设置了容器环境变量YARN _ CONTAINER _ RUNTIME _ DOCKER _ CLIENT _ CONFIG。</p><p id="eb17" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">但是，我们需要生成config.json并放入HDFS，以便它可以被集群上运行的作业使用。为此，登录到一个核心节点并执行以下命令。</p><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="fd19" class="nn mf iq nj b gy no np l nq nr"><strong class="nj ir">ssh -i permission.pem </strong><a class="ae ok" href="mailto:hadoop@ec2-3-83-46-34.compute-1.amazonaws.com" rel="noopener ugc nofollow" target="_blank"><strong class="nj ir">hadoop@</strong>ec2-1-23-45-678.compute-1.amazonaws.com</a></span><span id="ff86" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">aws ecr get-login-password </strong>--region us-east-1 | sudo docker login --username AWS --password-stdin <!-- -->123456789123<!-- -->.dkr.ecr.us-east-1.amazonaws.com</span><span id="5080" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">mkdir -p ~/.docker</strong><br/><strong class="nj ir">sudo cp </strong>/root/.docker/config.json ~/.docker/config.json<br/><strong class="nj ir">sudo chmod </strong>644 ~/.docker/config.json</span><span id="3bd8" class="nn mf iq nj b gy ou np l nq nr"><strong class="nj ir">hadoop fs -put</strong> ~/.docker/config.json /user/hadoop/</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ow"><img src="../Images/cac0da214b79b51dde71fc6831355d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*GqCPLdVCxr6q7rqED6XHMg.gif"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图14。让ECR接触纱线</p></figure><p id="143e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 6。EMR笔记本和配置</strong></p><p id="fde4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">您可以创建jupyter笔记本，并连接到运行Hadoop、Spark和Livy的Amazon EMR集群。EMR笔记本独立于集群保存在AWS S3中。</p><ul class=""><li id="18b4" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">点击亚马逊电子病历控制台上的“笔记本”和“创建笔记本”</li><li id="ba6e" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">选择运行笔记本的群集</li><li id="c6c4" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">在Jupyter笔记本中，<strong class="ki ir">给出下面的配置作为第一个单元格。</strong></li></ul><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="f243" class="nn mf iq nj b gy no np l nq nr"><strong class="nj ir">%%configure -f</strong><br/>{"conf": <br/> { <br/>     "spark.pyspark.virtualenv.enabled": "false",<br/>     "spark.yarn.appMasterEnv.YARN_CONTAINER_RUNTIME_TYPE":"<strong class="nj ir">docker</strong>",<br/>     "spark.executorEnv.YARN_CONTAINER_RUNTIME_DOCKER_CLIENT_CONFIG":"<strong class="nj ir">hdfs:///user/hadoop/config.json</strong>",<br/>     "spark.executorEnv.YARN_CONTAINER_RUNTIME_DOCKER_IMAGE":"<strong class="nj ir">123456789123.dkr.ecr.us-east-1.amazonaws.com/scalableml:s3spark</strong>",<br/>     "spark.executor.instances":"2",<br/>     "spark.yarn.appMasterEnv.YARN_CONTAINER_RUNTIME_DOCKER_CLIENT_CONFIG":"<strong class="nj ir">hdfs:///user/hadoop/config.json</strong>",<br/>     "spark.yarn.appMasterEnv.YARN_CONTAINER_RUNTIME_DOCKER_IMAGE":"<strong class="nj ir">123456789123.dkr.ecr.us-east-1.amazonaws.com/scalableml:s3spark</strong>"<br/> }<br/>}</span></pre><ul class=""><li id="0733" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">因此，您可以在EMR笔记本中使用<em class="md">笔记本范围的docker </em>来解决依赖性。现在您可以在后续单元格中执行PySpark代码。</li></ul><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="8a3a" class="nn mf iq nj b gy no np l nq nr">from pyspark.sql import SparkSession<br/>spark = SparkSession.builder.appName("docker-numpy").getOrCreate()<br/>sc = spark.sparkContext<br/><br/>import numpy as np<br/><strong class="nj ir">print(np.__version__)</strong></span></pre><p id="ca36" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">理想情况下，如果上面的代码在构建的docker中运行，您应该看到1.17.5 的numpy版本。如果没有，您需要找到S3集群日志路径。</p><ul class=""><li id="5c04" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">您可以使用上面的Spark独立代码，只是输入数据应该从S3读取，如下所示，并转换为RDD。</li></ul><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="d075" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如下图所示，随着EMR集群中节点数量的增加，RandomForest训练工作负载所用的时间稳步减少。<strong class="ki ir">节点间通信的基本开销将保持不变，即使是小数据集。</strong> <em class="md">因此，当训练数据集变大时，图形会下降得更陡。</em></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/72b448bed84827aead9e0bb158e60fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*cvuxMRhV6Knfx0_ZJdnEkA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图15。不同集群规模的EMR集群性能</p></figure><p id="3100" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">或者，在<em class="md">通过SSH连接到</em> <strong class="ki ir"> <em class="md">主节点</em> </strong> <em class="md">之后，您可以使用<strong class="ki ir"> spark-submit </strong>命令在集群中执行PySpark代码。</em></p><ul class=""><li id="1491" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb nu lu lv lw bi translated">设置<em class="md">DOCKER _ IMAGE _ NAME&amp;DOCKER _ CLIENT _ CONFIG</em>env变量</li><li id="435f" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">执行。带有<strong class="ki ir"> spark的py文件-提交</strong> &amp;部署模式为“集群”</li><li id="e5c7" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb nu lu lv lw bi translated">您可以从S3读取输入并写出输出，如下所示。</li></ul><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="1e05" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">但是，通过运行在Spark集群上的Notebook提交Spark作业更方便，同时docker可以解析所有集群节点中的依赖关系。</p><h2 id="3810" class="nn mf iq bd mg nw nx dn mk ny nz dp mo kp oa ob mq kt oc od ms kx oe of mu og bi translated">D.GPU集群:AWS EMR + Spark RAPIDs</h2><p id="0371" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">您可以使用“Nvidia Spark-RAPIDS plugin for Spark”来加速使用连接到EC2节点的GPU的ML管道。核心和任务实例组必须使用EC2 <a class="ae ok" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-supported-instance-types.html" rel="noopener ugc nofollow" target="_blank"> GPU实例类型</a>，而主节点可以是非ARM非GPU。</p><p id="7f22" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">Spark RAPID将加速数据处理和模型训练<strong class="ki ir">，而无需任何代码更改</strong>。要创建GPU加速集群，您可以遵循C节中的步骤，但要做以下更改:</p><ol class=""><li id="b36c" class="lo lp iq ki b kj kk km kn kp lq kt lr kx ls lb lt lu lv lw bi translated">在这里 使用<strong class="ki ir">步骤5 </strong> <a class="ae ok" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-rapids.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">给出的JSON，而不是C节中的config</strong></a></li><li id="528c" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated">保存<strong class="ki ir">自举</strong>脚本给<a class="ae ok" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-rapids.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">此处</strong> </a> <strong class="ki ir"> </strong>在S3为<em class="md">my-bootsap-action . sh</em></li><li id="9a7d" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated">将步骤2中的S3文件路径作为引导脚本(在GPU上使用YARN)</li><li id="e289" class="lo lp iq ki b kj lx km ly kp lz kt ma kx mb lb lt lu lv lw bi translated">到主节点的SSH并安装依赖项。要执行时序项目，请执行下面的命令。</li></ol><pre class="ld le lf lg gt ni nj nk nl aw nm bi"><span id="3cb6" class="nn mf iq nj b gy no np l nq nr">pip3 install sklearn statsmodels seaborn matplotlib pandas boto3</span></pre><p id="1f02" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">不需要更改代码。下面是Spark-RAPIDS集群上的随机森林回归训练的时间比较，该集群由1个m 5.2 x大型主节点和2个g4dn . 4x大型核心节点组成，具有其他执行模式。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/b62f2ef7e5954d3547e0018d9b742b2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*abbOGOOsG9BN4DSi0QCY6g.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图16。时间比较:独立vs Spark本地vs RAPIDS</p></figure><p id="5bdd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然而，在上面的例子中，由于数据集很小，所以速度提高不多。让我们对前面的“字母表计数”代码做一个修改，以比较Spark Local和Spark RAPIDS之间的时间统计。下面的代码<strong class="ki ir">生成100M个随机</strong>字符串和计数元组，以馈入分布式计数操作。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ns nt l"/></div></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oz"><img src="../Images/70585c612fd3bdba70a5f4bd6f125f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMwyK8ZngmgJHIMxWmRV_A.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图17。AWS EMR笔记本中的Spark作业进度报告</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/95d73522b3c440678b55d0564118ff1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*ELgwTk1K9yM7vtLkk--VaA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图18。时间比较:火花本地vs火花急流</p></figure><h1 id="3750" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">结束语</h1><p id="9287" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">为博客的长度道歉。如果您已经读到这里，您应该考虑用一些分布式编码来弄脏您的手。本文为您提供了Spark的历史和逻辑背景，以及在Local、AWS EMR和Spark Rapids上的多个示例实现。如果它激励你进一步探索，那么它就达到了它的目的。</p><p id="cd71" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">以上实验的<strong class="ki ir">完整源代码</strong>可以在<a class="ae ok" href="https://github.com/AdroitAnandAI/Scalable-ML-with-Spark" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">这里</strong> </a> <strong class="ki ir">找到。</strong></p><p id="46d2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> <em class="md">如有任何疑问或建议，可在此</em> </strong> 联系我  <a class="ae ok" href="https://www.linkedin.com/in/ananduthaman/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir"> <em class="md"/></strong></a></p><h1 id="7ead" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">参考</h1><p id="f5cc" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">[1]<a class="ae ok" href="http://www.appliedaicourse.com" rel="noopener ugc nofollow" target="_blank">www.appliedaicourse.com</a></p><p id="38aa" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">[2]迪安、杰弗里和桑杰·格玛瓦特。<em class="md">“MapReduce:大型集群上的简化数据处理。”</em> <em class="md">美国计算机学会通讯</em> 51.1 (2008)</p><p id="e683" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">[3]巴加瓦蒂、阿伦库马尔&amp;察切娃、安吉丽娜。(2017).<em class="md">分布式环境中基于规则的系统:调查。</em> 10.11159/cca17.107</p><p id="9f28" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">[4] <strong class="ki ir"> PySpark文档:</strong><a class="ae ok" href="https://spark.apache.org/docs/latest/api/python/index.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/latest/api/python/index.html</a></p><p id="fc08" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">[5] <strong class="ki ir">火花MLLib:</strong><a class="ae ok" href="https://spark.apache.org/docs/1.2.1/mllib-guide.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/1.2.1/mllib-guide.html</a></p><p id="1648" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">[6]<strong class="ki ir">Spark SQL:</strong><a class="ae ok" href="https://spark.apache.org/docs/2.2.0/sql-programming-guide.html#sql" rel="noopener ugc nofollow" target="_blank">https://Spark . Apache . org/docs/2 . 2 . 0/SQL-programming-guide . html # SQL</a></p><p id="5ff2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">【7】<strong class="ki ir">AWS EMR:</strong><a class="ae ok" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-docker.html" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/EMR/latest/release guide/EMR-spark-docker . html</a></p><p id="8a0b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">[8]<strong class="ki ir">AWS EMR with Docker:</strong><a class="ae ok" href="https://aws.amazon.com/blogs/big-data/simplify-your-spark-dependency-management-with-docker-in-emr-6-0-0/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/blogs/big-data/simplify-your-spark-dependency-management-with-Docker-in-EMR-6-0-0/</a></p><p id="320d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">[9] <strong class="ki ir"> GPU集群(Spark-Rapids):</strong><a class="ae ok" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-rapids.html" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/EMR/latest/release guide/EMR-Spark-Rapids . html</a></p></div></div>    
</body>
</html>