<html>
<head>
<title>Xgboost Regression Training on CPU and GPU in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中CPU和GPU上的Xgboost回归训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/xgboost-regression-training-on-cpu-and-gpu-in-python-5a8187a43395?source=collection_archive---------20-----------------------#2021-03-22">https://towardsdatascience.com/xgboost-regression-training-on-cpu-and-gpu-in-python-5a8187a43395?source=collection_archive---------20-----------------------#2021-03-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4899" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用GPU解锁Python中xgboost模型的快速训练</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/844da70f302ed1c57714027350422a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q6IdeF35djYrU177L_PoKA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GPU vs CPU作者绘画</p></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="a5d3" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在本文中，我将介绍使用GPU而不是默认CPU来训练xgboost模型所需的步骤。</p><p id="b9be" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">此外，还分析了矩阵的大小和某些超参数对训练速度的影响。</p><p id="db62" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">随意从这里克隆或派生所有代码:<a class="ae mb" href="https://github.com/Eligijus112/xgboost-regression-gpu" rel="noopener ugc nofollow" target="_blank">https://github.com/Eligijus112/xgboost-regression-gpu</a>。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="da8d" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">为了在GPU上训练机器学习模型，你需要在你的机器上安装一个<strong class="lh iu"> G </strong>图形<strong class="lh iu"> P </strong>处理<strong class="lh iu">U</strong>nit——GPU-a显卡。默认情况下，机器学习框架会在计算机内部搜索一个<strong class="lh iu">C</strong>entral<strong class="lh iu">P</strong>processing<strong class="lh iu">U</strong>nit——CPU。</p><p id="bdcb" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我在训练中使用的机器内部:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mc"><img src="../Images/2dec030765231d8bf5cd1236ee59ec67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ND6tFTj0AjY76UzB972yA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在我的桌面内部；照片归作者所有</p></figure><p id="87ef" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">有问题的主要部分是:</p><p id="cf95" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu"> <em class="md"> GPU —英伟达GeForce RTX 3080 </em> </strong></p><p id="e7ef" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu"> <em class="md"> CPU — AMD锐龙7 5800X </em> </strong></p><p id="adf3" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">下一步是获得Nvidia提供的所有驱动程序，使软件能够联系GPU硬件，并使用那里的内存来优化机器学习系数。</p><p id="e659" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我不会复制粘贴其他优秀文章中出现的相同代码和链接。要完整安装所有必需的软件包<a class="ae mb" rel="noopener" target="_blank" href="/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781">，请遵循以下步骤</a>。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="ac3e" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">一旦完成了上一节中的所有步骤，我们需要确保一切都正常工作。理想的地方是anaconda提示符命令行面板。在其中，键入:</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="2712" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">python </strong></span><span id="bdba" class="mj mk it mf b gy mp mm l mn mo"><strong class="mf iu">import tensorflow as tf</strong></span><span id="33b3" class="mj mk it mf b gy mp mm l mn mo"><strong class="mf iu">tf.test.is_built_with_cuda()</strong></span><span id="4c46" class="mj mk it mf b gy mp mm l mn mo"><strong class="mf iu">tf.config.list_physical_devices()</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mq"><img src="../Images/7de9d3f8ae098bdea11609eef3f3e14b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkc85ZZ9OnPTMNgGIAUQiQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">命令列表；作者图片</p></figure><p id="372c" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">如果没有丢失任何东西并且安装正确，本地计算机上的命令应该会输出与图中非常相似的输出。主线是TensorFlow找到了我的显卡。从我的实践来看，这意味着scikit-learn机器学习框架也可以使用该卡。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="ee8f" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在我们有了能够使用GPU的软件，让我们来训练一些模型吧！</p><p id="234d" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对于建模任务，我将加载包含<strong class="lh iu"> 1017209 </strong>行和以下各列的数据:</p><p id="318f" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">店铺</strong> —店铺识别号</p><p id="029f" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">日期</strong> —店铺销售记录的日期</p><p id="1697" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">星期几</strong> —日期的星期几</p><p id="c050" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">销售额</strong> —该日期销售商品的收入(仅在train_data.csv中可用)</p><p id="8750" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu"> ShopOpen </strong> —布尔标志，表示商店在该日期是否营业(如果不营业，销售额应为0)</p><p id="5c8b" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">促销</strong> —如果在该日期进行了任何促销，则为布尔标志</p><p id="5168" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">法定假日</strong> —日期是否为法定假日的因子变量</p><p id="f9eb" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">学校假期</strong> —日期是否为学校假期的因子变量</p><p id="bd5f" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">商店类型</strong> —描述商店类型的因素变量</p><p id="fb3b" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu">分类类型</strong> —描述商店分类类型的因素变量</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/21a22b9374a4ce19df4abdfd19916b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g2rlxTTwcROj4ZiF2CFMUQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据片段；作者图片</p></figure><p id="d750" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">任务是使用所有其他特性对<strong class="lh iu"> Sales (Y) </strong>变量进行建模。注意，所有其他特征都是分类的。</p><p id="fbf5" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">添加了关于一月中的某一天和一年中的某一月的两个附加特征后，我们可以检查数据集中有多少个唯一的分类值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/0e09495579e7885eef1f0aa1f9e1e5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*zi3UmgSstEyxIjE5rrzSqw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">独特的分类水平；作者图片</p></figure><p id="0d20" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">Y变量的分布:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/e6790d23bc65f5cd163de097170b36d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*3wg6zjt5b-il_6Kqi4cALA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">y变量直方图；作者图片</p></figure><p id="4032" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">完整Y和X矩阵的最终尺寸:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/62d7035b058f4e6d09813d806f19978c.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*P-yzrcfDO33nLeKPn_83QA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">尺寸；作者图片</p></figure><p id="ce34" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">X矩阵有1150个特征和超过一百万行。测试计算速度的理想真实数据集！</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="f199" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">建模类将是python中的xgboost回归实现:</p><div class="mv mw gp gr mx my"><a href="https://xgboost.readthedocs.io/en/latest/parameter.html" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd iu gy z fp nd fr fs ne fu fw is bi translated">XGBoost参数-XGBoost 1 . 4 . 0-快照文档</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">min_child_weight [default=1]子对象中所需的实例权重的最小总和(hessian)。如果树分区步骤…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">xgboost.readthedocs.io</p></div></div></div></a></div><p id="46dd" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">初始化模型类的模板是:</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="3fc5" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">import xgboost as xgb </strong></span><span id="a02d" class="mj mk it mf b gy mp mm l mn mo"><strong class="mf iu">model = xgb.XGBRegressor(**kwargs)</strong></span></pre><p id="7f6b" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">回归的目标参数应该是:<strong class="lh iu"> 'reg:squarederror '。</strong></p><p id="cfbc" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh iu"> <em class="md">为了能够在GPU上进行训练，唯一需要做的就是传递一个参数tree_method = 'gpu_hist '。</em>T19】</strong></p><p id="44d8" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">CPU和GPU字典示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/2341cac25d00461c99f054d7a0a306cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*h8XcNSnBl93730cbkvVVOA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CPU和GPU kwargs作者图片</p></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="1a4d" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">可能出现的第一个有趣的问题是，训练速度如何根据CPU和GPU训练的行数而不同？</p><p id="af41" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们现在将使用默认的超参数，并且只改变用来训练模型的行数。</p><p id="3fc9" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如我们所看到的，当添加更多行时，GPU和CPU之间的差异迅速增加:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/c34f8fd4919b6497ae0ce166f5b4533b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*v2aBJ0ab63iqrOI9W64SAQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练行数vs训练时间；作者图片</p></figure><p id="9004" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">从图中可以清楚地看出，在训练CPU模型时增加行数会线性地增加训练时间，而增加GPU训练类型的行数会对数地增加训练时间。</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="7302" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">log(n) &lt;&lt; n for big n.</strong></span></pre><p id="2fc6" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">有趣的是，对于非常小的数据集，CPU实际上表现得更好:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e696ff40b8a7575a460885a4edfa9558.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*ZMSy5_wMN_vF_o33tethQw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">速度表I；作者图片</p></figure><p id="1508" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这是因为调用GPU API进行计算比调用CPU API花费的时间更长。当然，实际计算在GPU上更快，但是请求的开销使得在小而简单的数据集上，CPU可能是更好的选择。</p><p id="2ae5" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">完整的伪代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nk nl l"/></div></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="f861" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">第二个有趣的问题是某些超参数值的变化如何影响训练时间？</p><p id="3983" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">为此，我们将设置一个30000行的随机样本，并且只改变两个超参数:<strong class="lh iu"> n_estimators </strong>和<strong class="lh iu"> max_depth。</strong></p><p id="dc5d" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">带有拟合速度结果的表尾，按秒差排序:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4fcbdb45a2284ba99639d60320d8da1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*_dG5nbOh0XGiVsG5K_o2kA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">速度表II；作者图片</p></figure><p id="187c" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">一个3d表面图，其中Z轴是速度差(正值表示GPU训练更快的秒数):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/88a4aaa13608342f6c2e929468a52a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PoOhf4YZiGzia2Xt8OLnTw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">速度差的3D平面；作者图片</p></figure><p id="fd97" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">有趣的是，平面显示增加估计器的数量线性地增加训练时间的差异，增加max_depth参数没有线性效应。</p><p id="1537" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">代码片段:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nk nl l"/></div></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="173f" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">总之，根据我的桌面规格，GPU显著减少了大型xgboost模型的训练时间。</p><p id="e96d" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">使用GPU启用xgboost模型的训练非常简单——只需将超参数tree_method设置为<strong class="lh iu">“GPU _ hist”。</strong></p></div></div>    
</body>
</html>