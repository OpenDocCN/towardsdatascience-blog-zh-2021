<html>
<head>
<title>Intuitively Understand Maximum Likelihood</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">直观理解最大似然</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intuitively-understand-maximum-likelihood-121893bea5d0?source=collection_archive---------23-----------------------#2021-07-19">https://towardsdatascience.com/intuitively-understand-maximum-likelihood-121893bea5d0?source=collection_archive---------23-----------------------#2021-07-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="61c0" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">基本概念</h2><div class=""/><div class=""><h2 id="b258" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用简单的日常例子来理解基本概念，这样你甚至可以向你的祖母解释。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/3de78b7cf3b3d88d579291feb5ce7cc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2WHQQEbs7eb3fcwj"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">罗斯·索科洛夫斯基在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="9acf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据科学和机器学习有很多术语。往往需要一段时间才能真正理解一些往往被形式定义和数学方程掩盖的概念。<a class="ae lh" href="https://skeptics.stackexchange.com/questions/8742/did-einstein-say-if-you-cant-explain-it-simply-you-dont-understand-it-well-en" rel="noopener ugc nofollow" target="_blank">据称</a>，根据爱因斯坦的说法，</p><blockquote class="me mf mg"><p id="289e" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">"除非你能向你的祖母解释，否则你不会真正理解某件事。"</p></blockquote><p id="4c6c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最大似然法是机器学习中估计参数的两种基本方法之一(另一种是最小二乘估计),许多新方法都是从这两种方法中得到启发的。</p><p id="a1f5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">尽管如此，许多解释最大似然法的课程和书籍都没能清楚地表明这种技术只是常识。刚学的时候(十几年前)我的经历没什么不同。然而，读完这篇文章后，你会有更好的学习体验。我也相信在读完这篇文章后，你会很好地理解最大似然的概念，甚至可以向你的祖母解释。让我们开始吧。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="5528" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">我们通常都使用最大似然估计</h1><p id="3b7a" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">想象一个场景，你的冰箱里有最美味的巧克力冰淇淋，可以在晚餐时享用。此外，想象你正在照顾4个孩子(阿尔法、贝塔、伽马和德尔塔),你明确指示他们白天不要吃冰箱里的冰淇淋。你出去买杂货。当你回来时，你发现四个孩子中的一个已经咬了一口冰淇淋。你现在的任务是确定4个孩子中谁吃了冰淇淋。</p><p id="75cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你将如何辨认吃冰淇淋的孩子？我们还假设这四个孩子都不合作。你现在必须像侦探一样收集线索(即收集数据)。在您收集任何数据之前，您已经提出了一个模型，它是:</p><p id="0dcb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="mh">【孩子的名字】</em> </strong> <em class="mh">吃起冰淇淋来。</em></p><p id="e2da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该模型有一个自由参数，<strong class="lk jd"> <em class="mh">【孩子的名字】</em> </strong>。如果你不收集任何进一步的线索(数据)，你最好的估计是模型中的自由参数可以以相等的概率(即0.25)取四个子名中的任意一个。然而，你最终还是收集到了一些线索。让我们把这些不同的线索叫做<em class="mh"> x1 </em>，<em class="mh"> x2 </em>，…。，<em class="mh"> xn </em>暗示你一共收集了<em class="mh"> n </em>条线索。一旦你考虑了你收集的所有线索，每个孩子吃过冰淇淋的概率就会改变。</p><p id="8cf8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">利用线索(您收集的数据)来帮助识别孩子是通过最大可能性来完成的。当您试图识别正确的孩子时，您应该这样做。<strong class="lk jd">马上关注！</strong></p><p id="213f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在你的脑海中，你会说:</p><p id="0ac0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mh">根据我现在观察到的所有数据，那个</em> <strong class="lk jd"> <em class="mh">阿尔法</em> </strong> <em class="mh">吃了冰淇淋的</em> <strong class="lk jd"> <em class="mh">可能性有多大？</em></strong></p><p id="f35e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，您将对测试版重复同样的问题:</p><p id="c58d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">给定我现在观察到的所有数据，那个 <strong class="lk jd"> <em class="mh">贝塔</em> </strong> <em class="mh">吃了冰淇淋的</em> <strong class="lk jd"> <em class="mh">可能性有多大？</em></strong></p><p id="97c5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，你将为伽马和德尔塔重复它。</p><p id="db47" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你会如何总结并得出答案？嗯，你只需选择<strong class="lk jd"><em class="mh"/></strong>可能性最高的孩子。</p><p id="127e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">换句话说，你将选择给你<strong class="lk jd"> <em class="mh">最大可能性的答案。</em>T49】</strong></p><p id="0313" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">就是这样。你刚刚完成了最大似然估计程序。概括地说，您选择了一个有参数的模型。最终答案要求为该参数选择一个特定值。你观察到一些数据。然后，考虑模型中参数的每个值来估计似然值。最后，您选择了与最高可能性相关联的最终参数值。换句话说，你选择了最有可能的答案。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="9497" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">将直觉与现有的书籍和课程相结合</h1><p id="0eaf" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">让<strong class="lk jd"> <em class="mh"> me </em> </strong>来看看<strong class="lk jd"> </strong>目前大多数课程和书籍是如何教授最大似然概念的，以进一步巩固你的理解。到目前为止，解释最大似然的最常见的例子是估计正态曲线(也称为高斯曲线)的参数。正态分布曲线由平均值和标准偏差参数化。</p><p id="ca7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为简单起见，以一维正态分布为例，平均值决定了曲线的位置，左边还是右边。sigma参数决定曲线的宽度或宽度。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi np"><img src="../Images/e1a6f29828af19b215107497b10357f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADBOpI1KPodsJG6lG2PzcQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">比较两条正态分布曲线。每条正态曲线都用平均值和标准偏差来表示。均值决定曲线的位置，标准差决定曲线的宽度(图片由作者提供)</p></figure><p id="5e1d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在想象一下，一个商业投资者来找你，他想开一家冰淇淋店。他在两个地点中的一个之间感到困惑，并选择你来帮助他决定。你需要弄清楚他需要选择两个地点中的哪一个来开一家新的冰淇淋店。对于每个城市，随机抽取100人进行抽样调查，以1到10分(10分是最好的，0分是最差的)表示他们对冰淇淋的喜爱程度。</p><p id="cad3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你的任务是利用他掌握的这两个城市的所有数据，想出一个数据驱动的答案。你假设对冰淇淋的爱是正态分布的。接下来的任务是确定两个城市的均值和标准差的具体参数，然后确定哪一个会带来更高的利润。</p><p id="fb31" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于每个城市，您使用最大似然法来估计平均值和标准差。换句话说，假设你观察了100个人对一个给定城市的评价，最能解释每个城市的冰淇淋评价的最可能分布是什么。</p><p id="16d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从数学上来说，我们对每个位置做了以下工作:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/ea8ae438c7b9b763044dda382afa6775.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*Mj5M9Bpaq9KkrN1cs3PjDA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">联合条件概率函数，用于确定函数最大时<em class="nr"> θ </em>的值(图片由作者提供)</p></figure><p id="dbb5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在较早的谁吃了冰淇淋的例子中，我们手动输入θ(孩子的名字)的每个可能值，然后找到可能性的值。我们不需要手动操作。我们使用数学和一些简化的假设来求解最大似然方程。</p><p id="c2f5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望这个帖子能够被广泛地访问，所以我不会再放任何方程了(如果你感兴趣，请留下评论，我会有一个后续的帖子，有更多的数学知识)。</p><p id="8645" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">说白了，我们假设这100个数据点是<a class="ae lh" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables" rel="noopener ugc nofollow" target="_blank"><em class="mh"/></a>(独立同分布)。<em class="mh"> iid </em>假设有助于将联合概率函数简化为每个单独数据点概率的乘积(因为独立性假设)。随后，我们通过使用“对数”技巧将乘积项转换为总和，使我们的生活变得更加简单。最后，我们使用微积分(微分)来推导平均值和标准偏差的最终方程。</p><p id="b8bd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里的数学步骤特定于我们拥有的初始联合概率模型(似然函数)。对于法方程参数的估计，我们可以解析求解。然而，对于其他模型，我们可能不得不求助于数值解并使用迭代算法。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="e9ff" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">摘要</h1><p id="3773" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">最大似然法是机器学习的基本方法之一。它帮助我们找到似然函数的未知参数。似然函数是以我们需要估计的参数为条件的联合概率函数。</p><p id="95d7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数学方法给了我们一种估计这些参数的方法。从概率上来说，最大似然法使我们能够证明，给定我们观察到的数据，我们选择的带有估计参数的模型是最有可能解释这些数据的模型。</p><p id="17c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这都是常识，即使我们没有意识到或者没有被正式教导，我们在日常生活中已经在大脑中这样做了。</p><div class="ns nt gp gr nu nv"><a href="https://ahmarshah.medium.com/membership" rel="noopener follow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd jd gy z fp oa fr fs ob fu fw jc bi translated">阅读艾哈迈尔·沙阿博士(牛津)的每一个故事(以及媒体上成千上万的其他作家)</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">ahmarshah.medium.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj lb nv"/></div></div></a></div></div></div>    
</body>
</html>