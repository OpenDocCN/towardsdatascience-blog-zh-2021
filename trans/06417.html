<html>
<head>
<title>Comprehensive Guide to Multiclass Classification Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多类分类标准综合指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd?source=collection_archive---------0-----------------------#2021-06-09">https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd?source=collection_archive---------0-----------------------#2021-06-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="07e7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">成为生活的书签:你需要的所有多类分类标准都有清晰的解释</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9d331fa49f6472b8937d8248f89ce3ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XvH2BXiP1HFi5o_qpqJK8w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">照片由</strong> <a class="ae kz" href="https://www.pexels.com/@deon-black-3867281?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ky">德昂黑</strong> </a> <strong class="bd ky">上</strong> <a class="ae kz" href="https://www.pexels.com/photo/long-fitness-health-measure-5915361/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ky">像素</strong> </a></p></figure><h2 id="31bb" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">介绍</h2><p id="0fca" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">我最近发表了<a class="ae kz" rel="noopener" target="_blank" href="/comprehensive-guide-to-multiclass-classification-with-sklearn-127cc500f362?source=your_stories_page-------------------------------------">我最具挑战性的文章</a>，主题是多类分类(MC)。我在这个过程中所面临的困难很大程度上是由于我必须学习和解释过多的分类标准。当我完成的时候，我已经意识到这些指标应该有一篇自己的文章。</p><p id="bd16" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">因此，这篇文章将是关于7个最常用的MC指标:精确度、召回率、F1值、ROC AUC值、Cohen Kappa值、Matthew相关系数和对数损失。您将了解它们是如何计算的，它们在Sklearn中的细微差别，以及如何在您自己的工作流程中使用它们。</p><div class="mu mv gp gr mw mx"><a href="https://ibexorigin.medium.com/membership" rel="noopener follow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">通过我的推荐链接加入Medium-BEXGBoost</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">获得独家访问我的所有⚡premium⚡内容和所有媒体没有限制。支持我的工作，给我买一个…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">ibexorigin.medium.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ks mx"/></div></div></a></div><p id="6d29" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">获得由强大的AI-Alpha信号选择和总结的最佳和最新的ML和AI论文:</p><div class="mu mv gp gr mw mx"><a href="https://alphasignal.ai/?referrer=Bex" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">阿尔法信号|机器学习的极品。艾总结的。</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">留在循环中，不用花无数时间浏览下一个突破；我们的算法识别…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">alphasignal.ai</p></div></div><div class="ng l"><div class="nm l ni nj nk ng nl ks mx"/></div></div></a></div></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="7352" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">解释N乘N混淆矩阵</h2><p id="fa85" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">您今天将要介绍的所有指标都以这样或那样的方式与混淆矩阵相关联。虽然2乘2混淆矩阵直观且易于理解，但更大的混淆矩阵可能会<em class="nu">真正混淆</em>。出于这个原因，在深入研究从矩阵中导出的指标之前，最好先了解一些较大的N乘N矩阵。</p><p id="67b4" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在本文中，我们将使用钻石分类的例子。具体来说，目标包含4种类型的钻石:理想、优质、优质和一般。对该钻石数据的任何分类器进行评估将产生一个4x 4矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/0460402cc5ffe6313e5fc29612d4ee46.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*-0zEanUrY9lmwmsTC_lylA.png"/></div></figure><p id="2bff" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">尽管随着类别数量的增加，解释矩阵变得越来越困难，但是有一些万无一失的方法可以找到任何形状的矩阵。</p><p id="37f3" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">第一步是始终确定你的积极和消极类。这取决于你要解决的问题。如果分类是平衡的，也就是说，你平等地关心每一个类(这种情况很少发生)，可能就不会有任何积极或消极的类。如果是这种情况，正类和负类是按类定义的。</p><p id="5f62" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">但是，作为珠宝店老板，您可能希望您的分类器能够更好地分类理想钻石和优质钻石，因为它们更贵。在这种情况下，理想和优质标签将是一个积极的类别，其他标签被统称为消极的。</p><p id="20e1" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">识别阳性和阴性类别后，定义真阳性、真阴性、假阳性和假阴性。就我们自己的问题而言:</p><ul class=""><li id="cf07" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo ob oc od oe bi translated"><strong class="ly iu">真阳性，类型1 </strong>:实际理想值，预测理想值</li><li id="aaba" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><strong class="ly iu">真阳性，类型2 </strong>:实际保费，预测保费</li><li id="d012" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><strong class="ly iu">真否定</strong>:正确预测的任何否定类别标签(好、一般)</li><li id="a33f" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><strong class="ly iu">误报</strong>:实际值属于“良好”或“一般”类别，但预测为“理想”或“溢价”</li><li id="3023" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><strong class="ly iu">假阴性</strong>:实际值属于阳性类别，但预测为良好或一般</li></ul><p id="9f17" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">一旦你定义了4项，从矩阵中找出每一项应该很容易，因为这只是简单的加法和减法。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="96e2" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">从二元度量到多元类</h2><p id="5b35" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">默认情况下，大多数分类指标都是针对二元情况定义的。在将这些二进制度量扩展到多类时，使用了几种平均技术。</p><p id="11bf" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">首先，使用一对一(OVO)或一对其余(OVR，也称为一对所有)方法，将多类问题分解为一系列二元问题。OVO存在计算上的缺陷，所以专业人士更喜欢OVR方法。正如我在我的上一篇文章中详细讨论了这两种方法的区别，我们今天将只关注OVR。</p><p id="c11a" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">本质上，一对一策略将一个多类问题转化为目标中每个类的一系列二元任务。例如，分类4种类型的钻石类型可以用OVR二进制化为4个任务:</p><ul class=""><li id="f13d" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo ob oc od oe bi translated">任务1:理想与[优质、良好、一般] —即理想与不理想</li><li id="8237" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated">任务2:优质与[理想、良好、一般]——即优质与非优质</li><li id="ee86" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated">任务3:好与[理想、优质、一般] —即好与不好</li><li id="7fc9" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated">任务4:公平与[理想、优质、良好] —即公平与不公平</li></ul><p id="e71e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">对于每个任务，将构建一个二进制分类器(在所有任务中应该是相同的分类器)，并使用二进制分类度量(如precision)(或我们今天将讨论的任何度量)来测量它们的性能。结果将是4个精确分数。为了比较一个分类器和另一个分类器，我们需要一个单一的精度分数，而不是4，所以我们需要一种方法来表示所有类的精度。这就是平均技术的用武之地。</p><p id="5271" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">具体来说，有3种适用于多类分类的平均技术:</p><ul class=""><li id="9f16" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo ob oc od oe bi translated"><strong class="ly iu"> macro </strong>:这是跨类的所有指标的简单算术平均值。这种技术对所有类别赋予相同的权重，使其成为平衡分类任务的好选择。</li><li id="5d02" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><strong class="ly iu">加权</strong>:通过计算目标中每个类别的样本数加权的二进制度量的平均值，说明类别不平衡。如果3个类别的3 ( <em class="nu">精度分数</em>)分别为:类别1 (0.85)、类别2 (0.80)和类别3 (0.89)，则通过将每个分数乘以每个类别的出现次数并除以样本总数来计算加权平均值。</li><li id="d911" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><strong class="ly iu">微</strong>:这个和精度一样。微平均是用矩阵对角线单元之和除以所有单元之和，即精度。由于精确度是一个误导性的指标，这种平均技术很少使用。</li></ul><p id="4dfe" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">现在，让我们最终转向实际的指标！</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="930f" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">多类分类的精度和召回率</h2><p id="8bd5" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">Precision回答了“预测阳性<strong class="ly iu">与实际阳性<em class="nu"/>的比例是多少？”当然，你只能用二元分类来回答这个问题。这就是为什么你问这个问题的次数和目标中类的数量一样多。每一次，你都将针对一个班级向其他班级提出问题。对于我们的钻石分类，一个例子是“预测的理想钻石有多少比例实际上是理想的？”</strong></p><p id="6f35" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">通过将真阳性除以真阳性和假阳性之和来计算精度(<em class="nu">三p规则</em>):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/af7320fe08da4c8ea54485504730f63f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*KWZHeEuBGhDfw5CTE_PRfQ.png"/></div></figure><p id="e503" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">让我们计算理想类的精度。以下是混淆矩阵，供参考:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/0460402cc5ffe6313e5fc29612d4ee46.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*-0zEanUrY9lmwmsTC_lylA.png"/></div></figure><p id="6fd3" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">理想钻石的真阳性是左上角的单元格(22)。假阳性是其他类型的钻石被预测为理想的所有细胞。这些是左上角单元格下面的单元格(5 + 2 + 9 = 19)。因此，精度将是:</p><p id="08b2" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">精度(理想):22 / (22 + 19) = 0.536 </strong> —很恐怖的分数。</p><p id="8cff" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">当你想减少<em class="nu">假阳性</em>的数量时，你应该优化你的模型的精确度。在我们的案例中，针对理想钻石的精度进行优化是有意义的。原因是理想钻石是最贵的，得到一个误报意味着将一个更便宜的钻石归类为理想。如果你不小心漏掉了这样的事件，你可能会被指控欺诈。现在，让我们继续<em class="nu">回忆</em>。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="496e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">Recall回答了“有多少比例的<strong class="ly iu">实际阳性</strong>被正确分类？”它的计算方法是将真阳性的数量除以真阳性和假阴性的总和。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/5046b5667955ba57141829cbcdd81fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*LmttOOk86tXBGlaC_73Xag.png"/></div></figure><p id="6790" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">让我们为特级钻石计算一下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/0460402cc5ffe6313e5fc29612d4ee46.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*-0zEanUrY9lmwmsTC_lylA.png"/></div></figure><p id="50cb" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">有27个真阳性(第2行，第2列)。假阴性是指优质钻石被归类为理想、良好或一般的任何情况。这些将是真阳性细胞左边和右边的细胞(5 + 7 + 6 = 18)。因此，召回将是:</p><p id="618c" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">召回(溢价):27/(27+18)= 0.6</strong>——也不是个好成绩。</p><p id="d773" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如果你想减少<em class="nu">假阴性</em>的数量，你应该优化你的召回模型。如果您试图在黄色和红色香蕉中检测蓝色香蕉，您会希望减少假阴性，因为蓝色香蕉非常罕见(如此罕见，以至于您第一次听说它们)。你不会想把它们和普通的香蕉混在一起。</p><p id="a7c1" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如果你想查看所有类的精度和召回率以及它们的宏观和加权平均值，你可以使用Sklearn的<code class="fe om on oo op b">classification_report</code>函数。假设我们的标签在<code class="fe om on oo op b">y_test</code>并且预测在<code class="fe om on oo op b">y_pred</code>，钻石分类的报告将是:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="4383" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">最后两行显示的是精度和召回率的宏观和加权平均值，看起来不太好！</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="c965" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">多类分类的F1分数</h2><p id="c43e" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">由于它们的性质，精确度和召回率是一种权衡关系。你可能不得不以牺牲另一个为代价来优化一个。然而，如果您想要一个分类器，它在最小化误报和漏报方面同样出色，该怎么办呢？例如，有一个模型是有意义的，该模型同样擅长于捕捉意外出售廉价钻石作为理想钻石的情况，以便您不会被起诉，并检测意外以更低的价格出售理想钻石的情况。</p><p id="631e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">这就是F1分数的来源。它是通过取精度和召回率的调和平均值来计算的，范围从0到1。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/5a36b1d4e43fcd5bfd0030456fe02879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XH-bmDiJ50rWfqBR82NOdQ.png"/></div></div></figure><p id="cef1" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">为什么要取调和平均值而不是简单的算术平均值？调和平均值有一个很好的算术特性，代表一个真正平衡的平均值。如果准确率或召回率较低，就会受到严重影响。例如，假设我们正在比较两个分类器。第一个分类器的精度和召回率分别为0.9、0.9，第二个分类器的精度和召回率分别为1.0和0.7。计算两者的F1得到0.9和0.82。如你所见，第二个分类器的低回忆分数降低了分数。</p><p id="0e7f" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">使用分类报告输出，您可以看到F1的两个平均分数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="16c9" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">F1分数通常介于精确度和召回率之间，但是取加权平均值可能会给出超出其范围的值。</p><p id="6edb" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在接下来的几节中，我们将讨论ROC AUC得分并将其与F1进行比较。你会发现这两个指标的主要缺点。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="9d79" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">多类分类的ROC AUC得分</h2><p id="b82b" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">二元分类中另一个常用的度量是受试者操作特征曲线下的面积(ROC AUC或AUROC)。它量化了模型区分各个类别的能力。该度量仅用于可以生成类成员概率的分类器。就Sklearn估计器而言，这些是具有<code class="fe om on oo op b">predict_proba()</code>方法的模型。</p><p id="f184" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">例如，如果目标包含猫和狗类，那么使用<code class="fe om on oo op b">predict_proba</code>方法的分类器可以为每个样本生成隶属概率，例如猫为0.35，狗为0.65。然后，基于像0.5这样的决策阈值对每个预测进行分类。在进一步解释AUROC之前，我们先来详细看看它是如何计算MC的。</p><p id="b670" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在使用<code class="fe om on oo op b">predict_proba</code>方法的二元分类器被选择之后，它被用于为OVR的第一个二元任务生成成员概率。然后，选择接近0的初始决策阈值。使用阈值，进行预测，并创建混淆矩阵。从这个混淆矩阵中，计算出两个度量，真阳性率(与回忆相同)和假阳性率:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/b3b4e2eb5ac7245f1626538b6e2687cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*k5kBhahQyx0ex_KjoFwf8g.png"/></div></figure><p id="7480" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">然后，选择新的、更高的阈值，并创建新的混淆矩阵。使用这个混淆矩阵，计算新的TPR和FPR。对于0和1之间的许多不同的判决阈值重复该过程，并且对于每个阈值，找到新的TPR和FPR。最后，所有TPR和FPR相互对应绘制:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/21c7e74a910c36aa83bc8a3138660776.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*0bRtPPrWpNTIJ7HjzDzTTw.png"/></div></figure><p id="bd23" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">该图是在我们的diamonds数据集中计算理想类相对于其他类的ROC曲线的实现。对于所有其他二进制任务，重复整个过程。换句话说，又发现了3条ROC曲线:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/ec788711f75d5c14cb41bffb782a8a94.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*m-4F5yiboWPqO6T6Z8F_Ug.png"/></div></figure><p id="aa7f" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">最终的图还显示了这些曲线下的面积。AUROC越大，等级之间的差别就越大。最终的AUROC也使用宏观或加权方法进行平均。以下是这一切在Sklearn中的实现:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="8df3" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们的平均得分是0.82。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="02f2" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">多类分类中ROC AUC分数与F1分数的对比</h2><p id="a66d" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">简而言之，ROC AUC和F1之间的主要差异与类别不平衡有关。以下是阅读了许多StackOverflow线程后对如何选择一个线程的总结:</p><p id="c053" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如果你有很高的类别不平衡，总是选择F1分数，因为高的F1分数同时考虑了精确度和召回率。为了获得高F1，假阳性和假阴性都必须低。另一方面，ROC AUC可以以足够高的假阳性数给出宝贵的高分。此外，您还可以将ROC AUC分数视为在各种阈值下评估的F1分数(好的和坏的)的平均值。当你有阶级不平衡的时候，总是使用F1。更高的ROC AUC不一定意味着更好的分类器。</p><p id="aedf" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如果你想更多地了解这种差异，下面的讨论对我有所帮助:</p><ul class=""><li id="9aba" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo ob oc od oe bi translated"><a class="ae kz" href="https://stackoverflow.com/questions/44172162/f1-score-vs-roc-auc" rel="noopener ugc nofollow" target="_blank"> F1得分与ROC AUC的对比</a></li><li id="10b9" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><a class="ae kz" href="https://stackoverflow.com/questions/34698161/how-to-interpret-almost-perfect-accuracy-and-auc-roc-but-zero-f1-score-precisio#34698935" rel="noopener ugc nofollow" target="_blank">如何解释几乎完美的准确性和AUC-ROC但f1-得分、精确度和召回为零</a></li><li id="f764" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><a class="ae kz" href="https://stats.stackexchange.com/questions/210700/how-to-choose-between-roc-auc-and-f1-score" rel="noopener ugc nofollow" target="_blank">如何在ROC AUC和F1成绩之间做出选择？</a></li><li id="6fa2" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><a class="ae kz" href="https://stats.stackexchange.com/questions/123036/what-are-the-differences-between-auc-and-f1-score()" rel="noopener ugc nofollow" target="_blank">AUC和F1-score有什么区别？</a></li></ul></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="1b4c" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">Cohen的多类分类Kappa评分</h2><p id="4426" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">你可以把<em class="nu"> kappa评分</em>看作是准确性的增强版，这个版本也整合了对机会和等级不平衡的测量。</p><p id="05d0" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">正如你可能知道的，准确性可能非常误导人，因为它没有考虑到阶级的不平衡。在正负比率为10:100的目标中，如果分类器简单地正确预测所有负样本，您仍然可以获得超过90%的准确性。此外，由于机器学习算法依赖于数据的概率假设，我们需要一个分数来衡量生成预测时固有的不确定性。以雅各布·科恩(Jacob Cohen)命名的Kappa评分是少数几个可以在一个指标中代表所有这些的评分之一。</p><p id="d78b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在官方文献中，它的定义是“量化两个评分者之间的一致程度的度量标准。”这是维基百科的定义:</p><blockquote class="ov ow ox"><p id="c402" class="lw lx nu ly b lz mp ju mb mc mq jx me oy mr mg mh oz ms mj mk pa mt mm mn mo im bi translated">Cohen的kappa系数(κ)是一种统计数据，用于测量定性(分类)项目的评分者之间的可靠性(以及评分者内部的可靠性)。一般认为这是一个比简单的百分比一致计算更稳健的方法，因为κ考虑了偶然发生一致的可能性。</p></blockquote><p id="0f66" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">以下是官方公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/9f5fddda74ae65a13f6d05a3fd0ad0dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*JLLnjZaKhZWT1EPLd2LUIA.png"/></div></figure><p id="ffe6" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在分类中，这个公式解释如下:</p><p id="9f45" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><em class="nu">P0</em>是实际值和预测值之间的<em class="nu">观测比例一致</em>。这将是任何混淆矩阵的对角线单元的总和除以非对角线单元的总和。换句话说，简单准确性的另一个名称。</p><p id="6d87" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><em class="nu"> P_e </em>是真值和假值偶然重合的概率。我们将看到如何使用我们在本指南中使用的矩阵来计算这些值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/9bae13e00b64d133de550323f192cc80.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*gTRRofbbMDVQYuaTEcp5WQ.png"/></div></figure><p id="8f80" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">让我们先找出精确度:对角线单元格的总和除以非对角线单元格的总和— 0.6。为了找到<em class="nu"> P_e </em>的值，我们需要找到每个类的真实值与预测值偶然相同的概率。</p><ol class=""><li id="8ef0" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo pd oc od oe bi translated"><em class="nu">理想</em>类—真实值和预测值都是<em class="nu">理想值</em>的概率。共有250个样品，其中57个是理想钻石。因此，随机钻石成为理想钻石的概率是</li></ol><p id="9b94" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P(实际_理想)= 57 / 250 = 0.228 </strong></p><p id="1276" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">现在，在所有250个预测中，有38个是理想的。所以，随机预测成为理想预测的概率是</p><p id="0e25" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P(预测_理想)= 16 / 250 = 0.064 </strong></p><p id="2cd3" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">两个条件都为真的概率是它们的乘积，所以:</p><p id="a5c4" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P_e(实际_理想，预测_理想)= 0.228 * 0.064 = 0.014592 </strong></p><p id="50cc" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">现在，我们将为其他类做同样的事情:</p><ol class=""><li id="9ae0" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo pd oc od oe bi translated"><em class="nu">溢价</em>类——真实值和预测值的概率都是<em class="nu">溢价</em>偶然:</li></ol><p id="136b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">P(actual _ premium)= 45/250 = 0.18</strong></p><p id="e708" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P(预测保费)= 28 / 250 = 0.112 </strong></p><p id="e4da" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P_e(实际_溢价，预测_溢价)= 0.02016 </strong></p><ol class=""><li id="8ba2" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo pd oc od oe bi translated"><em class="nu">好</em>类—真实值和预测值都是<em class="nu">好</em>偶然的概率:</li></ol><p id="9189" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P(实际_良好)= 74 / 250 = 0.296 </strong></p><p id="f410" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">P(predicted _ good)= 26/250 = 0.104</strong></p><p id="c58c" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P_e(实际_良好，预测_良好)= 0.030784 </strong></p><ol class=""><li id="a853" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo pd oc od oe bi translated"><em class="nu">一般</em>类—真实值和预测值的概率都<em class="nu">一般</em>偶然:</li></ol><p id="0879" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P(实际_公平)= 74 / 250 = 0.296 </strong></p><p id="5a0c" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">P(predicted _ fair)= 30/250 = 0.12</strong></p><p id="6aa7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P_e(实际_公平，预测_公平)= 0.03552 </strong></p><p id="affa" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">最终P_e是上述计算的总和:</p><p id="031b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu"> P_e(最终)= 0.014592+0.02016+0.030784+0.03552 = 0.101056</strong></p><p id="db4b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">精度，P_0 = 0.6 </strong></p><p id="91b7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">插入数字:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/409ab55f593fd5d96288e77663fb256e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*eEn7mKVVIlHzxegKvzAJTA.png"/></div></figure><p id="5256" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">好消息是，您可以使用Sklearn在一行代码中完成所有这些工作:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="8a3a" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">一般来说，0.8以上的分数被认为是优秀的。我们得到的分数是一个谦逊的温和派。</p><p id="a4f7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">想了解更多信息，我建议阅读这两篇优秀的文章:</p><ul class=""><li id="1644" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo ob oc od oe bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/multi-class-metrics-made-simple-the-kappa-score-aka-cohens-kappa-coefficient-bdea137af09c">简单的多类指标，第三部分:Kappa分数(又名科恩的Kappa系数)</a></li><li id="1d1f" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><a class="ae kz" href="https://www.statisticshowto.com/cohens-kappa-statistic/" rel="noopener ugc nofollow" target="_blank">科恩的卡帕统计是什么？</a></li></ul></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="3c92" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">多类分类的马修相关系数</h2><p id="6fac" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">来看看精确度的另一个单一数字替代品——马修相关系数。我认为这是统计学家能够想出的唯一一个包含所有4个矩阵术语并且实际上有意义的指标:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/6fa84874b8836d9f1b3d316c56b90c1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MGuKc8FR0ckgyYPJ5Zf0vw.png"/></div></div></figure><p id="7be8" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">即使我知道为什么它是这样计算的，我也不会费心去解释它。您只需要知道这个度量表示真实值和预测值之间的相关性。类似于皮尔逊的相关系数，范围从-1到1。1.0的分数意味着完美的分类器，而接近0的值意味着我们的分类器不比随机机会好。</p><p id="2582" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">MCC的酷之处在于它完全对称。与精确度和召回率不同，交换正类和负类会得到相同的分数。况且它只关心每个类预测的好不好，不考虑类的不平衡性。根据维基百科，一些科学家甚至说MCC是在混淆矩阵上下文中建立分类器性能的最佳得分。</p><p id="0134" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">幸运的是，Sklearn也包含了这个指标:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="795b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们得到了0.46的分数，这是一个中等强度的相关性。一般来说，超过0.7的值被认为是好成绩。</p><p id="f0a6" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">顺便说一下，上面的公式是针对二元分类器的。对于多类，Sklearn给出了一个更可怕的公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/89573ec356fdb89cb4a92c76c5a69c98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3dllKdxA0SneUyNr0n75A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">图片由Sklearn提供。(他们甚至不辞辛苦，试图简化公式，他们真好！)</strong></p></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="baa8" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">多类分类的对数损失</h2><p id="3619" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">最稳健的单一数字度量之一是<em class="nu">对数损失</em>，称为交叉熵损失和逻辑错误损失。它不是一个点度量(越大越好)，而是一个误差函数(越低越好)。因此，尽可能最小化对数函数的分类器被认为是最好的分类器。</p><p id="eb7f" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">log loss的另一个优点是，它只对概率分数起作用，或者换句话说，是可以生成概率成员分数的算法。这意味着这个误差函数考虑了模型的不确定性。例如，分数为0.9的类预测比分数为0.6的预测更确定。我们今天讨论的许多指标使用预测标签(即1类、2类)，这些标签隐藏了模型在生成这些预测时的不确定性，而测井曲线损失则没有。</p><p id="f0b7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">它严重地惩罚了模型预测低分数的类成员的情况。对于二进制情况，其公式为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/0c707bc75876ae93844c9a8c5b6fe182.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*JDklEeETecRRJxtNLZ0Khw.png"/></div></figure><p id="5a1d" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">以上是二进制情况的公式。多类的情况更加复杂。我将不再解释这个函数是如何计算的，因为这已经超出了本文的范围。因此，我将用Sklearn展示一个例子，并留下一些链接，可能有助于您进一步理解这一指标:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="640b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">这里有几个链接可以巩固你的理解:</p><ul class=""><li id="df8a" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo ob oc od oe bi translated"><a class="ae kz" href="https://www.kaggle.com/dansbecker/what-is-log-loss" rel="noopener ugc nofollow" target="_blank">一本关于测井记录丢失的笔记本</a></li><li id="179f" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><a class="ae kz" href="https://www.kaggle.com/c/tabular-playground-series-jun-2021/discussion/243636" rel="noopener ugc nofollow" target="_blank">从Kaggle看测井曲线丢失</a></li><li id="b01d" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><a class="ae kz" href="https://scikit-learn.org/stable/modules/model_evaluation.html#log-loss" rel="noopener ugc nofollow" target="_blank"> Sklearn原木损耗用户指南</a></li><li id="c5ed" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated"><a class="ae kz" href="https://stats.stackexchange.com/questions/113301/multi-class-logarithmic-loss-function-per-class" rel="noopener ugc nofollow" target="_blank">每类多类对数损失函数</a></li></ul></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="1b36" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">摘要</h2><p id="9435" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">今天，我们学习了如何以及何时使用7个最常见的多类分类指标。我们还了解了它们是如何在Sklearn中实现的，以及它们是如何从二进制模式扩展到多类的。使用这些指标，您可以评估任何分类器的性能，并将它们相互比较。</p><p id="cd29" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">这是最后一张备忘单，根据你在多类问题中的需要来决定使用哪种度量标准:</p><ul class=""><li id="1512" class="nw nx it ly b lz mp mc mq lj ny ln nz lr oa mo ob oc od oe bi translated">以单一指标比较一个分类器与另一个分类器的整体性能—使用马修相关系数、科恩kappa和对数损失。</li><li id="be20" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated">衡量分类器在平衡分类中区分各类别的能力:<strong class="ly iu"> ROC AUC </strong>得分</li><li id="eb5e" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated">在不平衡分类中最小化假阳性和假阴性的度量:<strong class="ly iu"> F1分数</strong></li><li id="1072" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated">专注于减少单个类的误报:该类的<strong class="ly iu">精度</strong></li><li id="7924" class="nw nx it ly b lz of mc og lj oh ln oi lr oj mo ob oc od oe bi translated">专注于减少单个类别的假阴性:<strong class="ly iu">召回该类别的</strong>。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/f91b8a21f12d3c3b7d428e0f8d5f48be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*KeMS7gxVGsgx8KC36rSTcg.gif"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://ibexorigin.medium.com/membership"><div class="gh gi pi"><img src="../Images/9eb4976c578910227077de97ec17e118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4gJvpmETueLg_jn47vJ0MA.png"/></div></a></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="12ce" class="pj lb it bd lc pk pl pm lf pn po pp li jz pq ka lm kc pr kd lq kf ps kg lu pt bi translated">您可能也会对…感兴趣</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://towardsdatascience.com/25-numpy-functions-you-never-knew-existed-p-guarantee-0-85-64616ba92fa8"><div class="gh gi pu"><img src="../Images/d1f61af83178ef33ca100733ae58308c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RUpe8vQVwFgcA3sU7w-xmw.png"/></div></a></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://towardsdatascience.com/fail-proof-formula-to-learn-any-package-ruthlessly-in-less-than-a-day-c85e49a55459?source=your_stories_page-------------------------------------"><div class="gh gi pv"><img src="../Images/64ff4180c5cd4b01dd243e64cbce80b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tid9Qm6QsmU06BV3eVQ12A.png"/></div></a></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://towardsdatascience.com/10-underrated-sklearn-features-you-can-use-for-your-advantage-right-now-3a87b10a8d7f"><div class="gh gi pw"><img src="../Images/8b7298e1750218f40fae6e8fca8be3d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0GdHWC6Xa24QLr2tv0qqw.png"/></div></a></figure></div></div>    
</body>
</html>