<html>
<head>
<title>Image Compression Using Principal Component Analysis (PCA)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用主成分分析(PCA)的图像压缩</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-compression-using-principal-component-analysis-pca-253f26740a9f?source=collection_archive---------4-----------------------#2021-04-12">https://towardsdatascience.com/image-compression-using-principal-component-analysis-pca-253f26740a9f?source=collection_archive---------4-----------------------#2021-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="eac7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">行动中的维度缩减</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/df3fd7809a6af4c7f880233635078f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PyAiFHUhqVLpMhqyKk8m2w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jjying?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> JJ英</a>在<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="99ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">主成分分析(PCA) </strong>是一种线性降维技术(算法)，它将一组相关变量(p)转化为更小的k (k &lt; p)个不相关变量，称为<strong class="lb iu"> <em class="lv">主成分</em> </strong>，同时尽可能保留原始数据中的可变性。</p><p id="3fa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PCA的一个用例是，它可以用于<strong class="lb iu"> <em class="lv">图像压缩</em></strong>——一种在尽可能保持图像质量的同时最小化图像字节大小的技术。在本帖中，我们将通过使用手写数字的<a class="ae ky" href="https://drive.google.com/file/d/1hboV-OLFfazEzV9tRqz7Nf1uoHU9jYO3/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>来讨论这项技术。阅读完本文后，您将获得使用Python和Scikit-learn进行PCA图像压缩的实践经验。</p><p id="ac5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p><h1 id="3b1e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">加载数据集</h1><p id="b2a1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae ky" href="https://drive.google.com/file/d/1hboV-OLFfazEzV9tRqz7Nf1uoHU9jYO3/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>包含手写数字的图像数据。因为它是CSV文件格式，所以让我们使用Pandas <strong class="lb iu"> read_csv() </strong>函数加载它。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3fea" class="my lx it mu b gy mz na l nb nc">import pandas as pd<br/>mnist = pd.read_csv('mnist.csv')<br/>mnist.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/c524cbe723aad740224680296c243674.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2L--yw5X9BI9eHPXuhg5Bw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MNIST数据集的一部分(图片由作者提供)</p></figure><p id="1d93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每行包含一个单一图像的像素值。构成图像的像素可以被认为是图像数据的维度(列/变量)。<strong class="lb iu">‘标签’</strong>列包含数字的值(0-9)。我们的分析不需要该列，因为PCA是一种无监督的机器学习任务，不处理标记为的<em class="lv">数据。因此，我们可以简单地删除该列。</em></p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="85b0" class="my lx it mu b gy mz na l nb nc">mnist.drop(columns='label', inplace=True)<br/>mnist.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/4245b5f14fa2c4b10ffd986075b7cb1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9jTadGnAR2fggdrLi_TiOQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">移除<strong class="bd nf">标签</strong>栏后的MNIST数据(图片由作者提供)</p></figure><p id="2701" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，数据集的形状是:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="8733" class="my lx it mu b gy mz na l nb nc">mnist.shape<br/>#(60000, 784)</span></pre><p id="6d6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据集包含60，000张28x28 (784)像素的图像！</p><h1 id="ed8a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">显示图像</h1><p id="06f5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们显示MNIST数据集中的第二幅图像(第二行)。该图像应包含<strong class="lb iu">数字“0”</strong>，因为第2行的标签列值为“0”。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/4c39de11613891903de8ad5f5efd5189.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*g8RURpslaT2EARJisg7SQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片1(作者图片)</p></figure><p id="cf3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哇！是数字0！</p><h1 id="bcc7" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">特征缩放</h1><p id="7fef" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">由于PCA方向对数据的尺度高度敏感，如果数据不是在相似的尺度上测量的，我们必须在应用PCA之前进行特征缩放。</p><p id="36c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在MNIST数据集中，每幅图像的像素值范围为0到255(相似的比例)。例如:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="139a" class="my lx it mu b gy mz na l nb nc">#2nd image<br/>print(mnist.iloc[1].min())<br/>print(mnist.iloc[1].max())<br/>#0<br/>#255</span></pre><p id="ae10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们的数据是在相似的尺度上测量的，所以我们不需要对PCA进行特征缩放。</p><h1 id="289a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">应用PCA</h1><h2 id="c432" class="my lx it bd ly nj nk dn mc nl nm dp mg li nn no mi lm np nq mk lq nr ns mm nt bi translated"><strong class="ak">选择正确的维度数量</strong></h2><p id="a54e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，我们需要选择正确的维数(即正确的主成分数)。为此，我们应用具有原始维数(即784)的PCA，并创建scree图，以查看PCA如何捕捉数据的方差。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e8a4ca057cfdc3587dbb7b970d7f1ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*obeP0ttQR00oi3gRu2DgSA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将方差解释为组件数量的函数(图片由作者提供)</p></figure><p id="06b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们尝试使用前10个组件来压缩图像。这些组件没有捕捉到原始数据中的很多可变性。所以，我们不会得到一个清晰的图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/6d245d8cef3ce09a019a200ea3246e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Z65DSIPqy0uR4w65tE83IA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="525a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将此与我们之前获得的图像1(原始图像)进行比较。这个图像不是很清晰，缺乏信息。</p><p id="50b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们尝试使用前184个组件来压缩图像。最初的184个成分捕获了原始数据中大约96%的可变性。所以，这一次，我们将得到一个非常清晰的图像，与原始图像非常相似。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/4900794f9fd26817eb29b035afab5137.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*VdCb-SCGHw_E2k5BdQZcaQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="4b3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以计算184个成分的解释方差:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="132d" class="my lx it mu b gy mz na l nb nc">np.cumsum(pca_184.explained_variance_ratio_ * 100)[-1]<br/>#96.11980535398752</span></pre><p id="1fc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是96.1%。</p><p id="779a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将压缩图像与原始图像进行比较:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/5b5f5c24031fe738340994fa1819c58a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*Eep8seWUQ7_evYa0rl3kkw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="8f7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们如何使用PCA进行图像压缩。左边的图片是784维的原图。右边的图像是184维的压缩图像。在对图像数据应用PCA后，维数减少了600维，同时保持了原始图像数据中约96%的可变性！通过比较这两幅图像，可以看到图像质量略有损失，但压缩后的图像内容仍然可见！</p><h1 id="3316" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">摘要</h1><p id="7f08" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">今天，我们讨论了如何使用PCA进行图像压缩。当维度或组件的数量增加时，图像质量损失减少。我们应该始终努力保持最佳数量的组件，以平衡解释的可变性和图像质量。</p><p id="f200" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> pca </em>对象的<strong class="lb iu"> inverse_transform() </strong>方法用于将缩减的数据集解压缩回784维。这对于可视化压缩图像非常有用！</p><p id="676a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p><p id="b630" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程由<a class="ae ky" href="https://www.linkedin.com/in/rukshan-manorathna-700a3916b/" rel="noopener ugc nofollow" target="_blank"><em class="lv">Rukshan Pramoditha</em></a><em class="lv">，</em>数据科学365博客作者设计创作。</p><p id="a37f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" href="https://rukshanpramoditha.medium.com/" rel="noopener">https://rukshanpramoditha.medium.com</a>阅读我的其他文章</p><p id="f476" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">2021–04–12</p></div></div>    
</body>
</html>