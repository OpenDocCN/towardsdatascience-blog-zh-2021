<html>
<head>
<title>Parallel Sentence Mining in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的平行句挖掘</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/parallel-sentence-mining-in-python-ad54fc909f85?source=collection_archive---------29-----------------------#2021-10-11">https://towardsdatascience.com/parallel-sentence-mining-in-python-ad54fc909f85?source=collection_archive---------29-----------------------#2021-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9ce4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用语言无关的BERT句子嵌入模型的双文本挖掘</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/505f7ec3babd4f4b6949133e0e22097b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mcSA9KfnDEMwBnlDojtZDA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由乔尼·卡斯帕里在<a class="ae ky" href="https://unsplash.com/s/photos/mining?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="8153" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天的主题是关于在两个单语文件(无序的句子)上进行双文本挖掘，以找到平行的句子。在本教程中，您将学习使用一个名为LaBSE的语言无关的BERT句子嵌入模型。</p><p id="c5f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从Tensorflow中心，它表明<a class="ae ky" href="https://tfhub.dev/google/LaBSE/2" rel="noopener ugc nofollow" target="_blank"> LaBSE模型</a></p><blockquote class="lv lw lx"><p id="8ca4" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">…经过训练和优化，专门为相互翻译的双语句子对生成相似的表示。因此，它可以用于在更大的语料库中挖掘句子的翻译。</p></blockquote><p id="b84a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，给定以下文本:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="da76" class="mh mi it md b gy mj mk l ml mm">That is a happy person</span></pre><p id="ddab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当使用来自LaBSE模型的嵌入时，您将获得以下句子相似度:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="798f" class="mh mi it md b gy mj mk l ml mm">That is a happy dog<br/>0.741</span><span id="62e0" class="mh mi it md b gy mn mk l ml mm">That is a very happy person<br/>0.897</span><span id="87a0" class="mh mi it md b gy mn mk l ml mm">Today is a sunny day<br/>0.450</span></pre><p id="231c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，您也可以在翻译文本上识别句子相似性。让我们重复使用前面的句子</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="6af1" class="mh mi it md b gy mj mk l ml mm">That is a happy person</span></pre><p id="70e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并与下面的翻译文本进行比较。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="6106" class="mh mi it md b gy mj mk l ml mm">Questo è un cane felice<br/>0.624</span><span id="c258" class="mh mi it md b gy mn mk l ml mm">Questa è una persona molto felice<br/>0.757</span><span id="02da" class="mh mi it md b gy mn mk l ml mm">Oggi è una giornata di sole<br/>0.422</span><span id="9f7e" class="mh mi it md b gy mn mk l ml mm">Questa è una persona felice<br/>0.830</span></pre><p id="0ec9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它表明</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="e17f" class="mh mi it md b gy mj mk l ml mm">Questa è una persona felice</span></pre><p id="3580" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与原始句子最相似，因此可能是其翻译文本。</p><p id="b6ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，您可以使用这个概念来识别在两个不同的语料库上共享高相似度值的翻译对。假设一个英语语料库包含以下句子</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="fecd" class="mh mi it md b gy mj mk l ml mm">This is an example sentences.<br/>Good morning, Peter.<br/>Hello World!</span></pre><p id="3574" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你得到了另一个意大利语语料库，如下所示:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="af17" class="mh mi it md b gy mj mk l ml mm">Salve, mondo!<br/>L'esame è dietro l'angolo<br/>Buongiorno, Peter.</span></pre><p id="be82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过利用LaBSE模型，您将能够执行bitext挖掘，以便获得以下正确的平行句子:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="5a3a" class="mh mi it md b gy mj mk l ml mm">Hello World!    <!-- -->Salve, mondo!<br/>Good morning, Peter.    <!-- -->Buongiorno, Peter.</span></pre></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="9d81" class="mv mi it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">设置</h1><p id="e7de" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">强烈建议您在继续安装之前创建一个新的虚拟环境。</p><p id="b1bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在那之前，你需要在你的系统中安装<a class="ae ky" href="https://github.com/facebookresearch/faiss" rel="noopener ugc nofollow" target="_blank"> FAISS </a>。有一个库<a class="ae ky" href="https://github.com/kyamagu/faiss-wheels" rel="noopener ugc nofollow" target="_blank">为cpu和gpu安装提供python轮子。根据您的使用情况，按如下方式安装它:</a></p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="1ace" class="mh mi it md b gy mj mk l ml mm"># CPU<br/>pip install faiss-cpu</span><span id="23e2" class="mh mi it md b gy mn mk l ml mm"># GPU<br/>pip install faiss-gpu</span></pre><p id="2086" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，运行下面的命令来安装<code class="fe nr ns nt md b">sentence-transformer</code>，这是一个用于多语言句子、段落和图像嵌入的BERT模型。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="1a88" class="mh mi it md b gy mj mk l ml mm">pip install sentence-transformers</span></pre><p id="e4b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个Python包不仅限于挖掘平行句。它可用于各种应用，例如:</p><ul class=""><li id="f958" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu nz oa ob oc bi translated"><code class="fe nr ns nt md b">semantic search</code>:给定一个句子，在大集合中寻找语义相似的句子。</li><li id="c464" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated"><code class="fe nr ns nt md b">image search</code>:将图像和文本映射到同一个向量空间。这允许给定用户查询的图像搜索。</li><li id="c85d" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">给定一篇长文档，找出k个句子，这些句子对内容进行了简明扼要的总结。</li><li id="7583" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated"><code class="fe nr ns nt md b">clustering</code>:根据句子的相似性将句子分组。</li><li id="d16a" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated"><code class="fe nr ns nt md b">cross-encoder</code>:两个句子同时出现在变压器网络中，得到一个分数(0…1)，表示相似性或标签。</li></ul><p id="6cc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">官方存储库包含一些示例脚本，您可以根据您的用例直接使用:</p><ul class=""><li id="45f4" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu nz oa ob oc bi translated"><code class="fe nr ns nt md b"><a class="ae ky" href="https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/parallel-sentence-mining/bitext_mining_utils.py" rel="noopener ugc nofollow" target="_blank">bitext_mining_utils.py</a></code>:计算分数、执行knn聚类和打开文件的实用程序脚本。</li><li id="5154" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated"><code class="fe nr ns nt md b"><a class="ae ky" href="https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/parallel-sentence-mining/bitext_mining.py" rel="noopener ugc nofollow" target="_blank">bitext_mining.py</a></code>:读入两个文本文件(每行一句)，输出平行句为gzip文件(parallel-sentences-out.tsv.gz)。</li><li id="5413" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated"><code class="fe nr ns nt md b"><a class="ae ky" href="https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/parallel-sentence-mining/bucc2018.py" rel="noopener ugc nofollow" target="_blank">bucc2018.py</a></code>:BUCC 2018共享任务关于寻找平行句的<a class="ae ky" href="https://comparable.limsi.fr/bucc2018/bucc2018-task.html" rel="noopener ugc nofollow" target="_blank">示例脚本。</a></li></ul><h2 id="ab84" class="mh mi it bd mw oi oj dn na ok ol dp ne li om on ng lm oo op ni lq oq or nk os bi translated">概念</h2><p id="44cf" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">让我们深入探讨bitext挖掘的底层过程。流程如下:</p><ol class=""><li id="e81d" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu ot oa ob oc bi translated">使用<a class="ae ky" href="https://tfhub.dev/google/LaBSE/2" rel="noopener ugc nofollow" target="_blank"> LaBSE </a>将所有句子编码成各自的编码，LaBSE 是一种语言无关的BERT句子嵌入模型，支持多达109种语言。</li><li id="1c6d" class="nu nv it lb b lc od lf oe li of lm og lq oh lu ot oa ob oc bi translated">下一步是找到所有句子的k个最近邻句子(基于两个方向)。使用近似最近邻(ANN)算法，k应介于4和16之间。</li><li id="dfb3" class="nu nv it lb b lc od lf oe li of lm og lq oh lu ot oa ob oc bi translated">之后，根据Artetxe和Schwenk(第4.3节)的论文<a class="ae ky" href="https://arxiv.org/pdf/1812.10464.pdf" rel="noopener ugc nofollow" target="_blank">中的公式，对所有可能的句子组合打分。分数可以高于1。</a></li><li id="6600" class="nu nv it lb b lc od lf oe li of lm og lq oh lu ot oa ob oc bi translated">然后对分数进行排序。高分说明最有可能是骈文。大约1.2-1.3的阈值表示高质量的翻译。</li></ol><p id="db21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然在大多数运行中转化率较低，但是该方法适合于从开源的大单语语料库中获取附加的平行句。例如，您可以从维基百科EN-IT中提取文本，为您的EN-IT机器翻译模型获取额外的数据集。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="721a" class="mv mi it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">bucc2018</h1><p id="28fd" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">对于<code class="fe nr ns nt md b">bucc2018.py</code>，数据集必须采用以下语法(由制表符分隔的id和文本):</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="e6fd" class="mh mi it md b gy mj mk l ml mm">id    text</span></pre><p id="788b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如(每个数据点一行):</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="e44c" class="mh mi it md b gy mj mk l ml mm">en-000000005 The Bank of England’s balance sheet is also at 20% of GDP.</span><span id="a04f" class="mh mi it md b gy mn mk l ml mm">en-000000007 The most important of these was the creation of regional federations of savings banks.</span><span id="71b6" class="mh mi it md b gy mn mk l ml mm">en-000000008 Alongside CECA the central or main clearing bank for Spanish savings banks developed.</span><span id="dc40" class="mh mi it md b gy mn mk l ml mm">en-000000010 By 1970 the CECA had attained considerable credibility as a savings bank association.</span></pre><p id="7551" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只需从<a class="ae ky" href="https://comparable.limsi.fr/bucc2018/bucc2018-task.html" rel="noopener ugc nofollow" target="_blank"> BUCC2018任务</a>中获取数据集，并修改以下几行:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="4a28" class="mh mi it md b gy mj mk l ml mm">source_file = "bucc2018/de-en/de-en.training.de"                       target_file = "bucc2018/de-en/de-en.training.en"                       labels_file = "bucc2018/de-en/de-en.training.gold"</span></pre><p id="b981" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该脚本将使用<code class="fe nr ns nt md b">source_file</code>和<code class="fe nr ns nt md b">target_file</code>执行bitext挖掘。然后，它将根据<code class="fe nr ns nt md b">labels_file</code>评估结果。</p><p id="b1df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">按如下方式运行它:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="9d61" class="mh mi it md b gy mj mk l ml mm">python bucc2018.py</span></pre><p id="65a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在初始运行期间，它将从HuggingFace下载模型及其依赖项。如果您使用基于Linux的系统，它将存储在以下位置:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="80d8" class="mh mi it md b gy mj mk l ml mm">`~/.cache/huggingface/transformers`</span></pre><p id="c980" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，它将对PCA的训练嵌入进行编码，以减少维数，从而减少内存消耗，代价是性能略有下降。此外，嵌入将被保存在本地，以便以后可以直接从光盘加载。</p><p id="35a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您应该在终端上得到以下输出:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="f9b9" class="mh mi it md b gy mj mk l ml mm">Shape Source: (32593, 128)<br/>Shape Target: (40354, 128)<br/>Perform approx. kNN search<br/>Done: 5.04 sec<br/>Perform approx. kNN search<br/>Done: 5.03 sec<br/>17039<br/>Best Threshold: 1.22599776371784<br/>Recall: 0.9691714836223507<br/>Precision: 0.9853085210577864<br/>F1: 0.9771733851384167</span></pre><p id="d406" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦这个过程完成，就会生成一个名为<code class="fe nr ns nt md b">result.txt</code>的文件:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="0a59" class="mh mi it md b gy mj mk l ml mm">1.7022742387767527 de-000012693 en-000020744<br/>1.7002160776448074 de-000012458 en-000038209<br/>1.6910422179786977 de-000019004 en-000000538<br/>1.6634726798079071 de-000017671 en-000033396<br/>1.6572470385575508 de-000028406 en-000014338<br/>1.6525712862491655 de-000022783 en-000027704</span></pre><p id="05b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每一行由以下项目组成:</p><ul class=""><li id="4da9" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu nz oa ob oc bi translated">得分</li><li id="418c" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">源句子的id</li><li id="be48" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">目标句子的id</li></ul><p id="4343" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分数表示翻译对的质量。越高越好，并按降序排列。高质量的翻译对通常在1.3以上。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="7199" class="mv mi it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">比特矿业公司</h1><p id="074a" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">另一方面，<code class="fe nr ns nt md b">bitext_mining.py</code>接受不带id的普通每行格式的句子</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="59e7" class="mh mi it md b gy mj mk l ml mm">The Bank of England’s balance sheet is also at 20% of GDP.</span><span id="3452" class="mh mi it md b gy mn mk l ml mm">The most important of these was the creation of regional federations of savings banks.</span><span id="85fd" class="mh mi it md b gy mn mk l ml mm">Alongside CECA the central or main clearing bank for Spanish savings banks developed.</span><span id="2a61" class="mh mi it md b gy mn mk l ml mm">By 1970 the CECA had attained considerable credibility as a savings bank association.</span></pre><p id="3d60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在以下几行修改数据集的路径:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="96c8" class="mh mi it md b gy mj mk l ml mm">source_file = "data/so.txt.xz"<br/>target_file = "data/yi.txt.xz"</span></pre><p id="b7e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个脚本还过滤掉长度不在<code class="fe nr ns nt md b">min_sent_len</code>和<code class="fe nr ns nt md b">max_sent_len</code>字符之间的句子。根据您自己的用例修改代码中的以下变量:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="dadd" class="mh mi it md b gy mj mk l ml mm">min_sent_len = 10<br/>max_sent_len = 200</span></pre><p id="c9d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在您的终端上运行以下命令:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="c211" class="mh mi it md b gy mj mk l ml mm">python bitext_mining.py</span></pre><p id="162c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您应该会在控制台上看到以下输出:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="9567" class="mh mi it md b gy mj mk l ml mm">Read source file<br/>Read target file<br/>Shape Source: (6149, 128)<br/>Shape Target: (5579, 128)<br/>Perform approx. kNN search<br/>Done: 0.84 sec<br/>Perform approx. kNN search<br/>Done: 0.68 sec<br/>2222</span></pre><p id="2997" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将在同一个目录中生成一个名为<code class="fe nr ns nt md b">parallel-sentences-out.tsv.gz</code>的新zip文件。这个脚本将输出句子而不是句子id作为输出:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="87fe" class="mh mi it md b gy mj mk l ml mm">score    source_sentence    target_sentence</span></pre><p id="98c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您遇到类似<code class="fe nr ns nt md b">Segmentation fault (core dumped)</code>的错误，请仔细检查数据集。你需要有足够多的句子才能让它发挥作用。上述结果在6149个源句子和5579个目标句子上进行了测试。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="c2d2" class="mv mi it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">结论</h1><p id="4597" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">让我们回顾一下你今天所学的内容。</p><p id="872a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文首先简要介绍了LaBSE模型，以及如何使用它来计算不同语言的两个文本之间的相似性得分。</p><p id="8924" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，它进入安装过程。此外，它还解释了示例脚本和bitext挖掘背后的关键概念。</p><p id="e6a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">稍后，它将逐步介绍如何运行两个示例脚本，即<code class="fe nr ns nt md b">bucc2018.py</code>和<code class="fe nr ns nt md b">bitext_mining.py</code>。</p><p id="a430" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢你阅读这篇文章。祝你有美好的一天！</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="3840" class="mv mi it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">参考</h1><ol class=""><li id="83ae" class="nu nv it lb b lc nm lf nn li ou lm ov lq ow lu ot oa ob oc bi translated"><a class="ae ky" href="https://tfhub.dev/google/LaBSE/2" rel="noopener ugc nofollow" target="_blank"> Tensorflow Hub — LaBSE </a></li><li id="ebb1" class="nu nv it lb b lc od lf oe li of lm og lq oh lu ot oa ob oc bi translated"><a class="ae ky" href="https://github.com/UKPLab/sentence-transformers" rel="noopener ugc nofollow" target="_blank"> Github —句子转换器</a></li></ol></div></div>    
</body>
</html>