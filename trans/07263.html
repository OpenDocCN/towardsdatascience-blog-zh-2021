<html>
<head>
<title>Effortless Distributed Training of Ultra-Wide GCNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">轻松的超宽GCNs分布式训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/effortless-distributed-training-of-ultra-wide-gcns-6e9873f58a50?source=collection_archive---------38-----------------------#2021-07-01">https://towardsdatascience.com/effortless-distributed-training-of-ultra-wide-gcns-6e9873f58a50?source=collection_archive---------38-----------------------#2021-07-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/4ba7cc144ba15a222b7ffb90e522f8c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cCNYDUZ2IBYqMTGvu54V-w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图GIST培训管道的描述。子GCNs将GCN模型分成多个子GCNs。每个子GCN都是用聚类操作构造的小批量子训练的。通过subAgg操作，子GCN参数被间歇地聚集到全局模型中。【图由作者创作。]</p></figure><p id="e180" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这篇文章中，我将概述最近提出的用于大规模图卷积网络(GCNs)的分布式训练框架，称为图独立子网训练(GIST) [1]。GIST极大地加速了任何架构的GCN训练过程，并可用于支持超过单个GPU能力的大规模模型的训练。我的目标是在这篇文章中涵盖GIST的最关键的方面，包括相关的背景信息，对训练方法的全面描述，以及关于GIST的实验验证的细节。一份完整、详细的手稿被用来描述GIST，可在Arxiv 上获得<a class="ae ld" href="https://arxiv.org/abs/2102.10424" rel="noopener ugc nofollow" target="_blank">。此外，使用GIST进行的所有实验的源代码都可以在GitHub </a>上公开获得<a class="ae ld" href="https://github.com/wolfecameron/GIST" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="814b" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">介绍</h1><p id="0d13" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">机器学习和深度学习已经通过它们在工业和科学问题上的许多应用而普及(例如，自动驾驶汽车、推荐系统、人员跟踪等)。)，但图形上的机器学习(我将简称为graphML)最近刚刚成为计算机科学和人工智能研究的焦点。虽然graphML的普及有许多原因，但一个主要原因是一个简单的事实，即并非所有数据都可以在欧几里得空间中编码。在许多应用中，图是更直观的数据结构，例如社交网络(即，图的节点是人，边代表社交关系)或化学(即，图的节点代表原子，边代表化学键)。同样地，在欧几里德数据上概括现有的学习策略(例如，卷积神经网络、变换器等。)研究图表是一个很有价值的问题。</p><p id="8add" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了实现这个目标，已经开发了几种针对图的(深度)学习技术，其中最流行的是图卷积网络(GCN) [2]。受光谱图卷积的一阶近似的启发，GCN实现了图的卷积运算的一般化。尽管GCN很受欢迎，并且在执行节点和图级别的分类任务方面取得了广泛的成功，但该模型的效率非常低，并且难以扩展到大型图。这一问题促进了节点划分技术的发展，包括邻域采样(例如，LADIES和FastGCN)和图划分(例如，ClusterGCN和GraphSAGE)，其将大图划分成计算上易处理的部分。尽管如此，graphML研究中使用的数据仍然保持在相对较小的规模，由于更深层次网络中的过度平滑问题，大多数GCN模型的规模有限[3]。graphML实验中这种较小数据和模型的使用与主流深度学习研究形成鲜明对比，后者的实验规模不断扩大。</p><p id="9d45" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了弥合深度学习和graphML之间的规模差距，GIST旨在利用更大的模型和数据集进行实验。GIST可用于训练任何GCN体系结构，并与现有的节点划分技术兼容，它通过随机划分全局模型内的隐藏特征空间，将全局GCN模型分解成几个等深度的窄子gcn来操作。然后，这些子gcn被分发到单独的GPU，并在将它们的更新聚合到完整的全局模型中之前，独立且并行地训练几次迭代。然后，创建/分发一组新的子gcn，重复相同的过程，直到收敛。在非常大的图的情况下，我们采用现有的图划分方法来形成小批量，这允许GIST在任意大的图上训练GCN模型。</p><p id="f10d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">简而言之，GIST旨在以最少的挂钟训练时间为大规模GCN实验提供一个分布式训练框架。此外，因为GIST训练子gcn而不是直接训练全局模型，所以它可以用于训练具有超过单个GPU能力的极大隐藏层的模型(例如，我们使用GIST在Amazon2M上训练“超宽”32，768维GraphSAGE模型)。需要注意的是，我们选择关注缩放模型的宽度，而不是深度，因为深度GCN模型会受到过度平滑的影响[3]。</p><h1 id="30d3" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">要点是什么？</h1><p id="6717" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">这里，我们解释GIST使用的一般训练方法。这种培训方法旨在实现快速、大规模的GCN实验，适用于任何GCN建筑或取样方法。在我们的解释中，我们假设读者对GCN建筑有一个大致的了解。为了全面了解GCN的建筑，我们推荐<a class="ae ld" href="https://tkipf.github.io/graph-convolutional-networks/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。图1提供了GIST培训方法的全局视图，我们将在以下部分进一步解释该方法的每个组成部分。</p><h2 id="5fea" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">创建子gcn</h2><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mt"><img src="../Images/145eb4a9c3b3b74ed6b76ea447b16ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Le4gNEgLf6-jlW15BOhoYw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图2:m = 2的GCN分割。橙色和蓝色代表不同的功能分区。两个隐藏维度(d1和d2)都被分区。输出维度(d3)没有分区，对输入维度(d0)的分区是可选的。GIST不划分输入维度。【图由作者创作。]</p></figure><p id="e1b9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用GIST训练GCN模型的第一步是划分全局模型的隐藏维度，以形成多个等深度的窄子gcn(即，图1中的<code class="fe my mz na nb b">sub-GCNs</code>)。在划分之前，必须知道子gcn的数量，表示为<code class="fe my mz na nb b">m</code>。然后，对于全局模型的每个隐藏层，该层内的神经元的索引被随机划分成大小相等的<code class="fe my mz na nb b">m</code>不相交组，对应于不同的子gcn。一旦构造了这些分区，通过用来自前一层的分区索引来索引全局权重矩阵的行，用当前层的分区索引来索引全局权重矩阵的列，可以构造任意层的子GCN权重矩阵。这样，这种划分方法为对应于已经选择的随机特征划分的每个子GCN创建更小的权重矩阵。</p><p id="35e2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">图2中描述的上述方法对全局GCN模型的所有层执行，但是输入和输出维度不包括在划分中。输入维度(即，图2中的d0)没有被划分，因为这将导致每个子GCN只能访问每个节点的输入向量的一部分，这将导致<code class="fe my mz na nb b">m</code>的值越大，性能越下降。类似地，全局模型的输出维度(即，图2中的d3)没有被分割，使得每个子GCN产生相同大小的输出向量。因此，不需要对损失函数进行修改，并且可以训练所有子gcn来最小化相同的全局损失函数。</p><p id="6f09" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">一旦构建了子gcn，它们每个都被发送到单独的GPU进行独立和并行的训练。应当注意的是，完整模型从不被传送(即，仅子gcn在设备之间被传送)，这极大地提高了利用GIST的分布式训练的通信效率。子GCN分区的过程如图2所示，其中不同的子GCN分区用橙色和蓝色表示。回想一下，GIST中没有划分输入和输出维度，如图2的(b)所示。</p><h2 id="19a8" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">培训子GCNs</h2><p id="950e" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">在子gcn被构造并被发送到它们各自的设备之后，它们每个都被独立且并行地训练一组迭代次数(即图1中的<code class="fe my mz na nb b">subTrain</code>),这被称为局部迭代。当子GCN已经完成它们的局部迭代时，每个子GCN的参数更新被聚集到全局模型中，并且新的子gcn组被创建。这个过程重复进行，直到收敛。如前所述，训练子gcn以最小化相同的全局损失函数。此外，在相同的数据上训练每个子GCN(即，不假设跨设备的数据的非iid分区)。</p><p id="e6ab" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了确保使用GIST训练的模型和使用标准单GPU方法训练的模型之间的训练总量保持恒定，使用GIST训练的GCN模型具有跨子gcn分割的训练历元总数。例如，如果普通的基线GCN模型使用单个GPU训练10个时期，那么使用两个子GCN用GIST训练的可比GCN模型将为每个子GCN进行5个时期的训练。因为子GCN是并行训练的，所以每个子GCN的训练历元数量的这种减少导致了大的训练加速。</p><p id="424b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果训练图足够小，子gcn可以并行进行整批训练。然而，在训练图对于要执行的整批训练来说太大的情况下，作为预处理步骤，采用图划分方法将训练图分解成更小的、计算上易处理的子图(即，图1中的<code class="fe my mz na nb b">Cluster</code>)。然后，这些子图在独立的训练迭代期间被用作小批量，这大致反映了clusterGCN提出的训练方法[4]。尽管可以使用任何划分方法，但GIST使用METIS是因为它在大规模图形上证明了效率[5]。</p><h2 id="d4bb" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">聚集子gcn</h2><p id="0a67" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">在子gcn完成独立训练之后，在新的子gcn的另一轮独立训练开始之前，必须将它们的参数聚集到全局模型中(即图1中的<code class="fe my mz na nb b">subAgg</code>)。这种聚集通过简单地将每个子GCN的参数复制到它们在全局模型中的相应位置来执行。由于在GIST中创建的特征分区是不连续的，因此在此过程中不会发生冲突。有趣的是，不是所有的参数都在每一轮独立训练中更新。例如，在图2的(b)中，实际上只有重叠的橙色和蓝色块被划分为子gcn，而其他参数被排除在独立训练之外。然而，如果进行了足够多的独立训练回合，则全局模型中的所有参数都应该被更新多次，因为每个训练回合都利用了新的随机特征划分。</p><h1 id="9c79" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">GIST为什么有用？</h1><p id="1ba8" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">乍一看，GIST培训方法似乎有些复杂，让人想知道为什么要使用它。在这一节中，我概述了GIST的好处，以及为什么它会带来更有效的、大规模的图形实验。</p><h2 id="2361" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">与架构无关的分布式培训</h2><p id="b9cb" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">GIST是一种分布式培训方法，可用于任何GCN架构。特别地，GIST被用于训练原始手稿中的普通GCN、GraphSAGE和图形注意力网络(GAT)架构，但是GIST不限于这些模型。因此，它是一个通用框架，可用于加速任何GCN模型的训练。</p><h2 id="c5d7" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">与取样方法的兼容性</h2><p id="9719" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">GIST中的特征划分策略与为有效的GCN训练而提出的许多节点划分策略是正交的。因此，这些策略中的任何一种都可以很容易地与GIST相结合，以提高训练效率。例如，图划分被用于在具有GIST的较大图上训练gcn，GIST甚至被用于训练GraphSAGE模型。这些实验证明了GIST与现有的图形和邻域采样方法的兼容性。</p><h2 id="82c4" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">超宽GCN训练</h2><p id="9436" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">GIST通过训练更小的子GCN来间接更新全局GCN模型，这使得具有极大隐藏维度(即超过单个GPU的能力)的模型能够被训练。例如，当使用8个子GCN训练具有GIST的GCN模型时，在单个GPU的容量限制下，该模型的隐藏维度可以比模型大大约8倍。这种性质使得能够用GIST训练“超宽”GCN模型，如在用GIST的实验中所证明的。</p><h2 id="414b" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">提高了模型的复杂性</h2><p id="ff75" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">GIST显著降低了分布式GCN训练的通信和计算复杂度，导致挂钟训练时间的急剧加速。这种复杂度的降低是由于GIST只传送和训练比全局模型小得多的子gcn。GIST提供的复杂性降低的更精确的表达可在原始手稿中获得。</p><h1 id="458d" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">GIST在实践中表现如何？</h1><p id="b23c" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">在这一节中，我概述了使用GIST进行的实验，这些实验验证了它在显著减少挂钟时间的情况下训练GCN模型达到高性能的能力。实验在大量数据集上进行，包括Cora、Citeseer、Pubmed、OGBN-Arxiv、Reddit和Amazon2M。然而，在本文中，我将重点放在Reddit和Amazon2M的实验上，因为这些数据集要大得多，并且与实际的graphML应用程序更相关。较小的数据集主要用作GIST方法的设计/消融实验，更多细节可在手稿中获得。</p><h2 id="e7e1" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">Reddit数据集</h2><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/5fe19ef3c7a12024460fb987c5b6502a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2c8gVIPUOtyiEQg5GzspMw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图3:在Reddit数据集上使用GIST和标准单GPU方法训练的GraphSAGE和GAT模型的F1分数和挂钟训练时间。【图由作者创作。]</p></figure><p id="cbb7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">GIST在Reddit数据集上的实验是用256维GraphSAGE和GAT模型两到四层进行的。使用多个不同数量的子GCN用GIST训练模型，其中假设每个子GCN被分配到单独的GPU(即，8个子GCN实验总共使用8个GPU)。使用Adam优化器执行总训练的80个时期，并且没有权重衰减，并且局部迭代的数量被设置为500。在训练期间，训练图被分成15，000个子图。基线模型使用标准的单GPU方法进行训练，所有其他实验细节保持不变。如图3所示，使用GIST训练的所有模型的性能都达到或超过了使用标准单GPU方法训练的模型。此外，与标准的单GPU训练相比，GIST的训练时间显著减少。</p><h2 id="9de8" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">Amazon2M数据集</h2><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nd"><img src="../Images/d82086ccf2f65ab6ce3989e88011650e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6peYsmyqNGHRzgpfdi3QCw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图GraphSAGE模型的F1分数和挂钟训练时间，这些模型具有不同的隐藏维度和层数，使用GIST和标准的单GPU方法在Amazon2M数据集上进行训练。【图由作者创作。]</p></figure><p id="0c74" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在Amazon2M数据集上使用GraphSAGE模型进行GIST实验，该模型具有400和4096的隐藏维度(即窄模型和宽模型)以及不同的层数。再次，使用多个不同数量的子gcn用GIST训练模型，并且训练图被分解成15，000个分区。基线实验使用标准的单GPU训练方法来执行。使用Adam优化器进行训练，在总共400个时期内没有权重衰减，并且局部迭代的数量被设置为5，000。如图4所示，与使用标准单GPU方法训练的基线模型相比，使用GIST训练的模型完成训练的速度明显更快。此外，在所有情况下，用GIST训练的模型与用标准方法训练的模型表现相当。</p><h2 id="3ce0" class="mh lf it bd lg mi mj dn lk mk ml dp lo kq mm mn ls ku mo mp lw ky mq mr ma ms bi translated">超宽GCNs</h2><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ne"><img src="../Images/3930ef1cbb962ee7d6c10ec2ce3d51a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w7ZmsF-WeJ9zTxM7pQtNcA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图5:在Amazon2M数据集上使用GIST和单GPU方法训练的400到32，768个隐藏维度的GraphSAGE模型的性能指标。标有“OOM”的事例在训练过程中导致内存不足错误。【图由作者创作。]</p></figure><p id="bed2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如前所述，GIST可以用于训练非常广泛的GCN模型，因为全球模型是通过子gcn的独立训练间接更新的。为了展示这种能力，在Amazon2M数据集上训练了具有越来越大的隐藏维度的GraphSAGE模型。如图5所示，GIST可用于在Amazon2M数据集上训练隐藏维度高达32，768的GraphSAGE模型，从而以相对最少的训练时间获得高性能。在这些情况下，单GPU训练方法会出现内存不足的错误(即使是在小得多的GCN模型中)，从而证明GIST可以用于训练远远超过单个GPU能力的模型。此外，与使用GIST训练的模型相比，仅使用单个GPU训练的模型的挂钟训练时间变得非常令人望而却步，从而突出了其加速大规模GCN实验的能力。正如这些实验所表明的，GIST使GCN实验能够在以前不可行的规模上进行。</p><h1 id="50d2" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">结论</h1><p id="0ce4" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">在这篇博文中，我概述了GIST，一种用于大型GCN模型的新型分布式训练方法。GIST通过将全局GCN模型划分为几个狭窄的子gcn来运行，这些子gcn分布在单独的GPU上，并且在将它们的参数聚集到全局模型中之前独立地并行训练。GIST可以用于训练任何GCN体系结构，与现有的采样方法兼容，并且可以在不降低模型性能的情况下显著加快训练时间。此外，GIST能够将难以置信的宽GCN模型训练到最先进的性能，如Amazon2M数据集上的32，768维GraphSAGE模型。</p><p id="2133" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我真的很感谢你对这篇博客感兴趣。如果您有任何意见或问题，请随时联系我或留下您的意见(联系信息可在<a class="ae ld" href="https://wolfecameron.github.io" rel="noopener ugc nofollow" target="_blank">我的网站</a>上找到)。GIST是作为独立子网训练(IST)计划的一部分，在莱斯大学我的研究实验室(T3)内开发的。更多相关项目信息请点击<a class="ae ld" href="https://akyrillidis.github.io/ist/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="353d" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><em class="nf">引文</em></h1><p id="e018" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">[1]<a class="ae ld" href="https://arxiv.org/abs/2102.10424" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2102.10424</a></p><p id="f1d1" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><a class="ae ld" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1609.02907</a></p><p id="9d49" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">[3]<a class="ae ld" href="https://arxiv.org/abs/1801.07606" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1801.07606</a></p><p id="ca73" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><a class="ae ld" href="https://arxiv.org/abs/1905.07953" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.07953</a></p><p id="0197" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><a class="ae ld" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.106.4101" rel="noopener ugc nofollow" target="_blank">http://citeseerx.ist.psu.edu/viewdoc/summary?[5]doi=10.1.1.106.4101 </a></p></div></div>    
</body>
</html>