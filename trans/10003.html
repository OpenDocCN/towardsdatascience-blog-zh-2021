<html>
<head>
<title>Selecting Multiple Columns in PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在PySpark中选择多个列</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/selecting-multiple-columns-in-pyspark-d1aac072fcc0?source=collection_archive---------9-----------------------#2021-09-21">https://towardsdatascience.com/selecting-multiple-columns-in-pyspark-d1aac072fcc0?source=collection_archive---------9-----------------------#2021-09-21</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="8e10" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">讨论如何通过列名、索引或使用正则表达式从PySpark数据帧中选择多个列</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/6258e3a2b0690b138adaee6de2062e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K_euPyHCZsvmt25UwTYwSQ.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://unsplash.com/@azevdoluana?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Luana Azevedo </a>在<a class="ae kz" href="https://unsplash.com/s/photos/select?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="2859" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">介绍</h2><p id="72b7" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在使用Spark时，我们通常需要处理大量的行和列，因此，有时我们只能处理列的一小部分。</p><p id="26a7" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">在今天的简短指南中，我们将探索从PySpark数据帧中选择列的不同方法。具体来说，我们将讨论如何选择多个列</p><ul class=""><li id="d733" class="mu mv iu ly b lz mp mc mq lj mw ln mx lr my mo mz na nb nc bi translated">按列名</li><li id="8308" class="mu mv iu ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">按索引</li><li id="b98a" class="mu mv iu ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">使用正则表达式</li></ul></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><p id="bcbe" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">首先，让我们创建一个示例数据框架，我们将在本文中引用它来演示一些概念。</p><pre class="kk kl km kn gu np nq nr ns aw nt bi"><span id="7bcc" class="la lb iu nq b gz nu nv l nw nx">from pyspark.sql import SparkSession</span><span id="18f9" class="la lb iu nq b gz ny nv l nw nx"><br/># Create an instance of spark session<br/>spark_session = SparkSession.builder \<br/>    .master('local[1]') \<br/>    .appName('Example') \<br/>    .getOrCreate()</span><span id="b5cf" class="la lb iu nq b gz ny nv l nw nx"># Create an example DataFrame<br/>df = spark_session.createDataFrame(<br/>    [<br/>       (1, 'a', True, 1.0, 5),<br/>       (2, 'b', False, 2.0, None),<br/>       (3, 'c', False, 3.0, 4),<br/>       (4, 'd', True, 4.0, 3),<br/>    ],<br/>    ['colA', 'colB', 'colC', 'colD', 'E']<br/>)</span><span id="b771" class="la lb iu nq b gz ny nv l nw nx"><br/>df.show()<br/><em class="nz">+----+----+-----+----+----+<br/>|colA|colB| colC|colD|   E|<br/>+----+----+-----+----+----+<br/>|   1|   a| true| 1.0|   5|<br/>|   2|   b|false| 2.0|null|<br/>|   3|   c|false| 3.0|   4|<br/>|   4|   d| true| 4.0|   3|<br/>+----+----+-----+----+----+</em></span></pre></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><h2 id="a183" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">按名称选择多个列</h2><p id="88f1" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">为了从一个现有的PySpark数据帧中选择多个列，您可以简单地指定您希望通过<code class="fe oa ob oc nq b"><a class="ae kz" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.select.html" rel="noopener ugc nofollow" target="_blank">pyspark.sql.DataFrame.select</a></code>方法检索的列名。举个例子，</p><pre class="kk kl km kn gu np nq nr ns aw nt bi"><span id="6507" class="la lb iu nq b gz nu nv l nw nx"><strong class="nq iv">df.select('colA', 'colC').show()</strong></span><span id="bd20" class="la lb iu nq b gz ny nv l nw nx"><em class="nz">+----+-----+<br/>|colA| colC|<br/>+----+-----+<br/>|   1| true|<br/>|   2|false|<br/>|   3|false|<br/>|   4| true|<br/>+----+-----+</em></span></pre><p id="0ca3" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">或者，如果您希望检索的列存储在列表中，您可以使用以下符号:</p><pre class="kk kl km kn gu np nq nr ns aw nt bi"><span id="b382" class="la lb iu nq b gz nu nv l nw nx">col_names = ['colA', 'colC']</span><span id="f323" class="la lb iu nq b gz ny nv l nw nx"><strong class="nq iv">df.select(*col_names).show()</strong></span><span id="5921" class="la lb iu nq b gz ny nv l nw nx"><em class="nz">+----+-----+<br/>|colA| colC|<br/>+----+-----+<br/>|   1| true|<br/>|   2|false|<br/>|   3|false|<br/>|   4| true|<br/>+----+-----+</em></span></pre></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><h2 id="23f1" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">通过索引选择多个列</h2><p id="a2f0" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">现在，如果您想基于它们的索引选择列，那么您可以简单地从返回列名列表的<code class="fe oa ob oc nq b">df.columns</code>中截取结果。例如，为了检索前三列，下面的表达式应该可以做到:</p><pre class="kk kl km kn gu np nq nr ns aw nt bi"><span id="5812" class="la lb iu nq b gz nu nv l nw nx"><strong class="nq iv">df.select(df.columns[:3]).show()</strong></span><span id="a1b9" class="la lb iu nq b gz ny nv l nw nx"><em class="nz">+----+----+-----+<br/>|colA|colB| colC|<br/>+----+----+-----+<br/>|   1|   a| true|<br/>|   2|   b|false|<br/>|   3|   c|false|<br/>|   4|   d| true|<br/>+----+----+-----+</em></span></pre><p id="5b49" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">或者，如果你只想获取第二列和第三列，那么<code class="fe oa ob oc nq b">df.columns[1:3]</code>就可以了:</p><pre class="kk kl km kn gu np nq nr ns aw nt bi"><span id="e9b9" class="la lb iu nq b gz nu nv l nw nx"><strong class="nq iv">df.select(df.columns[1:3]).show()</strong></span><span id="a6cf" class="la lb iu nq b gz ny nv l nw nx"><em class="nz">+----+-----+<br/>|colB| colC|<br/>+----+-----+<br/>|   a| true|<br/>|   b|false|<br/>|   c|false|<br/>|   d| true|<br/>+----+-----+</em></span></pre></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><h2 id="1e80" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用正则表达式选择多个列</h2><p id="4eb8" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">最后，为了选择多个匹配特定正则表达式的列，您可以使用<code class="fe oa ob oc nq b"><a class="ae kz" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.colRegex.html" rel="noopener ugc nofollow" target="_blank">pyspark.sql.DataFrame.colRegex</a></code>方法。例如，为了获取所有以<code class="fe oa ob oc nq b">col</code>开头或包含【】的列，下面的代码就可以做到:</p><pre class="kk kl km kn gu np nq nr ns aw nt bi"><span id="8792" class="la lb iu nq b gz nu nv l nw nx"><strong class="nq iv">df.select(df.colRegex("`(col)+?.+`")).show()</strong></span><span id="a3bc" class="la lb iu nq b gz ny nv l nw nx"><em class="nz">+----+----+-----+----+<br/>|colA|colB| colC|colD|<br/>+----+----+-----+----+<br/>|   1|   a| true| 1.0|<br/>|   2|   b|false| 2.0|<br/>|   3|   c|false| 3.0|<br/>|   4|   d| true| 4.0|<br/>+----+----+-----+----+</em></span></pre><p id="2197" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">类似地，我们可以使用下面的正则表达式来选择除<code class="fe oa ob oc nq b">colA</code>之外的所有列:</p><pre class="kk kl km kn gu np nq nr ns aw nt bi"><span id="efb4" class="la lb iu nq b gz nu nv l nw nx"><strong class="nq iv">df.select(df.colRegex("`(colA)?+.+`")).show()</strong></span><span id="6531" class="la lb iu nq b gz ny nv l nw nx"><em class="nz">+----+-----+----+----+<br/>|colB| colC|colD|   E|<br/>+----+-----+----+----+<br/>|   a| true| 1.0|   5|<br/>|   b|false| 2.0|null|<br/>|   c|false| 3.0|   4|<br/>|   d| true| 4.0|   3|<br/>+----+-----+----+----+</em></span></pre></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><h2 id="78f3" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">最后的想法</h2><p id="f311" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在今天的简短指南中，我们讨论了如何在PySpark数据框架中执行列选择。我们探讨了如何通过指定列名或索引来选择多个列。此外，我们还看到了如何使用正则表达式来执行列选择。</p></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><p id="1b77" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><a class="ae kz" href="https://gmyrianthous.medium.com/membership" rel="noopener"> <strong class="ly iv">成为会员</strong> </a> <strong class="ly iv">阅读介质上的每一个故事。你的会员费直接支持我和你看的其他作家。</strong></p></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><p id="676e" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><strong class="ly iv">你可能也会喜欢</strong></p><div class="od oe gq gs of og"><a rel="noopener follow" target="_blank" href="/sparksession-vs-sparkcontext-vs-sqlcontext-vs-hivecontext-741d50c9486a"><div class="oh ab fp"><div class="oi ab oj cl cj ok"><h2 class="bd iv gz z fq ol fs ft om fv fx it bi translated">spark session vs spark context vs SQLContext vs hive context</h2><div class="on l"><h3 class="bd b gz z fq ol fs ft om fv fx dk translated">SparkSession、SparkContext HiveContext和SQLContext有什么区别？</h3></div><div class="oo l"><p class="bd b dl z fq ol fs ft om fv fx dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="oq l or os ot op ou kt og"/></div></div></a></div></div><div class="ab cl ni nj hy nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="in io ip iq ir"><div class="kk kl km kn gu og"><a rel="noopener follow" target="_blank" href="/how-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3"><div class="oh ab fp"><div class="oi ab oj cl cj ok"><h2 class="bd iv gz z fq ol fs ft om fv fx it bi translated">加快PySpark和Pandas数据帧之间的转换</h2><div class="on l"><h3 class="bd b gz z fq ol fs ft om fv fx dk translated">将大火花数据帧转换为熊猫时节省时间</h3></div><div class="oo l"><p class="bd b dl z fq ol fs ft om fv fx dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ov l or os ot op ou kt og"/></div></div></a></div></div></div>    
</body>
</html>