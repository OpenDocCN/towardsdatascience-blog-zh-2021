<html>
<head>
<title>FISH-Net: Automating the Fish Doorbell</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">鱼网:自动鱼门铃</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automating-the-fish-doorbell-a668285728d6?source=collection_archive---------40-----------------------#2021-06-18">https://towardsdatascience.com/automating-the-fish-doorbell-a668285728d6?source=collection_archive---------40-----------------------#2021-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="054e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用机器学习和计算机视觉支持鱼类洄游</h2></div><p id="5c52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">许多不同的鱼类每年都要长途跋涉才能到达它们的繁殖地。如今，由于水闸等障碍，这一旅程变得更加困难。乌特勒支的Weerdsluis 是沿着一条受欢迎的鱼类迁徙路线设置的水闸之一。为了提高认识，与乌得勒支市共同发起了一项倡议:T2鱼门铃。在这里，用户可以观看船闸处的实时水流，如果他们发现了一条鱼，就会“按铃”。然后锁可以打开，让任何等待的鱼通过。这个倡议很快就像病毒一样传播开来，门铃被按了<a class="ae lc" href="https://www.rtvutrecht.nl/nieuws/2184860/visdeurbel-gaat-offline-maar-niet-getreurd-hij-komt-volgend-jaar-terug.html" rel="noopener ugc nofollow" target="_blank">超过10万次！</a></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/23e2dfe1feda5475e47b4b2e7dc977c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NbfpzRVGk_vsAGce.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">乌特勒支的Weerdsluis，图片来自<a class="ae lc" href="https://commons.wikimedia.org/wiki/File:Weerdsluis_Utrecht.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="a784" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管这显然是一场提高意识的活动，但我们开始想知道是否有一种方法可以自动检测这些鱼，这样即使没有人观看溪流，它们也可以通过。我们使用图像处理方法和深度学习创建了一个解决方案。</p><h1 id="3478" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">我们的解决方案</h1><p id="61d1" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">那么我们到底如何才能检测到这些鱼呢？我们提出了一个由两步组成的解决方案:</p><ul class=""><li id="a3e5" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la mv mw mx my bi translated">使用传统的图像处理从包含运动的静止视频中提取碎片</li><li id="dc97" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">使用快速简单的卷积神经网络(CNN)来确定图像块是否包含鱼。</li></ul><p id="f575" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">图像处理</strong></p><p id="1d46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鱼可见的时间只占直播的一小部分。我们希望收集潜在鱼类游过的图像，并希望这些图像包含尽可能多的有用信息。<br/>为了做到这一点，我们决定实施一种<a class="ae lc" href="https://en.wikipedia.org/wiki/Foreground_detection" rel="noopener ugc nofollow" target="_blank">背景减法</a>方法来检测运动并获得包含没有背景的鱼的图像块。“数据收集”一节<strong class="kh ir">解释了我们是如何做到这一点的。</strong>检索到的图像块然后被调整到100x100像素的分辨率，并被送入下一部分:CNN。</p><p id="82fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">网络</strong></p><p id="a65c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该模型应该能够实时工作，以便与直播工作。我们也更喜欢网络只使用有限的训练数据。我们选择使用一个简单的CNN进行鱼类分类。该网络仅由两个卷积层和两个全连接层组成。由此产生的网络架构如下图所示。在一些测试中，我们发现增加更多的层并没有显著的积极效果，但是仍然有优化的空间。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/f285490e03acf8e3e22c077ce2eb4399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/0*CCaIvVW_Gspp2M-A.png"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">通过<a class="ae lc" href="https://bit.ly/3vlnkuU" rel="noopener ugc nofollow" target="_blank">https://bit.ly/3vlnkuU</a>获得的网络架构</p></figure><h1 id="e736" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">收集和注释数据</h1><p id="8ceb" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">因为我们是作为监督学习任务来处理的，所以我们需要一些带注释的数据来训练我们的网络。由于游过Weerdsluis的鱼的公共注释数据集并不存在，我们不得不创建自己的数据集。</p><p id="a0e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">数据收集</strong></p><p id="7f12" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们直接从<a class="ae lc" href="http://visdeurbel.nl/" rel="noopener ugc nofollow" target="_blank"> visdeurbel.nl </a>读取直播，为此我们使用了OpenCV和从网站上提取的直播url。使用<a class="ae lc" href="https://en.wikipedia.org/wiki/Moving_average#Approximating_the_EMA_with_a_limited_number_of_terms" rel="noopener ugc nofollow" target="_blank">指数加权移动平均</a> (EWMA)，我们获得了一个移动的背景流图像，如下图左上角所示。这个背景图像不会包含快速移动的物体，如鱼，并且会随着白天的光照条件而变化。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/4f01b699e453df5acf77d02a1a315cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PcNeVwhODd-ODwdfeRTMkw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">数据收集器的快照，左上:背景图像，右上:带有边界框的视频帧，左下:阈值，右下:减去背景后的帧-作者提供的图像</p></figure><p id="bd92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们对视频的最新帧的背景图像执行简单的数字减法，并将结果放大五倍，以获得仅包含移动对象的图像，如本视频所示。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ng nh l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">背景减除的视频流——作者根据<a class="ae lc" href="https://www.youtube.com/watch?v=45khuKKECyw" rel="noopener ugc nofollow" target="_blank">原始来源</a>制作的视频</p></figure><p id="0527" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们在图像上应用过滤器并执行阈值操作，从而产生包含运动物体轮廓的遮罩。如果轮廓超过一定的大小，并且可以跟踪20帧，我们将保存一帧视频以及减影图像的100×100像素块。在仅仅2-3天的时间里，我们收集了超过7000种潜在鱼类的照片。</p><p id="c4c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">数据标注</strong></p><p id="a893" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为注释成千上万的图像补丁听起来并不吸引我们，所以我们想让它尽可能简单。为此，我们编写了一个单独的脚本:<em class="lb"> annotator.py. </em>这个脚本加载还没有被注释的图像补丁，然后允许用户通过一次按键来标记它们。它还会统计注释的总量、当前会话中的注释量以及您每分钟的平均注释量，有时会达到每分钟55个以上的注释。我们区分两类:鱼(30%)和非鱼(70%)。我们也可以将图像归类为不清晰，之后在训练中忽略。我们最终注释了大约3000个样本，其中2500个是清晰的，用于我们的网络。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ni"><img src="../Images/10721416bff2c3a1b407867c5c1c4432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UU9mRBgSiHQ_F3X1pIbmgg.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">数据标注工具快照—图片由作者提供</p></figure><h1 id="a41d" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">训练网络</h1><p id="0230" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们使用TensorFlow 2和Keras构建了网络。我们使用Adam作为优化器，使用二进制交叉熵损失作为损失函数。我们使用80/20的训练测试分割。训练网络真的很快，在普通笔记本电脑上只需要一分钟左右。我们做了一些简短的实验，看看什么样的超参数最适合我们的问题。在未来的工作中，我们希望进行更广泛的超参数优化，以获得最佳结果。</p><h1 id="69e4" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结果</h1><p id="c561" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">下图显示了训练和测试数据集在训练时期数量上的准确度曲线。奇怪的是，测试精度曲线在20个时期后变平，但随着模型过度拟合，不会进一步降低。对于最佳模型，我们在大约10个时期后使用早期停止。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/cc1fddf0362216f2bd47f3940b532b99.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/0*YCpTTZSrfHtZK6C0.png"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">精确度曲线</p></figure><p id="d0d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里画出了模型的损失。随着训练损失接近于0，测试损失继续增加。我们的假设是，网络试图使训练损失尽可能接近于0，但在这样做的过程中，预测错误的预测越来越多。这不会对准确性产生负面影响，但会增加这种预测的损失，从而增加总体测试损失。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/93f63810acbf63e8f803046926512cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/0*KLNp0XjFNu4_0pLz.png"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">损失曲线</p></figure><p id="6c79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里绘制了ROC曲线。该模型实现了高的真阳性率(或召回率)，即使是在相对低的假阳性率下。这意味着该模型能够非常频繁地检测到鱼，而当对象不是鱼时，将对象分类为鱼的机会非常低。这对于这种应用尤其重要，因为我们不希望水锁无缘无故被打开。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/fd0ad0f1e6160d4ab3cd4dc2c5cc814d.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/0*8tDhYRJMIw31rtNU.png"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">受试者工作特征曲线</p></figure><h1 id="217a" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">项目的状态</h1><p id="6be6" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们这个项目的计划是让这个模型对鱼进行实时分类。然而，到目前为止，我们只能在同一天收集的图像块上测试该模型。当我们想用直播实现这个模型时，我们发现鱼门铃刚刚离线<a class="ae lc" href="https://www.dutchnews.nl/news/2021/06/utrecht-migrating-fish-will-keep-their-doorbell-next-season/" rel="noopener ugc nofollow" target="_blank">到2022年春天</a>，我们再也不能用直播演示这个模型了。<br/>我们希望在某个时候能够用视频数据展示这个模型的工作情况。如果是这样的话，我们一定会用我们的结果更新这篇博文。</p><p id="be87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Simon已经为FISH-Net v2编制了一个主要和次要的更改列表，包括更好的背景过滤、数据收集值嵌入等。所以明年一定要收听更多。</p><h1 id="3ac3" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">接触</h1><p id="09e0" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">西蒙·范·伊登~ 5185734<br/><a class="ae lc" href="http://simonvaneeden@hotmail.com" rel="noopener ugc nofollow" target="_blank">simonvaneeden@hotmail.com</a><br/>沃特·德·勒乌~ 4487753<br/><a class="ae lc" href="http://w.f.deleeuw@student.tudelft.nl" rel="noopener ugc nofollow" target="_blank">w . f . deleeuw @ student . tudelft . nl</a></p><p id="baff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">如需获取本项目中使用的源代码，请发送电子邮件至:</em><a class="ae lc" href="http://simonvaneeden@hotmail.com" rel="noopener ugc nofollow" target="_blank"><em class="lb">simonvaneeden@hotmail.com</em></a></p></div></div>    
</body>
</html>