<html>
<head>
<title>Python Implementation of Grid Search and Random Search for Hyperparameter Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超参数优化的网格搜索和随机搜索的Python实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/python-implementation-of-grid-search-and-random-search-for-hyperparameter-optimization-2d6a82ebf75c?source=collection_archive---------11-----------------------#2021-06-07">https://towardsdatascience.com/python-implementation-of-grid-search-and-random-search-for-hyperparameter-optimization-2d6a82ebf75c?source=collection_archive---------11-----------------------#2021-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6d6f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Scikit-learn GridSearchCV和RandomizedSearchCV函数进行超参数优化的指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1d3cd7363ef2ae291b451a93e71ee969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H24oWvwfItbD8BYtg_Cv-w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@dichatz?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">迪查茨</a>在<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="7555" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果不进行任何超参数优化(调整)，就无法从机器学习模型中获得最佳效果。默认的超参数值并不是您的数据的最佳模型。sikit-learn-Python机器学习库为超参数优化提供了两个特殊函数:</p><ul class=""><li id="86e2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> GridSearchCV — </strong>进行网格搜索</li><li id="d0c7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> RandomizedSearchCV — </strong>进行随机搜索</li></ul><p id="ed44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是数据科学和机器学习领域的新手，你可能不熟悉这些词。在这篇文章中，我将重点介绍网格搜索和随机搜索的Python实现，并解释它们之间的区别。读完这篇文章后，您将能够获得使用Scikit-learn实现网格搜索和随机搜索的实践经验。</p><h2 id="cec8" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">先决条件</h2><p id="873a" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">强烈建议对<strong class="lb iu"><em class="mj">k</em>-折叠交叉验证</strong>有良好的了解。我们也推荐构建<strong class="lb iu">决策树模型</strong>的知识，因为我们在这里使用这样的模型来实现网格搜索和随机搜索。如果你不熟悉这些东西，不要担心。我也为他们写了内容。首先，阅读它们，然后继续阅读这一个。以下是链接:</p><p id="ac55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">对于<em class="mj">k</em>-折叠交叉验证:</strong></p><div class="ni nj gp gr nk nl"><a rel="noopener follow" target="_blank" href="/k-fold-cross-validation-explained-in-plain-english-659e33c0bc0"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd iu gy z fp nq fr fs nr fu fw is bi translated">用简单的英语解释k倍交叉验证</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">用于评估模型的性能和超参数调整</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz ks nl"/></div></div></a></div><p id="3807" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">对于决策树:</strong></p><div class="ni nj gp gr nk nl"><a rel="noopener follow" target="_blank" href="/train-a-regression-model-using-a-decision-tree-70012c22bcc1"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd iu gy z fp nq fr fs nr fu fw is bi translated">使用决策树训练回归模型</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">对于复杂的非线性数据</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="oa l nw nx ny nu nz ks nl"/></div></div></a></div><p id="f2d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将区分模型<strong class="lb iu"> <em class="mj">参数</em> </strong>和<strong class="lb iu"> <em class="mj">超参数</em> </strong>。</p><h1 id="8a97" class="ob ml it bd mm oc od oe mp of og oh ms jz oi ka mv kc oj kd my kf ok kg nb ol bi translated">模型参数与超参数</h1><p id="117f" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated"><strong class="lb iu"> <em class="mj">模型参数</em> </strong>在训练过程中学习它们的值。我们不手动设置这些值。他们从我们提供的数据中学习。例如，线性回归模型的模型系数可以被认为是模型参数。</p><p id="f045" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，<strong class="lb iu"> <em class="mj">模型超参数</em> </strong>不从数据中学习它们的值。所以，我们必须手动设置它们。我们总是在创建特定模型时(即在训练过程之前)设置超参数的值。例如，我们可以通过为<strong class="lb iu"> <em class="mj">规格化</em> </strong>超参数设置一个布尔值来指定是否规格化线性回归模型的输入特征(X):</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="faf1" class="mk ml it on b gy or os l ot ou">from <!-- -->sklearn.linear_model import <!-- -->LinearRegression</span><span id="1361" class="mk ml it on b gy ov os l ot ou">lr_1 = LinearRegression(<em class="mj">normalize=False</em>) # No any normalization<br/>lr_2 = LinearRegression(<em class="mj">normalize=True</em>) # Normalization applied</span></pre><p id="9e24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> lr_1 </strong>和<strong class="lb iu"> lr_2 </strong>模型给出两种不同的输出，因为它们具有不同的<strong class="lb iu"> <em class="mj">归一化</em> </strong>超参数值。模型超参数可以控制模型参数。这意味着模型超参数会影响模型的性能。因此，我们有责任设置模型超参数值，以便它们给出模型的最优或最佳可能输出。</p><p id="b113" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在大多数情况下，即使简单的模型也有两个或更多的超参数。因此，我们必须同时考虑所有这些超参数，以找到每个超参数的最佳值。寻找模型超参数最优组合的过程称为<strong class="lb iu"> <em class="mj">超参数优化(调优)</em> </strong>。我们不能手动这样做，因为有许多超参数，每个超参数有许多不同的值。幸运的是，Scikit-learn提供了<strong class="lb iu"> GridSearchCV </strong>和<strong class="lb iu"> RandomizedSearchCV </strong>函数来自动化优化(调整)过程。</p><h1 id="836c" class="ob ml it bd mm oc od oe mp of og oh ms jz oi ka mv kc oj kd my kf ok kg nb ol bi translated">超参数搜索空间</h1><p id="1125" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">这是超参数调整过程中一个非常重要的概念。搜索空间包含用户定义的超参数值的所有不同组合。下图显示了两个不同超参数的二维搜索空间— <strong class="lb iu">最大深度</strong>和<strong class="lb iu">最小样本分割</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/4e926445a767d237b83835b3c25062f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*Acu5HV3fhDTTOqqYdgbSTA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="54ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有3个不同的超参数，则搜索空间是三维的。同样，随着超参数数量的增加，搜索空间可以是高维的。你应该知道的一般事情是:</p><ul class=""><li id="93f1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">搜索空间中的维数定义了超参数的数量。(例如2维-2个超参数)</li><li id="1428" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">搜索空间中的每个点定义了超参数值的每个组合。点<strong class="lb iu"> (8，30) </strong>定义了<strong class="lb iu">最大_深度</strong>的值8和<strong class="lb iu">最小_样本_分割</strong>的值30。</li></ul><p id="4cf8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将搜索空间定义为一个Python字典，其中包含作为关键字的超参数名称和作为值列表的这些超参数的值。这种字典的一般格式是:</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="44f5" class="mk ml it on b gy or os l ot ou">search_space = {'param_1':[val_1, val_2],<br/>                'param_2':[val_1, val_2],<br/>                'param_3':['str_val_1', 'str_val_2']}</span></pre><p id="10d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们区分网格搜索和随机搜索。</p><h1 id="b85e" class="ob ml it bd mm oc od oe mp of og oh ms jz oi ka mv kc oj kd my kf ok kg nb ol bi translated">网格搜索与随机搜索</h1><p id="bd2d" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated"><strong class="lb iu"> <em class="mj">网格搜索</em> </strong>在搜索空间中搜索用户定义的所有不同的超参数组合。这将耗费大量的计算资源，并且当搜索空间是高维的并且包含许多值的组合时，通常具有高的执行时间。当有少量超参数和有限(固定)数量的超参数值时，这种方法是理想的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/a93e92a9de0a238152ce448d0b03cd89.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*6GQfpZxHyrwKeX1RC85pbQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网格搜索(作者图片)</p></figure><p id="b7cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相比之下，随机搜索在寻找最优组合时不会检查所有不同的超参数组合。相反，它检查在<strong class="lb iu"> RandomizedSearchCV </strong>函数的<strong class="lb iu"> n_iter </strong>中指定的随机选择的固定数量的组合。随机搜索在随机选择的组合中找到最佳超参数组合的概率非常高。当搜索空间是高维的并且包含许多值的组合时，该方法对于快速有效地找到最优超参数组合是非常有用的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/bf8172f0021c6fba7501f7ee0a967f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*jcvBwHq6oK4xdcPS4YzkXw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机搜索(图片由作者提供)</p></figure><h1 id="7879" class="ob ml it bd mm oc od oe mp of og oh ms jz oi ka mv kc oj kd my kf ok kg nb ol bi translated">构建基础模型</h1><p id="f966" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">现在，我们在<a class="ae ky" href="https://drive.google.com/file/d/1zQ3GzQrhtR4_cwlSbs7pAA34ekGkwz_c/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">“heart _ disease”数据集</a>上构建决策树分类模型，而不做任何超参数调整。在整篇文章中，我们将使用这个模型作为<strong class="lb iu"> <em class="mj">基础模型</em> </strong>，以便可以与使用网格搜索和随机搜索调优的其他模型进行比较。看看下面的Python代码，它构建了我们的基本模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基本模型(等到加载Python代码！)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/9d1364ba25a7dfb103ea9189a00a7cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*5XkVEaDrdDd2787y2pHNIA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="fce0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如您从输出中看到的，我们的基本模型不是很好。它已经很好地学习了训练数据，但它无法对新的输入数据(测试集)进行归纳。用技术术语来说，我们的基本模型显然是过度拟合的。决策树模型通常倾向于过度拟合。</p><p id="5a4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以使用网格搜索和随机搜索方法来提高我们模型的性能(测试准确度分数)。</p><p id="984d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将尝试网格搜索。</p><h1 id="64a3" class="ob ml it bd mm oc od oe mp of og oh ms jz oi ka mv kc oj kd my kf ok kg nb ol bi translated">网格搜索的Python实现</h1><p id="7f15" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">网格搜索的Python实现可以使用Scikit-learn<strong class="lb iu">GridSearchCV</strong>函数来完成。它具有以下重要参数:</p><ul class=""><li id="3df2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> estimator — </strong>(第一个参数)一个Scikit-learn机器学习模型。换句话说，这是我们的基本模型。</li><li id="57a0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> param_grid — </strong>如前所述的搜索空间的Python字典。我们的搜索空间是三维的，包含576种不同的组合。这意味着我们用网格搜索训练576个不同的模型！</li><li id="6fcd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">评分— </strong>用于衡量模型性能的评分方法。对于分类，我们一般用‘准确度’或‘roc _ AUC’。对于回归，首选“r2”或“负均方误差”。由于我们的基础模型是一个分类模型(决策树分类器)，我们使用“准确性”作为评分方法。要查看可用评分方法的完整列表，请点击<a class="ae ky" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank">此处</a>。</li><li id="82be" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> n_jobs — </strong>指定执行网格搜索时要运行的并行作业的数量。如果您的计算机处理器有许多内核，请为此设置一个较高的值。<strong class="lb iu"> -1 </strong>值使用所有可用的内核。这将加快执行过程。</li><li id="9926" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> cv — </strong>交叉验证的折叠数。标准数字是5，10。当cv为10时，每个超参数组合重复10次。因此，总迭代次数为5760 (576 x 10)。</li></ul><p id="d3b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看看下面的Python代码，它在我们的基本模型上执行网格搜索。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网格搜索(等到加载Python代码！)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/1896ae2748fda07d3296960d7160752f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jIxLnqeNWMaphyQjvVrLOg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="843d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个用几个<strong class="lb iu"> print() </strong>函数格式化的很好的输出。您可以将这个输出与我们基本模型的先前输出进行比较。该模型的性能现已得到明显改善。这一次，模型并没有过度拟合。它在训练集和测试集上都表现良好。除此之外，调整超参数后，假阳性和假阴性都显著减少。</p><p id="915b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们来关注一下这种情况下网格搜索的执行时间。大约只有22.5秒。运行5760次迭代在处理器所有内核都启用的情况下只需要22.5秒(<strong class="lb iu"> n_jobs=-1 </strong>)！</p><p id="cd7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们尝试随机搜索。</p><h1 id="6ea9" class="ob ml it bd mm oc od oe mp of og oh ms jz oi ka mv kc oj kd my kf ok kg nb ol bi translated">随机搜索的Python实现</h1><p id="bff3" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">随机搜索的Python实现可以使用Scikit-learn的<strong class="lb iu"> RandomizedSearchCV </strong>函数来完成。大多数参数与<strong class="lb iu"> GridSearchCV </strong>函数中的参数相同。这里，搜索空间由<strong class="lb iu">参数_分布</strong>而不是<strong class="lb iu">参数_网格</strong>定义。<strong class="lb iu"> </strong>除此之外，</p><ul class=""><li id="4810" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> n_iter — </strong>指定随机选择的超参数组合的数量。这是因为随机搜索不会检查搜索空间中定义的所有超参数组合。相反，它只考虑组合的随机样本。这里，n_iter=10意味着它执行大小为10的随机样本任务，该样本包含10个不同的超参数组合。所以随机搜索只训练10个不同的模型(之前是576个带网格搜索的模型)。</li><li id="179f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> random_state — </strong>控制每次不同执行时获取超参数组合样本的随机化。我们可以使用任何整数。</li></ul><p id="c10d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，总迭代次数是100 (10 x 10)，这比前一种情况(5760次迭代)少得多。</p><p id="6127" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，看看下面的Python代码，它在我们的基本模型上执行随机搜索。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机搜索(等到加载Python代码！)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/2c31911cdc1875b8e3b3489e8394271c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TsFPi5KnJZwlDAIYxZA7Xg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="9104" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型性能与网格搜索完全相同。然而，最佳超参数值是不同的。现在，执行时间仅为0.51秒，比前一个版本(22.5秒)少得多。在这种情况下，随机搜索比网格搜索快44倍(22.5 / 0.51)。这是因为随机搜索只少执行57.6倍(5760 / 100)的迭代！</p><h1 id="4a17" class="ob ml it bd mm oc od oe mp of og oh ms jz oi ka mv kc oj kd my kf ok kg nb ol bi translated">结论</h1><p id="5b8d" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">在我们的例子中，您可以尝试网格搜索和随机搜索，因为这两种方法只需要不到半分钟的时间。然而，请记住，随机搜索的力量。在我们的例子中，它快了44倍(22.5 / 0.51)。这意味着如果随机搜索将花费1分钟的执行时间，网格搜索将花费大约44分钟！所以，当搜索空间是高维的，包含很多不同的超参数组合时，我强烈推荐你使用随机搜索。</p><p id="f06a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行网格搜索或随机搜索后，您将获得最佳超参数组合。例如，我们在网格搜索中得到以下最优超参数组合:</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="2e3a" class="mk ml it on b gy or os l ot ou">{'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 2}</span></pre><p id="6273" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们可以将最优模型定义如下:</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="d33f" class="mk ml it on b gy or os l ot ou">from <!-- -->sklearn.tree import <!-- -->DecisionTreeClassifier</span><span id="fc3c" class="mk ml it on b gy ov os l ot ou">dtclf_optimal = DecisionTreeClassifier(<strong class="on iu">max_depth=6</strong>,<br/>                                       <strong class="on iu">min_samples_leaf=6</strong>,<br/>                                       <strong class="on iu">min_samples_split=2</strong>,<br/>                                       random_state=42)</span></pre><p id="8228" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我们不需要这样写代码。<strong class="lb iu"> GridSearchCV </strong>和<strong class="lb iu">randomzedsearchcv</strong>函数都有一个名为<strong class="lb iu"> best_estimator_ </strong>的属性，用来获得具有最优超参数的模型。因此，</p><pre class="kj kk kl km gt om on oo op aw oq bi"><span id="2de6" class="mk ml it on b gy or os l ot ou">gs.best_estimator_ </span></pre><p id="eff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">会给出同样的<strong class="lb iu"> dtclf_optimal </strong>模型。这里，<strong class="lb iu"> <em class="mj"> gs </em> </strong>是拟合的GridSearchCV模型。</p><p id="8928" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，请注意，网格搜索和随机搜索一次考虑所有超参数，而不是一个接一个。这就是为什么网格搜索和随机搜索得到的不同超参数值给出了相同的准确率分数。如果您想查看单个超参数的影响，我建议您使用<strong class="lb iu">验证曲线</strong> —一种图形技术。我写的下面这篇文章解释了我们如何使用它。</p><div class="ni nj gp gr nk nl"><a rel="noopener follow" target="_blank" href="/validation-curve-explained-plot-the-influence-of-a-single-hyperparameter-1ac4864deaf8"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd iu gy z fp nq fr fs nr fu fw is bi translated">解释验证曲线—绘制单个超参数的影响</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">少代码出图！省点时间解读吧！</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="pd l nw nx ny nu nz ks nl"/></div></div></a></div></div><div class="ab cl pe pf hx pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="im in io ip iq"><p id="60d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><p id="0e0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">报名链接:</strong><a class="ae ky" href="https://rukshanpramoditha.medium.com/membership" rel="noopener">https://rukshanpramoditha.medium.com/membership</a></p><p id="f693" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢你一直以来的支持！下一个故事再见。祝大家学习愉快！</p><p id="3655" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除封面图片、代码样本、其他内容链接和文字内容外的所有图片均归作者版权所有。特别要感谢Unsplash <strong class="lb iu"> </strong>上的<strong class="lb iu">迪查茨</strong>，他是封面图片的所有者。非常感谢，<strong class="lb iu">迪查茨</strong>，为我在本帖中提供了一张出色的封面图片！</p><p id="5ebe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="pl pm ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----2d6a82ebf75c--------------------------------" rel="noopener" target="_blank"> <strong class="lb iu">鲁克山普拉莫迪塔</strong></a><strong class="lb iu"><br/>2021–06–07</strong></p></div></div>    
</body>
</html>