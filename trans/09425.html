<html>
<head>
<title>My ML Model Fails. Why? Is It the data?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我的ML模型失败了。为什么？是数据吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/my-ml-model-fails-why-is-it-the-data-d8fbfc50c254?source=collection_archive---------23-----------------------#2021-09-01">https://towardsdatascience.com/my-ml-model-fails-why-is-it-the-data-d8fbfc50c254?source=collection_archive---------23-----------------------#2021-09-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="bd9e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解模型表现不佳是因为错误的模型选择，还是因为训练数据中的噪声，并提供一个真实的示例。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/724a64d796823e9962fb272c4cc25a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WpLAABF4-HXlJWYB.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片:<a class="ae kv" href="https://commons.wikimedia.org/wiki/File:%22The_School_of_Athens%22_by_Raffaello_Sanzio_da_Urbino.jpg" rel="noopener ugc nofollow" target="_blank">拉斐尔1509年创作的《雅典学院》</a></p></figure><h1 id="d591" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="9879" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">当你建立和训练一个模型并检查其准确性时，机器学习中最常见的问题之一是"<strong class="lq ir">我能从数据中获得的准确性最好吗</strong>或者a能找到更好的模型吗？"。</p><p id="06a7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">此外，一旦您的模型被部署，下一个常见的问题是“<strong class="lq ir">为什么模型失败了</strong>”。有时这两个问题都无法回答，但有时我们可以通过研究模型误差的统计分布来发现预处理误差、模型偏差以及数据泄漏。</p><p id="41af" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在本教程中，我们将解释和演示如何对模型结果进行统计研究，以<strong class="lq ir">在示例<strong class="lq ir">中发现错误</strong>的原因。</strong></p><h1 id="b383" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">商业案例</h1><p id="4074" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在本例中，我们将使用来自<a class="ae kv" href="https://www.drivendata.org/competitions/50/worldbank-poverty-prediction/" rel="noopener ugc nofollow" target="_blank">驱动的数据竞赛</a>的数据，从一组社会经济变量中预测一个人是否生活在贫困状态。</p><p id="e710" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">该商业案例的价值不仅在于能够利用机器学习模型<strong class="lq ir">预测贫困状况</strong>，还在于了解衡量贫困的社会经济变量的预测性，并从特征上分析其原因。</p><h1 id="2237" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">模特培训</h1><p id="eae8" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">数据由一组九个描述性变量组成，其中四个是分类变量，另外五个是数字变量(但是其中一个似乎是id，所以我们将丢弃它)。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="1ee3" class="mu kx iq mq b gy mv mw l mx my">import pandas as pd<br/><br/>pd.set_option('display.max_columns', None)<br/>train = pd.read_csv('train.csv', index_col='id')<br/>print(train)</span></pre><p id="1b45" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">它返回</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="c25e" class="mu kx iq mq b gy mv mw l mx my">  Unnamed: 0 kjkrfgld bpowgknt raksnhjf vwpsxrgk  omtioxzz  yfmzwkru<br/>id                                                                          <br/>29252  2225    KfoTG    zPfZR    DtMvg      NaN      12.0      -3.0   <br/>98286  1598    ljBjd    THHLT    DtMvg    esAQH      21.0      -2.0   <br/>49040  7896    Lsuai    zPfZR    zeYAm    ZCIYy      12.0      -3.0   <br/>35261  1458    KfoTG    mDadf    zeYAm    ZCIYy      12.0      -1.0   <br/>98833  1817    KfoTG    THHLT    DtMvg    ARuYG      21.0      -4.0   <br/><br/>       tiwrsloh  weioazcf   poor  <br/>id                                <br/>29252      -1.0       0.5  False  <br/>98286      -5.0      -9.5   True  <br/>49040      -5.0      -9.5   True  <br/>35261      -5.0      -9.5  False  <br/>98833      -5.0      -9.5   True  </span></pre><p id="cc92" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这里可以看到数据分布</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/b79b080b16b905a349e3c94930348750.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c3nzlYF2ui40BiE3-tyJZQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者分类的图像:数据集中用目标着色的所有要素的成对绘图。黄色表示差=假，紫色表示差=真。</p></figure><p id="8046" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在一些预处理(NaN值插补、缩放、分类编码等)之后，我们将训练一个SVM模型(它通常在来自一键编码的高维数据中工作良好)</p><h2 id="9c17" class="mu kx iq bd ky na nb dn lc nc nd dp lg lx ne nf li mb ng nh lk mf ni nj lm nk bi translated">支持向量机</h2><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="ce81" class="mu kx iq mq b gy mv mw l mx my">from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import RobustScaler<br/>from sklearn.neighbors import KNeighborsClassifier<br/><br/>model = Pipeline(steps=preprocess+[<br/>                 ('scaler', RobustScaler()),<br/>                 ('estimator', KNeighborsClassifier(n_neighbors=5))])<br/><br/>model.fit(X_train, y_train)<br/>y_pred = model.predict(X_test)<br/>print(classification_report(y_test,y_pred))</span></pre><p id="488a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">它返回</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="e987" class="mu kx iq mq b gy mv mw l mx my">precision    recall  f1-score   support<br/><br/>       False       0.73      0.77      0.75       891<br/>        True       0.70      0.66      0.68       750<br/><br/>    accuracy                           0.72      1641<br/>   macro avg       0.72      0.71      0.71      1641<br/>weighted avg       0.72      0.72      0.72      1641</span></pre><p id="c800" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从二进制分类问题来看，0.72的精度不是非常好的精度。相比之下，查全率和查准率似乎是平衡的，这使我们认为该模型不是偏向于任何一个类别。</p><h1 id="3316" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">测试其他模型</h1><p id="e53d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">尝试改进模型的下一步是尝试其他ML模型和超参数，看看我们是否找到任何提高性能的配置(或者甚至只是检查性能是否在平稳状态下保持不变)。</p><p id="9b34" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们将使用来自不同系列函数的两个<strong class="lq ir">其他模型。KNN模型是学习局部模式影响的一个很好的选择，梯度增强树也是具有最高能力的ML模型之一</strong></p><p id="818b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">K-最近邻</strong></p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="8c94" class="mu kx iq mq b gy mv mw l mx my">from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import RobustScaler<br/>from sklearn.neighbors import KNeighborsClassifier<br/><br/>model = Pipeline(steps=preprocess+[<br/>                 ('scaler', RobustScaler()),<br/>                 ('estimator', KNeighborsClassifier(n_neighbors=5))])<br/><br/>model.fit(X_train, y_train)<br/>y_pred = model.predict(X_test)<br/>print(classification_report(y_test,y_pred))</span></pre><p id="a9dd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">它返回</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="5c29" class="mu kx iq mq b gy mv mw l mx my">precision    recall  f1-score   support<br/><br/>       False       0.71      0.74      0.72       891<br/>        True       0.67      0.63      0.65       750<br/><br/>    accuracy                           0.69      1641<br/>   macro avg       0.69      0.69      0.69      1641<br/>weighted avg       0.69      0.69      0.69      1641</span></pre><h2 id="2da6" class="mu kx iq bd ky na nb dn lc nc nd dp lg lx ne nf li mb ng nh lk mf ni nj lm nk bi translated">梯度推进</h2><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="4e7b" class="mu kx iq mq b gy mv mw l mx my">from sklearn.pipeline import Pipeline<br/>from sklearn.ensemble import GradientBoostingClassifier<br/><br/>model = Pipeline(steps=preprocess+[<br/>                 ('estimator', <br/>                  GradientBoostingClassifier(max_depth=5,<br/>                                             n_estimators=100))])<br/><br/>model.fit(X_train, y_train)<br/>y_pred = model.predict(X_test)<br/>print(classification_report(y_test,y_pred))</span></pre><p id="12a3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">它返回</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="2cf2" class="mu kx iq mq b gy mv mw l mx my">precision    recall  f1-score   support<br/><br/>       False       0.76      0.78      0.77       891<br/>        True       0.73      0.70      0.72       750<br/><br/>    accuracy                           0.74      1641<br/>   macro avg       0.74      0.74      0.74      1641<br/>weighted avg       0.74      0.74      0.74      1641</span></pre><p id="5f4e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们可以看到，其他两个模型的表现似乎非常相似。这提出了以下问题:</p><blockquote class="nl"><p id="6723" class="nm nn iq bd no np nq nr ns nt nu mj dk translated">这是我们用ML模型所能预测的最好结果吗？</p></blockquote><h1 id="a400" class="kw kx iq bd ky kz la lb lc ld le lf lg jw nv jx li jz nw ka lk kc nx kd lm ln bi translated">模型预测分布</h1><p id="2217" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">除了检查性能的一般指标之外，分析模型输出分布也很重要。我们不仅要检查测试数据集中的分布，还要检查训练数据集中的分布。原因是因为我们不想看到我们的模型表现如何，而是<strong class="lq ir">是否也学会了如何分割训练数据</strong>。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="3a72" class="mu kx iq mq b gy mv mw l mx my">import matplotlib.pyplot as plt</span><span id="1c4c" class="mu kx iq mq b gy ny mw l mx my">pd.DataFrame(model.predict_proba(X_train))[1].hist()<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/2a79acc654b7088331f9e5c6bc84aa5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*d9_D310c-XeXUMpx5pZYyw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者排序的图片:在训练集上评估的模型输出分布</p></figure><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="829b" class="mu kx iq mq b gy mv mw l mx my">pd.DataFrame(model.predict_proba(X_test))[1].hist()<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/cd67384a10cdb4d05db097cd18209502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*BUfVOwR3zbeevk0xC5RIOQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:测试集上评估的模型输出分布</p></figure><p id="b7a3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们可以看到，在0 的预测数量中有一个<strong class="lq ir">高峰，这表明有一个数据子集，该模型非常确定其标签为0。除此之外，分布似乎相当均匀。</strong></p><p id="ffc3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果模型已经知道肯定区分两个标签，则分布将具有两个峰值，一个在0附近，另一个在1附近。因此，我们可以看到我们的模型没有正确地学习模式来区分数据。</p><h1 id="cf5e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">偏差分布</h1><p id="bffb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们已经看到，该模型还没有学会清楚地区分这两个类别，但我们还没有看到它是否即使不自信也能猜出预测，或者它只是一直失败。</p><p id="c3d2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">此外，检查模型是否更偏向于某一类别也很重要。为了检查这两个方面，我们可以画出预测值与目标值的偏差分布图</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="ccaf" class="mu kx iq mq b gy mv mw l mx my">train_proba = model.predict_proba(X_train)[:,1]<br/>pd.DataFrame(train_proba-y_train.astype(int)).hist(bins=50)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/d20c4cc2f5bdad41f125f1e8789e32c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*az4pTXSpZUShPq86x1mnyQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:模型置信度输出与在训练集上评估的基础真实值的偏差</p></figure><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="23ff" class="mu kx iq mq b gy mv mw l mx my">test_proba = model.predict_proba(X_test)[:,1]<br/>pd.DataFrame(test_proba-y_test.astype(int)).hist(bins=50)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/108283a8b304b37edce69b21e97df52a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*a3TwWyT9Q8yasGUjaSCstg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:模型置信度输出与测试集上评估的基础事实的偏差</p></figure><p id="812a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从这两幅图中我们可以看到，偏差分布似乎是<strong class="lq ir">对称的，以零</strong>为中心。差距正好为零，因为模型从不返回0和1的精确值，我们不必担心这一点。</p><p id="9108" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果模型误差来自训练数据的统计/测量噪声误差，而不是偏差误差，我们预计偏差分布遵循高斯分布<strong class="lq ir">。</strong></p><p id="9ae0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们的分布类似于在0中具有更高峰值的<strong class="lq ir">高斯分布</strong>，但是该峰值可能是由于模型预测的更大数目的0(即，模型已经学习了一种模式来区分0的子集和1的类别)。</p><h1 id="f5fc" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">正规性检验</h1><p id="37df" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">由于训练数据中的统计噪声，在考虑模型预测偏差是否合理之前，我们必须确保它们遵循高斯分布。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="45d8" class="mu kx iq mq b gy mv mw l mx my">import scipy<br/><br/>scipy.stats.normaltest(train_proba-y_train.astype(int))</span></pre><p id="6d78" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">带退货</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="6a0f" class="mu kx iq mq b gy mv mw l mx my">NormaltestResult(statistic=15.602215177113427, pvalue=0.00040928141243470884)</span></pre><p id="32af" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在p值=0.0004的情况下，我们可以假设预测与目标的偏差遵循高斯分布<strong class="lq ir"> </strong>，这使得模型<strong class="lq ir">误差来自训练数据</strong>中的噪声的理论看似合理。</p><h1 id="bf32" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">模型可解释性</h1><p id="2398" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">正如我们之前提到的，这个商业案例的目标不仅仅是一个可以预测为什么会发生以及与之相关的社会经济变量的模型。</p><p id="9be1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">可解释模型不仅能对未知数据进行预测，还能提供特征如何影响模型的信息(全局可解释性)，以及为什么某个预测是这样的(局部可解释性)。</p><p id="2924" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然而，一个模型的可解释性越少，也就越有助于理解它为什么能做出预测以及为什么会失败。从梯度推进模型中，我们可以如下提取全局可解释性:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="cda1" class="mu kx iq mq b gy mv mw l mx my">cols = X_train.columns<br/>vals= dict(model.steps)['estimator'].feature_importances_<br/><br/>plt.figure()<br/>plt.bar(cols, vals)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/f4d77d116fe11cf1d3da9fe8c2b235c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*c3KVA_ijQOhWTvbq59uabw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:梯度增强特征重要性</p></figure><p id="438d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在，我们将进行相同的特征重要性分析，但只是在数据子集内进行训练。具体来说，我们将只使用零类别的明显为零的数据(之前模型明确预测为零的数据)来训练模型。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="811b" class="mu kx iq mq b gy mv mw l mx my">zero_mask = model.predict_proba(X_train)[:,1]&lt;=0.1<br/>one_mask = y_train==1<br/>mask = np.logical_or(zero_mask,one_mask)<br/>X_train = X_train.loc[mask,:]<br/>y_train = y_train.loc[mask]<br/>model.fit(X_train,y_train)</span></pre><p id="f32a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在特征的重要性是</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/bad21740fb74027aa3ab90617323643f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*jHc0wd_Vnl0T1rBvZUxpyg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:在模型表现最佳的训练集的子样本上训练的梯度增强要素重要性</p></figure><p id="f2a6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们可以看到，现在，<em class="oa"> tiwrsloh，</em>和<em class="oa"> yfmzwkru </em>的重要性增加了，而<em class="oa"> vwpsxrgk </em>的值减少了。这意味着人口中有一个<strong class="lq ir">子集明显不属于贫困人口</strong>(0类),可以用贫困变量中的这两个变量来表征，并且<em class="oa"> vwpsxrgk </em>在许多情况下可能很重要，但并不具有决定性</p><p id="90aa" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果我们绘制这两个特征的过滤值，我们会看到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/4ae7d013166601725f1c3209c061a6d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*zrx-sR4LvLzvFLByB7vKaw.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者分类的图像:分割并描述模型明确检测到非贫困的特征区域。</p></figure><p id="a95f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于这两个特征，模型已经学会区分两个类别，同时对于这些变量的其他值，对于整个数据集，零类别和一类别是混合的，因此不能清楚地区分。</p><p id="1157" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们也可以从前面的图表中将<strong class="lq ir">非贫困人口的一个明确子集描述为那些具有<em class="oa"> tiwrsloh </em> &lt; 0和<em class="oa"> yfmzwkru </em> &lt; -2 </strong>的人。</p><h1 id="3434" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><ul class=""><li id="381a" class="oc od iq lq b lr ls lu lv lx oe mb of mf og mj oh oi oj ok bi translated">我们分析了在给定数据集中检测贫困的问题，并分析了给定社会经济数据的贫困原因，发现贫困不容易预测，但是，我们可以定义一些明确确定人们贫困状况的区域:<em class="oa">tiwrsloh</em>T12】0和<em class="oa"> yfmzwkru </em> &lt; -2。</li><li id="47ce" class="oc od iq lq b lr ol lu om lx on mb oo mf op mj oh oi oj ok bi translated">我们已经尝试了许多不同的型号和配置，性能稳定在0.75。根据这一点以及模型预测和误差偏差分布的统计性质，我们可以得出结论，问题在于缺乏从训练数据预测目标的预测能力。所以不可能建立一个更好的模型。</li><li id="7b14" class="oc od iq lq b lr ol lu om lx on mb oo mf op mj oh oi oj ok bi translated">数据预测性不足的原因可能是因为噪音，但也因为除了我们的数据集中的社会经济特征之外，缺乏一些预测贫困的预测特征。</li></ul><h1 id="7adf" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">我们学到了什么？</h1><p id="7773" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们已经用一个真实的例子解决了模型没有得到足够好的结果的问题。这种情况下的目标是试图理解模型未能理解的地方，如果问题是在数据或模型中。</p><p id="a288" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">回答这个问题的过程是:</p><p id="7f5f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">1 —尝试不同的系列函数模型和超参数，并确认所有的性能都处于平稳状态。</p><p id="8ada" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">2-对于可解释的最好的一个，计算目标的模型输出分布和偏差分布。如果数据有问题，输出必须一致，偏差必须遵循高斯分布</p><p id="a046" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">3-尽管数据是问题所在，但尝试从模型输出和偏差分布中找出模型表现良好的区域。尝试分割和描述这个区域，例如，用这个子集重新训练模型，并提取它的可解释性。</p><p id="daa0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">4 —此外，在描述某些子集的特征时，我们可以尝试从业务知识的角度考虑问题是来自数据的统计/测量噪声，还是缺少预测因变量所需的某些特征值。</p></div></div>    
</body>
</html>