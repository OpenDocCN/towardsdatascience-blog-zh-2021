<html>
<head>
<title>Getting started with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-tensorflow-e33999defdbf?source=collection_archive---------28-----------------------#2021-06-28">https://towardsdatascience.com/getting-started-with-tensorflow-e33999defdbf?source=collection_archive---------28-----------------------#2021-06-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2eeb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过示例学习基础知识</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/57b35eac2acd1fd408c5d1e067853eb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NVlrGXh7gCRxQ5Vf6bDUUg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由来自Unsplash的<a class="ae ky" href="https://unsplash.com/@laughayette" rel="noopener ugc nofollow" target="_blank"> Marten Newhall </a>拍摄。</p></figure><h1 id="ce96" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="12a8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">好，我们来讨论一下房间里的大象。应该学Tensorflow还是PyTorch？</p><p id="68ce" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">老实说，没有正确的答案。这两个平台背后都有一个大型开源社区，易于使用，并且能够构建复杂的深度学习解决方案。如果你真的想成为一名出色的深度学习研究者，你必须了解这两方面。</p><p id="9e42" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在来讨论Tensorflow是如何产生的，以及如何利用它进行深度学习。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="f44e" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">Tensorflow是什么时候开发的？</h1><p id="0875" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">人工神经网络(ANN)的研究已经存在了很长时间。沃伦·麦卡洛克和沃尔特·皮茨在1943年发表了其早期作品之一，其中作者开发了人工神经网络的第一个计算模型。</p><p id="9f9c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在21世纪初之前，只有粗略的框架可用，需要有经验的ML从业者来建立简单/适度的人工神经网络方法。</p><p id="8692" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">随着2012年对人工神经网络的兴趣激增，深度学习(DL)框架的前景开始发生变化。Caffe、Chainer和Theano可以说是早期的顶级竞争者，它们使普通数据科学家更容易使用DL。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/eee90c280180bca293cccd86c0c77141.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PIB68v84YyIOCQsyWWk8aw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">谷歌在“机器学习和人工智能”类别下搜索2012年1月至2021年7月之间的顶级低/高级深度学习框架。图片来自作者。</p></figure><p id="996c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">2015年2月，谷歌开源了Tensorflow 1.0，这一框架迅速获得了关注。Tensorflow swift的采用与几个因素有关，如家喻户晓的名字、快速和频繁的更新、简单的语法以及对可用性和可扩展性的关注(如移动和嵌入式devices)⁴⁵.</p><p id="a847" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">随着PyTorch的日益普及和Tensorflow⁶市场份额的减少，谷歌团队在2019年发布了对库“Tensorflow 2.0"⁷.”的重大更新这次更新引入了急切执行(PyTorch的关键卖点之一)，以及对Keras的本机支持(通过静态计算图极大地简化了开发)。</p><p id="a908" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">到2021年6月，超过99%的谷歌搜索主要深度学习框架包含Tensorflow、Keras或PyTorch。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="6bb6" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">通过例子学习</h1><p id="a8d7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最简单的学习方法(至少对我来说)是通过例子。这种方法允许您测试一个工作过程，修改它，或者获取对您的项目有用的组件。</p><p id="9b72" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这篇博客中，我将通过两个ML示例来指导您，说明构建简单张量流模型所需的关键组件。</p><p id="71c3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了提高可复制性，我建议使用Google Colab作为这里描述的例子。为此，只需打开<a class="ae ky" href="https://research.google.com/colaboratory/" rel="noopener ugc nofollow" target="_blank">这个</a>链接，按照步骤创建一个新的python 3笔记本。</p><h2 id="f2f8" class="nf la it bd lb ng nh dn lf ni nj dp lj ma nk nl ll me nm nn ln mi no np lp nq bi translated">线性回归</h2><p id="e33c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在此示例中，我们将构建一个简单的1层神经网络来解决线性回归问题。这个例子将解释如何初始化你的权重(又名回归系数)，以及如何通过反向传播来更新它们。</p><p id="1d88" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们首先需要的是一个数据集。让我们模拟一个噪声线性模型如下</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/ec737bbfb915fbbbfc3295a5d4ab673c.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/0*6lJaa7emJ96TkbEJ"/></div></figure><p id="09bd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">其中Y是我们的目标，X是我们的输入，w是我们要确定的系数，N是高斯分布噪声变量。为此，在笔记本的第一个单元格中粘贴并运行以下代码片段。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="4bc1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这将显示X和Y之间关系的散点图，清楚地表明在一些高斯噪声下的线性相关性。在这里，我们期望一个合理的模型来估计2作为理想的回归系数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/efd6dff9bac11d305248dad4bb3bab4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*O-gJbzzuaf9Qvu-cji6Bag.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代表高斯噪声下X和Y之间线性相关性的模拟数据。</p></figure><p id="c33d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们用一个常数(0.1)开始我们的回归系数(这里称为权重)。为此，我们首先需要导入Tensorflow库，然后将权重初始化为Tensorflow变量。</p><p id="517c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了这个例子的目的，假设一个变量具有与张量相似的性质。张量是由tf表示的多维元素阵列。张量对象。张量只有一种数据类型(在下面的例子中为“float32”)和一种形状。该对象允许其他Tensorflow函数执行某些操作，例如计算与该变量相关的梯度并相应地更新其值。复制以下代码片段来初始化我们的权重变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="44fc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">运行这个代码片段将输出变量名、形状、类型和值。注意，这个变量有一个“()”形状，表示它是一个0维向量。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="8e26" class="nf la it nw b gy oa ob l oc od">&lt;tf.Variable ‘Variable:0’ shape=() dtype=float32, numpy=0.1&gt;</span></pre><p id="cb04" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">给定初始化的权重张量和输入X，为了获得预测的Y (Yhat ),我们可以简单地调用“Yhat = x * w_tensor.numpy()”。的’。“numpy()”用于将权重向量转换为numpy数组。复制并运行下面的代码片段，看看初始化后的重量如何符合数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="5c05" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正如你所观察到的,‘w _ tensor’的当前值与理想值相差甚远。回归线完全符合数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7a9deb808a307fef0b438c5971bb48fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*RkAn47t2W21XtujkwjmqGA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练前模型拟合的表示。</p></figure><p id="20b7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了找到‘w _ tensor’的最佳值，我们需要定义一个损失度量和一个优化器。这里，我们将使用均方误差(MSE)作为我们的损失度量，随机梯度下降(SGD)作为我们的优化器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="930e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在有了优化我们的“w _张量”的所有部分。优化循环只需要定义“前进步骤”,并从我们的优化器调用最小化函数。</p><p id="c609" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">“前进步骤”告诉模型如何将输入与权重张量相结合，以及如何计算我们的目标与预测目标之间的误差(下面代码片段中的第5行)。在一个更复杂的例子中，这将是一组定义从输入X到目标y的计算图的指令。</p><p id="bda5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了最小化定义的损失，我们只需要告诉我们的优化器最小化关于‘w _ tensor’的‘损失’(下面代码片段中的第17行)。</p><p id="4762" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将下面的代码片段添加到您的示例中，为模型定型100次迭代。这将动态绘制新的权重值和当前拟合。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="9459" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在训练结束时，你的体重应该接近2(理想值)。要使用此模型进行推理(即，在给定X值的情况下预测Y变量)，只需执行` Yhat = x * w_tensor.numpy()'</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7cbdc62cce5bec1bc7d2e4d6d0b6d1b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*MuZBfiKyjlMvmMgfot1DGQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练后模型拟合的表示。</p></figure><h2 id="0d1c" class="nf la it bd lb ng nh dn lf ni nj dp lj ma nk nl ll me nm nn ln mi no np lp nq bi translated">分类问题</h2><p id="bb91" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本例中，我们将引入Keras顺序模型定义来创建更复杂的神经网络。我们将把这个模型应用于一个线性可分的分类问题。</p><p id="531d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">像以前一样，让我们从构建数据集开始。在下面的代码片段中，我们为第一个聚类创建了两个以(0.2，0.2)为中心的点聚类，为第二个聚类创建了两个以(0.8，0.8)为中心的点聚类。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="6e31" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以很快观察到，用一条与两个聚类距离相等的线将两个数据集线性分离的模型是理想的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7b99b2a74482e695201fb5e6d2b81325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*N2HY_cey8QEKm6i5MGPVIA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模拟数据表示两个数据聚类，第一个聚类以(0.2，0.2)为中心，第二个聚类以(0.8，0.8)为中心。</p></figure><p id="fb36" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">像以前一样，让我们定义我们的损失度量和优化器。在这个例子中，我们应该使用分类损失度量，例如交叉熵。因为我们的目标被编码为整数，所以我们必须使用“SparseCategoricalCrossEntropy”方法。</p><p id="5a3a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于优化器，我们可以像以前一样使用SGD。然而，普通SGD的收敛速度慢得令人难以置信。相反，我们将使用最近的自适应梯度下降方法(RMSProp)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="527b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下一步是定义自定义神经网络模型。让我们创建一个5层神经网络如下:</p><ol class=""><li id="2640" class="oe of it lt b lu mn lx mo ma og me oh mi oi mm oj ok ol om bi translated">有10个节点的线性层。这将有一个2 x 10(输入形状x图层大小)的形状。</li><li id="7bc1" class="oe of it lt b lu on lx oo ma op me oq mi or mm oj ok ol om bi translated">批量标准化层。这一层将对每一批的第一层的输出进行归一化，避免爆炸/消失梯度。</li><li id="f5c6" class="oe of it lt b lu on lx oo ma op me oq mi or mm oj ok ol om bi translated">Relu激活层。这一层将为我们的网络提供非线性能力。请注意，我们仅以此为例。对于这个问题，relu层是不必要的，因为它是线性可分离的。</li><li id="af44" class="oe of it lt b lu on lx oo ma op me oq mi or mm oj ok ol om bi translated">具有两个节点的线性层。这将有一个10 x 2(层大小x输出形状)的形状。</li><li id="ba5d" class="oe of it lt b lu on lx oo ma op me oq mi or mm oj ok ol om bi translated">Softmax层。该层会将第4层的输出转换为softmax。</li></ol><p id="36e9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在网络用于训练之前，我们需要调用“编译”方法。这将允许Tensorflow将模型链接到优化器和上面定义的损失度量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="f845" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">和以前一样，我们先来检查一下我们的网络在训练前表现如何。要使用该模型进行推理，我们只需键入“yhat = model.predict(x)”。现在，复制下面的片段来可视化网络输出。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="4f74" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">你可以确认网络一点也不好。显然需要一些训练来正确区分这两个类别。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/8bfbe3b4534e85b90193956ebec1e10b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*Qlms5CQzqc9J-kqEgPJkjw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练前模型拟合的表示。</p></figure><p id="17c4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要训练一个Keras模型，我们只需输入“model.fit(x，y，epochs=50)”。将下面的片段添加到您的笔记本中，以训练模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="d071" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在训练循环结束时，你的网络应该能够很好地分离这两个类。要使用此模型进行推理(即，在给定X值的情况下预测Y变量)，只需执行“yhat = model.predict(x)”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/cb4ece974c1f230445ec9ab1bab5d28c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*kYoMGKvDqscxQc5hKzc6PA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练后模型拟合的表示。</p></figure><h2 id="403a" class="nf la it bd lb ng nh dn lf ni nj dp lj ma nk nl ll me nm nn ln mi no np lp nq bi translated">完整脚本</h2><p id="1ac8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如需完整的脚本，请点击以下链接进入我的Github页面:</p><div class="ot ou gp gr ov ow"><a href="https://github.com/andreRibeiro1989/medium/blob/main/tensorflow_getting_started.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">安德里贝罗1989/中号</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">tensor flow _ getting _ started . ipynb</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">github.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk ks ow"/></div></div></a></div><p id="1fa2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">或者通过以下链接直接访问Google Colab笔记本:</p><div class="ot ou gp gr ov ow"><a href="https://colab.research.google.com/github/andreRibeiro1989/medium/blob/main/tensorflow_getting_started.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">谷歌联合实验室</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">tensor flow _ getting _ started . ipynb</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">colab.research.google.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk ks ow"/></div></div></a></div></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="581b" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">结论</h1><p id="757f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Tensorflow是目前开发定制深度学习解决方案的最佳深度学习框架之一。在这篇博客中，我介绍了构建两个简单神经网络模型的关键概念。</p><p id="c147" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">警告！！！</strong>你的学习才刚刚开始。要变得更好，你需要练习。<a class="ae ky" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank">官方Tensorflow </a>网站提供了从初学者到专家级别的示例，以及Tensorflow软件包的官方文档。祝你好运！</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="6cf4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[1]沃伦·麦卡洛克和沃尔特·皮茨”<em class="pm">神经活动中固有的逻辑思想演算</em>(1943)，《数学生物物理学通报》。5: 115–133.<br/><a class="ae ky" href="https://link.springer.com/article/10.1007%2FBF02478259" rel="noopener ugc nofollow" target="_blank">https://link.springer.com/article/10.1007%2FBF02478259</a></p><p id="1853" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[2]袁林。<em class="pm">深度学习框架简史</em><br/><a class="ae ky" rel="noopener" target="_blank" href="/a-brief-history-of-deep-learning-frameworks-8debf3ba6607">https://towardsdatascience . com/A-Brief-History-of-Deep-Learning-Frameworks-8 deb F3 ba 6607</a></p><p id="41d9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[3] Alex Krizhevsky等著《<em class="pm">深度卷积神经网络的ImageNet分类</em>》(2012)，neur IPS<br/><a class="ae ky" href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/paper/2012/file/c 399862d 3 b 9 d6b 76 c 8436 e 924 a 68 c 45 b-paper . pdf</a></p><p id="4120" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[4]苏尼思·谢蒂。"<em class="pm">为什么TensorFlow总是高居机器学习和人工智能工具调查榜首"</em><br/><a class="ae ky" href="https://hub.packtpub.com/tensorflow-always-tops-machine-learning-artificial-intelligence-tool-surveys/" rel="noopener ugc nofollow" target="_blank">https://hub . packtpub . com/tensor flow-always-tops-machine-learning-artificial-intelligence-tool-surveys/</a></p><p id="32a9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[5]叶达鑫·瓦朗冈卡。<em class="pm">十大深度学习框架</em><br/><a class="ae ky" href="https://hub.packtpub.com/top-10-deep-learning-frameworks/" rel="noopener ugc nofollow" target="_blank">https://hub.packtpub.com/top-10-deep-learning-frameworks/</a></p><p id="ef5d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[6]贺拉斯何。"<em class="pm">2019年机器学习框架状况"</em><br/><a class="ae ky" href="https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/" rel="noopener ugc nofollow" target="_blank">https://The gradient . pub/State-of-ml-Frameworks-2019-py torch-domains-research-tensor flow-domains-industry/</a></p><p id="efde" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[7] TensorFlow团队。"<em class="pm"> TensorFlow 2.0现已上市！"</em><br/><a class="ae ky" href="https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html" rel="noopener ugc nofollow" target="_blank">https://blog . tensor flow . org/2019/09/tensor flow-20-is-now-available . html</a></p></div></div>    
</body>
</html>