<html>
<head>
<title>Word, Subword, and Character-Based Tokenization: Know the Difference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">词、子词和基于字符的标记化:了解区别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/word-subword-and-character-based-tokenization-know-the-difference-ea0976b64e17?source=collection_archive---------8-----------------------#2021-07-01">https://towardsdatascience.com/word-subword-and-character-based-tokenization-know-the-difference-ea0976b64e17?source=collection_archive---------8-----------------------#2021-07-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e835" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="3d06" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">从事NLP项目的任何人都应该知道的区别</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/ec91760290037335b2803de4a6babb38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rsDXrromH4qnxCA1UNG2QA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片由<a class="ae le" href="https://unsplash.com/@sincerelymedia" rel="noopener ugc nofollow" target="_blank">真诚媒体</a>在<a class="ae le" href="https://unsplash.com/photos/-gG86PdIzUA" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="c070" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">自然语言处理(NLP) </strong>是人工智能(AI)的一个分支，它为机器(计算机)提供了像人类一样理解书面和口头人类语言的能力。NLP几乎无处不在，帮助人们完成日常任务。😍这是一项如此普遍的技术，以至于我们经常认为这是理所当然的。一些例子是拼写检查，自动完成，垃圾邮件检测，Alexa或谷歌助理。NLP可以被认为是理所当然的，但人们永远不能忘记，机器是与数字而不是字母/单词/句子一起工作的。因此，为了处理互联网上的大量文本数据，我们需要对文本进行处理和清理，我们通常称之为自然语言处理中的文本预处理。</p><p id="d450" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">预处理是处理文本和建立模型来解决业务问题的第一步。预处理本身是一个多阶段的过程。在本文中，我们将只讨论标记化和标记化器。那么，我们开始吧。🏄🏼</p><p id="3b95" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="mb">注:</em> </strong> <em class="mb">我们主要关注的是英语。</em></p><h1 id="dca2" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">标记化</h1><p id="9bef" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">标记化是文本预处理中最重要的步骤之一。无论是使用传统的NLP技术还是使用先进的深度学习技术，都不能跳过这一步。🙅🏻</p><p id="5de8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">记号化</strong>简单来说就是将一个短语、句子、段落、一个或多个文本文档拆分成更小单元的过程。🔪这些更小的单元中的每一个都被称为<strong class="lh ja">令牌</strong>。现在，这些标记可以是任何东西——一个单词、一个子单词，甚至是一个字符。不同的算法在执行标记化时遵循不同的过程，但是下面给出的例子将让您对这三者之间的差异有一个基本的了解。</p><p id="5435" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑下面的句子/原文。</p><p id="d51d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">“让我们学习记号化。”</strong></p><p id="8d2a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个基于单词的分词算法将把句子分解成单词。最常见的是基于空间的拆分。</p><p id="099b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">【“让”、“我们”、“学”、“标记化”。】</strong></p><p id="22be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于子词的记号化算法将把句子分成子词。</p><p id="2f14" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">【“让”、“我们”、“学”、“令牌”、“化”。】</strong></p><p id="2fee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于字符的记号化算法将把句子分解成字符。</p><p id="a31a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">【" L "、" e "、" t "、" u "、" s "、" L "、" e "、" a "、" r "、" n "、" t "、" o "、" k "、" e "、" n "、" I "、" z "、" a "、" t "、" I "、" o "、" n "、" n "】] </strong></p><p id="161c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">标记实际上是NLP的构建块，所有的NLP模型都在标记级别处理原始文本。这些标记用于形成词汇表，词汇表是语料库(NLP中的数据集)中的一组唯一标记。这个词汇表然后被转换成数字(id ),帮助我们建模。😎</p><p id="a1e7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们在这里提到了三种不同的标记化技术。这些技术的工作方式各不相同，各有优缺点。让我们深入了解这些技术的细节。🏇🏻</p><h2 id="cfde" class="mz md iq bd me na nb dn mi nc nd dp mm lo ne nf mo ls ng nh mq lw ni nj ms iw bi translated">基于单词的标记化</h2><p id="5d1b" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">这是最常用的标记化技术。它根据分隔符将一段文本分割成单词。最常用的分隔符是空格。您也可以使用多个分隔符来拆分文本，如空格和标点符号。根据您使用的分隔符，您将获得不同的单词级标记。</p><p id="73d3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用定制的正则表达式或Python的split()方法可以很容易地完成基于单词的标记化。除此之外，Python中还有大量的库——NLTK、spaCy、Keras、Gensim，它们可以帮助您轻松地执行标记化。</p><p id="896f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">示例:</p><p id="07c6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">“我不喜欢咖啡是不是很奇怪？”</strong></p><p id="f3f6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过使用空格作为分隔符执行基于单词的标记化，我们得到:</p><p id="f163" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">【“是”、“它”、“怪异”、“我”、“不要”、“喜欢”、“咖啡？”] </strong></p><p id="d11d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果我们看看“不要”和“咖啡？”，我们会注意到这些单词都附有标点符号。如果我们的语料库中有另一个类似这样的原始文本(句子)会怎么样— <strong class="lh ja">“我爱咖啡。”这一次将会有一个令牌“咖啡”</strong>哪个可以引导模型学习单词coffee(“coffee？”还有“咖啡”)并将使单词(记号)的表示不是最佳的。🙆🏻</p><p id="edbb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在执行标记化时，我们应该考虑标点符号的原因是，我们不希望我们的模型使用每种可能的标点符号(当然是可以跟在单词后面的标点符号)来学习同一单词的不同表示。如果我们允许我们的模型这样做，我们将会被模型将要学习的表示的数量(一种语言中每个单词×标点符号的数量)所震惊。😳所以，让我们考虑点状。</p><p id="4f48" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">【“是”、“它”、“wierd”、“我”、“唐”、“'”、“t”、“喜欢”、“咖啡”、“呢？”] </strong></p><p id="7f34" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这比我们先前的要好。然而，如果我们注意到，标记化为单词“don”做了三个标记——“don”，“t”。更好的“不做”标记应该是“做”和“不做”，这样，如果模型在未来看到单词“不做”，它会将其标记为“做”和“不做”，因为模型在过去已经学习了“不做”，它会在这里应用它的知识。这个问题听起来很复杂，但是可以通过一些规则来解决。🤓</p><p id="a8ed" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您一定已经注意到，最新的NLP模型有自己的标记化器，因为每个模型使用不同的规则来执行标记化以及使用空格进行标记化。因此，不同NLP模型的标记器可以为同一文本创建不同的标记。空格和标点符号，以及基于规则的标记化都是基于单词的标记化的例子。</p><p id="96ac" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后每个单词用一个ID表示，每个ID包含大量信息，因为句子中的一个单词通常包含大量上下文和语义信息。😲</p><p id="3e51" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种技术听起来令人印象深刻，但是这种类型的标记化会产生大量的语料库，进而产生大量的词汇。😏最先进的型号<a class="ae le" href="https://arxiv.org/pdf/1901.02860.pdf" rel="noopener ugc nofollow" target="_blank"> Transformer XL </a>，使用空格和标点符号化，词汇量为267，735。这是巨大的！这种巨大的词汇规模导致用于输入和输出层的巨大嵌入矩阵，导致模型更重并且需要更多的计算资源。</p><p id="e2c2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种标记化还为英语中几乎相似的单词(一个是单数，另一个是复数)如“boy”和“boys”赋予了不同的id。我们实际上希望我们的模型知道像这样的单词是相似的。</p><p id="7443" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了解决这个巨大的词汇问题，我们可以限制可以添加到词汇中的单词数量。例如，我们可以在词汇表中只保存最常见的(基于单词在语料库中出现的频率)5000个单词。然后，该模型将为这5000个常用单词创建id，并将其余单词标记为OOV(不在词汇表中)。但是这导致了信息的丢失，因为模型不会学习任何关于OOV单词的内容。这对于模型来说可能是一个很大的妥协，因为它将为所有未知单词学习相同的OOV表示。🙄</p><p id="a378" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">另一个缺点是关于拼写错误的单词。如果语料库中的“知识”被拼错为“knowldge ”,则模型会将OOV令牌分配给后面的单词。</p><p id="149a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，为了解决所有这些问题，研究人员提出了基于字符的标记化。</p><h2 id="815c" class="mz md iq bd me na nb dn mi nc nd dp mm lo ne nf mo ls ng nh mq lw ni nj ms iw bi translated">基于字符的标记化</h2><p id="f457" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">基于字符的记号赋予器将原始文本分割成单独的字符。这种标记化背后的逻辑是，一种语言有许多不同的单词，但有固定数量的字符。这导致词汇量非常小。😍</p><p id="0643" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，在英语中，我们使用256种不同的字符(字母、数字、特殊字符)，而它的词汇表中有将近170，000个单词。因此，与基于单词的标记化相比，基于字符的标记化将使用更少的标记。</p><p id="98d3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于字符的标记化的一个主要优点是不会有或很少会有未知或OOV单词。因此，它可以使用每个字符的表示来创建未知单词(在训练期间看不到的单词)的表示。另一个优点是拼写错误的单词可以被正确拼写，而不是将它们标记为OOV令牌并丢失信息。</p><p id="c545" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种类型的标记化非常简单，可以大大减少内存和时间复杂度。那么，它是标记化的最好或最完美的算法吗？🤔答案是否定的(至少对于英语来说)！一个字符通常不像一个单词那样携带任何意义或信息。😕</p><p id="f323" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="mb">注:</em> </strong> <em class="mb">几种语言的每个字符中都承载着大量的信息。因此，基于字符的标记化在这里会很有用。</em></p><p id="0ab7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，在基于字符的标记化中，减小词汇表的大小需要权衡序列长度。每个单词被分成每个字符，因此，标记化的序列比原始文本长得多。例如，单词“知识”将有9个不同的标记。🙄</p><p id="e3a7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="mb">注:</em> </strong> <em class="mb">研究者</em><a class="ae le" href="https://github.com/karpathy/char-rnn" rel="noopener ugc nofollow" target="_blank"><em class="mb">karpathy</em></a><em class="mb">，</em> <a class="ae le" href="https://arxiv.org/pdf/1704.01444.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mb">拉德福德等人</em> </a>，<a class="ae le" href="https://arxiv.org/pdf/1610.10099.pdf" rel="noopener ugc nofollow" target="_blank"> Kalchbrenner等人</a>，<em class="mb"/><a class="ae le" href="https://www.aclweb.org/anthology/Q17-1026.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mb">Lee等人</em> </a> <em class="mb">已经演示了基于字符的标记化的使用，并得出了一些令人印象深刻的结果阅读这些论文了解更多！</em></p><p id="6224" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于字符的标记化尽管存在一些问题，但已经解决了基于单词的标记化所面临的许多问题。让我们看看我们是否也能解决基于字符的符号化所面临的问题。</p><h2 id="71d9" class="mz md iq bd me na nb dn mi nc nd dp mm lo ne nf mo ls ng nh mq lw ni nj ms iw bi translated">基于子词的标记化</h2><p id="71b7" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">另一种流行的标记化是基于子词的标记化，这是一种介于基于词和基于字符的标记化之间的解决方案。主要思想是解决基于单词的标记化(非常大的词汇量，大量的OOV标记，以及非常相似的单词的不同含义)和基于字符的标记化(非常长的序列和不太有意义的单个标记)所面临的问题。</p><p id="fb86" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于子词的标记化算法使用以下原则。</p><ol class=""><li id="c3ab" class="nk nl iq lh b li lj ll lm lo nm ls nn lw no ma np nq nr ns bi translated">不要将常用词拆分成更小的子词。</li><li id="a6ab" class="nk nl iq lh b li nt ll nu lo nv ls nw lw nx ma np nq nr ns bi translated">将生僻字拆分成更小的有意义的子字。</li></ol><p id="31c1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，不应该将“男孩”拆分，而应该将“男孩”拆分为“男孩”和“s”。这将有助于模型了解单词“boys”是由意思略有不同但词根相同的单词“boy”构成的。</p><p id="efb7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本文的开始，我们将单词“tokenization”分为“token”和“ization”，其中“token”是词根，“ization”是第二个子单词，作为词根的附加信息。子词分割将帮助模型了解与“token”具有相同词根的词，如“tokens”和“tokenizing”在含义上是相似的。它还将帮助模型了解“标记化”和“现代化”由不同的词根组成，但具有相同的后缀“化”，并在相同的句法情况下使用。另一个例子可以是“惊讶”这个词。基于子词的标记化将把它分成“惊奇”和“谎言”，因为这些独立的子词会更频繁地出现。</p><p id="e805" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于子词的记号化算法通常使用特殊符号来指示哪个词是记号的开始，哪个词是记号开始的结束。例如，“标记化”可以分为“token”和“# #化”，这表明“token”是单词的开始，而“# #化”是单词的结束。</p><p id="2b6c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">不同的NLP模型使用不同的特殊符号来表示子词。“##”由BERT模型用于第二个子字。请注意，特殊符号也可以添加到单词的开头。</p><p id="c714" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在英语语言中获得最先进结果的大多数模型使用某种子词标记化算法。几个常见的基于子词的分词算法是<a class="ae le" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank"> BERT </a>和<a class="ae le" href="https://arxiv.org/pdf/1910.01108.pdf" rel="noopener ugc nofollow" target="_blank"> DistilBERT </a>使用的<a class="ae le" href="https://arxiv.org/pdf/1609.08144v2.pdf" rel="noopener ugc nofollow" target="_blank">词块</a>，由<a class="ae le" href="https://arxiv.org/pdf/1906.08237.pdf" rel="noopener ugc nofollow" target="_blank"> XLNet </a>和<a class="ae le" href="https://arxiv.org/pdf/1909.11942.pdf" rel="noopener ugc nofollow" target="_blank"> ALBERT </a>使用的<a class="ae le" href="https://arxiv.org/pdf/1804.10959.pdf" rel="noopener ugc nofollow" target="_blank"> Unigram </a>，以及由<a class="ae le" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>和<a class="ae le" href="https://arxiv.org/pdf/1907.11692.pdf" rel="noopener ugc nofollow" target="_blank">罗伯塔</a>使用的<a class="ae le" href="https://arxiv.org/pdf/1508.07909.pdf" rel="noopener ugc nofollow" target="_blank"> Bye-Pair编码</a>。😊</p><p id="1488" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于子词的标记化允许模型具有适当的词汇量，并且还能够学习有意义的上下文无关的表示。模型甚至有可能处理一个它以前从未见过的单词，因为分解可以导致已知的子单词。😇 🙌🏻</p><p id="db3f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，我们看到了标记化方法如何不断发展，以适应NLP领域不断增长的需求，并提出更好的问题解决方案。</p><p id="c824" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">参考文献:</strong></p><ol class=""><li id="47d4" class="nk nl iq lh b li lj ll lm lo nm ls nn lw no ma np nq nr ns bi translated">https://huggingface.co/docs/tokenizers/python/latest/<a class="ae le" href="https://huggingface.co/docs/tokenizers/python/latest/" rel="noopener ugc nofollow" target="_blank"/></li><li id="0118" class="nk nl iq lh b li nt ll nu lo nv ls nw lw nx ma np nq nr ns bi translated">文章还提供了相关研究论文的链接。</li></ol></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><p id="25ee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">感谢大家阅读这篇文章。请分享您宝贵的反馈或建议。快乐阅读！📗 🖌</p></div></div>    
</body>
</html>