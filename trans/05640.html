<html>
<head>
<title>A Primer On Gradient Descent</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梯度下降入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-primer-on-gradient-descent-410f2d1a0eaa?source=collection_archive---------32-----------------------#2021-05-19">https://towardsdatascience.com/a-primer-on-gradient-descent-410f2d1a0eaa?source=collection_archive---------32-----------------------#2021-05-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="277c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">直观地探索梯度下降，将其可视化，并使用Python中精彩的SymPy库实现一个示例</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5459430c5ba53be27844acea49937727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-7S2AeAY4RJgDJUP"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿曼德·库利在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="9a18" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">为什么我们需要知道什么是梯度下降？</h1><p id="56ab" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">让我们首先定义什么是优化问题。在优化问题中，我们首先列出一个成本，它是可变参数的函数。这些参数的取值范围很大，最终这些值决定了成本。我们在处理这些问题时的目标是找到<em class="mk">一组</em> <em class="mk">值，它们将最小化成本函数</em>。梯度下降有助于我们系统地<strong class="lq ir">这样做</strong>，而不是通过随机选择参数值来随意尝试这样做。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h1 id="b9aa" class="kw kx iq bd ky kz ms lb lc ld mt lf lg jw mu jx li jz mv ka lk kc mw kd lm ln bi translated">直觉</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/6ac3e290e4b7e2feeebe97038114d02d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E6enUU3Va47LUoAe"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae kv" href="https://unsplash.com/@cikstefan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">tefan tefaník</a>拍摄的照片</p></figure><p id="a18e" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">假设我们在山上徒步旅行，正沿着一个斜坡往下走。现在我们被告知下降时必须闭上眼睛。我们会怎么做？很简单，闭上我们的眼睛，用我们的脚去感觉我们站的地方周围有什么，在我们感觉到一个轻微向下的斜坡的地方走一步。这正是我们在梯度下降中要做的。我们向下迈出的这一步被称为<strong class="lq ir">更新步骤。现在，我们当中一些感觉更有冒险精神的人会迈出更大的一步，甚至可能是向下迈出一大步！我们迈出的一步的大小被称为<strong class="lq ir">学习率</strong>，它决定了我们到达底部的速度。</strong></p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h1 id="3772" class="kw kx iq bd ky kz ms lb lc ld mt lf lg jw mu jx li jz mv ka lk kc mw kd lm ln bi translated">梯度——数字感知的方式</h1><p id="c5ea" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们谈到了人类是如何轻松定位迈出一步的，但是数字是如何做到这一点的呢？向下的方向是多少？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/e5ae6a4a00047cbe7fca0f320a11925e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*th5mhsdHAAe2XXTxqIhi2g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:datahacker.rs</p></figure><p id="7c62" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">上图中，我们有一个成本J，它只是一个参数w的函数。该函数可以用一个w表示的等式来表示。为了更新w以减少J，我们首先从w的随机值开始，然后使用该等式来更新该值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/e61e4311f1fba1051bdb589b55eaaca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*NIL8PQ2PmYW8VC0P.jpg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:塞缪尔·特伦德勒</p></figure><p id="8145" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">这里，α是我们谈到的学习速率。那么到底发生了什么？首先让我们再来看一下图表。在全局最优值(最小成本)右边的任何地方，函数的<a class="ae kv" href="https://en.wikipedia.org/wiki/Partial_derivative#:~:text=In%20mathematics%2C%20a%20partial%20derivative,vector%20calculus%20and%20differential%20geometry." rel="noopener ugc nofollow" target="_blank">偏导数</a>都是正的。现在，通过查看图表我们知道，如果我们降低<strong class="lq ir"> w </strong>的值，我们就会降低成本。因此，使用上面的等式，我们从当前值<strong class="lq ir"> w中减去一个正数，这反过来使成本最小化。阿尔法决定了我们减去多少</strong>。类似地，对于全局最优值左侧的任何w，该w处的梯度为负，因此使用该等式，我们得到比之前更高的值<strong class="lq ir"> w，这再次最小化了成本。这总结了一个步骤。</strong></p><p id="9799" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated"><em class="mk">我们按照这个简单的步骤进行固定次数的迭代，或者直到我们看到我们的成本已经收敛并且不会再进一步降低。</em></p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h1 id="61c6" class="kw kx iq bd ky kz ms lb lc ld mt lf lg jw mu jx li jz mv ka lk kc mw kd lm ln bi translated">为什么要用SymPy？</h1><p id="7ef2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">SymPy是一个非常方便的库，它有很多我们可以使用的数学函数。我们将使用它来定义成本函数并计算给定方程的梯度。我们可以很容易地通过SymPy计算偏导数。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h1 id="7522" class="kw kx iq bd ky kz ms lb lc ld mt lf lg jw mu jx li jz mv ka lk kc mw kd lm ln bi translated">让我们把手弄脏吧</h1><p id="a078" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">让我们尝试并优化成本函数cost = x + y，看看梯度下降是否给出x和y的最佳值(x=0且y=0时成本=0)。</p><ol class=""><li id="d00d" class="nf ng iq lq b lr my lu mz lx nh mb ni mf nj mj nk nl nm nn bi translated">导入必要的库(我在Google Colab上运行)，如果你想在本地运行，请安装这些库。</li></ol><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="527e" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">2.创造符号，让SymPy发挥它的魅力&amp;定义一个成本函数</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="7448" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">3.可视化成本函数，我们可以看到在x=0和y=0时最小值为0</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">成本函数(向下滚动)</p></figure><p id="94a6" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">4.使用带有接头的sympy.evalf计算成本</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="b1b5" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">5.计算给定点x，y处参数的偏导数</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="a21d" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">6.肉！这是梯度下降函数，它迭代更新梯度并返回最佳参数值和最小化成本。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="f660" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">7.随着算法的进展，可视化我们的成本函数的变化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/5440635473d8917c4005e5198afdb320.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LNxsF6RvwZMHBMw2Siuk_w.png"/></div></div></figure></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h1 id="1b51" class="kw kx iq bd ky kz ms lb lc ld mt lf lg jw mu jx li jz mv ka lk kc mw kd lm ln bi translated"><strong class="ak">学习率大的问题</strong></h1><p id="8398" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">好吧，那我们为什么要等这么多次迭代呢？为什么不迈出巨大的一步，降低成本。问题是梯度和学习率的乘积变得非常大，我们的成本直线上升。我们所有的努力都被冲走了，这可能是我们的成本不断飙升，永远不会收敛。</p><p id="c9ce" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">这些图表说明了为什么学习速度如此重要</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/351d27b94fe83ddd57f9baf83454c4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r-fvd-RH5bC6zkdh.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:走向数据科学</p></figure></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><p id="be48" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">让我们看看实际情况，如果我们将学习率提高到1.1，就会发生这种情况。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/d354999b4db515cd5f475f0056be8c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oWFz5SIUMO2VUFhU1K4g2A.png"/></div></div></figure><p id="73bd" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated"><strong class="lq ir"> <em class="mk">我在代码里加了一个条件，如果代价开始射击，不会收敛，会自动降低学习率。</em>T3】</strong></p><h1 id="5cce" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">非凸成本函数的问题</h1><p id="ae9c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">由于这是一个入门，我选择了一个非常简单的成本函数，但实际上我们的成本函数可能是非凸的，并且有多个局部最小值。在这种情况下，我们可能会陷入局部最小值，永远不会达到全局最小值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/aa0869ad5d659155f0c1d1d01473cdb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/0*9OtsGkrlKqPgw0Zy.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">资料来源:vitalflux.com</p></figure><p id="7876" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">如图所示，我们得到了一个错误的印象，即算法已经最小化了成本和收敛，而实际上我们陷入了一个远离全局最小值的局部最小值。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h1 id="bcfd" class="kw kx iq bd ky kz ms lb lc ld mt lf lg jw mu jx li jz mv ka lk kc mw kd lm ln bi translated">处理这些问题</h1><p id="3683" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">因为这是给初学者的，我用了简单的梯度下降。我将写一篇关于更复杂的变体的文章，这些变体收敛得更快，并且避开了前面提到的问题。这些包括</p><ol class=""><li id="1b03" class="nf ng iq lq b lr my lu mz lx nh mb ni mf nj mj nk nl nm nn bi translated">使用随机梯度下降/批量梯度下降</li><li id="e502" class="nf ng iq lq b lr nu lu nv lx nw mb nx mf ny mj nk nl nm nn bi translated">使用RMSProp或Adam。</li><li id="06c5" class="nf ng iq lq b lr nu lu nv lx nw mb nx mf ny mj nk nl nm nn bi translated">使用指数递减的学习速率。</li></ol><p id="fd97" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">如果你想让我写这些话题，请在评论中提及。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h1 id="d468" class="kw kx iq bd ky kz ms lb lc ld mt lf lg jw mu jx li jz mv ka lk kc mw kd lm ln bi translated">结尾部分</h1><p id="a0a1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们了解了如何使用梯度下降优化成本函数，以及SymPy如何轻松地为我们完成所有的计算和繁重的工作。这是对惊人算法的温和介绍，该算法被广泛用于优化机器学习和深度学习模型。</p><p id="d4e7" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">我很想听一些关于这方面的反馈，如果你想要一篇更高级的文章来解释上面提到的调整，也请告诉我。</p><p id="2874" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">查看我的<a class="ae kv" href="https://github.com/rajlm10" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> github </strong> </a>的一些其他项目和完整代码。可以联系我<a class="ae kv" href="https://rajsangani.me/" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> <em class="mk">这里</em> </strong> </a> <strong class="lq ir"> <em class="mk">。</em> </strong>感谢您的宝贵时间！</p></div></div>    
</body>
</html>