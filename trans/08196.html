<html>
<head>
<title>Automating Hyperparameter Tuning with Optunity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Optunity自动调整超参数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automating-hyperparameter-tuning-with-optunity-e5576807f41e?source=collection_archive---------40-----------------------#2021-07-27">https://towardsdatascience.com/automating-hyperparameter-tuning-with-optunity-e5576807f41e?source=collection_archive---------40-----------------------#2021-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bc68" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用Optunity进行ML模型的超参数优化</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4f856238c3e697f9b874e011527c3fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pvul_zcb_CVujfnu"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">沙哈达特·拉赫曼在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="ba5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">超参数调整对于任何模型都是一项重要的任务，无论是机器学习还是深度学习，因为它不仅有助于优化模型，而且有助于获得更高的精度和更好的性能。</p><p id="584f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有不同的<a class="lv lw ep" href="https://medium.com/u/845dbbffa85e?source=post_page-----e5576807f41e--------------------------------" rel="noopener" target="_blank"> Python </a>库有助于超参数优化，但是大多数都很耗时或者效率不高。Optunity是一个开源Python库，有助于自动化超参数调优过程。</p><p id="5981" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将探索Optunity提供的一些功能。</p><p id="cac3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们开始吧…</p><h1 id="dc87" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">安装所需的库</h1><p id="5230" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">我们将从使用pip安装Optunity库开始。下面给出的命令可以做到这一点。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="b7dc" class="mz ly it mv b gy na nb l nc nd">!pip install optunity</span></pre><h1 id="2833" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">导入所需的库</h1><p id="7d35" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在这一步中，我们将导入加载数据集、创建模型和查找最佳超参数所需的库。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="c1a7" class="mz ly it mv b gy na nb l nc nd">import optunity<br/>import optunity.metrics<br/>import numpy as np<br/># importing machine learning models<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.datasets import load_digits</span></pre><h1 id="81a7" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">正在加载数据集</h1><p id="3dbf" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">对于本文，我们将使用Sklearn中预定义的Digits数据集。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="65b0" class="mz ly it mv b gy na nb l nc nd">digits = load_digits()<br/>n = digits.data.shape[0]</span><span id="78bc" class="mz ly it mv b gy ne nb l nc nd">positive_digit = 3<br/>negative_digit = 9</span><span id="daf7" class="mz ly it mv b gy ne nb l nc nd">positive_idx = [i for i in range(n) if digits.target[i] == positive_digit]<br/>negative_idx = [i for i in range(n) if digits.target[i] == negative_digit]</span></pre><h1 id="0c9f" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">定义模型</h1><p id="4c02" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在这一步中，我们将定义一个函数，它将包含我们将在本文中使用的所有模型。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="ceb4" class="mz ly it mv b gy na nb l nc nd">def train_svm(data, labels, kernel, C, gamma, degree, coef0):<br/>    """A generic SVM training function, with arguments based on the chosen kernel."""<br/>    if kernel == 'linear':<br/>        model = SVC(kernel=kernel, C=C)<br/>    elif kernel == 'poly':<br/>        model = SVC(kernel=kernel, C=C, degree=degree, coef0=coef0)<br/>    elif kernel == 'rbf':<br/>        model = SVC(kernel=kernel, C=C, gamma=gamma)<br/>    else: <br/>        raise ArgumentError("Unknown kernel function: %s" % kernel)<br/>    model.fit(data, labels)<br/>    return model</span></pre><p id="8b21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义模型后，我们将相应地定义超参数及其值。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a168" class="mz ly it mv b gy na nb l nc nd">search = {'algorithm': {'k-nn': {'n_neighbors': [1, 5]},<br/>                        'SVM': {'kernel': {'linear': {'C': [0, 2]},<br/>                                           'rbf': {'gamma': [0, 1], 'C': [0, 10]},<br/>                                           'poly': {'degree': [2, 5], 'C': [0, 50], 'coef0': [0, 1]}<br/>                                           }<br/>                                },<br/>                        'naive-bayes': None,<br/>                        'random-forest': {'n_estimators': [10, 30],<br/>                                          'max_features': [5, 20]}<br/>                        }<br/>         }</span></pre><p id="e6fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们将定义性能函数，该函数将相应地测量所有模型的性能。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="eda6" class="mz ly it mv b gy na nb l nc nd">@optunity.cross_validated(x=data, y=labels, num_folds=5)<br/>def performance(x_train, y_train, x_test, y_test,<br/>                algorithm, n_neighbors=None, n_estimators=None, max_features=None,<br/>                kernel=None, C=None, gamma=None, degree=None, coef0=None):<br/>    # fit the model<br/>    if algorithm == 'k-nn':<br/>        model = KNeighborsClassifier(n_neighbors=int(n_neighbors))<br/>        model.fit(x_train, y_train)<br/>    elif algorithm == 'SVM':<br/>        model = train_svm(x_train, y_train, kernel, C, gamma, degree, coef0)<br/>    elif algorithm == 'naive-bayes':<br/>        model = GaussianNB()<br/>        model.fit(x_train, y_train)<br/>    elif algorithm == 'random-forest':<br/>        model = RandomForestClassifier(n_estimators=int(n_estimators),<br/>                                       max_features=int(max_features))<br/>        model.fit(x_train, y_train)<br/>    else:<br/>        raise ArgumentError('Unknown algorithm: %s' % algorithm)</span><span id="7b88" class="mz ly it mv b gy ne nb l nc nd"># predict the test set<br/>    if algorithm == 'SVM':<br/>        predictions = model.decision_function(x_test)<br/>    else:<br/>        predictions = model.predict_proba(x_test)[:, 1]</span><span id="31cd" class="mz ly it mv b gy ne nb l nc nd">return optunity.metrics.roc_auc(y_test, predictions, positive=True)</span></pre><h1 id="5657" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">寻找表演</h1><p id="20bd" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">现在，我们将使用性能函数来查找我们定义的不同模型的性能。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d741" class="mz ly it mv b gy na nb l nc nd">performance(algorithm='k-nn', n_neighbors=3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/8d66c5b6dce448ca36116b9ee4a7730c.png" data-original-src="https://miro.medium.com/v2/resize:fit:276/format:webp/1*NZ-sbzjgaB68J9spQXwpwg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">`资料来源:作者</p></figure><p id="3eb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将找到最佳配置。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="5658" class="mz ly it mv b gy na nb l nc nd">optimal_configuration, info, _ = optunity.maximize_structured(performance, <br/>                                                              search_space=search, <br/>                                                              num_evals=300)<br/>print(optimal_configuration)<br/>print(info.optimum)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/d1a27c07a3ec47f360726341b63ae379.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h0SGbzdxKaEAqpz7NUz2Ag.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者</p></figure><h1 id="2369" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">寻找最佳解决方案</h1><p id="39f1" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在这一步中，我们将找出具有最佳超参数的数据集的最佳解决方案。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a354" class="mz ly it mv b gy na nb l nc nd">solution = dict([(k, v) for k, v in optimal_configuration.items() if v is not None])<br/>print('Solution\n========')<br/>print("\n".join(map(lambda x: "%s \t %s" % (x[0], str(x[1])), solution.items())))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/af254f0b8f001f60256785ea88018e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*XC3WW7dZ243y-t9DXiMZgQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者</p></figure><p id="7df9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，您可以清楚地看到，性能最好的算法是SVM算法，超参数的值也是由optunity提供的。</p><p id="d718" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">继续使用不同的数据集进行尝试，并找到该数据的最佳模型和最佳超参数。如果您发现任何困难，请在回复部分告诉我。</p><p id="6a89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文是与<a class="lv lw ep" href="https://medium.com/u/40808d551f5a?source=post_page-----e5576807f41e--------------------------------" rel="noopener" target="_blank"> Piyush Ingale </a>合作的。</p><h1 id="6d03" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">在你走之前</h1><p id="058e" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated"><strong class="lb iu"> <em class="ni">感谢</em> </strong> <em class="ni">的阅读！如果你想与我取得联系，请随时通过hmix13@gmail.com联系我或我的</em> <a class="ae ky" href="http://www.linkedin.com/in/himanshusharmads" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ni"> LinkedIn个人资料</em> </strong> </a> <em class="ni">。可以查看我的</em><a class="ae ky" href="https://github.com/hmix13" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="ni">Github</em></strong><em class="ni"/></a><em class="ni">简介针对不同的数据科学项目和包教程。还有，随意探索</em> <a class="ae ky" href="https://medium.com/@hmix13" rel="noopener"> <strong class="lb iu"> <em class="ni">我的简介</em> </strong> </a> <em class="ni">，阅读我写过的与数据科学相关的不同文章。</em></p></div></div>    
</body>
</html>