<html>
<head>
<title>Implement and Train Text Classification Transformer Models — the Easy Way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实现和训练文本分类转换器模型——简单的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implement-and-train-text-classification-transformer-models-the-easy-way-432ca3492608?source=collection_archive---------40-----------------------#2021-06-14">https://towardsdatascience.com/implement-and-train-text-classification-transformer-models-the-easy-way-432ca3492608?source=collection_archive---------40-----------------------#2021-06-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cd3e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">了解如何用几行代码实现和训练文本分类转换器模型，如BERT、DistilBERT等</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/8dec81e5567244ba5390c55a7c14efab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z6BZ19kFpHSAOqSJsyWo5A.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">作者图片</p></figure><p id="ef9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本分类无疑是自然语言处理最常见的应用。而且，像大多数NLP应用一样，变压器模型近年来在该领域占据了主导地位。在本文中，我们将讨论如何使用一个Python包(我是名为<a class="ae lv" href="https://happytransformer.com/" rel="noopener ugc nofollow" target="_blank">快乐转换器</a>的主要维护者)用几行代码实现和训练文本分类转换器模型。Happy Transformer建立在Hugging Face的transformers库之上，允许程序员只需几行代码就可以实现和训练Transformer模型。</p><h1 id="9e59" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">预训练模型</h1><p id="5b10" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在<a class="ae lv" href="https://huggingface.co/models?pipeline_tag=text-classification" rel="noopener ugc nofollow" target="_blank">拥抱脸的模型分发网络</a>上有100种预训练的文本分类模型可供选择。因此，我建议在你花太多时间担心训练模型之前——看看是否有人已经为你的特定应用微调了模型。例如，我已经制作了关于如何为<a class="ae lv" href="https://youtu.be/Ew72EAgM7FM" rel="noopener ugc nofollow" target="_blank">情感分析</a>和<a class="ae lv" href="https://youtu.be/jti2sPQYzeQ" rel="noopener ugc nofollow" target="_blank">仇恨言论检测</a>实现预训练变压器模型的内容。在本教程中，我们将实现一个名为<a class="ae lv" href="https://huggingface.co/ProsusAI/finbert" rel="noopener ugc nofollow" target="_blank"> finbert </a>的模型，它是由一家名为Prosus的公司创建的。该模型检测金融数据的情绪。</p><h1 id="da6f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">装置</h1><p id="7fb1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">PyPI上有Happy Transformer，因此我们可以用一行代码安装它。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="8c06" class="my lx it mu b gy mz na l nb nc">pip install happytransformer</span></pre><h1 id="f8e2" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">实例化</h1><p id="415e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们导入一个名为HappyTextClassification的类，我们将使用它来加载模型。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="78ad" class="my lx it mu b gy mz na l nb nc">from happytransformer import HappyTextClassification</span></pre><p id="5f00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们可以使用HappyTextClassification类为模型实例化一个对象。第一个position参数指定模型的类型，并且全部大写。例如，“BERT”、“ROBERTA”和“ALBERT”都是有效的模型名称。第二个位置参数表示模型的名称，可以在模型的<a class="ae lv" href="https://huggingface.co/ProsusAI/finbert" rel="noopener ugc nofollow" target="_blank">网页</a>上找到。最后一个参数是一个名为“num_labels”的参数，它指定了模型拥有的类的数量。在这种情况下，模型有三个标签:“正面”、“中性”和“负面”</p><p id="ea19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">重要提示:实例化模型时，不要忘记设置num_labels。否则，可能会发生错误。</em></p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="31cc" class="my lx it mu b gy mz na l nb nc">happy_tc = HappyTextClassification("BERT", "ProsusAI/finbert", num_labels=3)</span></pre><h1 id="2804" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">使用</h1><p id="c2f2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们可以用一行代码通过“classify_text”方法对文本进行‌begin分类</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="8b9a" class="my lx it mu b gy mz na l nb nc">result = happy_tc.classify_text("Tesla's stock just increased by 20%")</span></pre><p id="32d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们把结果打印出来，以便更好地理解它。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="c327" class="my lx it mu b gy mz na l nb nc">print(result)</span></pre><p id="10df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">输出:TextClassificationResult(label = ' positive '，score=0.929110586643219) </em></p><p id="8c21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，‌the的输出是一个数据类，有两个变量:“标签”和“分数”标签是一个字符串，用于指示输入被分类到哪个类。“分数”变量指定模型以浮点形式分配给答案的概率。我们不能孤立这两个变量。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="b606" class="my lx it mu b gy mz na l nb nc">print(result.label) <br/>print(result.score)</span></pre><p id="d044" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">结果:</em></p><p id="62b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">正向</em></p><p id="86e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd"> 0.929110586643219 </em></p><p id="4efb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是另一个显示负输入输出的例子。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="16ea" class="my lx it mu b gy mz na l nb nc">result = happy_tc.classify_text("The price of gold just dropped by 5%") <br/>print(result.label)<br/>print(result.score)</span></pre><p id="056f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">输出:</em></p><p id="8a68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">负</em></p><p id="c3a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd"> 0.8852565288543701 </em></p><h1 id="7867" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">培训—自然语言处理情感分析</h1><p id="52ae" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在让我们来讨论培训。我们将训练一个模型来检测与NLP相关的文本的情感。我们将只使用两个例子进行训练——这当然不足以稳健地训练一个模型。但是，这只是为了演示。</p><p id="49cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们必须创建一个包含两列的CSV文件:文本和标签。文本列包含我们希望分类的文本。标签列包含大于或等于0的整数形式的标签类型。下表给出了一个培训CSV的示例。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/280f1b23167353dfac4ba883ea4f4bab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXeCJIwl99rCQYpuZSLh2g.png"/></div></div></figure><p id="b708" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是生成上述CSV文件的代码:</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="380a" class="my lx it mu b gy mz na l nb nc">import csv<br/><br/>cases= [("Wow I love using BERT for text classification", 0), ("I hate NLP", 1)]<br/><br/>with open("train.csv", 'w', newline='') as csvfile:<br/>        writer = csv.writer(csvfile)<br/>        writer.writerow(["text", "label"])<br/>        for case in cases:<br/>            writer.writerow([case[0], case[1]])</span></pre><p id="c9c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将安装一个普通版本的DistilBERT作为起点。您还可以使用其他模型，如BERT、ALBERT、RoBERTa等。访问<a class="ae lv" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank">拥抱脸的模特分销网络</a>获取更多模特。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="ca5f" class="my lx it mu b gy mz na l nb nc">happy_tc = HappyTextClassification(model_type="DISTILBERT", model_name="distilbert-base-uncased", num_labels=2)</span></pre><p id="a11e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以使用新实例化的类简单地调用方法“train”。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="bdc7" class="my lx it mu b gy mz na l nb nc">happy_tc.train("train.csv")</span></pre><p id="dff2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！我们刚刚训练了模型。我们现在可以像在上一节中一样继续使用它。所以，举个例子，你现在可以像以前一样调用“happy_tc.classify_text()”，新微调的模型就会被使用。</p><h1 id="3e64" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">自定义参数</h1><p id="a8f6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">通过使用一个名为“TCTrainArgs”的类，我们可以很容易地修改学习参数，比如时期数、学习速率等等。让我们导入TCTrainArgs。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="db83" class="my lx it mu b gy mz na l nb nc">from happytransformer import TCTrainArgs</span></pre><p id="1b2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以使用TCTrainArgs类创建一个对象来包含训练参数。在这里你可以修改<a class="ae lv" href="https://happytransformer.com/text-classification/finetuning/" rel="noopener ugc nofollow" target="_blank">的参数列表。让我们将训练时期的默认数量从3增加到5。</a></p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="f48f" class="my lx it mu b gy mz na l nb nc">args = TCTrainArgs(num_train_epochs=5)</span></pre><p id="f6bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们像以前一样调用happy_tc的train方法，但是这次将args对象传递给该方法的args参数。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="11fa" class="my lx it mu b gy mz na l nb nc">happy_tc.train("train.csv", args=args)</span></pre><p id="31d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好了，我们刚刚修改了学习参数！</p><h1 id="294d" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">评价</h1><p id="49ac" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">HappyTextGeneration对象有一个内置的方法，允许您快速评估您的模型。首先，按照培训中讨论的方式格式化数据，然后调用。eval()"方法。为了简单起见，让我们使用训练文件来评估。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="c245" class="my lx it mu b gy mz na l nb nc">result = happy_tc.eval("train.csv") <br/>print(result)</span></pre><p id="b9ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">结果:eval Result(loss = 0.2848379611968994)</em></p><p id="3a3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以像这样隔离损失变量:</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="05ab" class="my lx it mu b gy mz na l nb nc">print(result.loss)</span></pre><p id="9dee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出:<em class="nd">0.284879611968994</em></p><p id="09ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我建议你用总体数据的一部分来训练，另一部分来评估。然后，在训练前后评估你的模型。如果损失减少，那就意味着你的模型学会了。你也可以创建你的数据的第三部分来运行实验，以找到最佳的学习参数——但这是另一个时间的话题。</p><h1 id="dfbc" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="104c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">就是这样！您刚刚学习了如何实现和训练文本分类转换器模型。使用Happy Transformer只用几行代码就能完成这么多工作，这真是令人惊讶。</p><h1 id="fc60" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">相关文章</h1><p id="babd" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是我最近在《走向数据科学》上发表的一篇相关文章。它涵盖了如何使用零镜头文本分类模型来标记训练数据。这样，您可以在没有任何标记数据的情况下微调小型监督模型。</p><p id="30d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" rel="noopener" target="_blank" href="/generating-text-classification-training-data-with-zero-shot-transformer-models-e16d390eea3e">https://towards data science . com/generating-text-class ification-training-data-with-zero-shot-transformer-models-e16d 390 EEA 3 e</a></p><h1 id="74ef" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">本文中的代码:</h1><p id="1f2c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae lv" href="https://colab.research.google.com/drive/1Jq3o8whsgEL994noS14qyv98jt5We-pU?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/drive/1 jq 3o 8 whs gel 994 nos 14 qyv 98 JT 5 we-pU？usp =共享</a></p><p id="2c28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">原载于2021年6月14日</em><a class="ae lv" href="https://www.vennify.ai/train-text-classification-transformers/" rel="noopener ugc nofollow" target="_blank"><em class="nd">https://www . vennify . ai</em></a><em class="nd">。</em></p></div></div>    
</body>
</html>