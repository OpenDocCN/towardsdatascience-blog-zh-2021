<html>
<head>
<title>Scraping Data from Wikipedia Tables</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从维基百科表格中抓取数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scraping-data-from-wikipedia-tables-3efa04c6b53f?source=collection_archive---------20-----------------------#2021-05-05">https://towardsdatascience.com/scraping-data-from-wikipedia-tables-3efa04c6b53f?source=collection_archive---------20-----------------------#2021-05-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ebe7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">只需几行代码就能打开一个有价值的数据源</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4a1e51f6641269a8b1d208c661e6067c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*43HirPkazgfslP1Hx-UfRQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GPA照片档案:<a class="ae ky" href="https://www.flickr.com/photos/iip-photo-archive/27336508138" rel="noopener ugc nofollow" target="_blank">https://www.flickr.com/photos/iip-photo-archive/27336508138</a></p></figure><p id="6280" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几周前，我用美国许多城市的历史人口数据写了一篇关于T2的文章。虽然这些数据大部分直接来自美国人口普查，但我也从维基百科的表格中搜集了人口数据，这些表格在一个地方汇集了每个城市的所有可用数据。虽然核实通过维基百科找到的原始数据来源是值得的，但这个在线百科全书包含了大量通常值得搜集的信息。</p><p id="0302" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将分享我用来抓取<a class="ae ky" href="https://en.wikipedia.org/wiki/Houston" rel="noopener ugc nofollow" target="_blank">一个维基百科表格</a>的代码，该表格包含德克萨斯休斯顿的历史人口数据。这段代码可以很容易地从维基百科的其他页面或其他网页上抓取表格。我将介绍的方法基于我在研究生院数据科学课程中教授的材料，相关材料可以在这里找到<a class="ae ky" href="https://p8105.com/reading_data_from_the_web.html" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="bfeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们看一下我们将要抓取的表(用红色标出):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/f5e5c0f95980107fbaf2e3d379b0349b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3WQQ-itT3QDduMABbRx5-A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">https://en.wikipedia.org/wiki/Houston<a class="ae ky" href="https://en.wikipedia.org/wiki/Houston" rel="noopener ugc nofollow" target="_blank">的屏幕截图</a></p></figure><p id="60db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个足够简单的表，尽管我们已经可以看到，当我们将这些数据放入r中时，可能需要清理一些格式。</p><p id="8b73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦你有机会看到网页，让我们来看看代码。首先，加载“tidyverse”和“rvest”包。我们将使用tidyverse来操作和清理我们抓取的数据，并使用rvest包来进行实际的抓取:</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="3d86" class="mb mc it lx b gy md me l mf mg">library(tidyverse)<br/>library(rvest)</span></pre><p id="6ebe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们需要给R我们感兴趣的网页的url:</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="d9ad" class="mb mc it lx b gy md me l mf mg">url = "<a class="ae ky" href="https://en.wikipedia.org/wiki/Houston" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Houston</a>"</span></pre><p id="3cfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们使用read_html()函数将该网页转换为R可以使用的信息，然后使用html_nodes()函数专门关注网页中包含的表格对象:</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="47f4" class="mb mc it lx b gy md me l mf mg">houston_html = read_html(url)</span><span id="302e" class="mb mc it lx b gy mh me l mf mg">houston_html %&gt;% <br/>  html_nodes(css = "table")</span></pre><p id="0fd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来休斯顿维基百科页面包含了19个表格，尽管其中一些类别的描述比其他的更有信息量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mi"><img src="../Images/da826866901fae28ae5064def96c2a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vw9JZMQJBJajwF0gIy6Hhg.png"/></div></div></figure><p id="bba0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们从这些可用的表中取出感兴趣的表。函数指定我们想要上面列表中的第四个表。当网页上有多个表格时，确定要在此指定的正确表格可能需要一些反复试验。您可以通过查看网页尽最大努力猜出正确的数字，也可以查看不同的表格，直到看到您想要的内容:</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="9208" class="mb mc it lx b gy md me l mf mg">pop_table = <br/>  houston_html %&gt;% <br/>  html_nodes(css = "table") %&gt;% <br/>  nth(4) %&gt;% <br/>  html_table(fill = TRUE)</span></pre><p id="7059" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们得到下面的输出，Wikipedia表现在在R！然而，正如web抓取经常发生的那样，这个表还不能真正使用。所有四列具有相同的名称，第一行和最后一行不包含数据，并且在我们的数据框中间有一个额外的列:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mj"><img src="../Images/25257594de9ca56089d1cf4b15fdb5c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v3VKdZkVLlBs9NJTdr-8Fg.png"/></div></div></figure><p id="1f7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们快速清理一下这张桌子，让它更有用。在我们的列有唯一的名称之前，我们什么也做不了，我们还需要将该表限制在第2-19行:</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="adf1" class="mb mc it lx b gy md me l mf mg">colnames(pop_table) = c("year", "population", "blank", "percent_change")</span><span id="9012" class="mb mc it lx b gy mh me l mf mg">pop_table = pop_table[2:19, ]</span></pre><p id="4dd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还没有完全实现，但是输出看起来要好得多:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mk"><img src="../Images/717eca475e993ce62d903e737ab98a73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8Yo-m6UHi2T1xJT48UVvA.png"/></div></div></figure><p id="953f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们做一些最后的清洁。首先，我们将删除空白列。所有列目前都存储为字符变量，而year应该是日期，population和percent_change应该是数字。我们从percent_change和population列中删除不必要的字符串，然后将所有列转换为适当的格式:</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="fa99" class="mb mc it lx b gy md me l mf mg">pop_table = <br/>  pop_table %&gt;% <br/>  select(-blank) %&gt;% <br/>  mutate(<br/>    percent_change = str_replace(percent_change, "%", ""),<br/>    percent_change = str_replace(percent_change, "—", ""),<br/>    population = str_replace_all(population, ",", ""),<br/>    year = lubridate::ymd(year, truncated = 2L),<br/>    population = as.numeric(population),<br/>    percent_change = as.numeric(percent_change)<br/>  )</span></pre><p id="a96a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就这么简单。现在，表中的所有内容都符合我们的预期:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/91aa26159ef11dae7a67f84182383fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*YaPBLknplvDGxRHssVKJOg.png"/></div></figure><p id="ba3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人口数据现在完全可用，可以进行分析了。Web抓取是一种访问各种数据源的强大工具，鉴于其可重复性和减少人为错误的可能性，它比手动复制在线表格中包含的值要好得多。本文中包含的代码还可以用来一次抓取多个表，从而实现更高的效率和访问更多的数据。</p><p id="37e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面使用的代码也可以在<a class="ae ky" href="https://github.com/emilyhalford/scraping_tables" rel="noopener ugc nofollow" target="_blank"> this GitHub repo </a>中找到。</p></div></div>    
</body>
</html>