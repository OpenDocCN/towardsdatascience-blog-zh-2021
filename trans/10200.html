<html>
<head>
<title>Are We Thinking about eXplAInability Backwards?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们是否在逆向思考可解释性？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/are-we-thinking-about-explainability-backwards-c9a719cb1250?source=collection_archive---------28-----------------------#2021-09-27">https://towardsdatascience.com/are-we-thinking-about-explainability-backwards-c9a719cb1250?source=collection_archive---------28-----------------------#2021-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="bebe" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/model-interpretability" rel="noopener" target="_blank">模型可解释性</a></h2><div class=""/><div class=""><h2 id="afd5" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在构建人工智能解决方案之前，你应该能够回答三个问题</h2></div><p id="4635" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">围绕人工智能的一个普遍问题是它的黑盒性质，但为可解释性而设计是可能的。不是每个用例都需要一个可解释的解决方案，但是很多都需要。当我们开发XAI时，我们经常问，“我们能解释什么？”在这篇文章中，我要求我们首先考虑最终用户。我强调了在构建你的人工智能解决方案之前要考虑的三个问题，这样它就可以通过设计来解释。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lu"><img src="../Images/490f351b71ff6d035d11b20b5a5dfeef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LtAkUbwJxTP85DDE"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">照片由<a class="ae mk" href="https://unsplash.com/@fakurian?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">法库里安设计</a>在<a class="ae mk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="1ba8" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">动机</h1><p id="d3ce" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">我的大部分博士研究都围绕着可解释的数据融合。结果，我花了相当一部分时间研究可解释的人工智能。可解释性引起了我的兴趣，因为它涉及到算法将自身的一些东西翻译给用户。哲学辩论围绕着解释的构成，但是算法解释需要向用户展示一些关于它们自己的东西。</p><p id="5519" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们以不同的方式发展XAI方法。一种常见的方法是独立于人工智能开发XAI。例如，流行的LIME [1]位于人工智能之外，允许它是人工智能不可知论者；然而，这限制了它所提供的解释类型。第二种方法是从一开始就将XAI直接开发到我们的人工智能中——通过设计来解释。我的XAI之旅凸显了在开发之初考虑最终用户的重要性。我鼓励你们思考需要建立什么，而不是能够建立什么——这是我学到的最重要的一课。</p><p id="896b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">设计的可解释性给了人工智能工程师最大的自由来开发相关的解释，以赋予算法的用户权力。在我的职业生涯中，我创造了多种XAI方法，并将我所学到的归纳为三个以用户为中心的问题— <strong class="kt jd"> <em class="ni">谁、什么、如何</em> </strong>。</p><h1 id="b874" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated"><strong class="ak"> 1。谁会使用你的人工智能？</strong></h1><p id="6889" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated"><strong class="kt jd">开发相关解决方案需要了解谁将使用您的人工智能。会不会是一个</strong>:</p><ul class=""><li id="78bf" class="nj nk it kt b ku kv kx ky la nl le nm li nn lm no np nq nr bi translated">人工智能工程师</li><li id="b7a5" class="nj nk it kt b ku ns kx nt la nu le nv li nw lm no np nq nr bi translated">数据科学家</li><li id="f511" class="nj nk it kt b ku ns kx nt la nu le nv li nw lm no np nq nr bi translated">商业领袖</li><li id="dc60" class="nj nk it kt b ku ns kx nt la nu le nv li nw lm no np nq nr bi translated">农民</li><li id="9881" class="nj nk it kt b ku ns kx nt la nu le nv li nw lm no np nq nr bi translated">医生</li><li id="87c8" class="nj nk it kt b ku ns kx nt la nu le nv li nw lm no np nq nr bi translated">人工智能驱动车辆的驾驶员</li><li id="f5f1" class="nj nk it kt b ku ns kx nt la nu le nv li nw lm no np nq nr bi translated">法官</li><li id="0bfa" class="nj nk it kt b ku ns kx nt la nu le nv li nw lm no np nq nr bi translated">军事领导</li></ul><p id="78e1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这些人每天都在做出重大的、改变生活的决定，所以了解谁得到了解释以确保我们得到正确的翻译是非常重要的。无人驾驶汽车的驾驶员想要驾驶汽车时使用的图像的显著图，这是值得怀疑的。不要误解我，显著图有效地突出了图片的一部分，但我认为这种解释与人工智能模型构建器最相关。并不是所有的XAI都会产生相关的解释，首先，考虑谁会收到解释将确保你正在构建相关的XAI。今天大多数可用的XAI集中于将信息传递给人工智能从业者，而不是终端用户。为了制造有效的XAI，我们必须打破这种模式。我们必须跳出框框思考。我们必须理解用户的用例，以便在正确的时间向他们传递正确的信息。</p><p id="7cea" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">考虑最终用户似乎是显而易见的，对吗？</strong>但是，大多数XAI开发者本质上都是数学家，我们专注于扩展数学，而不是翻译给非数学家。首先，我会挑战我们去理解我们的用户，在开发XAI时发现最好的<strong class="kt jd"> <em class="ni">媒介</em> </strong>(双关语)来交付翻译。</p><p id="6028" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，让我们考虑一个对预测产量感兴趣的农民。他们不会关心模型的可解释性。但是，他们需要了解人工智能正在做什么，以及如何使用它来增强他们的决策。</p><h1 id="dcbe" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated"><strong class="ak">②<em class="nx">。他们想知道什么？</em>T19】</strong></h1><p id="3b60" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">在考虑你的XAI(或人工智能)影响时，识别和理解你的受众可以说是最关键的因素。一旦被认可，对话就可以面向他们希望解决的问题；他们不知道他们需要什么AI或者XAI。根据我的经验，用户希望了解每个数据点对最终模型输出的影响。为什么？<strong class="kt jd">揭示数据影响允许他们干预以改变结果。</strong></p><p id="1b4b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，考虑一个预测一个农民今年玉米产量的算法。农民的目标是最大化产量和最小化成本，因此了解每个数据点的影响将为农民提供最佳决策信息。作为一名数据科学家/人工智能工程师，识别这个痛点为实施适当的解决方案打开了大门，以便将这些信息传递给农民。农民根本不在乎相关系数——他们拿它没办法。</p><h1 id="c6c7" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">3.我们如何向他们传达这一点？</h1><p id="1d21" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">到目前为止，我们只讨论了理解谁将使用XAI (AI)以及他们想知道什么。在这一节中，我们将深入探讨XAI的一些方法。存在许多不同的思想流派来产生解释。仅在我的酒吧里，我就用了三种不同的类型。我喜欢这篇论文中的框架[5]。作者深入研究了几种不同的解释，他们的分类考虑了最终用户。</p><blockquote class="ny"><p id="6008" class="nz oa it bd ob oc od oe of og oh lm dk translated">“……我们可以区分出<em class="nx">文本解释、可视化、局部解释、举例解释、简化解释</em>和<em class="nx">特征相关性</em>。”[4]</p></blockquote><p id="9bb9" class="pw-post-body-paragraph kr ks it kt b ku oi kd kw kx oj kg kz la ok lc ld le ol lg lh li om lk ll lm im bi translated">每种方法在适当的背景下都是必不可少的，因为人是不可概括的，所以不可能建立一个完全适合每个人的解释。使用每种类型的解释，我们可以开发出一个可以在多个层次上解释的解决方案，以达到更广泛的受众。</p><p id="6ff3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Bryce，这在高层次上是很棒的，但是我们如何实现一个可以通过设计来解释的系统呢？问得好。让我们考虑一下我们的农民。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="9877" class="ml mm it bd mn mo on mq mr ms oo mu mv ki op kj mx kl oq km mz ko or kp nb nc bi translated"><strong class="ak">举例</strong></h1><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi os"><img src="../Images/ce21782d36c6266e17fd133065e654aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xpyfOGctgwYGMGjj"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">杰西·加德纳在<a class="ae mk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c95c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第一部分指出了我们基于不同特征预测整个农场玉米产量的问题。接下来，我们确定了我们的最终用户——农民。然后，我们强调了对基于预测收益率的干预选项的兴趣。现在，我们必须确定将农民的愿望融入我们的AI/XAI设计的最佳方式。</p><p id="5cb8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以将我们的问题描述为“开发一个玉米产量的预测模型，为农民提供改善产量的选择。”T13】</p><p id="39b3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我将增加一个约束来实现一个解决方案——使用2/3的计算智能分支。你能花点时间想想你会如何解决这个问题吗？方法有很多。</p><p id="b219" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了设计一个利用计算智能的这两个分支的系统，我们需要了解我们需要这些分支中的哪些算法。具体来说，一个<strong class="kt jd">模糊推理系统(FIS) </strong>将提供底层分类能力，以有效地为农民的田地建模。查看这篇文章可以找到一个很好的例子。FIS由可学习的参数组成。例如，我们可以优化规则的数量和每个规则的隶属函数。如果你读过我的CI文章，你会发现这是一个使用<strong class="kt jd">遗传算法</strong>的绝佳机会。染色体是每一组规则，其中每个基因是一个模糊隶属函数的参数。以这种形式设置问题允许我们优化最能预测农民产量的FIS参数。你猜怎么着？一旦我们知道了参数，我们就可以明确地将它们传递给农民。有两种可能的解释。首先，文本解释陈述了一个规则:</p><blockquote class="ot ou ov"><p id="3d3d" class="kr ks ni kt b ku kv kd kw kx ky kg kz ow lb lc ld ox lf lg lh oy lj lk ll lm im bi translated">"如果氮含量高，产量也会高."</p></blockquote><p id="7152" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">或者是一张隶属图，它显示了相对于玉米已经施用的量，最佳的氮量是多少。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi oz"><img src="../Images/c3cb1f22973d5a27d141dbc9919a4bfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lMTIIJHqabUmycqdirhOVg.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">绿线代表学习到的隶属函数——“高”，橙色框代表当前的氮量。这意味着农民需要产出更多的氮。背景由<a class="ae mk" href="https://unsplash.com/@js90" rel="noopener ugc nofollow" target="_blank">朱利安·谢尔</a>提供。</p></figure><p id="e902" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这两种情况下，农民都可以采取直接措施，在农田里施更多的氮肥。因此，我们有效地为农民创建了一个XAI，并提供了相关的解决方案。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="ab82" class="ml mm it bd mn mo on mq mr ms oo mu mv ki op kj mx kl oq km mz ko or kp nb nc bi translated"><em class="nx">结论</em></h1><p id="badd" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">我相信，作为人工智能的创造者，我们最终有责任确保我们的算法翻译正确的信息。释放数据和人工智能的潜力是我们的责任，我们必须利用这一点。所以很多时候，我们作为人工智能工程师，把自己限制在目前可能的范围内(用目前的数学)。让我们颠倒一下我们对XAI的看法——让我们在计算之前先考虑用户。让我们跳出框框思考。让我们为没有明确解决方案的问题创造解决方案。转变我们的视角让我们能够跳出框框思考，并为非专业人士设计解决方案。要做到这一点，需要了解用户，他们需要和想要知道什么，并实施有效的AIs人工智能。</p><p id="92fd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">参考文献</strong></p><p id="88d7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[1]<a class="ae mk" href="https://homes.cs.washington.edu/~marcotcr/blog/lime/" rel="noopener ugc nofollow" target="_blank">https://homes.cs.washington.edu/~marcotcr/blog/lime/</a></p><p id="eedb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae mk" href="https://ieeexplore.ieee.org/document/9149954/" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/document/9149954/</a></p><p id="8f6a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[3]<a class="ae mk" href="https://ieeexplore.ieee.org/document/8491501" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/document/8491501</a></p><p id="63d7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[4]https://ieeexplore.ieee.org/document/9494563<a class="ae mk" href="https://ieeexplore.ieee.org/document/9494563" rel="noopener ugc nofollow" target="_blank"/></p><p id="16a8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[5]<a class="ae mk" href="https://www.sciencedirect.com/science/article/pii/S1566253519308103" rel="noopener ugc nofollow" target="_blank">https://www . science direct . com/science/article/pii/s 1566253519308103</a></p></div></div>    
</body>
</html>