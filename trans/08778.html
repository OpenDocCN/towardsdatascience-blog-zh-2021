<html>
<head>
<title>Variational Autoencoder: Introduction and Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">变分自动编码器:介绍和例子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/variational-autoencoder-55b288f2e2e0?source=collection_archive---------19-----------------------#2021-08-13">https://towardsdatascience.com/variational-autoencoder-55b288f2e2e0?source=collection_archive---------19-----------------------#2021-08-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5fbd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用变分自动编码器生成看不见的图像</h2></div><p id="15fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可能已经知道，经典的自动编码器被广泛用于通过图像重建进行表征学习。然而，有许多其他类型的自动编码器用于各种任务。这篇文章的主题是变分自动编码器(VAE)。如下图所示，VAE也试图重建输入图像；然而，与传统的自动编码器不同，编码器现在产生两个矢量，解码器使用这两个矢量来重建图像。因此，给定分布，我们可以对随机噪声进行采样并生成逼真的图像。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/0b8fd658cfcec6953ac38428c34f2b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W94xyAr7PWN16578uZmtGw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">可变自动编码器。图片作者。</p></figure><h1 id="ee52" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">VAE原则</h1><p id="bd7b" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">VAE的目标是给定一个从预定义的分布生成的随机向量，生成一个逼真的图像。这对于我上次提到的简单的自动编码器是不可能的，因为我们没有指定生成图像的数据的分布。因此，战略如下:</p><ol class=""><li id="57b7" class="mo mp iq kh b ki kj kl km ko mq ks mr kw ms la mt mu mv mw bi translated">编码器获取图像并输出两个向量，其中每个向量代表平均值和标准偏差。</li><li id="de7d" class="mo mp iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated">我们把均值向量和标准差向量相加，先乘以一个随机的小值作为噪声，得到一个修正向量，这个向量和is大小一样。</li><li id="cc7c" class="mo mp iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated">解码器采用修改后的矢量，并尝试重建图像。</li><li id="fa26" class="mo mp iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated">我们试图优化的损失值是L2距离和KL散度的组合，KL散度测量平均值和标准偏差向量的分布分别从0和1的偏差。</li></ol><p id="f73a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们鼓励我们的平均向量具有以0为中心的分布，而后一个向量应该以1为中心(高斯分布)。最后，我们的解码器将能够从均值为0、标准差为1的随机噪声(向量)中生成逼真的图像。</p><h1 id="6e2b" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">KL散度</h1><p id="f24d" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">我们使用KL散度来计算我们的特征向量与平均值为0且标准分布为1的值的期望分布有多不同。损失计算如下:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/119a96c74cfff0f4ae6e82bda59e9e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/0*BKWy5kNNjL4mUrfy.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">KL发散。图片作者。</p></figure><p id="72b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中σ和μ分别代表标准差和平均值。如图所示，目标是使平均值(μ)尽可能接近0(通过平方该值)。而等式的其余部分确保标准偏差(σ)接近1。请注意，我们使用对数来确保标准差不为负。</p><p id="e383" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">例子</strong></p><p id="d19f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将使用的模型如下所示:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="1bd6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如所见，我们的编码器输出的是方差的对数，而不是标准偏差向量，所以这里要小心。该示例在MNIST数字数据集上运行。最后，损失函数如下:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="3572" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">瞧！仅经过10个时期的训练，我们的解码器就能够产生非常逼真的随机噪声图像，其均值为0，标准差为1(可以使用torch.randn函数生成)。</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/b2bf242275f6827633477352132b8fee.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*D453mzYWPFHYw3z9-NvngA.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">VAE生成图像。图片作者。</p></figure><h1 id="3fa0" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">一些遗言</h1><p id="cc9a" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">变分自动编码器是一个非常简单而有趣的算法。我希望这对你来说很容易理解，但是不要着急，确保你理解了我们讨论的所有内容。除了VAE之外，还有许多类型的自动编码器。通过下面的链接，你可以随意学习其他的自动编码器。谢谢大家！</p><div class="ng nh gp gr ni nj"><a rel="noopener follow" target="_blank" href="/autoencoders-introduction-and-practical-applications-3eb7b5c1c7fd"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd ir gy z fp no fr fs np fu fw ip bi translated">自动编码器:介绍和实际应用</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">当我们想到无监督学习时，自动编码器可能是第一个想到的神经网络…</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">towardsdatascience.com</p></div></div><div class="ns l"><div class="nt l nu nv nw ns nx ll nj"/></div></div></a></div><div class="ng nh gp gr ni nj"><a href="https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd ir gy z fp no fr fs np fu fw ip bi translated">从自动编码器到贝塔VAE</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">自动编码器是一组神经网络模型，旨在学习高维数据的压缩潜变量…</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">lilianweng.github.io</p></div></div><div class="ns l"><div class="ny l nu nv nw ns nx ll nj"/></div></div></a></div></div></div>    
</body>
</html>