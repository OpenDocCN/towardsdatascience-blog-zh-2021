<html>
<head>
<title>How to Tame Your Bandit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何驯服你的强盗</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-tame-your-bandit-4c6b2723d0db?source=collection_archive---------13-----------------------#2021-09-26">https://towardsdatascience.com/how-to-tame-your-bandit-4c6b2723d0db?source=collection_archive---------13-----------------------#2021-09-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2b6d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">揭开纯粹探索的神秘面纱(第一部分)</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6149e7dacf0f57f1a5016d2e5c0699de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dA8bp2irdnJEVnQY"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一个独臂强盗。(照片由<a class="ae kv" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</p></figure><h2 id="5a44" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">TLDR</h2><p id="e764" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">多臂强盗很棒，超越了简单的A/B测试，走上了<em class="ml">之路</em>。对于有强盗的假设检验，有效的算法和<em class="ml">非常</em>紧<em class="ml"> </em>的样本大小界限是可用的。让我们检查一下！😃</p><h1 id="f2da" class="mm kx iq bd ky mn mo mp lb mq mr ms le jw mt jx li jz mu ka lm kc mv kd lq mw bi translated">在前一集里…</h1><p id="c3cd" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi mx translated"><span class="l my mz na bm nb nc nd ne nf di"> P </span>我的关于<strong class="lu ir">的系列文章第0篇解释了为什么使用<em class="ml">顺序统计</em>可以显著地<em class="ml"> </em>提高A/B测试的效率，以达到期望的性能水平(第0部分<a class="ae kv" rel="noopener" target="_blank" href="/why-most-a-b-tests-are-not-efficient-11b289414191">点击此处</a>)。在其中，我还解释了一个叫做“多臂bandit”的统计结构如何概括顺序A/B测试，并提供了一个使用Bandit方法的优势列表。</strong></p><p id="7a84" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">在过去的二十年里，班迪特背景下的序贯假设检验受到了研究者的广泛关注。计算机科学家和统计学家一样，已经开发了一个丰富的算法和证明技术的工具包来处理建立在异常严格的数学基础上的各种各样的此类问题。</p><p id="bbbc" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">在本系列的这一部分和随后的部分中，我希望呈现关于这个主题的大量文献中的一小部分，以帮助读者更好地欣赏顺序统计分析的强大功能。让我们首先了解我们正在处理的问题，特别是它不是什么。</p><h1 id="3ea6" class="mm kx iq bd ky mn mo mp lb mq mr ms le jw mt jx li jz mu ka lm kc mv kd lq mw bi translated">纯探索≠后悔最小化！😮</h1><p id="a6ea" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">多臂强盗(MAB)的设定包括K个动作，一些特别虐待狂的统计学家决定称之为'<em class="ml">武器</em>'，以唤起拉斯维加斯吃角子老虎机的可悲形象，又名独臂强盗，偷走你所有的钱。在继续下一步之前，我将快速总结一下MAB模型(新手可以参考这个网站上任何数量的关于后悔最小化的基础知识的文章)。</p><p id="50d6" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">每个臂K代表一个分布P(k)，1≤ k≤ K，拉臂代表从分布P(k)中取样。在时间t = 1，2，3，mab算法拉臂Aₜ.在时间s拉动臂k产生从分布P(k)中抽取的样本X(s，k)。这个样本被称为“奖励”。</p><p id="290b" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">分布Pₖ的均值用θₖ表示，均值最大的臂称为<strong class="lu ir">最佳臂</strong>。不用说，除了它们所属的概率分布的<em class="ml">类</em>之外，我们并不先验地知道任何报酬分布。贯穿本文，我们将假设所有的奖励分布都在<a class="ae kv" href="https://en.wikipedia.org/wiki/Sub-Gaussian_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="lu ir">亚高斯</strong> </a> <strong class="lu ir"> </strong>类<strong class="lu ir">中。</strong>称随机变量z是σ-次高斯的，如果对于每个λ ∈ ℝ</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/43e963a6704a82c124fa7958e569e448.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*NW_S2OGAVpnQUzuxPaBKQQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">亚高斯的定义(作者图片)</p></figure><p id="3704" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">上面的参数σ本质上表现为z的方差的代理。在本文的其余部分，我们将假设我们的问题有一个<strong class="lu ir">唯一的最佳臂</strong>，并且该臂是<strong class="lu ir">臂1 </strong>。此外，让δₖ= θ₁-θₖ表示臂1和k之间的平均回报差距。为了便于表示，让我们设置δ₁= δ₂.</p><p id="3270" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated"><strong class="lu ir">后悔最小化:</strong>在上面的框架中，给定固定的时间范围T，MAB算法的后悔本质上测量了由于它没有拉最佳臂的所有时间而导致的回报损失。</p><p id="aeff" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">后悔最小化不是这个系列的重点。我感兴趣的是激起普通读者对A/B测试的激进概括的兴趣，这种测试被不同地称为“<em class="ml">纯探索</em>”和“<em class="ml">最佳手臂识别</em>”</p><h2 id="bf3f" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">纯探索</h2><p id="40cc" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">给定置信参数δ∈(0，1)，找到概率至少为1-δ的最佳臂，使用尽可能少的臂拉动。因此，我们的算法需要使用尽可能少的样本来找到Arm 1。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/e94928d761b6eaf240f45c7d08b347c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LVDQKWpIT_tXG87t"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">杰瑞能通过你的测试吗？(照片由<a class="ae kv" href="https://unsplash.com/@sweetmangostudios?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Ricky Kharawala </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</p></figure><p id="0db8" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated"><strong class="lu ir">例子:</strong>一个医学研究者有一种药物的K种构型，她希望找出其中最有效的一种。</p><p id="830c" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">测试这一点的自然方法是通过注射不同配置的实验室小鼠，并观察每种配置的成功率。这样的实验并不关心老鼠本身如何受到药物的影响。事实上，所采用的协议必须相当积极地快速找出次优配置(或武器)(在她耗尽鼠标并不得不四处寻求更多资金之前)。</p><p id="0f97" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">听起来可能很可怕，但这个例子有助于说明这两个问题之间的区别。后悔最小化算法，根据它们处理的问题的本质，必须“小心行事”，尽可能少地采样次优臂。纯粹的探索算法没有这种强迫性，只关心尽可能快地聚焦于最佳行动，而不关心在此期间他们会产生什么样的遗憾。</p><p id="3e29" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">💡考虑到我们只有来自分布的样本，臂k的平均θₖ的一个很好的代理是从采样臂k到时间t所获得的平均回报。因此，我们应该研究如何<em class="ml">控制θₖ和这个平均值</em>之间的距离。幸运的是，两位著名的数学家发明了一种技术来做到这一点。</p></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><h1 id="e668" class="mm kx iq bd ky mn nu mp lb mq nv ms le jw nw jx li jz nx ka lm kc ny kd lq mw bi translated">切尔诺夫和赫夫丁前来救援</h1><p id="aacd" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在文章的剩余部分，给定随机变量X₁，X₂，…由术语'<strong class="lu ir"> <em class="ml">样本意味着</em> </strong> <em class="ml"> ' </em>我们将指随机变量</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/82ed9d2e2c36c499bf23296c754ce626.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*ibuUCZZk7QhhTqADMBv8Zw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">“样本均值”的定义(图片由作者提供)</p></figure><p id="4caf" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">当X₁，X₂，…也是独立同分布(IID)且均值为μ时，我们知道𝔼Xᵐ(t)=𝔼X₁=μ.为了突出μ在某种程度上代表了IID序列的基本事实，我们将称其为'<strong class="lu ir"><em class="ml"/></strong>'(与样本均值相对)。</p><h2 id="3a7a" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">问题1 </strong></h2><p id="2937" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">Xᵐ(t离μ有多远)？假设我们的IID序列X₁，X₂，…由σ-亚高斯随机变量组成，标准<a class="ae kv" href="https://en.wikipedia.org/wiki/Chernoff_bound" rel="noopener ugc nofollow" target="_blank">切尔诺夫-赫夫丁分析</a>告诉我们</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/d0b6480c32a6d3e6bf040864e6cb5769.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*LOgkfMTZRPfEckgMT3q96w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">单面装订(图片由作者提供)</p></figure><p id="b7f0" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">Xᵐ(t)-μ的情况也是如此</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/19046e610710ab03d962cdcb09a9b434.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*3vtgKv3OOjObfEmmpvmnUw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(Image by author)</p></figure><p id="9c48" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">💡 This means that O(1/ϵ² log(1/δ)) samples are needed to bring the sample mean to within ϵ of the true mean with high probability. This brings us to the next question.</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/8e987de6285dd594b27c54eb274964fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gkGDZXqU6kiiiJPsvk870A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">The sample mean is close to the true mean for large enough t. (Image by author)</p></figure><blockquote class="od oe of"><p id="2581" class="ls lt ml lu b lv ng jr lx ly nh ju ma og ni mc md oh nj mf mg oi nk mi mj mk ij bi translated">O(1/ϵ² log(1/δ)) samples are needed to bring the sample mean to within ϵ of the true mean with high probability.</p></blockquote><h2 id="db0d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">问题2(回到单克隆抗体)</strong></h2><p id="80f1" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">给定一个双臂土匪，假设已知δ=θ₁-θ₂，需要多少样本才能高概率找到更好的手臂？(回想一下，我们假设臂1是最佳臂。)</p><p id="2b55" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">💡回答这个问题的一个方法是对两个臂采样足够的次数，以确保它们的样本均值Xᵐ₁(t和Xᵐ₂(t分别足够接近真实均值θ₁和θ₂，并且简单地选择具有较大样本均值的臂。</p><p id="c728" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">事实证明这非常有效！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/a10cf3143965314b083dda4f9f0f5f6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ht-ir6fL_g9oPv5FAd4i3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">臂1的样本均值比臂2的样本均值大得多(图片由作者提供)</p></figure><p id="d613" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">根据上面的分析，假设我们现在处理的是4个区间，而不是2个，我们需要用δ/4代替δ/2。还有，如图所示，在这种情况下，ϵ=δ/2。由此，我们看到</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/fea33732c7cf8eb1f507475120ba161e.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*z0-wo9cXYegQElPfYaaaPw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7e63" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">样本确保在概率大于1 - δ的情况下，臂1的样本均值xᵐ₁(t)&gt;θ₁-δ/2≥θ₂+δ/2 &gt; xᵐ₂(t)，臂2的样本均值。所以，选择样本均值较大的臂给出正确答案的概率较大。</p><p id="30c4" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">一个名为<strong class="lu ir">动作消除或‘AE’</strong>的非常简单的算法正好利用了这一原理，以高概率在多臂强盗中找到最佳臂。然而，AE还必须应对增加的复杂性</p><ul class=""><li id="a635" class="ol om iq lu b lv ng ly nh lf on lj oo ln op mk oq or os ot bi translated">事先不知道δᵢ=θ₁-θᵢ的差距，以及</li><li id="7f75" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">不得不(潜在地)处理两个以上的臂。</li></ul><p id="93db" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">让我们看看算法如何设法解决这个问题。</p><h1 id="806d" class="mm kx iq bd ky mn mo mp lb mq mr ms le jw mt jx li jz mu ka lm kc mv kd lq mw bi translated">动作消除算法</h1><p id="32c4" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">AE，顾名思义，是一种“消除”类型的算法，它分阶段进行，丢弃或…消除(啊哈！)在阶段结束时看起来不太理想的武器。</p><p id="49e4" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">该算法巧妙地回避了需要知道的差距</p><ul class=""><li id="c2b6" class="ol om iq lu b lv ng ly nh lf on lj oo ln op mk oq or os ot bi translated">选择每个阶段结束时样本均值最大的臂作为<em class="ml">当前</em>(或<em class="ml">经验</em>)最佳臂，</li><li id="f59b" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">丢弃其样本均值在经验最佳值一定距离之外的所有臂，该距离在阶段开始时选择，以及</li><li id="67a8" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">通过选择一个新的、更小的距离来开始下一阶段，以使武器在即将到来的阶段中存活。这意味着，随着阶段的进展，样本均值将不得不越来越接近经验最佳值，对应的臂才能存活。</li></ul><p id="e199" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">下面的流程图说明了算法的细节。AE从所有臂开始，并在一个阶段结束时恰好剩下一个臂时结束。请注意，由于ϵₗ随着阶段的进展呈指数下降，样本均值需要非常接近经验最佳值才能生存。换句话说，该算法非常积极地丢弃arms。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/865177044fac597f001242c8fcf14063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0oqhzks_j4hvC47oOnaX8Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">给定置信度δ∈(0，1)的动作消除算法。(图片由作者提供)</p></figure><p id="d1f3" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">分析AE在停止前消耗的样本数包括显示(很有可能)</p><ul class=""><li id="452c" class="ol om iq lu b lv ng ly nh lf on lj oo ln op mk oq or os ot bi translated">臂1永远不会被消除</li><li id="1411" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">武器的样本手段永远不会比ϵₗ在每个阶段都远离它们真正的对手<em class="ml"> l </em>。</li><li id="0a1e" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">臂k最多存在o(log(8/δₖ)阶段。</li></ul><p id="cea8" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">这些观察意味着动作消除返回概率至少为1-δ的最佳臂，消耗了最多以下数量的样本</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/ba5bda41ea5ece763767c50215ed0eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*M81bq4c8LuTnq6q80FQF9w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">活动消除消耗的样本数。(图片由作者提供)</p></figure><h2 id="626a" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">好消息和坏消息</h2><p id="3f57" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们将在后面看到，AE样本量中的许多项实际上从根本上是不可避免的。然而，这种算法存在许多问题。</p><ul class=""><li id="f3b4" class="ol om iq lu b lv ng ly nh lf on lj oo ln op mk oq or os ot bi translated">首先，不能保证动作消除会停止。样本均值估计可能会波动，Arm 1可能会在早期被踢出局，一系列问题可能会破坏算法。</li><li id="e9cb" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">即使在AE停止的轨迹上，在概率1-δ的集合之外，其性能也可能是任意差的。</li><li id="7b43" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">在开始下一阶段之前，该算法实际上丢弃了在给定阶段收集的所有样本。</li></ul><p id="b98a" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">基于这些原因，我决定称动作消除法为‘无齿’算法(明白吗？😉无牙…被驯服的龙…)。无论如何，回到样本大小，我们现在会看到，尽管它没有什么作用，但AE样本复杂性的表达式是一个有价值的信息宝库。</p><h1 id="0146" class="mm kx iq bd ky mn mo mp lb mq mr ms le jw mt jx li jz mu ka lm kc mv kd lq mw bi translated">无齿算法的教训</h1><p id="76e4" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">让我们更仔细地看看样本量表达式。可以说，我只强调了“顺序”项，而隐藏了不相关的常量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/55ac79c4a4ab17a82fb3065af82168db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EP4Uvgr13AKeH341xkwU3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">红色圆圈中的术语不能删除，但绿色圆圈中的术语可以删除。(图片由作者提供)</p></figure><p id="931c" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">用红色圈出的术语是统计分析和随机过程理论中非常基本的问题的结果。在本系列接下来的部分中，我们将看到它们是如何出现的。简而言之，</p><ul class=""><li id="4847" class="ol om iq lu b lv ng ly nh lf on lj oo ln op mk oq or os ot bi translated">事实上，第1项(σₖ1/δₖ)是任何好的纯探索算法所消耗的样本数的一个著名下限的最重要部分。</li><li id="c334" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">第2项(log(K))是弱并集的结果。我们将看到这个术语最终是如何被删除的。</li><li id="2bf1" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">第3项(log(1/δ))是统计分析中的一个基本极限。事实上，这篇文章暗示了为什么这个术语不可避免。你能找到它吗？提示:如果我给你δₖ的差距值，你能避免吗？</li><li id="2ed5" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">第4项(log(log(1/Delta)))来自一个有趣的现象，称为重对数的<strong class="lu ir">定律，它控制着独立随机变量之和的增长率。</strong></li></ul></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><h1 id="827d" class="mm kx iq bd ky mn nu mp lb mq nv ms le jw nw jx li jz nx ka lm kc ny kd lq mw bi translated">结束语</h1><ul class=""><li id="25c2" class="ol om iq lu b lv lw ly lz lf pc lj pd ln pe mk oq or os ot bi translated">在纯探索的背景下，AE是最早提出的算法之一(并经过严格分析)。</li><li id="698c" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">AE不是真的“无牙！”我只是用这个形容词来强调这样一个事实，即更先进的技术显示了接近最优的样本复杂性。事实上，AE已经被许多研究者成功地用于解决MABs和强化学习中的几个问题(包括你的)😅)，通常作为更复杂算法中的构建块。</li><li id="2fe4" class="ol om iq lu b lv ou ly ov lf ow lj ox ln oy mk oq or os ot bi translated">多年来，AE的许多问题都已经解决了。在接下来的部分中，我将描述一些成功解决AE问题的尝试。</li></ul><p id="a456" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">因此，在纯探索传奇的这一部分，我们正式定义了这个问题，并看到了如何构造一个算法来解决它。算法的性能分析给了我们一些提示，告诉我们在这种情况下什么可以做，什么不可以做。</p><p id="4fa6" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated">在本系列的剩余部分，我将解释是什么使得这些术语不可避免，以及log(K)术语是如何被消除的。</p><p id="c576" class="pw-post-body-paragraph ls lt iq lu b lv ng jr lx ly nh ju ma lf ni mc md lj nj mf mg ln nk mi mj mk ij bi translated"><strong class="lu ir">注:</strong>参考资料将在第2部分末尾提供。</p></div></div>    
</body>
</html>