<html>
<head>
<title>5 Minutes Cheat Sheet Explaining all Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释所有机器学习模型的5分钟备忘单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-minutes-cheat-sheet-explaining-all-machine-learning-models-3fea1cf96f05?source=collection_archive---------3-----------------------#2021-06-07">https://towardsdatascience.com/5-minutes-cheat-sheet-explaining-all-machine-learning-models-3fea1cf96f05?source=collection_archive---------3-----------------------#2021-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3a52" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">没有时间深入研究流行的机器学习模型？</h2><div class=""/><div class=""><h2 id="f61e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">解释最重要的机器学习模型</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/5526c727c132fb9a9fc40c6720e8aad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AB5ATpgQdCoyaFGe"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">马库斯·温克勒在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="fbbc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">很多时候，恰好你过几天就要面试了，你的日程排得满满的准备。或者可能你正处于修订模式，想看看所有基本的流行机器学习模型。如果是这样的话，你来对地方了。在这篇博客中，我将简要解释一些在采访中最常被问到的机器学习模型。我还将列出与每个模型相关的重要参数，以及找到同一主题的详细解释的来源，因此如果需要，您可以更深入地了解。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="me mf l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://giphy.com/" rel="noopener ugc nofollow" target="_blank">吉菲</a></p></figure><p id="0bb7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">机器学习模型可以大致分为监督学习和非监督学习两类。在监督学习中，我们有两大类回归和分类。接下来的几节将对它们进行简要的解释，让您有必要的了解。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mg"><img src="../Images/5095c2ae4a92ecae5706da3cc814baf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q1zJuy-lHSkvVOYJXCltTg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">分类(按作者分类的图片)</p></figure><blockquote class="mh mi mj"><p id="969f" class="li lj mk lk b ll lm kd ln lo lp kg lq ml ls lt lu mm lw lx ly mn ma mb mc md im bi translated">注意:我提供的是模型，我认为这是最常见的模型，应该在接受任何数据科学采访之前准备好。然而，这个列表是主观的。</p></blockquote><h1 id="36b0" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">监督学习</h1><p id="cba8" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">在监督学习中，用于训练模型的数据被“标记”。这意味着每个输入的输出是已知的。例如，如果您的模型试图预测房价，您可能会有一些变量，如房子的大小、楼层数等。当您的数据被标记时，这意味着您还有一个包含房价的变量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nl"><img src="../Images/19954103ade427b05e449689d876181b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A5foGcLM0nAYPMxWHgJTlQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">监督学习的例子。作者图片</p></figure><p id="ce1f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面的例子是为了回归。现在让我们仔细看看回归和分类。</p><h1 id="d25a" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">分类</h1><p id="eeea" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">在分类中，模型的输出是离散的。例如，考虑狗与猫的图像分类，其中我们预测图像是否包含狗或猫的家庭。类别(这是模型的输出)在这里将是离散的，即狗或猫。现在，我们将浏览常用于分类的模型。</p><h2 id="f6f0" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">逻辑回归</h2><p id="f1a9" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">不要迷茫；名字中有“回归”二字，但用于分类。逻辑回归使用一个方程来创建数据曲线，然后使用该曲线来预测新观察的结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/96d1c4d98442f2a490f0d8c52f5b4553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DT5V8kFSqglaMQPGkhRiA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">逻辑回归(图片由作者提供)</p></figure><p id="cd24" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">实质上，创建了一个逻辑等式，使得输出值只能在0和1之间。</p><p id="dffb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详细</strong> <strong class="lk jd">解说</strong><a class="ae lh" rel="noopener" target="_blank" href="/logistic-regression-explained-9ee73cede081">T5】此处 </a></p><h2 id="46c4" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">支持向量机</h2><p id="0433" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">支持向量机(SVM)在用于分类的数据点之间形成边界。例如，在2维的情况下，SVM将创建一个边界，使得一个类的大部分数据点落在边界的一侧，而另一个类的大部分数据点落在另一侧。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/23b655fbe87cff9715efb0ad91f6054e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*gtQRTftftbA1sNPrfzQ8sg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">SVM(修改后的<a class="ae lh" href="https://commons.wikimedia.org/wiki/File:Svm_max_sep_hyperplane_with_margin.png" rel="noopener ugc nofollow" target="_blank">图片</a>带CC牌照)</p></figure><p id="06f8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以SVM的目标是找到最大化利润的边界(如上图所示)。</p><p id="d008" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">重要参数/概念</strong> —内核、C、伽玛、余量</p><p id="2254" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详细解释</strong> <a class="ae lh" href="https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72" rel="noopener"> <strong class="lk jd">此处</strong> </a></p><h2 id="0337" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">决策图表</h2><p id="c0c0" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">在决策树中，你基本上是问一些关于你的观察的问题，并沿着树向下直到你得到一个结果，如下所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/fe6c0981cbafa97917d97be7d3ded738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hxchw-ZEheXogRTVlJZRlA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">决策树(图片由作者提供)</p></figure><p id="a54f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的例子中，每个正方形被称为一个<strong class="lk jd">节点，</strong>，这里的节点数量越多，将导致数据集上的模型越过度拟合。</p><p id="7f64" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">重要参数/概念</strong> —节点、叶节点、熵、信息增益</p><p id="73b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详细解释</strong> <a class="ae lh" href="https://www.saedsayad.com/decision_tree.htm" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">此处</strong> </a></p><h2 id="0252" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">随机森林</h2><p id="227b" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">它是一种集成学习技术，使用多个决策树来给出最终输出。随机森林基于原始数据集的<a class="ae lh" href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/" rel="noopener ugc nofollow" target="_blank">引导数据集</a>创建多个决策树，并在决策树的每一步随机选择变量的子集。在推理过程中，我们得到所有决策树的输出，最后，我们选择具有最多票数的输出。随机森林通常比决策树更受欢迎，因为它们可以防止过度拟合。</p><p id="03d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">重要参数/概念</strong> —决策树的数量、引导数据的大小、随机森林特征的数量，以及决策树部分提到的所有其他内容。</p><p id="a090" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详细解释</strong> <a class="ae lh" rel="noopener" target="_blank" href="/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205"> <strong class="lk jd">这里的</strong> </a> <strong class="lk jd"> </strong>(也包括其他的合奏方法)</p><h2 id="a284" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">朴素贝叶斯</h2><p id="e0ff" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">这个模型需要很强的概率基础。它的工作是基于贝叶斯定理。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/03d88fd93c5b42a658b760329f8b6594.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/1*EmuTEwEeyfkqUBJbfWXuPw.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="2f81" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基本上，我们试图找出“给定一个输入(X)，一个特定输出(y)的概率是多少”。我们假设每个输入变量都是相互独立的，所以P(X|y)可以写成</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/98e5358116ab26b30eeceba0649e3c15.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/1*kHjTdlMR_jzC7IM0YTzN0A.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="6c8b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，对于所有可能的输出(0，1)，P(X)(出现在分母中)将保持不变。所以我们对所有可能的输出计算P(y|X)，概率最高的输出将是模型的最终预测。</p><p id="e169" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详解</strong> <a class="ae lh" rel="noopener" target="_blank" href="/naive-bayes-explained-9d2b96f4a9c0"> <strong class="lk jd">此处</strong> </a></p><h2 id="e40a" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">神经网络</h2><p id="470a" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">当今最基本的机器学习模型之一。它被称为神经网络，因为它是模仿我们大脑中神经元的工作方式而设计的。神经网络发现数据集中的模式，有时甚至人类都无法识别。它们非常强大，非常有用，尤其是在处理图像、文本和音频时。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/f5e457791d6c095ee71b939419234e42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*CRDQ3JctdRL7SRAnkrJARw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">神经网络(图片来自<a class="ae lh" href="https://commons.wikimedia.org/wiki/File:Neural_network.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a>带CC许可)</p></figure><p id="9aed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上图中，前两个圆圈表示输入图层，中间5个圆圈表示隐藏图层，最后一个黄色圆圈表示输出图层。隐藏层中的每个节点代表一个线性函数和一个激活函数。</p><p id="ab9f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">重要参数/概念— </strong>学习率、损失函数、反向传播、激活函数。</p><p id="4be4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详细解释</strong> <a class="ae lh" rel="noopener" target="_blank" href="/first-neural-network-for-beginners-explained-with-code-4cfd37e06eaf"> <strong class="lk jd">此处</strong> </a></p><h1 id="a61d" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">回归</h1><p id="8f3b" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">在回归中，模型的输出是连续的。例如，考虑房价预测，我们根据房子的大小和层数来预测房子的价格。这个房价将是一个连续的变量，而不是离散的。</p><h2 id="73d7" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">线性回归</h2><p id="b149" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">它类似于逻辑回归。这里我们试图找到一条最符合数据的线。然后，该最佳拟合线用于预测新的数据点。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/3c4a1dc6daa82deb322112839236eb38.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*BDIA6zfqhqd5iaM4i6RxdA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">线性回归(图片来自<a class="ae lh" href="https://commons.wikimedia.org/wiki/File:Linear_regression.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="8c22" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">线性回归只不过是直线或平面的方程。该等式包含每个输入变量的系数，反映每个输入变量对输出的敏感度。</p><p id="def9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">重要参数/概念— </strong>回归系数</p><p id="6611" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详解</strong> <a class="ae lh" rel="noopener" target="_blank" href="/linear-regression-explained-d0a1068accb9"> <strong class="lk jd">此处</strong> </a></p><p id="ce97" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">可用于回归任务的其他重要模型有决策树、随机森林、神经网络等。因为上面我已经讲过了，所以我现在就跳过它们。</p><h1 id="ea47" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">无监督学习</h1><p id="6ba4" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">在无监督学习中，用于训练模型的数据是“未标记的”。这意味着你只有输入。在无监督学习中，我们试图仅基于输入数据来发现模式。无监督学习中使用的两种主要方法包括聚类和降维。</p><h2 id="21a4" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">使聚集</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/356ec13c7f02e7ac8b3f22ca45a223bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*JKMhSIEtZgC6XVkSgavXeA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">聚类(图片由<a class="ae lh" href="https://commons.wikimedia.org/wiki/File:DBSCAN-density-data.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a>提供CC许可)</p></figure><p id="9e3f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">聚类包括基于某些标准对数据点进行分组或聚类。它用于客户细分、欺诈检测、文档分类等。</p><p id="12a2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一些常见的聚类技术包括k均值聚类、层次聚类、均值漂移聚类和基于密度的聚类。虽然每种技术在寻找聚类时使用不同的标准，但它们都旨在实现相同的目标。</p><p id="74b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详解</strong><a class="ae lh" rel="noopener" target="_blank" href="/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68">T5】此处 </a></p><h2 id="e9c3" class="nm mp it bd mq nn no dn mu np nq dp my lr nr ns na lv nt nu nc lz nv nw ne iz bi translated">降维</h2><p id="b23a" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">它包括通过寻找/提取一组更重要的变量来减少所考虑的输入变量的数量。有两种方法通过特征消除或特征提取来减少输入特征。</p><p id="7fab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最著名的降维方法之一是基于特征提取的主成分分析(PCA)。</p><p id="e231" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">详细解释</strong> <a class="ae lh" href="https://medium.com/@raghavan99o/principal-component-analysis-pca-explained-and-implemented-eeab7cb73b72" rel="noopener"> <strong class="lk jd">此处</strong> </a></p><h1 id="e0c2" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">结论</h1><p id="dc3d" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">我希望这种总结所有重要机器学习模型的尝试对你们所有人都有用。如果你认为有任何改进的余地，或者你想要一个关于任何其他模型的解释，请让我知道。如果你想了解更多关于机器学习的话题，请关注我们的<a class="ae lh" href="https://medium.com/@AnveeNaik" rel="noopener"> medium </a>。</p><p id="c6af" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mk">成为</em> <a class="ae lh" href="https://medium.com/@AnveeNaik/membership" rel="noopener"> <em class="mk">介质会员</em> </a> <em class="mk">解锁并阅读介质上的许多其他故事。</em></p></div></div>    
</body>
</html>