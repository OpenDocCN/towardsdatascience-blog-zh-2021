<html>
<head>
<title>Automatically Parse any Document</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动解析任何文档</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/auto-parse-and-understand-any-document-5d72e81b0be9?source=collection_archive---------17-----------------------#2021-07-01">https://towardsdatascience.com/auto-parse-and-understand-any-document-5d72e81b0be9?source=collection_archive---------17-----------------------#2021-07-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7d91" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于文档布局解析的基于Train Detectron2的定制模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6ca400ed893d3e4497f0e96eb38d6f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dc63KJapDFxivyeoksWEDg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://github.com/Layout-Parser/layout-parser/blob/master/.github/example.png" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的<a class="ae kv" href="https://layout-parser.github.io/" rel="noopener ugc nofollow" target="_blank">布局解析器</a>解析</p></figure><p id="cab0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated">自从人类首次开发出书面文字以来，文档就无处不在。杂志、协议、历史档案、当地商店的小册子、税单、房契、大学申请表等等。到目前为止，处理这些文档一直是一项相当手工的任务，自动化只是在最近几十年才开始接管。这一自动化之旅在很大程度上受到了一个致命缺陷的阻碍——计算机无法像人类那样直观地理解布局。</p><p id="9199" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着现代计算机视觉的出现，这一切都改变了。我们现在有了<a class="ae kv" href="https://github.com/Layout-Parser/layout-parser/blob/master/docs/notes/modelzoo.md" rel="noopener ugc nofollow" target="_blank">模型</a>，它可以准确地定位、表示和理解文档布局的组件。但是对于一般的自动化爱好者来说，这些模型相当抽象，通常需要全面的Python知识才能理解文档，更不用说在项目中使用它了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/b17299f413fa34f99e7f6c767c65efd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*TJrHkouC2GvocDgVPhokdQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学分:<a class="ae kv" href="https://layout-parser.github.io/" rel="noopener ugc nofollow" target="_blank">布局解析器</a></p></figure><p id="863e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种程度上，<a class="ae kv" href="https://pypi.org/project/layoutparser/" rel="noopener ugc nofollow" target="_blank">布局解析器</a>，正如在他们非常酷的<a class="ae kv" href="https://arxiv.org/pdf/2103.15348.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中所解释的，通过一个干净的API减轻了这种复杂性，该API允许并实现完整的端到端布局检测、解析和理解，只需要几行代码(我的意思是非常少，比如5行)。他们有一堆可以直接开箱使用的<a class="ae kv" href="https://github.com/Layout-Parser/layout-parser/blob/master/docs/notes/modelzoo.md" rel="noopener ugc nofollow" target="_blank">型号</a>。总之是一个超级酷的工具。</p><h1 id="edd8" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated"><strong class="ak">现在，除了预训练模型的功能之外，如何使用该工具来理解和处理定制布局？</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/26f76f9037f1d77ce314c71ea87c0d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1vMzOHtusP88Wzz0L5F2tw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><blockquote class="mv mw mx"><p id="86d2" class="kw kx my ky b kz la jr lb lc ld ju le mz lg lh li na lk ll lm nb lo lp lq lr ij bi translated">显而易见的想法是在您的定制布局上微调现有的布局模型。</p></blockquote><p id="7240" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你是对的，这是最好的办法，特别是考虑到我们并不是所有人都有从头开始训练这种模型所需的硬件火力。</p><p id="f39e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated">虽然微调过程比仅仅使用预先训练的模型在技术上更复杂一些，但是由<a class="ae kv" href="https://pypi.org/project/layoutparser/" rel="noopener ugc nofollow" target="_blank">布局解析器</a>的作者创建的一个方便的<a class="ae kv" href="https://github.com/Layout-Parser/layout-model-training" rel="noopener ugc nofollow" target="_blank">库</a>，通过大量处理训练/微调活动中不合理的部分，有助于缓解这些问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/14840c3a89332b5aab8ff86b9d0588e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/1*c5cS72gecmtJSNUD3QfoFA.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Gareth Fowler 在Tumblr<a class="ae kv" href="https://gifsofprocesses.tumblr.com/post/160274145124/nautilus-gears" rel="noopener ugc nofollow" target="_blank">上发布的GIF</a></p></figure><p id="e467" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">在接下来的章节中，我们将通过一个全面的教程来使用</strong> <a class="ae kv" href="https://github.com/Layout-Parser/layout-model-training" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">这个库</strong> </a> <strong class="ky ir">来训练你自己的定制模型。</strong></p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="7927" class="mc md iq bd me mf nk mh mi mj nl ml mm jw nm jx mo jz nn ka mq kc no kd ms mt bi translated">先决条件</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9abacad07a83cfab384e396f3f57722e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*86SnJ0zzd3QNQHMLE4gqcg.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://www.linkedin.com/in/navanshu-agarwal/" rel="noopener ugc nofollow" target="_blank">纳万舒·阿加瓦尔</a></p></figure><ol class=""><li id="cec8" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">Python ≥ 3.6</li><li id="224d" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><a class="ae kv" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">探测器2 </a>从<a class="ae kv" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">主分支</a>分叉或克隆而来。*</li><li id="795e" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">最新版本的<a class="ae kv" href="https://pypi.org/project/layoutparser/" rel="noopener ugc nofollow" target="_blank">布局解析器</a>及其依赖项。</li><li id="d303" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">Pytorch (Linux: 1.6+或Windows: 1.6)**</li><li id="a934" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">CUDA工具包:10+(与Pytorch兼容)***</li><li id="053b" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">数据集:以<a class="ae kv" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>格式标注。</li></ol><h2 id="d516" class="oe md iq bd me of og dn mi oh oi dp mm lf oj ok mo lj ol om mq ln on oo ms op bi translated">警告</h2><p id="1fd0" class="pw-post-body-paragraph kw kx iq ky b kz oq jr lb lc or ju le lf os lh li lj ot ll lm ln ou lp lq lr ij bi translated">* <a class="ae kv" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"> Detectron2 </a>不容易安装在Windows系统上，请参考<em class="my"> ivanapp </em>的这篇<a class="ae kv" href="https://ivanpp.cc/detectron2-walkthrough-windows/#step3installdetectron2" rel="noopener ugc nofollow" target="_blank">精彩帖子</a>以获得基于Windows的安装过程的指导。</p><p id="85d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">* *尽管<a class="ae kv" href="https://detectron2.readthedocs.io/tutorials/install.html" rel="noopener ugc nofollow" target="_blank">官方文档</a>中推荐使用1.8，但Windows用户应该坚持使用1.6。</p><p id="8df6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">***CUDA不是强制性的，理论上也可以在CPU上训练。尽管如此，这样的训练尝试将会非常缓慢。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="26f8" class="mc md iq bd me mf nk mh mi mj nl ml mm jw nm jx mo jz nn ka mq kc no kd ms mt bi translated">步骤1:基本设置</h1><ul class=""><li id="6dde" class="nq nr iq ky b kz oq lc or lf ov lj ow ln ox lr oy nw nx ny bi translated">将<a class="ae kv" href="https://github.com/Layout-Parser/layout-model-training" rel="noopener ugc nofollow" target="_blank">布局模型训练</a>库克隆或分支到您的系统中。</li><li id="bbfc" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated">打开命令/anaconda提示符并激活环境，其中安装了<a class="ae kv" href="https://pypi.org/project/layoutparser/" rel="noopener ugc nofollow" target="_blank">布局解析器</a>和<a class="ae kv" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjx2tnXp7zxAhXVvp4KHQYJAbgQFjAJegQIBRAD&amp;url=https%3A%2F%2Fai.facebook.com%2Fblog%2F-detectron2-a-pytorch-based-modular-object-detection-library-%2F&amp;usg=AOvVaw1LG6fe39i41xY1II3rd3GJ" rel="noopener ugc nofollow" target="_blank">检测器2 </a>。</li><li id="6844" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated">将工作目录更改为保存<a class="ae kv" href="https://github.com/Layout-Parser/layout-model-training" rel="noopener ugc nofollow" target="_blank">布局-模型-训练</a>报告的位置。</li></ul><h1 id="45b9" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">步骤2:拆分数据集(可选)</h1><ul class=""><li id="caa6" class="nq nr iq ky b kz oq lc or lf ov lj ow ln ox lr oy nw nx ny bi translated">打包在<a class="ae kv" href="https://github.com/Layout-Parser/layout-model-training" rel="noopener ugc nofollow" target="_blank">布局-模型-训练</a> repo中的是一个内置脚本(<code class="fe oz pa pb pc b">utils\cocosplit.py</code>)，用于将数据集分割成测试和训练子集。</li><li id="35cb" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated">该脚本确保在数据集中不存在标记区域的图像的情况下，训练和测试子集中标记图像与未标记图像的比率将是相等的。</li><li id="994d" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated">使用以下命令分割数据集(假设工作目录与上一步中的指示一致)。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="36a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="my">请注意，以上命令是在基于Windows 10的系统上执行的，请根据操作系统更改路径分隔符。</em></p><h2 id="cb74" class="oe md iq bd me of og dn mi oh oi dp mm lf oj ok mo lj ol om mq ln on oo ms op bi translated">论据解释</h2><ul class=""><li id="2c50" class="nq nr iq ky b kz oq lc or lf ov lj ow ln ox lr oy nw nx ny bi translated"><em class="my"> annotation_path </em>:合并数据集所在的路径。</li><li id="c047" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated"><em class="my">训练</em>和<em class="my">测试</em>:训练/测试数据集应该保存的路径。</li><li id="4b67" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated"><em class="my">分割比</em>:分配给训练的合并数据集的分数。</li></ul><h1 id="ea6f" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">步骤3:下载预训练模型</h1><ul class=""><li id="f03c" class="nq nr iq ky b kz oq lc or lf ov lj ow ln ox lr oy nw nx ny bi translated">从布局解析器的<a class="ae kv" href="https://github.com/Layout-Parser/layout-parser/blob/master/docs/notes/modelzoo.md" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">模型动物园</strong> </a>下载一个预先训练好的模型及其相关配置文件。</li><li id="8187" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated">下载包含两个文件:</li></ul><ol class=""><li id="cf4d" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated"><em class="my"> model_final.pth </em>:这是预训练模型的权重。</li><li id="b7e1" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><em class="my"> config.yaml </em>:这是预训练模型的配置。有关配置文件的信息，请参考<a class="ae kv" href="https://detectron2.readthedocs.io/en/latest/modules/config.html#config-references" rel="noopener ugc nofollow" target="_blank"> <em class="my">检测器2文档</em> </a> <em class="my">。</em></li></ol><h1 id="c589" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">步骤4:训练模型</h1><p id="e95b" class="pw-post-body-paragraph kw kx iq ky b kz oq jr lb lc or ju le lf os lh li lj ot ll lm ln ou lp lq lr ij bi translated">既然数据集已被分割，预训练的模型权重也已下载，让我们进入有趣的部分:<strong class="ky ir"> <em class="my">模型训练</em> </strong>(或者更确切地说是微调)。</p><ul class=""><li id="bf2a" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr oy nw nx ny bi translated">使用<code class="fe oz pa pb pc b">tools\train_net.py</code>处的训练脚本完成训练</li><li id="130f" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated">使用下面的命令来训练模型。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="1881" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="my">请注意，以上命令是在基于Windows 10的系统上执行的，请根据操作系统更改路径分隔符。</em></p><h2 id="e215" class="oe md iq bd me of og dn mi oh oi dp mm lf oj ok mo lj ol om mq ln on oo ms op bi translated">论据解释</h2><ul class=""><li id="44b3" class="nq nr iq ky b kz oq lc or lf ov lj ow ln ox lr oy nw nx ny bi translated"><em class="my"> dataset_name </em>:自定义数据集的名称(可以随意命名)。</li><li id="3b77" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated"><em class="my"> json_annotation_train </em>:训练标注的路径。</li><li id="bb17" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated"><em class="my"> json_annotation_val </em>:测试注释的路径。</li><li id="7b2f" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated"><em class="my">图像_路径_训练</em>:训练图像的路径。</li><li id="0653" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated"><em class="my"> image_path_val </em>:测试图像的路径。</li><li id="a499" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr oy nw nx ny bi translated"><em class="my"> config-file </em>:步骤3下载的模型配置文件的路径。</li></ul><p id="688e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="my">注意，其余的参数-值对实际上是配置修改，并且特定于用例(有时)。为了清楚地了解如何使用和设置它们，请参考</em> <a class="ae kv" href="https://detectron2.readthedocs.io/en/latest/modules/config.html#config-references" rel="noopener ugc nofollow" target="_blank"> <em class="my">检测器2文档</em> </a> <em class="my">。</em></p><ul class=""><li id="e5d9" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr oy nw nx ny bi translated">微调后的模型及其配置文件、训练指标和日志将保存在输出路径中，如上面命令中的<code class="fe oz pa pb pc b">OUTPUT_DIR</code>所示。</li></ul><h1 id="3fd6" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">第五步:推理</h1><p id="fcf1" class="pw-post-body-paragraph kw kx iq ky b kz oq jr lb lc or ju le lf os lh li lj ot ll lm ln ou lp lq lr ij bi translated">有了finetuned模型，使用它来解析文档就成了一项简单的任务。</p><ul class=""><li id="72ca" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr oy nw nx ny bi translated">在<a class="ae kv" href="https://pypi.org/project/layoutparser/" rel="noopener ugc nofollow" target="_blank">布局解析器</a>的演示中，用以下代码替换模型初始化。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="9846" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="my">请注意，以上路径基于基于Windows 10的系统，请根据操作系统更改路径分隔符。</em></p><ul class=""><li id="83e7" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr oy nw nx ny bi translated"><code class="fe oz pa pb pc b">custom_label_map</code>是<code class="fe oz pa pb pc b">int_label -&gt; text_label</code>的映射。这种映射是根据训练数据的<a class="ae kv" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO Json </a>中存在的<code class="fe oz pa pb pc b">'categories'</code>字段以如下方式进行的:每个<code class="fe oz pa pb pc b">category</code>对应<code class="fe oz pa pb pc b">{'id': 'name'}</code>。例如:</li></ul><p id="0c75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe oz pa pb pc b">custom_label_map = {0: "layout_class_1", 1: "layout_class_2"}</code></p><h1 id="3874" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">结论</h1><p id="8379" class="pw-post-body-paragraph kw kx iq ky b kz oq jr lb lc or ju le lf os lh li lj ot ll lm ln ou lp lq lr ij bi translated">总而言之，可以使用<a class="ae kv" href="https://github.com/Layout-Parser/layout-model-training" rel="noopener ugc nofollow" target="_blank">布局-模型-训练</a> repo轻松训练任何数据集上的定制模型。这种模型可以用于解析和理解各种各样的文档，并且在训练后相对容易。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="c191" class="mc md iq bd me mf nk mh mi mj nl ml mm jw nm jx mo jz nn ka mq kc no kd ms mt bi translated">参考</h1><p id="0228" class="pw-post-body-paragraph kw kx iq ky b kz oq jr lb lc or ju le lf os lh li lj ot ll lm ln ou lp lq lr ij bi translated">[1] Y. Wu，a . a .，F. Massa，W. Y. Lo和R. Girshick，<a class="ae kv" href="https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/" rel="noopener ugc nofollow" target="_blank"> Detectron2 </a>:提供最先进的检测和分割算法的人工智能研究的下一代库(2019)，<a class="ae kv" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"> GitHub Repo </a></p><p id="f269" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]沈，张，戴尔，李，卡尔森和李，【LayoutParser:一个基于深度学习的文档图像分析的统一工具包】(T5)(2021)，arXiv预印本arXiv:2103.15348</p><p id="525d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] T. S. Lin，M. Maire，S. Belongie，L. Bourdev，R. Girshick，J. Hays，p .佩罗娜，D. Ramanan，C. L. Zitnick和P. Dollár，<a class="ae kv" href="https://arxiv.org/abs/1405.0312" rel="noopener ugc nofollow" target="_blank">微软COCO:上下文中的共同对象</a> (2015)，arXiv预印本arXiv:1405.0312v3</p></div></div>    
</body>
</html>