<html>
<head>
<title>Deep Dive: Artificial Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深潜:人工神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-dive-artificial-neural-network-e77aa627dc1b?source=collection_archive---------37-----------------------#2021-07-26">https://towardsdatascience.com/deep-dive-artificial-neural-network-e77aa627dc1b?source=collection_archive---------37-----------------------#2021-07-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="881b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">人工神经网络中涉及的完整解释和数学</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8ad8c59dac9af0a9c2295ab385957d8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bhnfIM_g43t0RwAw"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">蒙罗工作室在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="cd19" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">什么是安？</h1><p id="1c31" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">ANN代表人工神经网络。就像人类拥有BNN即生物神经网络一样，研究人员试图复制人脑的工作，并提出了人工神经网络的伟大发明。它是一种机器学习算法，现在广泛应用于各个领域。无论是检测COVID和癌症等疾病，还是检测图像中的人体姿势。安什么都做。这是迄今为止机器学习研究最多的部分之一。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/5d59342c01773d943e1554f24bb2baf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gOVohxvQXI1AgC20iDY15Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure><p id="46d4" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">最小级别的人工神经网络称为感知器。感知器也称为阈值逻辑单元(TLU)。它由单个单元组成，也称为神经元，具有多个输入和单个输出。这是一种最简单的人工神经网络结构。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/af0ea1f21925b3056b25b491ce0211ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZVGcY9ADaAyXzSOjGWlQ4Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)TLU(阈值逻辑单元)的结构</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/9f88e3bcad7521d3fc5d7081aa1e7b21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RKNGs9QPv2dOC4v0VXKR2g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)具有偏差的多感知器网络的表示。</p></figure><p id="d878" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">为了理解以下感知器模型，将神经元/单元的输入视为数据集的特征，您将在其他机器学习算法中输入这些特征。看看感知器的图表，输入通过称为权重的线与神经元相连。当输入被传递时，它们被单独乘以它们的权重，并且所有这些乘法的总和被传递到阶跃函数上以产生输出。阶跃函数用于提供以下计算的输出。有时，偏差也被添加到输入或TLU，以向右或向左偏移加权和的结果。这有助于模型更好地适应数据，因为它不仅可以调整网络的权重，还可以调整网络的偏差，使网络适应所需的数据集。因此，神经网络输出的计算公式为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/2d15f9b9d243643d84144b1ba4a0a680.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/1*e_i7RiSQGWKUD_649BkDoQ.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)计算简单图层的输出。</p></figure><p id="0e0d" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">其中phi是激活函数，X是输入矩阵，W是权重矩阵，B是偏差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/5a73aeb28e71b862ecc07d918f557fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*K9DC7gjMuypGo7xhmn0KpQ.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)感知机中使用的Heavyside step/ activation函数。</p></figure><p id="f3a2" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">当模型有一个输入层、多个隐藏层和一个输出层时，这就是所谓的MLP(多层感知器)。它的工作类似于感知器，但输入连接到第一层的一些权重，这些权重连接到其他一些输出神经元的一些权重。与感知器类似，首先，输入乘以它们的权重，然后相加传递给阶跃函数。然后，所有神经元的这个阶跃函数的输出乘以权重并相加。然后将其传递到阶跃函数，以获得网络的输出。</p><p id="569c" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">当您组合多个神经元以形成深度神经元层并将这些层堆叠成深度堆叠模型时，则该模型被称为人工神经网络。人工神经网络属于深度学习部分，是当今使用最多的算法之一。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="b69c" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">如何训练一个ANN？</strong></h1><p id="911c" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">使用称为反向传播的算法来训练人工神经网络。首先，采用单个训练实例，并执行正向传递以产生输出。然后将网络损耗与实例的实际输出进行比较。然后这种损失通过整个神经网络反向传播。在反向传播的这一步骤中，首先计算损失的梯度，因为我们必须使损失最小化。然后，计算网络的每个权重矩阵的梯度，并且通过减去η(即网络的学习速率)和损失函数的梯度的乘积来更新权重矩阵。接下来的过程一直持续到最后一层，这个步骤被称为反向传播算法的反向传递。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/70637327e411ab740d2a4f4b121f9e91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*QQihxh4A0gq83xqH1LPdWQ.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)人工神经网络的训练</p></figure><p id="f260" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">人工神经网络可以有单个输出，甚至多个输出。所有训练实例通过网络的单次向前和向后传递被称为单个时期。学习复杂模式所需的深度神经网络必须执行各种时期以获得良好的预测结果。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="b010" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">什么是步进/激活功能？</strong></h1><p id="94e8" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">阶跃/激活函数用于给网络增加非线性。如果网络的输出没有非线性，那么网络可能无法预测复杂的模式。因此，激活功能也用于此目的。使用的一些激活功能有:</p><ol class=""><li id="f411" class="nc nd iq lx b ly ms mb mt me ne mi nf mm ng mq nh ni nj nk bi translated">ReLU(整流线性单位)激活功能</li><li id="ffe4" class="nc nd iq lx b ly nl mb nm me nn mi no mm np mq nh ni nj nk bi translated">Sigmoid激活函数</li><li id="7638" class="nc nd iq lx b ly nl mb nm me nn mi no mm np mq nh ni nj nk bi translated">Tanh激活函数</li></ol><p id="23fa" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">还有更多……</p><blockquote class="nq"><p id="aebf" class="nr ns iq bd nt nu nv nw nx ny nz mq dk translated">ReLU激活功能</p></blockquote><figure class="ob oc od oe of kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4170ef9aef32c84fc6a803d19e6eb722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*c9mvKz2R4wi6L_SCJw2CWw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)ReLU激活函数的表示</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/b2aff9cf03aec5b22cc53d8f3f4632f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*KaoU62yqhihtWk7YJjdppg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)ReLU激活函数的数学表示</p></figure><blockquote class="nq"><p id="2a31" class="nr ns iq bd nt nu oh oi oj ok ol mq dk translated">Sigmoid激活函数</p></blockquote><figure class="ob oc od oe of kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/0381f14d10e815d351b726e3fb053815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*Q0KgF9Q5WRI0SVVe8-lbFQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)Sigmoid激活函数的表示</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/86b985229d152fae2f86a915278d87a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*DwGPsr9PrhGPjXBPPD8QAA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)Sigmoid激活函数的数学表示</p></figure><blockquote class="nq"><p id="c8b0" class="nr ns iq bd nt nu oh oi oj ok ol mq dk translated">Tanh激活函数</p></blockquote><figure class="ob oc od oe of kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/1a8851fe0e00027fbd1b7299766d88aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*J0kU8hqc2i-wUZlYUKEqpQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)Tanh激活函数的表示</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/f3cd3162f17502d08de62d6de377edc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*Q2XeIb-JOaROw4s5S4LXdw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)Tanh激活函数的数学表示</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="da1f" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">安在回归</strong></h1><p id="798c" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">回归分析中的人工神经网络有助于预测房价或某个对象边界框的坐标。在基于回归的人工神经网络中，通常不使用激活函数来防止值处于激活函数的范围内。用于训练神经网络的损失函数是均方误差或均方根误差。大多数情况下使用均方误差和均方根误差，但在异常值的情况下，使用平均绝对误差，因为它有助于减少异常值的影响。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/63391e9886d767ddc236f3d70267ca38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*egrSv4rcP5f0TDZMXmhtWQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="694c" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">人工神经网络分类</h1><p id="9a21" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">分类中的人工神经网络有助于根据提供的输入值预测类别。从分类狗或猫到分类复杂的人类情感，人工神经网络在各种问题中都有应用。当有2个类别要预测时，我们甚至可以使用具有单个输出和逻辑激活函数的神经网络作为最后一层的激活函数。当我们有多个类别要预测时，如果我们希望所有类别的输出值都等于1，我们可以使用softmax激活函数。交叉熵损失函数可用于训练网络。在多类分类中，我们必须为每个类分配一个神经元。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/0ea1d7161c985d770f0fd5b91f361319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*BkVego7ftP-fYAqFb4HGPA.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="78e5" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">参考</h1><ol class=""><li id="98ea" class="nc nd iq lx b ly lz mb mc me oo mi op mm oq mq nh ni nj nk bi translated">使用Scikit-Learn、Keras和TensorFlow进行机器学习，第二版，Aurélien Géron，2019年</li><li id="406d" class="nc nd iq lx b ly nl mb nm me nn mi no mm np mq nh ni nj nk bi translated">麻省理工6。S191:深度学习介绍，【https://www.youtube.com/playlist? T2】list = PLT bw 6 njqru-rwp 5 _ _ 7c 0 oivt 26 zgjg 9 ni</li></ol></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><p id="5f0b" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">我希望这篇文章和解释对你有用。请继续关注后续部分中的其他分段技术。</p><p id="d73a" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated">请随时联系并给出你的建议:【https://www.linkedin.com/in/mrinal-tyagi-02a1351b1/ T4】</p><p id="5798" class="pw-post-body-paragraph lv lw iq lx b ly ms jr ma mb mt ju md me mu mg mh mi mv mk ml mm mw mo mp mq ij bi translated"><a class="ae kv" href="https://github.com/MrinalTyagi" rel="noopener ugc nofollow" target="_blank">https://github.com/MrinalTyagi</a></p></div></div>    
</body>
</html>