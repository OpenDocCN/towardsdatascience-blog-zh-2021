<html>
<head>
<title>Detecting Mask On/Off Or Incorrectly Worn Using Yolo-V4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Yolo-V4 检测面罩开/关或佩戴不当</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-mask-on-off-or-incorrectly-worn-using-yolo-v4-c27911e4eadd?source=collection_archive---------26-----------------------#2021-11-16">https://towardsdatascience.com/detecting-mask-on-off-or-incorrectly-worn-using-yolo-v4-c27911e4eadd?source=collection_archive---------26-----------------------#2021-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="94f7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用计算机视觉解决当前现实世界的问题。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4575fac92260932b096e0b86f19ccd6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DRtHhPwedAf9oDRR"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Yoav Aziz 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4658" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">至少对我们大多数人来说，过去的两年是超现实的。这些天来，你环顾四周，无论你在世界的哪个角落，都有可能看到有人戴着面具。</p><p id="659e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特别是，如果你来自对戴口罩有严格要求的城市或国家，你可能会看到大多数人戴口罩，很少有人会戴错，有些人甚至根本不戴。我想看看机器视觉算法是否能完成完全相同的工作，而不是用一个权威单位来管理这个地区。</p><p id="b9cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【https://github.com/kmt112/probable-lamp】Github 回购:<a class="ae ky" href="https://github.com/kmt112/probable-lamp" rel="noopener ugc nofollow" target="_blank"/></p><p id="906b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据集引用:</strong></p><p id="bd65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原始掩模数据集:<a class="ae ky" href="https://www.kaggle.com/andrewmvd/face-mask-detection" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/andrewmvd/face-mask-detection</a></p><p id="52a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">附加屏蔽数据集:<a class="ae ky" href="https://github.com/cabani/MaskedFace-Net" rel="noopener ugc nofollow" target="_blank">https://github.com/cabani/MaskedFace-Net</a></p><h1 id="d559" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">问题陈述</h1><p id="62b0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">首先，由于机器视觉算法必须能够在实时设置中进行预测，我们需要一种能够在相对较低的 FPS 环境中工作的算法。其次，该模型必须反应迅速，因为人们通常相对较快地超过摄像机视野。因为它必须准确地预测所有三个类别(戴上面具、摘下面具和面具佩戴不正确)。基于 mAP (mean 平均精度)来评价模型会更好。</p><h1 id="a6c5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Yolo-v4</h1><p id="36a3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">根据上面的问题陈述，这使得 yolov4 成为理想的算法。Yolov4 在实时检测(FPS: &gt; 45)方面始终具有较高的平均精度，此外，yolov4 是一个单级对象检测器，因此计算量较轻。有关 YoloV4 性能的更多信息，请参考<a class="ae ky" href="https://blog.roboflow.com/pp-yolo-beats-yolov4-object-detection/" rel="noopener ugc nofollow" target="_blank">https://blog . robo flow . com/PP-yolo-beats-yolov 4-object-detection/</a>。</p><h1 id="26d5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">资料组</h1><p id="330f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">最初使用的数据集来自 T4 大学。该数据集由 800 多张带标签的照片组成。照片数据集也包括团体照片和个人照片。然而，初步的探索性数据分析表明，不同阶层之间存在巨大的阶层不平衡。对于戴错口罩的数据集。因此，有必要增加面罩佩戴不当的等级。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/2e8b5ca3dfcb50ba4aee7dc29b5e0a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/0*RO_WYooEaplKxGH8.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。阶层失衡(图片由作者提供)</p></figure><h2 id="53e5" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">改进数据集</h2><p id="15af" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">巨大的阶级不平衡会导致你的模型在代表性不足的阶级中表现不佳，这就是为什么在训练中不同阶级的平等代表性是重要的。由于 yolo v4 模型只接受适当标签格式的照片，因此需要将 XML 文件格式转换为 TXT 文件格式。此外，还对图像进行了归一化处理，使其对图像分辨率的变化更加鲁棒。</p><p id="0d75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">添加新数据。戴口罩的人和不戴口罩的人很容易区分。然而，确定口罩是否佩戴不当要困难得多。因此，更重要的是包括更多关于不正确佩戴的口罩的数据。虽然在互联网上可以找到许多可用的数据集。我使用了数据集<a class="ae ky" href="https://github.com/cabani/MaskedFace-Net" rel="noopener ugc nofollow" target="_blank"> MaskedFace-Net [1，2] </a>中的数据集。</strong></p><div class="kj kk kl km gt ab cb"><figure class="nf kn ng nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/12ec022f3794490dd0eedda7c02cc2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*udsj9uW2myPdaIGa7-5Agg.jpeg"/></div></figure><figure class="nf kn nl nh ni nj nk paragraph-image"><img src="../Images/7107fbec57482c81efc940ad4ab148ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*888yWPl1zFI9acq15UoVww.png"/><p class="ku kv gj gh gi kw kx bd b be z dk nm di nn no translated">图二。来自屏蔽网络数据集的样本数据(左)，来自 kaggle 的屏蔽和未正确佩戴的样本图像(右)</p></figure></div><p id="4e5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">标记新数据</strong>。不幸的是，没有办法自动化这个过程，因为我希望数据是干净的，我必须物理标记数据和边界框。使用<a class="ae ky" href="https://github.com/Cartucho/OpenLabeling" rel="noopener ugc nofollow" target="_blank">这个</a> python 程序手动标记边界框和类。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="9ecf" class="lv lw it bd lx ly nw ma mb mc nx me mf jz ny ka mh kc nz kd mj kf oa kg ml mm bi translated">数据建模</h1><p id="00bc" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们将利用 COCO 数据集的预训练权重进行迁移学习。这仅在第一次迭代中使用，此后我们将使用您在每个间隔保存的预训练权重。由于 yolo V4 是用 C 和 Cuda 编写的，为了调优超参数，必须在配置文件中完成。我已经上传了一个可以使用的配置文件，我将简要说明我为改进地图所做的更改。</p><ul class=""><li id="2fe7" class="ob oc it lb b lc ld lf lg li od lm oe lq of lu og oh oi oj bi translated"><code class="fe ok ol om on b">width/height </code>:将分辨率大小改为 416，增加 yolov4 的宽度和高度提高了分辨率。</li><li id="a93b" class="ob oc it lb b lc oo lf op li oq lm or lq os lu og oh oi oj bi translated"><code class="fe ok ol om on b">batches </code>:当批次被细分时，这决定了将被并行处理的图像的数量。</li><li id="d32f" class="ob oc it lb b lc oo lf op li oq lm or lq os lu og oh oi oj bi translated"><code class="fe ok ol om on b">saturation = 1.5, Hue = 1.5 </code>:改变饱和度和色调</li><li id="dbea" class="ob oc it lb b lc oo lf op li oq lm or lq os lu og oh oi oj bi translated"><code class="fe ok ol om on b">mosaic = 1 </code>:马赛克数据增强将 4 幅训练图像以一定的比例组合成一幅(而不是 cutmix 中的两幅)。这可以防止过度依赖任何关键功能。</li><li id="bf49" class="ob oc it lb b lc oo lf op li oq lm or lq os lu og oh oi oj bi translated"><code class="fe ok ol om on b">blur = 1 </code>:50%的时间会随机应用模糊。</li><li id="9114" class="ob oc it lb b lc oo lf op li oq lm or lq os lu og oh oi oj bi translated"><code class="fe ok ol om on b">jitter = 0.3</code>:随机改变图像的大小和长宽比。</li></ul><p id="941d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像增强可以从现有的训练数据中创建新的训练样本，因此减少了收集更多数据的需要。这也使得模型对于图像中的扰动更加鲁棒。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="b78c" class="lv lw it bd lx ly nw ma mb mc nx me mf jz ny ka mh kc nz kd mj kf oa kg ml mm bi translated">结果</h1><p id="68bd" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了显示不平衡数据和正确表示的数据之间的差异，我为这两种数据训练了模型。首先，跨地图比较模型。</p><p id="28c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">平均精度平均值</strong></p><div class="kj kk kl km gt ab cb"><figure class="nf kn ot nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/e2b033aab87d3ee961d7f7cfa1817fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*WQc5d6PUTemEF7zh.jpg"/></div></figure><figure class="nf kn ot nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/e1f87aad4f18e83803853aa0b29038b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*z73lqgmqwb31NqXx.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov no translated">图 3。不平衡数据训练(左)，平衡数据训练(右)，作者图片</p></figure></div><p id="19e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两个数据集之间模型性能没有太大差异。事实上，具有更平衡数据的模型在初始迭代中表现稍差。</p><p id="f74e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> IOU 阈值与映射图</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/6cc054928d6854dc75fe0b9c7fa91987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qyxchHxCZLGPq2DL.PNG"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4。IOU 阈值与图的关系，图由作者提供</p></figure><p id="425b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并集上的交集和映射的一个重要区别。也许在这一点上，有必要解释一下 IOU 和 mAP 是什么，以及它们之间的关系。一般来说，mAP 和 IoU 是反向相关的。这是因为 IoU 可以被认为是包围盒的紧密度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/08c05679c71b5546c0e4a6cfae355027.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*rz0KYbUa7QsW5HcN.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5。欠条插图，图片来自<a class="ae ky" href="https://www.mdpi.com/2073-8994/13/2/262/htm" rel="noopener ugc nofollow" target="_blank">https://www.mdpi.com/2073-8994/13/2/262/htm</a></p></figure><p id="a456" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你设置了一个很高的 IoU 阈值，你的模型将不得不定义一个非常精确的边界框。这可以从图 5 中看出，当 IoU 设置为 0.9 时，mAP 显著下降。</p><p id="b756" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结果可视化</strong></p><p id="6b40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一些例子来说明当不同的类达到平衡时模型的表现。</p><div class="kj kk kl km gt ab cb"><figure class="nf kn ot nh ni nj nk paragraph-image"><img src="../Images/2e91783acb44a76b69f5d5cb4c8e632f.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*on3txDQoxxg7BbP0.jpg"/></figure><figure class="nf kn ot nh ni nj nk paragraph-image"><img src="../Images/e6f133535547ca20a7a3cdffd1965bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*jndVL9zCXYyX51Pp.jpg"/><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov no translated">图 6。旧型号(左)和新型号(右)，作者图片</p></figure></div><div class="ab cb"><figure class="nf kn ot nh ni nj nk paragraph-image"><img src="../Images/ea60cb852234f983eff256636731c4a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*ypYzJMRqoHk1rSyp.jpg"/></figure><figure class="nf kn ot nh ni nj nk paragraph-image"><img src="../Images/ad68f09af15ab3544ed717f610d032e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*1tnVSxrdeOSDSl_s.jpg"/><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov no translated">图 7。旧型号(左)和新型号(右)，作者图片</p></figure></div><p id="73c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当更多面具佩戴不正确的照片被添加到训练模型中时，该模型在检测面具是否佩戴正确方面表现得明显更好。当比较新旧模型时，这一点在图 5 中也很明显。</p><p id="cfeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">快速部署时间</strong></p><p id="0ad8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型在处理单个帧中的大量类时也没有困难。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/dfb20668b33da5835f7126b5766464af.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*wGiyYmLMmCxagVnhESXh6w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 8。许多人的预测，图片来自 Kaggle</p></figure></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="e2ac" class="lv lw it bd lx ly nw ma mb mc nx me mf jz ny ka mh kc nz kd mj kf oa kg ml mm bi translated">结论</h1><p id="9ae4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">总的来说，Yolo-V4 的表现比预期的要好，不仅结果很好，而且部署和验证也很快。虽然我最初的计划是在现实生活中部署这一点，但我当地的公共交通提供商抢先一步，在公交和火车站部署了一个 CV 解决方案。</p><p id="1a49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">展望未来，我在 yolo-v4 上遇到的一个问题是我不熟悉配置文件、C 和 Cuda 编程语言。由于对 python 和 pytorch 更加熟悉，我认为 yolo-v5 可以让我更好地理解并调整参数来改进我的模型。</p><p id="3cd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也就是说，本教程大量引用了原版 darknet github repo<a class="ae ky" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank">https://github.com/pjreddie/darknet</a>的内容。</p><h2 id="5c83" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">参考</h2><ol class=""><li id="fc58" class="ob oc it lb b lc mn lf mo li oz lm pa lq pb lu pc oh oi oj bi translated">Adnane Cabani、Karim Hammoudi、Halim Benhabiles 和 Mahmoud Melkemi，“新冠肺炎背景下正确/不正确遮盖面部图像的数据集”，《智能健康》，ISSN 2352–6483，Elsevier，2020 年，<a class="ae ky" href="https://doi.org/10.1016/j.smhl.2020.100144" rel="noopener ugc nofollow" target="_blank">DOI:10.1016/j . smhl . 2020 . 100144</a></li><li id="0606" class="ob oc it lb b lc oo lf op li oq lm or lq os lu pc oh oi oj bi translated">Karim Hammoudi、Adnane Cabani、Halim Benhabiles 和 Mahmoud Melkemi，“通过自拍验证防护面罩的正确佩戴:设计一个移动应用程序“CheckYourMask”以限制新冠肺炎病毒的传播”，CMES——工程与科学中的计算机建模，第 124 卷，第 3 期，第 1049-1059 页，2020 年，<a class="ae ky" href="https://www.techscience.com/CMES/v124n3/39927" rel="noopener ugc nofollow" target="_blank">DOI:10.32604/cmes . 2020 . 1663</a></li></ol></div></div>    
</body>
</html>