<html>
<head>
<title>One-dimensional CNN for human behavior classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于人类行为分类的一维CNN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/one-dimensional-cnn-for-human-behavior-classification-fb4371d03633?source=collection_archive---------14-----------------------#2021-11-17">https://towardsdatascience.com/one-dimensional-cnn-for-human-behavior-classification-fb4371d03633?source=collection_archive---------14-----------------------#2021-11-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a4cb" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="7612" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一个循序渐进的教程，介绍如何将CNN整合到时间序列数据中</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/88bc6b7c8d5c92ae7688e7244c324f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2udrNb9kSSGVikIyFaLgMQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@whatyouhide?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">安德里亚·莱奥帕尔迪</a>在<a class="ae lh" href="https://unsplash.com/s/photos/running?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="82ad" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我在Medium上的第一篇<a class="ae lh" rel="noopener" target="_blank" href="/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7">出版物</a>是对卷积神经网络(CNN)的深入研究。在那篇文章中，我一步一步地介绍了如何使用这种技术进行医学图像分类。这是任何<em class="me">数据爱好者</em>的武器库中的一个强大工具，重要的是要认识到CNN并不局限于计算机视觉任务。今天，我将向您展示这项技术如何适用于一维顺序数据。</p><p id="90af" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">CNN可以适应1D的数据，这不应该太令人震惊。毕竟，图像也是一系列数据。唯一的区别是二维结构(或彩色图像的三维结构)。这种灵活性使其适用于各种应用，其中一些在这里<a class="ae lh" href="https://arxiv.org/ftp/arxiv/papers/1905/1905.03554.pdf" rel="noopener ugc nofollow" target="_blank">列出</a>。</p><p id="c4e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天这篇文章的目标是为您提供工具，在您可能感兴趣的任何顺序数据集上实现这一技术。我们将看看如何将我们的网络设置为一个连续的多头模型，并比较结果。如果你想跟随我的笔记本，你可以在这里找到它。现在，事不宜迟，让我们开始吧！</p><h1 id="9bbd" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated"><strong class="ak">图书馆</strong></h1><p id="0ea2" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">下面，你会发现我今天的分析所使用的库的列表。它们由标准数据科学工具包、sklearn的一个缩放器和必要的keras/tensorflow库组成。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="f5a8" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">数据</h1><p id="161f" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">今天的<a class="ae lh" href="https://www.kaggle.com/gaurav2022/mobile-health" rel="noopener ugc nofollow" target="_blank">数据集</a>是Kaggle的<strong class="lk jd">移动健康人类行为分析</strong>拥有CC0:公共领域许可证。它由10名参与者的右手腕和左脚踝上的Shimmer2可穿戴传感器组成。每个传感器收集x、y和z平面上的加速度和旋转速度，产生12个预测变量。</p><p id="b96f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些变量将用于将参与者的行为归类为以下12种活动之一:</p><ul class=""><li id="41ec" class="ne nf it lk b ll lm lo lp lr ng lv nh lz ni md nj nk nl nm bi translated">静止站立(1分钟)</li><li id="e288" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">坐着放松(1分钟)</li><li id="5a59" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">躺下(1分钟)</li><li id="2245" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">步行(1分钟)</li><li id="914d" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">爬楼梯(1分钟)</li><li id="5f25" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">向前折叠(20倍)</li><li id="730a" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">手臂正面图(20x)</li><li id="b524" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">蹲伏(20倍)</li><li id="5212" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">骑自行车(1分钟)</li><li id="2370" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">慢跑(1分钟)</li><li id="8ee6" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">跑步(1分钟)</li><li id="4013" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">前后跳跃(20x)</li></ul><p id="ecde" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">原始数据集还包含心电图和磁力计的数据，但在Kaggle版本中不可用。这让我决定不再坐卧活动。其原因是由于缺少磁力计数据，没有这些数据，站立的<strong class="lk jd">、<strong class="lk jd">、</strong>和<strong class="lk jd">、</strong>将没有加速度和旋转速度，使他们无法区分。</strong></p><p id="9a48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">结果是以下数据集:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="26d8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们稍微研究一下我们的数据，看看我们会发现什么。使用<strong class="lk jd"> df.info() </strong> <em class="me"> </em>可以让我们快速了解我们的数据框架。这里我们看到我们有一个非常整洁的数据集，没有丢失值。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="7098" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们将使用<strong class="lk jd"> df查看分类变量。Activity.value_counts() </strong>。有趣的是，我们引入了一个新的类0，这在Kaggle数据描述中没有提到。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="3700" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因为我不知道这个类指的是什么，我决定用<strong class="lk jd">df = df[df]把它放逐到数字炼狱。活动！= 0].</strong></p><p id="a825" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">帮助我们的模型学习的最后一步是使用下面的代码创建均匀的组大小。这将减少过多/过少的代表性影响我们的模型的机会。它也不会损害模型，因为我们没有删除有价值的信息。毕竟，无论是20秒还是1小时，跑步看起来都应该是一样的(假设跑步者没有摔倒)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="c043" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">分割、缩放和整形</h1><p id="3a69" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">我们需要做的最后一件事是准备数据集，使其格式适合我们的神经网络。下面的代码可以用来分割和缩放数据。让我们来解开它所说的。</p><p id="bfe3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">前两个模块将我们的数据集分成70%用于训练，30%用于测试。我还进一步将数据分为X(预测/特征)和y(结果)变量。您也可以使用sklearn的t <a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> rain_test_split </a>获得相同的结果。</p><p id="1ae3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在最后两个模块中，我们正在缩放数据。对于预测值，sklearn的<a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank">最小最大缩放器</a>用于转换我们的数据，以适应0到1的范围。它通过将每个值减去最小值，然后除以范围<strong class="lk jd"> (x -min)/(max -min) </strong>来实现。</p><p id="1430" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用Keras '<a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical" rel="noopener ugc nofollow" target="_blank">to _ categorial</a>函数对结果变量进行一次性编码。这将我们的类转换成一个1 * N的二进制矩阵(其中N是类的数量)。当类没有有序性时，这是一个重要的步骤。如果您的数据具有有序的结构(即温度、年龄、质量)，您可以考虑使用顺序编码器，而不是一次性编码器。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="ef37" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的CNN对输入数据的形状有一定的要求。下面，您将看到我们如何将数据重塑为3d输入块，从而将预测值和输出组织到窗口中。选择50的窗口大小是因为用于收集Kaggle上描述的数据的加速度计和陀螺仪的50Hz采样率。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="d248" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有了适当格式的数据，我们现在可以构建分类模型了！</p><h1 id="6cd1" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">美国有线新闻网；卷积神经网络</h1><h2 id="7e81" class="ns mg it bd mh nt nu dn ml nv nw dp mp lr nx ny mr lv nz oa mt lz ob oc mv iz bi translated">连续的</h2><p id="6d52" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">构建神经网络是一个高度迭代的过程，需要微调多个超参数以优化结果。它还包括尝试各种架构。今天我们将从建立一个连续的CNN开始。它将由2个卷积层、1个下降层、1个最大汇集层、1个展平层、1个密集连接层和我们的分类层组成(图1)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/34a653fad59adad5c8dc2cc8ca20c29b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*BJuDEzALnZR45J2579g-0g.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图1 —顺序CNN模型的网络架构</p></figure><p id="37ef" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以构建一个硬编码的模型，并在每次试验后对其进行调整，或者您可以构建一个函数来连续运行多次试验，如下面的代码所示。我从<a class="ae lh" href="https://machinelearningmastery.com/" rel="noopener ugc nofollow" target="_blank">杰森·布朗利</a>那里学到了这个，这是一个很好的省时方法。</p><p id="1258" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的代码中，我们定义了一个函数<em class="me"> fit_evaluate_model </em>，它将(你猜对了！)拟合并评估我们的模型。注意第2行，除了<em class="me"> n_filters之外，输入还期望我们的X和y训练/测试集。</em>使用上述架构，我们将评估以下过滤图【8，16，32，64，128，256】。我们将继续调整模型，因此，当我们调整内核大小和辍学率时，性能最佳的过滤器映射将被硬编码到下一轮中，正如您将看到的那样。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="b24d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每个试验将运行10次迭代，每次迭代的批量为32。使用单独的函数<em class="me"> performance_summary </em>，我们将收集结果并绘制出来。每个过滤图将运行5次，然后我们将计算这些试验的平均值和标准偏差，以确定我们的获胜者(下面的第4-6行)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="eeb8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，函数<em class="me"> run_trials </em>将把上面的所有东西联系在一起，并运行我们请求的试验。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="5e28" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这组试验的结果可以在下面看到。随着过滤图的增加，性能有提高的趋势。这种增加似乎在32个过滤图附近趋于平稳。最佳点似乎是64个过滤贴图，这导致了最高的性能和最低的方差，这意味着它是最稳定的。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="f11f" class="ns mg it of b gy oj ok l ol om">Param=8: 60.379% (+/-3.593)<br/>Param=16: 65.084% (+/-2.929)<br/>Param=32: 71.039% (+/-5.879)<br/>Param=64: 73.601% (+/-2.396)<br/>Param=128: 72.013% (+/-5.594)<br/>Param=256: 70.702% (+/-5.059)</span></pre><p id="b055" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有了最佳过滤图的概念，我们接下来将看看如何调整内核大小。如果你对这些超参数不清楚，别忘了看看我在开头链接的文章。还有许多其他的好资源，但是我深入研究了架构、优化器、激活函数和超参数，并给出了每一个的例子。</p><p id="86bd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大部分代码保持不变，如下图所示，但是，您可以在第2行看到一个新变量，<em class="me"> n_kernel </em>，它表示我们将在这里评估的内核大小[2，3，5，7，11]。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="c2b4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些试验的结果如下所示。看起来较小的内核获取了有用的信息来区分我们的类，我们的较大内核丢失了。虽然这些值变化不大，但是使用内核大小为3会给我们带来最好的结果。也就是说，这并没有提高我们第一次试验的准确性。让我们看看是否可以通过改变我们的辍学做得更好！</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="e0d2" class="ns mg it of b gy oj ok l ol om">Kernel=2: 73.285% (+/-4.676)<br/>Kernel=3: 73.585% (+/-4.133)<br/>Kernel=5: 69.066% (+/-1.468)<br/>Kernel=7: 62.953% (+/-3.858)<br/>Kernel=11: 65.167% (+/-2.749)</span></pre><p id="25bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的代码中，这将是序列模型的最后一组试验，我们测试的是辍学率[0.1，0.3，0.5，0.7，0.9]。重申一下，这里我们硬编码了tope执行过滤器映射(64)和内核大小(3)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="57ed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些试验的结果如下所示。虽然我们将整体性能提高了2%，但这并不是因为我们操纵了什么。对于之前的每个试验，随机选择0.5的退出率。观察到的改进是由于这些算法的随机性质。通常，你会发现人们在他们的模型中添加参数<em class="me">【随机状态】</em>，以确保他们得到一个可复制的结果。我选择不包括这一点，因为它可以让我们了解我们的模型到底有多稳定。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="552a" class="ns mg it of b gy oj ok l ol om">Dropout=0.1: 74.934% (+/-2.552)<br/>Dropout=0.3: 74.862% (+/-5.299)<br/>Dropout=0.5: 75.111% (+/-5.832)<br/>Dropout=0.7: 72.981% (+/-4.504)<br/>Dropout=0.9: 72.297% (+/-2.313)</span></pre><h2 id="5411" class="ns mg it bd mh nt nu dn ml nv nw dp mp lr nx ny mr lv nz oa mt lz ob oc mv iz bi translated">多头CNN</h2><p id="ec33" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">作为上述顺序模型的替代，本节将提供一种使用CNN的不同方法。使用多头CNN允许您并行添加多个不同的参数。从每个输入中学习到的信息在被馈送到最终的密集层和随后的分类层之前被合并(连接)。</p><p id="cea6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了帮助可视化这个过程，请参考图2。三个独立的头部被用作输入，每个头部由不同的过滤器贴图、内核大小和漏失组成。在每个输入被展平后，它们被连接并馈入密集层。最后，将合并后的结果输入分类层。让我们看看这对我们的准确性有什么影响！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/c5af55fd7c20b8a419c4a5a1caab0a70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adp7vIjTBf7nVt6NZfVLAg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图2 —多头CNN模型的网络架构</p></figure><p id="e457" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如您在下面看到的，代码并没有改变太多。不同之处在于如何定义各种输入，每个输入都有不同的参数。第一个输入有256个过滤贴图，内核大小为2，丢失率为0.5。第二个输入有128个过滤图，内核大小为3，丢失率为0.3。最后，最后一个输入有64个过滤图，内核大小为5，丢失率为0.1。</p><p id="ab7c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如上图所示，每个输出都被展平(第25行)，然后连接起来。剩下的和顺序模型类似，合并后的输出馈入有100个神经元的密集层，再馈入分类层。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="d0f3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">多头方法的结果如下所示。使用五次试验的平均值，我们看到我们的性能(72%)略低于我们使用顺序模型观察到的性能(75%)。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="c415" class="ns mg it of b gy oj ok l ol om">&gt;#1: 71.229<br/>&gt;#2: 71.903<br/>&gt;#3: 72.020<br/>&gt;#4: 69.389<br/>&gt;#5: 74.481<br/>Accuracy: 71.804% (+/-1.636)</span></pre><h1 id="7a21" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">摘要</h1><p id="ab78" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">在今天的帖子中，我们使用一维CNN对生物传感器测量的人类活动进行分类。我们使用顺序和多头方法浏览了示例。我们还研究了如何操作过滤图、内核大小和辍学率，看看我们是否可以提高模型的准确性。</p><p id="a7b7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们以75%的准确率完成了测试，这还不算太差，但也没什么值得大书特书的。当然，也有办法改善我们的结果。在下一篇文章中，我将向您展示如何将CNN的优势与另一位序列/时间序列数据专家结合起来。</p><p id="ed5a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢今天的帖子！下次见，感谢阅读！</p></div></div>    
</body>
</html>