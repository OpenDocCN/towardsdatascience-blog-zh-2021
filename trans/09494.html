<html>
<head>
<title>PyTorch Geometric Graph Embedding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch几何图形嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-geometric-graph-embedding-da71d614c3a?source=collection_archive---------9-----------------------#2021-09-03">https://towardsdatascience.com/pytorch-geometric-graph-embedding-da71d614c3a?source=collection_archive---------9-----------------------#2021-09-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4a04" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用<strong class="ak"> PyTorch几何</strong>模块中的SAGEConv嵌入图形</h2></div><p id="f5e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图形表示学习/嵌入通常是用于将图形数据结构转换为更结构化的向量形式的过程的术语。这通过提供更易管理的固定长度向量来实现下游分析。理想情况下，除了节点特征之外，这些向量还应包含图结构(拓扑)信息。我们使用图形神经网络(CNN)来执行这种转换。要对GNNs有一个基本的高级概念，您可以看一下下面的文章。</p><div class="lb lc gp gr ld le"><a rel="noopener follow" target="_blank" href="/what-can-you-do-with-gnns-5dbec638b525"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">你能用GNNs做什么</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">图形神经网络的操作、效用和优势</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">towardsdatascience.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls lt le"/></div></div></a></div><p id="9b05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我将讨论GraphSAGE架构，它是消息传递神经网络(MPNN)的一种变体。MPNN是一个描述gnn如何有效实现的奇特术语。</p><h1 id="db5e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">广义GNN表示</h1><p id="9add" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">任何MPNN都可以用两个函数<strong class="kh ir">集合</strong>和<strong class="kh ir">组合</strong>来正式表示。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mr"><img src="../Images/4249dc2c020088381d3490edaa64b917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vyx4jAF3wvFSUg5Y.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">作者引用的等式(<a class="ae ng" href="https://arxiv.org/pdf/1810.00826.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1810.00826.pdf</a>)</p></figure><p id="35ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">聚合</strong>函数控制如何为给定节点收集或聚合邻居信息。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mr"><img src="../Images/c96bdc68a0cd6de92c64d3de4ccb8bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HDV42nsRCV0khzs0.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">作者引用的等式(<a class="ae ng" href="https://arxiv.org/pdf/1810.00826.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1810.00826.pdf</a>)</p></figure><p id="4c80" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> combine </strong>函数控制节点本身的信息如何与来自邻居的信息相结合。</p><h1 id="d4d6" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">图表法</h1><p id="7c23" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">GraphSAGE代表图形样本和集合。让我们首先定义GraphSAGE的聚合和组合函数。</p><p id="4053" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">合并</strong> —使用相邻要素的元素均值</p><p id="aa84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">聚合</strong> —将聚合的特征与当前节点特征连接起来</p><h1 id="1f32" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">图形解释</h1><p id="fadd" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">GraphSAGE层可以直观地表示如下。对于给定的节点v，我们使用平均聚合来聚合所有邻居。结果与节点v的特征连接在一起，并通过多层感知(MLP)以及类似RELU的非线性反馈。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nh"><img src="../Images/ca4ad22822393bb18bb7dfe76c345b5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gc4Tjy9JHwqMIJ8v0ZW9Sg.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">作者图片</p></figure><p id="85ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">人们可以很容易地使用PyTorch geometric这样的框架来使用GraphSAGE。在我们开始之前，让我们建立一个用例来继续。嵌入图形的一个主要重要性是可视化。因此，让我们用GraphSAGE构建一个GNN来可视化Cora数据集。请注意，这里我使用的是<a class="ae ng" href="https://github.com/rusty1s/pytorch_geometric/blob/master/examples/graph_sage_unsup.py" rel="noopener ugc nofollow" target="_blank"> PyTorch几何知识库</a>中提供的例子，没有什么技巧。</p><h1 id="2367" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">图表用法细节</h1><p id="dc5a" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">GraphSAGE的核心思想是采样策略。这使得该架构能够扩展到非常大规模的应用。采样意味着，在每一层，仅使用最多<strong class="kh ir"> K </strong>个邻居。像往常一样，我们必须使用一个顺序不变的聚合器，如均值、最大值、最小值等。</p><h1 id="5d28" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">损失函数</h1><p id="7956" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">在图形嵌入中，我们以无人监督的方式操作。因此，我们使用图的拓扑结构来定义损失。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi ni"><img src="../Images/c147e7dca288bfea6bbe2eeae3e45cc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0aO-UKB6fG7B-iXKwxLDgA.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">来自GraphSAGE论文:【https://arxiv.org/pdf/1706.02216.pdf T2】</p></figure><p id="33ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里<strong class="kh ir"> Zu </strong>展示了节点<strong class="kh ir"> u </strong>的最终层输出。<strong class="kh ir"> Zvn </strong>表示负采样节点。简单来说，等式的第二项表示负(节点<strong class="kh ir"> u </strong>和任意随机节点<strong class="kh ir"> v </strong>)的求反点积应该最大化。换句话说，随机节点的余弦距离应该更远。对于节点<strong class="kh ir"> v </strong>来说，第一项说的是另外一种情况，这是一个我们需要嵌入得更靠近<strong class="kh ir"> u </strong>的节点。这个<strong class="kh ir"> v </strong>被称为正节点，通常使用从<strong class="kh ir"> u </strong>开始的随机行走来获得。<strong class="kh ir"> Evn~Pn(v) </strong>表示负节点取自负采样方法。在实际实现中，我们将直接邻居作为正样本，随机节点作为负样本。</p><h1 id="1633" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">构建图嵌入网络</h1><p id="cd80" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">我们可以从导入以下python模块开始。</p><pre class="ms mt mu mv gt nj nk nl nm aw nn bi"><span id="72c7" class="no lv iq nk b gy np nq l nr ns">import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>from torch_cluster import random_walk<br/>from sklearn.linear_model import LogisticRegression</span><span id="6c0e" class="no lv iq nk b gy nt nq l nr ns">import torch_geometric.transforms as T<br/>from torch_geometric.nn import SAGEConv<br/>from torch_geometric.datasets import Planetoid<br/>from torch_geometric.data import NeighborSampler as<br/>                                    RawNeighborSampler</span><span id="a4e6" class="no lv iq nk b gy nt nq l nr ns">import umap<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><p id="acd6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">初始化Cora数据集；</p><pre class="ms mt mu mv gt nj nk nl nm aw nn bi"><span id="7fd1" class="no lv iq nk b gy np nq l nr ns">dataset = 'Cora'<br/>path = './data'<br/>dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())<br/>data = dataset[0]</span></pre><p id="41e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，dataset对象是一个子图列表。对于Cora，我们有一个，所以我们选择索引为0的图。</p><p id="ed45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">采样器组件(这里我们扩展NeighborSampler类的sample方法，用正负样本创建批次)；</p><pre class="ms mt mu mv gt nj nk nl nm aw nn bi"><span id="8eb4" class="no lv iq nk b gy np nq l nr ns"># For each batch and the adjacency matrix<br/>pos_batch = random_walk(row, col, batch, <br/>                          walk_length=1,<br/>                          coalesced=False)[:, 1]<br/># row are source nodes, col are target nodes from Adjacency matrix<br/># index 1 is taken as positive nodes</span><span id="8959" class="no lv iq nk b gy nt nq l nr ns"># Random targets from whole adjacency matrix<br/>neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ),<br/>                                  dtype=torch.long)</span></pre><p id="8fb8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">GNN可以在PyTorch宣布如下；</p><pre class="ms mt mu mv gt nj nk nl nm aw nn bi"><span id="7144" class="no lv iq nk b gy np nq l nr ns">class SAGE(nn.Module):<br/>    def __init__(self, in_channels, hidden_channels, num_layers):<br/>        super(SAGE, self).__init__()<br/>        self.num_layers = num_layers<br/>        self.convs = nn.ModuleList()<br/>        <br/>        for i in range(num_layers):<br/>            in_channels = in_channels if i == 0 else hidden_channels<br/>            self.convs.append(<strong class="nk ir">SAGEConv(in_channels,<br/>                                   hidden_channels)</strong>)</span><span id="0bd1" class="no lv iq nk b gy nt nq l nr ns">    def forward(self, x, adjs):<br/>        for i, (edge_index, _, size) in enumerate(adjs):<br/>            x_target = x[:size[1]]  <br/>            x = self.convs[i]((x, x_target), edge_index)<br/>            if i != self.num_layers - 1:<br/>                x = x.relu()<br/>                x = F.dropout(x, p=0.5, training=self.training)<br/>        return x</span><span id="0419" class="no lv iq nk b gy nt nq l nr ns">    def full_forward(self, x, edge_index):<br/>        for i, conv in enumerate(self.convs):<br/>            x = conv(x, edge_index)<br/>            if i != self.num_layers - 1:<br/>                x = x.relu()<br/>                x = F.dropout(x, p=0.5, training=self.training)<br/>        return x</span></pre><p id="70b3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，我们使用PyTorch几何框架中的SAGEConv层。在前向传递中，邻居采样器为我们提供要在每一层中传递的数据作为数据索引。这是一个相当复杂的模块，所以我建议读者阅读论文(第12页)中的<a class="ae ng" href="https://arxiv.org/pdf/1706.02216.pdf" rel="noopener ugc nofollow" target="_blank"> Minibatch算法和PyTorch Geometric </a>中的<a class="ae ng" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html?highlight=neighborsampler#torch_geometric.data.NeighborSampler" rel="noopener ugc nofollow" target="_blank"> NeighborSampler模块文档。</a></p><h1 id="1144" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">形象化</h1><p id="f0f2" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">在没有使用图形结构的情况下，下面是UMAP图。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nu"><img src="../Images/6b32bf9cfa241139595272ee409406b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bi13WLSwH3EYdg9RwVbxfQ.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">作者图片</p></figure><p id="7aab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们使用GraphSAGE嵌入时，我们可以有如下更好的嵌入:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nu"><img src="../Images/532df1d6d5655f266ef2f30a220c8c69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lVva9W-35XcljMR7c4Mngg.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">作者图片</p></figure><p id="bb40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，与朴素UMAP嵌入相比，这些嵌入要好得多，并且分离得很好。然而，这并不完美，需要更多的工作。但我希望这是一个足够好的演示来传达这个想法。😊</p><p id="5ebb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望你喜欢这篇文章！</p><p id="9111" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整的代码和Jupyter笔记本可从<a class="ae ng" href="https://gist.github.com/anuradhawick/904e7f2d2101f4b76516d04046007426" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p></div></div>    
</body>
</html>