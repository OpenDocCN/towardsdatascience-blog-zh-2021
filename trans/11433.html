<html>
<head>
<title>Building Python Microservices with Apache Kafka: All Gain, No Pain</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Apache Kafka 构建 Python 微服务:一分耕耘一分收获</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-python-microservices-with-apache-kafka-all-gain-no-pain-1435836a3054?source=collection_archive---------6-----------------------#2021-11-10">https://towardsdatascience.com/building-python-microservices-with-apache-kafka-all-gain-no-pain-1435836a3054?source=collection_archive---------6-----------------------#2021-11-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a8ad356ab988816e5156a440eb4cf9d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oxAVA1wPSVWVfq16rvb6ow.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://ru.freepik.com/premium-photo/abstract-background-with-the-movement-of-luminous-particles-digital-technology-connection-concept_16582967.htm#page=1&amp;position=5&amp;from_view=user#position=2" rel="noopener ugc nofollow" target="_blank"> freepik </a>的<a class="ae jd" href="https://ru.freepik.com/mrjo-7" rel="noopener ugc nofollow" target="_blank"> mrjo_7 </a></p></figure><div class=""/><p id="b9a5" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">工程师在日常工作中经常使用阿帕奇卡夫卡。Kafka 执行的主要任务是:阅读消息、处理消息、将消息写到一个主题，或者在一定时间内聚合消息。窗口可以是固定的(例如每小时聚合)或滑动的(例如从某个时间点开始的每小时聚合)。</p><p id="d891" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴于 Kafka 作品的复杂性，我不建议您尝试从头构建自己的解决方案。微调、测试和支持将非常困难。幸运的是，有现成的实现，比如 Kafka Streams for Java 和 Kafka Streams for Python——由<a class="ae jd" href="https://robinhood.com/us/en/" rel="noopener ugc nofollow" target="_blank"> Robinhood </a>编写的<a class="ae jd" href="https://github.com/robinhood/faust" rel="noopener ugc nofollow" target="_blank"> Python Faust </a>。该团队还有一个社区支持的分支— <a class="ae jd" href="https://github.com/faust-streaming/faust" rel="noopener ugc nofollow" target="_blank">浮士德流媒体</a>。</p><p id="caef" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文分享了我在<a class="ae jd" href="https://provectus.com/" rel="noopener ugc nofollow" target="_blank"> Provectus </a>使用 Apache Kafka 构建异步 Python 微服务进行“通信”的经验。<a class="ae jd" href="https://faust.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Faust </a>，一个将 Kafka 流的思想移植到 Python 的流处理库，被用作微服务基础。Faust 还为间隔任务和调度任务提供了一个 HTTP 服务器和一个调度程序。在一个测试实现中，我将使用 FastAPI、Grafana 和 Prometheus 等工具和库。</p><h2 id="b7ee" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">浮士德</h2><p id="4e01" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">浮士德是<a class="ae jd" href="https://kafka.apache.org/documentation/streams/" rel="noopener ugc nofollow" target="_blank">卡夫卡流</a>在 Python 上的实现。它最初由 Robinhood 开发，现在仍被用作高性能分布式系统和实时数据管道的默认库。</p><p id="fd6d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该库适用于 Python 3.6+和 Kafka 0.10.1+，并支持各种数据存储、数据收集和加速模块。Faust 使您能够利用常见的 Python 库，如 NumPy、SciPy、TensorFlow、SQLAlchemy 等。</p><h2 id="e5f8" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">项目架构</h2><p id="d5ba" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我相信要真正学会如何做一件事，你应该一步一步地去做。下面是我们将要构建的一个简单测试项目的架构图。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lz"><img src="../Images/71a113dbce29066b15cbf159e7716614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ABNIBsrkyKTXjCuA"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="ca2c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测试数据将在<em class="me">演示服务器</em>微服务中编译，而<em class="me">数据请求者</em>微服务将每秒请求数据。<em class="me">数据请求者</em>是我们 Faust 系统中的第一个微服务。一旦数据被请求，<em class="me">data _ requestor</em>会将回复推送给 Kafka。然后，这个消息被<em class="me"> data_processor </em>读取、处理并推回给 Kafka。随后，它被<em class="me"> data_aggregator </em>和<em class="me"> db_loader </em>读取，其中第一个微服务计算平均值，第二个微服务将它们加载到数据库中。<em class="me"> db_loader </em>还加载由<em class="me"> data_aggregator </em>生成的消息。同时，当用户请求时，<em class="me"> api_gateway </em>可以从数据库中提取数据。使用 Prometheus 监控所有活动，并可在 Grafana 中可视化。该项目和附加服务在<em class="me"> docker-compose </em>推出。</p><h2 id="29eb" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第一步。基础设施设置</h2><p id="de32" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">因为我们将使用<em class="me"> docker-compose </em>加速项目，所以描述所有第三方服务是有意义的。我们将需要 Apache Kafka，一个数据库，一个管理仪表板来管理它，以及几个<a class="ae jd" rel="noopener" target="_blank" href="/overview-of-ui-tools-for-monitoring-and-management-of-apache-kafka-clusters-8c383f897e80">监控服务</a> (Prometheus 和 Grafana)。让我们使用 Postgres 作为我们的数据库，使用 PgAdmin 作为它的管理和监控组件。</p><p id="8d86" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个阶段，我们的<a class="ae jd" href="https://github.com/KrasnovVitaliy/microservice_in_python/blob/main/01_infrastructure/docker-compose.yml" rel="noopener ugc nofollow" target="_blank"> docker-compose.yml </a>看起来是这样的:</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="d932" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="me"> docker-compose，</em>与基础设施、配置和附加脚本一起，存储在存储库的<a class="ae jd" href="https://github.com/KrasnovVitaliy/microservice_in_python/tree/main/01_infrastructure" rel="noopener ugc nofollow" target="_blank">单独文件夹</a>中。</p><h2 id="90db" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">微服务的常见组件</h2><p id="0b82" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">尽管每个服务都有自己的任务，并使用两个不同的库(FastAPI 和 Faust)编写，但它们有几个共同的组件。</p><p id="ef52" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先是基于配置加载器库的配置加载器。它使您能够使用 yaml 文件加载配置，并通过可变的环境重新定义它们的值。这在需要在 docker 容器中重新定义特定值的情况下非常有用。</p><p id="768a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其次是普罗米修斯出口商。您可以使用它来导出数据和指标，并在 Grafana 中显示它们。请记住，它在 FastAPI 和 Faust 中的实现略有不同。</p><h2 id="5017" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第二步。数据仿真微服务</h2><p id="68b2" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">为了测试和演示该系统，我们将使用一个简单的服务，以 JSON 格式返回货币对的值。为此，我们也将使用 FastAPI 库。这项服务和 Flask 一样容易使用，但是它自带了<em class="me"> async </em>和 Swagger UI 文档。可以在这里找到:<a class="ae jd" href="http://127.0.0.1:8002/docs" rel="noopener ugc nofollow" target="_blank">http://127 . 0 . 0 . 1:8002/docs</a></p><p id="e894" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将只为服务指定一个请求:</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="0e50" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面的代码中可以看出，每个请求都返回一个 JSON，其中包含两对随机生成的值。回复可能是这样的:</p><pre class="ma mb mc md gt mh mi mj mk aw ml bi"><span id="dcc6" class="lb lc jg mi b gy mm mn l mo mp">{<br/> “USDRUB”: 85.33,<br/> “EURRUB”: 65.03<br/>}</span></pre><p id="cef6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要监控这些值，请将 Prometheus 添加到系统中。它应该作为<em class="me">中间件</em>添加，并有单独的指定路径。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="87fe" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以在浏览器中查看您的值的指标:<a class="ae jd" href="http://127.0.0.1:8002/metrics" rel="noopener ugc nofollow" target="_blank">http://127 . 0 . 0 . 1:8002/metrics</a></p><h2 id="8161" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第三步。数据请求者微服务</h2><p id="044f" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在 Faust 的帮助下，<em class="me">API _ requestor</em>微服务请求来自演示服务器的数据。因为 Faust 是异步的，我们可以简单地使用<em class="me"> aiohttp </em>客户端来请求测试数据。</p><p id="d49b" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们创建一个 Faust 应用程序。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="bf44" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建应用程序时，请确保指定了它的名称，这是一个必需的参数。如果我们启动几个同名的服务版本，Kafka 将在它们之间分配分区，使我们能够横向扩展我们的系统。接下来，我们需要在<em class="me"> value_serializer </em>中指定消息序列化的方法。在这个例子中，我们可以照原样读取原始的<em class="me">消息，以便随后序列化接收到的消息。我们还应该定义访问 Faust 托管的 HTTP 服务器的地址和端口。</em></p><p id="2989" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们需要定义将要接收来自<em class="me"> demo_server </em>的回复的主题。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="cad4" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一个参数是主题名；这是强制性的。然后，您可以指定分区的数量(可选)。请记住，分区的数量必须与 Kafka 中主题分区的数量相似(在创建主题时指定)。</p><p id="9c1a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，<em class="me">data _ requestor</em>服务并不从主题中读取消息，而是不断地将请求推送到数据模拟器，然后处理回复。要实现这一点，您需要编写一个实时时钟函数，该函数每秒触发一次，或者在指定的时间间隔触发。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="5487" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到该功能是由<em class="me"> @app.timer </em> decorator 周期性执行的。它接收每秒间隔作为参数。然后，该函数为 DataProvider 生成一个类实例，负责提供对请求的回复。在每一个随后的请求之后，普罗米修斯计时器的值增加。如果数据是按请求接收的，它将被发送到一个主题。因为 Kafka 使用特定的键和字节内消息，所以我们需要在将数据推送到主题之前对其进行序列化。</p><p id="ed83" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在启动应用程序时，您还需要初始化 Prometheus。为此，您可以简单地使用启动应用程序时调用的函数。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="a110" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请记住，函数是由<em class="me"> @app.task </em> decorator 分配和定义的。Prometheus 使用自己的端口作为独立的服务器启动，它与 Faust 的 HTTP 服务器并行工作。</p><p id="0cb4" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给你！每秒向 Kafka 发出请求和写入数据并不困难。添加监控组件也可以很快完成。</p><h2 id="28b8" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第四步。数据处理微服务</h2><p id="fa13" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我们的下一个微服务——<em class="me">数据处理器</em>——处理由<em class="me"> api 请求者</em>微服务接收的数据对。应用程序初始化和数据监控的代码与我们用来管理<em class="me">data _ requestor</em>的代码相同。然而，在<em class="me"> data_processor </em>的情况下，服务从主题接收消息来处理它们。可以用函数来完成。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="2d8a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该函数基于<em class="me">@ app . agent(src _ data _ topic)</em>装饰器，该装饰器告诉该函数处理<em class="me"> src_data_topic </em>中的消息。从 stream.items() 的 msg_key，msg_value 的<em class="me">异步读取消息。</em></p><p id="9084" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们需要序列化接收到的消息，并提取货币对及其值。每一对都应该分别写一个相应的主题。</p><h2 id="ad0d" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第五步。数据聚合微服务</h2><p id="8fe9" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">请求和处理数据的微服务以流的形式在 Kafka 中读写数据。每个新消息都独立于以前的消息进行处理。但是，偶尔您可能需要同时处理一定数量的消息。假设您需要找到最后十对值的平均值。为此，你的系统应该能够在某个地方存储这 10 对。您不能在本地存储数据:如果您触发了聚合服务的多个版本，每个版本都将只在本地存储其值，这将导致平均值计算不正确。这里是你可以利用浮士德表的地方。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="fac3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些表将值存储在<em class="me"> changelog </em>主题和本地——rocks db 中。这允许服务的所有版本同步工作。重启后，它从本地数据库恢复状态，当读取可用的<em class="me">变更日志</em>时，它继续工作。</p><p id="caa7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">表的主题名是这样分配的:<service-name> - <table-name> -changelog。在我们的系统中，名称是:data-aggregator-average-changelog。</table-name></service-name></p><p id="72e8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在表中处理和存储新消息非常简单:</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="8d42" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面的代码可以看出，您需要定义函数如何处理主题中的消息。收到的每个新值都应存储在表中，以计算平均值。您可以以类似于标准 Python 字典的方式使用该表。</p><h2 id="b04c" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第六步。数据库加载器微服务</h2><p id="2e6d" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated"><em class="me"> db_loader </em>微服务一次读取两个主题——<em class="me">data-aggregator-average-changelog</em>和<em class="me">processed _ data</em>——两个。它将消息从 data_aggregator 写入第一个主题，从 data_processor 写入第二个主题。这就是为什么我们需要描述消息处理的两个函数。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="9ba1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与其他服务类似，您需要:读取消息，将其存储在数据库中，更新指标。为了管理数据库，我们将使用 ORM SQLAlchemy。请注意，您应该将其设置为异步工作。为此，定义所需的依赖关系。</p><pre class="ma mb mc md gt mh mi mj mk aw ml bi"><span id="8cd2" class="lb lc jg mi b gy mm mn l mo mp">asyncpg==0.23.0<br/>SQLAlchemy==1.4.0</span></pre><p id="ee26" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在配置中指定<em class="me"> DB URI </em>。</p><pre class="ma mb mc md gt mh mi mj mk aw ml bi"><span id="8102" class="lb lc jg mi b gy mm mn l mo mp">DB_URI: “postgresql+asyncpg://postgres:postgres@127.0.0.1:5432/currencies”</span></pre><p id="bf50" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在数据库管理代码中使用异步会话。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="mf mg l"/></div></figure><h2 id="211d" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第七步。结果请求者微服务</h2><p id="04d2" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">最后，让我们使用 FastAPI 创建一个简单的服务，从数据库中请求结果。它将从数据库中读取结果，并将它们推送到 JSON。要管理数据库，可以使用 ORM(就像我们之前做的那样)。至于 FastAPI，说明类似于步骤 2。数据仿真微服务。</p><h2 id="edf9" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">结论</h2><p id="8b6b" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在 Python 上用 Apache Kafka 构建微服务相当简单。你可以把处理和管理卡夫卡的几乎所有工作都交给浮士德。然后，只需描述和定义函数，就能看到它们实时处理您的消息。</p><p id="c231" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望这篇教程能帮助你更好地理解如何将微服务、Apache Kafka 和 Python 结合起来。如果您对 Apache Kafka 中的集群监控和管理感兴趣，我建议您也查看一下本文<a class="ae jd" rel="noopener" target="_blank" href="/overview-of-ui-tools-for-monitoring-and-management-of-apache-kafka-clusters-8c383f897e80"/>。</p><p id="9df1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有什么问题吗？请在评论区联系我进行讨论。</p></div></div>    
</body>
</html>