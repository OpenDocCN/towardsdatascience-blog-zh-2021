<html>
<head>
<title>Developing and Deploying a Machine Learning Model on Vertex AI using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python在顶点人工智能上开发和部署机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python-865b535814f8?source=collection_archive---------7-----------------------#2021-11-08">https://towardsdatascience.com/developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python-865b535814f8?source=collection_archive---------7-----------------------#2021-11-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d7b8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">编写让您的MLOps团队满意的培训渠道</h2></div><p id="46ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">编写让您的MLOps团队满意的ML管道:遵循模型代码和Ops代码之间清晰的责任分离。本文将向您展示如何做到这一点。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/2ca4f118cfd6778d7f9d66e9b68dd581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cwy-tCX8uzLZ53RC6kzFvQ.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">普里西拉·杜·普里兹在<a class="ae lr" href="https://unsplash.com/s/photos/grateful?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="c35a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">为什么要分开责任？</h2><p id="4954" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在我之前关于Vertex AI的两篇文章中，我向您展示了如何<a class="ae lr" rel="noopener" target="_blank" href="/giving-vertex-ai-the-new-unified-ml-platform-on-google-cloud-a-spin-35e0f3852f25">使用web控制台创建和部署AutoML模型</a>，以及如何获取您以某种方式训练的TensorFlow模型并<a class="ae lr" rel="noopener" target="_blank" href="/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56">将其部署到Vertex AI </a>。但是这两种方法都不能真正扩展到数百个模型和大型团队。</p><p id="5b90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当您使用Google Cloud web控制台创建AutoML模型时，您会得到一个可以监控的端点，并且可以在其上设置持续评估。如果你发现模型在漂移，自动根据新数据重新训练它是很困难的——你不会想在凌晨2点醒来使用用户界面来训练模型。如果您可以仅使用代码来训练和部署模型，那就更好了。对于您的MLOps团队来说，代码自动化要容易得多。</p><p id="f038" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将您在Jupyter笔记本中训练的TensorFlow模型部署到Vertex AI也有同样的问题。再培训将是困难的，因为运营团队将不得不设置所有的运营、监控和调度，而这些都是非常笨重且完全非最小化的。</p><p id="78d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于再培训来说，整个过程——从数据集创建到培训再到部署——由代码驱动要好得多。做到这一点，您的运营团队将感谢您让他们的工作变得简单，因为他们清楚地将模型代码与运营代码分开，并且用Python而不是笔记本来表达所有内容。</p><p id="c7b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如何在Vertex AI中获得这种分离是我在本文中要展示给你的。</p><h2 id="f8ef" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">在Python文件中完成</h2><p id="727c" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">Jupyter笔记本非常适合开发，但是我强烈建议不要将这些笔记本直接投入生产(是的，我确实知道<a class="ae lr" href="https://papermill.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Papermill </a>)。</p><p id="23b3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我建议您将最初的原型模型代码转换成Python文件，然后在其中继续所有的开发。扔掉朱庇特笔记本。您将从一个临时笔记本中调用提取(和维护)的Python代码，以供将来试验。</p><p id="89d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在<a class="ae lr" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/tree/edition2/09_vertexai" rel="noopener ugc nofollow" target="_blank">https://github . com/Google cloud platform/data-science-on-GCP/tree/edition 2/09 _ vertexai</a>中看到我的例子。请参见文件model.py和train_on_vertexai.py，并使用它们进行后续操作。</p><h2 id="2844" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">编写模型. py</h2><p id="ad3a" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">文件model.py包含了我的Jupyter笔记本中所有的Keras模型代码(<a class="ae lr" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/edition2/09_vertexai/flights_model_tf2.ipynb" rel="noopener ugc nofollow" target="_blank"> flights_model_tf2.ipynb </a>在同一个GitHub目录下)。不同之处在于它是可执行的，笔记本的大部分代码被提取到一个名为train_and_evaluate.py的函数中:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="0171" class="ls lt iq mr b gy mv mw l mx my">def train_and_evaluate(train_data_pattern, eval_data_pattern, test_data_pattern, export_dir, output_dir):<br/>    ...</span><span id="c6d8" class="ls lt iq mr b gy mz mw l mx my">    train_dataset = read_dataset(train_data_pattern, train_batch_size)<br/>    eval_dataset = read_dataset(eval_data_pattern, eval_batch_size, tf.estimator.ModeKeys.EVAL, num_eval_examples)</span><span id="b102" class="ls lt iq mr b gy mz mw l mx my"><br/>    model = create_model()<br/>    history = model.fit(train_dataset,<br/>                        validation_data=eval_dataset,<br/>                        epochs=epochs,<br/>                        steps_per_epoch=steps_per_epoch,<br/>                        callbacks=[cp_callback])</span><span id="dea1" class="ls lt iq mr b gy mz mw l mx my">    # export<br/>    logging.info('Exporting to {}'.format(export_dir))<br/>    tf.saved_model.save(model, export_dir)</span></pre><p id="9732" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有三点需要注意:</p><ol class=""><li id="1a18" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">数据从分别用于训练、验证和测试数据集的由train_data_pattern、eval_data_pattern和test_data_pattern指定的URIs中读取。</li><li id="ea14" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">模型创建代码提取到一个名为create_model的函数中</li><li id="57ba" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">模型被写出到export_dir，任何其他中间输出被写入output_dir。</li></ol><p id="6228" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据模式和输出目录在model.py中从环境变量中获得:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="5848" class="ls lt iq mr b gy mv mw l mx my">    OUTPUT_DIR = 'gs://{}/ch9/trained_model'.format(BUCKET)<br/>    OUTPUT_MODEL_DIR = os.getenv("AIP_MODEL_DIR")<br/>    TRAIN_DATA_PATTERN = os.getenv("AIP_TRAINING_DATA_URI")<br/>    EVAL_DATA_PATTERN = os.getenv("AIP_VALIDATION_DATA_URI")<br/>    TEST_DATA_PATTERN = os.getenv("AIP_TEST_DATA_URI")</span></pre><p id="3a73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这非常重要，因为它是你的代码和Vertex AI之间的契约，是所有自动发生的事情所需要的。</p><p id="ca1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，您可能需要在Vertex AI之外运行这段代码(例如，在开发期间)。在这种情况下，不会设置环境变量，因此所有变量都是None。寻找这种情况，并将它们设置为您的开发环境中的值:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="9cbf" class="ls lt iq mr b gy mv mw l mx my">    if not OUTPUT_MODEL_DIR:<br/>        OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,<br/>                                        'export/flights_{}'.format(time.strftime("%Y%m%d-%H%M%S")))<br/>    if not TRAIN_DATA_PATTERN:<br/>        TRAIN_DATA_PATTERN = 'gs://{}/ch9/data/train*'.format(BUCKET)<br/>    if not EVAL_DATA_PATTERN:<br/>        EVAL_DATA_PATTERN = 'gs://{}/ch9/data/eval*'.format(BUCKET)</span></pre><p id="b33b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些文件可能非常小，因为它们仅用于开发。实际的生产运行将在顶点AI内部运行，在那里将设置环境变量。</p><p id="b2bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦你写完model.py，确保它能正常工作:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="c01e" class="ls lt iq mr b gy mv mw l mx my">python3 model.py  --bucket &lt;bucket-name&gt;</span></pre><p id="512f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，您已经准备好从顶点AI管道中调用它了。</p><h2 id="7470" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">编写培训管道</h2><p id="25ff" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">训练管道(参见train_on_vertexai.py)需要在代码中做五件事:</p><ol class=""><li id="2fc2" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">在Vertex AI中加载托管数据集</li><li id="8636" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">设置培训基础结构以运行model.py</li><li id="f08e" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">运行model.py，并传入托管数据集。</li><li id="23b4" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">找到要将模型部署到的端点。</li><li id="c454" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">将模型部署到端点</li></ol><p id="e3cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 1。托管数据集</strong></p><p id="7443" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是如何加载一个表格数据集(有图像、文本等选项。数据集，对于BigQuery中的表格数据):</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="f48f" class="ls lt iq mr b gy mv mw l mx my">data_set = aiplatform.TabularDataset.create(<br/>        display_name='data-{}'.format(ENDPOINT_NAME),<br/>        gcs_source=['gs://{}/ch9/data/all.csv'.format(BUCKET)]<br/>)</span></pre><p id="8b24" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我传入了*所有*的数据。Vertex AI将负责将数据分成训练、验证和测试数据集，并将其发送给训练程序。</p><p id="99c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2。培训设置</strong></p><p id="37ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，创建一个训练作业，传入model.py、训练容器映像和服务容器映像:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="d65d" class="ls lt iq mr b gy mv mw l mx my">model_display_name = '{}-{}'.format(ENDPOINT_NAME, timestamp)<br/>job = aiplatform.CustomTrainingJob(<br/>        display_name='train-{}'.format(model_display_name),<br/>        script_path="model.py",<br/>        container_uri=train_image,<br/>        requirements=[],  # any extra Python packages<br/>        model_serving_container_image_uri=deploy_image<br/>)</span></pre><p id="57b3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(关于为什么要给模型分配时间戳名称，请参见<a class="ae lr" rel="noopener" target="_blank" href="/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56">如何将TensorFlow模型部署到顶点AI </a></p><p id="4e73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 3。运行培训作业</strong></p><p id="58f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行作业包括在某些硬件上的托管数据集上运行model.py:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="ee64" class="ls lt iq mr b gy mv mw l mx my">model = job.run(<br/>        dataset=data_set,<br/>        model_display_name=model_display_name,<br/>        args=['--bucket', BUCKET],<br/>        replica_count=1,<br/>        machine_type='n1-standard-4',<br/>        accelerator_type=aip.AcceleratorType.NVIDIA_TESLA_T4.name,<br/>        accelerator_count=1,<br/>        sync=develop_mode<br/>    )</span></pre><p id="58ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 4。寻找终点</strong></p><p id="7534" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们想要部署到一个预先存在的端点(阅读见<a class="ae lr" rel="noopener" target="_blank" href="/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56">如何部署一个TensorFlow模型到顶点AI </a>了解什么是端点)。因此，找到一个现有端点，否则创建一个:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="5534" class="ls lt iq mr b gy mv mw l mx my">    endpoints = aiplatform.Endpoint.list(<br/>        filter='display_name="{}"'.format(ENDPOINT_NAME),<br/>        order_by='create_time desc',<br/>        project=PROJECT, location=REGION,<br/>    )<br/>    if len(endpoints) &gt; 0:<br/>        endpoint = endpoints[0]  # most recently created<br/>    else:<br/>        endpoint = aiplatform.Endpoint.create(<br/>            display_name=ENDPOINT_NAME, project=PROJECT, location=REGION<br/>        )</span></pre><p id="68e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 5。部署型号</strong></p><p id="06d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，将模型部署到端点:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="f918" class="ls lt iq mr b gy mv mw l mx my">model.deploy(<br/>        endpoint=endpoint,<br/>        traffic_split={"0": 100},<br/>        machine_type='n1-standard-2',<br/>        min_replica_count=1,<br/>        max_replica_count=1<br/>    )</span></pre><p id="a3be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！现在，您有了一个Python程序，您可以随时运行它来重新训练和/或部署训练好的模型。当然，MLOps人员通常不会大规模替换模型，而是只向模型发送一小部分流量。他们可能还会在Vertex AI中设置对端点的监控和持续评估。但是你让他们很容易做到这一点。</p><h2 id="1e3e" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">代码中的端到端自动ML</h2><p id="8c40" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">如果我想使用AutoML而不是我的定制培训工作，上面的管道会有什么变化？嗯，我不需要我自己的模型。因此，我将使用AutoML来代替CustomTrainingJob。</p><p id="92b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设置和运行培训作业(上面的步骤3和4)现在变成了:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="1300" class="ls lt iq mr b gy mv mw l mx my">def train_automl_model(data_set, timestamp):<br/>    # train<br/>    model_display_name = '{}-{}'.format(ENDPOINT_NAME, timestamp)<br/>    job = aiplatform.AutoMLTabularTrainingJob(<br/>        display_name='train-{}'.format(model_display_name),<br/>        optimization_prediction_type='classification'<br/>    )<br/>    model = job.run(<br/>        dataset=data_set,<br/>        target_column='ontime',<br/>        model_display_name=model_display_name,<br/>        budget_milli_node_hours=(300 if develop_mode else 2000),<br/>        disable_early_stopping=False<br/>    )<br/>    return job, model</span></pre><p id="798d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是唯一的变化！管道的其余部分保持不变。当我们说你有一个ML开发的统一平台时，这就是我们的意思。</p><p id="37ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事实上，您可以将ML框架类似地更改为PyTorch或sklearn或XGBoost，就MLOps人员而言，只有很小的更改。在我的train_on_vertexai.py中，我使用命令行参数在自定义Keras代码和AutoML之间切换。</p><h2 id="faaa" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">以非默认方式拆分数据</h2><p id="0ce2" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">默认情况下，Vertex AI会对数据进行部分拆分(80%用于训练，10%用于验证和测试)。如果你想控制分裂怎么办？有几个选项可用(基于时间等。).</p><p id="724c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设您想要向数据集中添加一个控制拆分的列，您可以在创建数据时执行此操作:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="94c3" class="ls lt iq mr b gy mv mw l mx my">CREATE OR REPLACE TABLE dsongcp.flights_all_data AS</span><span id="a930" class="ls lt iq mr b gy mz mw l mx my">SELECT<br/>  IF(arr_delay &lt; 15, 1.0, 0.0) AS ontime,<br/>  dep_delay,<br/>  taxi_out,<br/>  ...<br/>  <strong class="mr ir">IF (is_train_day = 'True',<br/>      IF(ABS(MOD(FARM_FINGERPRINT(CAST(f.FL_DATE AS STRING)), 100)) &lt; 60, 'TRAIN', 'VALIDATE'),<br/>      'TEST') AS data_split</strong><br/>FROM dsongcp.flights_tzcorr f<br/>...</span></pre><p id="9fea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基本上，有一个我称为data_split的列接受值TRAIN、VALIDATE或TEST。因此，托管数据集中的每一行都被分配给这三个拆分之一。</p><p id="2129" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，当我训练作业时(无论是自定义模型还是automl)，我指定预定义的拆分列是什么:</p><pre class="lc ld le lf gt mq mr ms mt aw mu bi"><span id="5cf9" class="ls lt iq mr b gy mv mw l mx my">model = job.run(<br/>        dataset=data_set,<br/>        # See <a class="ae lr" href="https://googleapis.dev/python/aiplatform/latest/aiplatform.html#" rel="noopener ugc nofollow" target="_blank">https://googleapis.dev/python/aiplatform/latest/aiplatform.html#</a><br/>        <strong class="mr ir">predefined_split_column_name='data_split',</strong><br/>        model_display_name=model_display_name,</span></pre><p id="74d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！Vertex AI将负责剩下的工作，包括将所有必要的元数据分配给正在训练的模型。</p><p id="cf46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一句话:随着越来越多的it变得自动化管理，MLOps变得越来越容易。通过在你的代码中遵循清晰的职责分离，你可以了解这一点。</p><p id="25e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽情享受吧！</p><h2 id="a3e7" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">更多关于Vertex AI的阅读:</h2><ol class=""><li id="a54c" class="na nb iq kh b ki ml kl mm ko no ks np kw nq la nf ng nh ni bi translated"><a class="ae lr" rel="noopener" target="_blank" href="/giving-vertex-ai-the-new-unified-ml-platform-on-google-cloud-a-spin-35e0f3852f25">给谷歌云上的新统一ML平台Vertex AI一个旋转</a> : <br/>我们为什么需要它，无代码ML培训到底有多好，所有这些对数据科学工作意味着什么？</li><li id="d9c3" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated"><a class="ae lr" rel="noopener" target="_blank" href="/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56">如何将TensorFlow模型部署到Vertex AI </a>:在Vertex AI中使用保存的模型和端点</li><li id="096a" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated"><a class="ae lr" href="https://medium.com/@lakshmanok/developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python-865b535814f8" rel="noopener">使用Python在Vertex AI上开发和部署机器学习模型</a>:编写让你的MLOps团队满意的训练管道</li><li id="c0c3" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated"><a class="ae lr" href="https://lakshmanok.medium.com/how-to-build-an-mlops-pipeline-for-hyperparameter-tuning-in-vertex-ai-45cc2faf4ff5" rel="noopener">如何在Vertex AI中为超参数调整构建MLOps管道</a> : <br/>为超参数调整设置模型和协调器的最佳实践</li></ol></div></div>    
</body>
</html>