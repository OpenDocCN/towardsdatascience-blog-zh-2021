<html>
<head>
<title>Messing with AWS Endpoint URLs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">扰乱AWS端点URL</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/messing-with-aws-endpoint-urls-aa56e6c9627?source=collection_archive---------40-----------------------#2021-05-12">https://towardsdatascience.com/messing-with-aws-endpoint-urls-aa56e6c9627?source=collection_archive---------40-----------------------#2021-05-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c0a5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">AWS CLI不知道的不会伤害它。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8e7a717db971a02a58a3d6f34f1457d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pj8wDqWBsjkBjU4rUI6NTQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">this engineering RAEng</a>在<a class="ae kv" href="https://unsplash.com/s/photos/technology?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="78fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您键入<code class="fe ls lt lu lv b">aws s3 ls s3://my-bucket</code>来列出一个S3桶的内容，那么您会期望连接到真正的桶并列出它的内容，这是完全有道理的。</p><p id="4fc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是没有硬性规定说你<em class="lw">必须</em>连接到真正的桶。事实上，有一个简单的参数<a class="ae kv" href="https://docs.aws.amazon.com/cli/latest/reference/" rel="noopener ugc nofollow" target="_blank">可以传递给上面的CLI命令，从而轻松地连接到您选择的任何URL。</a></p><p id="f4dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请考虑以下情况:</p><pre class="kg kh ki kj gt lx lv ly lz aw ma bi"><span id="4aac" class="mb mc iq lv b gy md me l mf mg">$ aws s3 ls s3://my-bucket --endpoint-url http://localhost:5000</span></pre><p id="6721" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意包含了指向端口5000上的本地主机的参数<code class="fe ls lt lu lv b">--endpoint-url</code>？我们不会在某个地方的AWS服务器上列出<code class="fe ls lt lu lv b">my-bucket</code>的内容，相反，我们会检查我们自己的机器，寻找能够响应<code class="fe ls lt lu lv b">ls</code>命令的类似桶的资源。</p><p id="df6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就引出了一个问题:为什么AWS要像这样公开一个参数，为什么我们要使用它？</p><p id="9be5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实证明，两者都有很好的理由。在本文中，我们将讨论两种情况，在这两种情况下，搞乱<code class="fe ls lt lu lv b">endpoint_url</code>是有用的。</p><h1 id="6422" class="mh mc iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">用例1:本地测试</h1><p id="3f2b" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">任何在本地测试过他们代码的人都知道当调用外部依赖时情况会变得多么令人担忧。例如，我们同意单元测试最好是<em class="lw">而不是</em> <em class="lw">实际上</em>将测试记录插入到我们的数据库中。</p><p id="22ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题，我们有一些策略。我们可以<a class="ae kv" href="https://en.wikipedia.org/wiki/Mock_object" rel="noopener ugc nofollow" target="_blank">嘲笑</a>。我们可以做T21的猴子补丁。或者我们会不愉快地在代码中添加测试专用的逻辑。</p><p id="40e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过运行AWS服务的<a class="ae kv" href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.DownloadingAndRunning.html" rel="noopener ugc nofollow" target="_blank">本地实例</a>，然后将代码中的<code class="fe ls lt lu lv b">endpoint_url</code>参数设置为localhost和正确的端口，我们可以轻松有效地模拟服务。</p><p id="ce09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看实际情况。</p><h2 id="8b72" class="mb mc iq bd mi nd ne dn mm nf ng dp mq lf nh ni ms lj nj nk mu ln nl nm mw nn bi translated">使用moto的示例</h2><p id="2f93" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">作为一个完整的例子，我会提到优秀的moto docs，这是一个专门用来模仿AWS服务的包。</p><p id="d9e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Moto有一个独立的服务器模式，这使得它的工作原理特别清晰。pip安装包后，启动本地moto服务器:</p><pre class="kg kh ki kj gt lx lv ly lz aw ma bi"><span id="fc32" class="mb mc iq lv b gy md me l mf mg">$ moto_server s3<br/> * Running on http://127.0.0.1:5000/</span></pre><p id="b387" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后在一段代码中，我们可以使用endpoint_url指向本地的moto S3实例:</p><pre class="kg kh ki kj gt lx lv ly lz aw ma bi"><span id="b192" class="mb mc iq lv b gy md me l mf mg">mock_s3 = boto3.resource(<br/>    service_name='s3',<br/>    region_name='us-east-1',<br/>    <strong class="lv ir">endpoint_url='http://localhost:5000'</strong>,<br/>)</span></pre><p id="5aff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以在<code class="fe ls lt lu lv b">mock_s3</code>对象上做任何我们想做的操作，而不用担心改变实际存储桶的内容。</p><h1 id="d681" class="mh mc iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">用例2:无缝集成</h1><p id="10ec" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">鉴于“云的兴起”，云服务的API变得无处不在也就不足为奇了。不管是好是坏，AWS S3 API现在是“对象存储领域事实上的标准”[ <a class="ae kv" href="https://min.io/" rel="noopener ugc nofollow" target="_blank"> 1 </a></p><p id="ab72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当多种技术采用相同的标准时，集成每一种成对组合的痛苦就消失了。</p><p id="9a99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://lakefs.io/" rel="noopener ugc nofollow" target="_blank"> lakeFS </a>、<a class="ae kv" href="https://min.io/" rel="noopener ugc nofollow" target="_blank"> MinIO </a>和<a class="ae kv" href="https://ceph.io/ceph-storage/object-storage/" rel="noopener ugc nofollow" target="_blank"> Ceph </a>是说S3语的技术的例子。或者更准确地说，它们与S3 API的一个有意义的子集保持兼容。</p><p id="3d00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，任何希望连接到S3的工具也可以通过端点URL与这些工具无缝集成！</p><h2 id="42c9" class="mb mc iq bd mi nd ne dn mm nf ng dp mq lf nh ni ms lj nj nk mu ln nl nm mw nn bi translated">以Spark和lakeFS为特色的示例</h2><p id="e005" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">Spark是经常与S3互动的技术的一个例子。最常见的是将数据读入数据帧，进行一些转换，然后将其写回S3。</p><p id="512a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">lakeFS旨在增强对象存储上的数据湖的功能，使分支、合并和恢复等操作成为可能。</p><p id="5866" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您想同时利用Spark和lakeFS的优势，并且无法设置自定义端点URL，那么就必须在两者之间开发一个定制的集成。</p><p id="4794" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">幸运的是，通过可配置的端点，集成变成了一个<a class="ae kv" href="https://docs.lakefs.io/using/spark.html" rel="noopener ugc nofollow" target="_blank">单行程序</a>，将Spark的S3端点指向一个lakeFS安装:</p><pre class="kg kh ki kj gt lx lv ly lz aw ma bi"><span id="4573" class="mb mc iq lv b gy md me l mf mg">spark<strong class="lv ir">.</strong>sparkContext<strong class="lv ir">.</strong>hadoopConfiguration<strong class="lv ir">.</strong>set<strong class="lv ir">(</strong>"fs.s3a.endpoint"<strong class="lv ir">,</strong> "https://s3.lakefs.example.com"<strong class="lv ir">)</strong></span></pre><p id="a6a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在从Spark访问lakeFS中的数据与从Spark访问S3数据完全一样！</p><h1 id="1df6" class="mh mc iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">最后的想法</h1><p id="92e3" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">虽然只是对这个主题的介绍，但希望您对什么是端点URL以及何时改变它们的默认值有更好的理解。</p><p id="9d38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="lw">注:本文首次发表于2011年4月20日lakeFS博客</em>  <em class="lw">上。</em></p></div></div>    
</body>
</html>