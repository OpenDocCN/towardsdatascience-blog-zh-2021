<html>
<head>
<title>Generative Adversarial Networks 101</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络101</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-networks-101-c4b135a440d5?source=collection_archive---------32-----------------------#2021-12-14">https://towardsdatascience.com/generative-adversarial-networks-101-c4b135a440d5?source=collection_archive---------32-----------------------#2021-12-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b3b0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何构建一个简单的GAN</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ebdca625130e7fb1c8e7444b6c4f44b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8XitYc3_bLLvusFnJb30A.png"/></div></div></figure><p id="5fa1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">自2014年首次提出以来，生成性对抗网络(简称GANs)就成为了机器学习社区的头条新闻。基于一个巧妙简单的想法，GANs很快成为产生人造图像的最先进的方法，这些图像现在与真实图像无法区分。他们不仅在生成人工智能艺术或人脸老化等有趣的任务中找到了应用，还在更实际的应用中找到了应用，如数据匿名化、提高照片分辨率等。在这篇文章中，我将解释GAN是如何工作的，我们将构建一个非常简单的GAN来生成新的口袋妖怪物种。我们开始吧！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/17162962021aaecbc1e67715dd0a3466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1df1f0VsSbe-sFK.png"/></div></figure><h2 id="eca2" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">关于甘斯</h2><p id="0a17" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">GANs首先由Goodfellow等人提出，并被迅速开发以发现大量令人着迷的用例，例如生成人脸的逼真图片、图像到图像的翻译(想想在图片中的一匹马身上画条纹以使它成为斑马)，或者衣服翻译(如果你想知道你穿同样的毛衣，但却是红色的高领毛衣会是什么样子)。他们甚至允许我们在图片上做算术:取一个戴眼镜的男人减去一个不戴眼镜的男人加上一个不戴眼镜的女人的图像，你会得到一个戴眼镜的女人的图像，从这个图像中你可以生成多个不同的戴眼镜的女人的图像。请查看<a class="ae mp" href="https://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/" rel="noopener ugc nofollow" target="_blank">这篇伟大的博文</a>，获取更多GAN应用示例图片。看看这只猫。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/33cde5278f15e0faaae6444df1ee051b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*wuj4JHX666O72nj2dfAI5g.jpeg"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">一只不存在的猫，由https://thiscatdoesnotexist.com/的<a class="ae mp" href="https://thiscatdoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">生成。</a></p></figure><p id="890a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这只猫既不喵喵叫也不咕噜咕噜叫。它不吃也不喝。因为它不存在。就像无数其他不存在的被甘斯创造出来的猫一样。你可以自己生成一些，只需导航到<a class="ae mp" href="https://thiscatdoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">thiscatdoesnotexist.com</a>。每次刷新页面，都会生成一个新的cat。对于<a class="ae mp" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">人</a>或<a class="ae mp" href="https://thisrentaldoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">住宿</a>也有类似的页面(虽然有些房间看起来还是有些毛骨悚然！).</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/17162962021aaecbc1e67715dd0a3466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1df1f0VsSbe-sFK.png"/></div></figure><h2 id="714d" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">甘斯直觉</h2><p id="d81e" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">GANs基于一个有趣的简单想法:让两个神经网络相互竞争，希望竞争能推动它们走向精通。</p><blockquote class="mv"><p id="df6d" class="mw mx it bd my mz na nb nc nd ne lp dk translated">GANs背后的想法:让我们让两个神经网络相互竞争，希望竞争能推动它们走向精通。</p></blockquote><p id="326b" class="pw-post-body-paragraph ku kv it kw b kx nf ju kz la ng jx lc ld nh lf lg lh ni lj lk ll nj ln lo lp im bi translated">总体目标是生成与训练数据中的内容无法区分的内容，例如图像。人们可以将这一思想应用于任何类型的数据，但是在本文中我们将重点关注图像。为了实现这一目标，我们需要两个独立的模型:</p><ul class=""><li id="197f" class="nk nl it kw b kx ky la lb ld nm lh nn ll no lp np nq nr ns bi translated">一个<em class="nt">发生器</em><strong class="kw iu"/>，以随机噪声为输入，并以此为基础生成图像；</li><li id="c5d9" class="nk nl it kw b kx nu la nv ld nw lh nx ll ny lp np nq nr ns bi translated">A d <em class="nt">是鉴别器</em>，它将图像作为输入(真实的或由生成器生成的)，其工作是将它们分类为真实或虚假。</li></ul><p id="aa16" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">生成器的目标是生成逼真的图像来欺骗鉴别器，而鉴别器的目标是从真实图像中分辨出假货。将这两个模型拟人化是很有帮助的，把生成器想象成一个艺术品伪造者，把鉴别器想象成一个警察调查员，去抓捕伪造者。这两个网络的这些相互冲突的目标应该确保每一个在训练期间逐渐变得更好。最终，生成器将有望生成逼真的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/6726b3258b51b8d005dc86a752fa71a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gskEz3DWBh0mVs3VUZrlfw.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">GAN的示意图。图片由作者提供。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/17162962021aaecbc1e67715dd0a3466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1df1f0VsSbe-sFK.png"/></div></figure><h2 id="c77b" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">发电机👨‍🎨</h2><p id="7a02" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">发生器最简单的形式可以是一个微小的神经网络，它接受输入的噪声向量，将它传递几层，并以图像的形式输出一个张量。当处理图像时，我们通常会使用卷积层，但训练卷积gan本身也会带来挑战，因此为了这个介绍性示例的目的，让我们使用一个简单的前馈网络，基本上是一个多层感知器。</p><p id="9d6d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将使用<a class="ae mp" href="https://github.com/PokeAPI/sprites" rel="noopener ugc nofollow" target="_blank">口袋妖怪精灵数据集</a>来生成我们自己的口袋妖怪物种。以下是一些示例图像。使用<a class="ae mp" href="https://github.com/MichalOleszak/gans/blob/main/notebooks/pokemon_data_prep.ipynb" rel="noopener ugc nofollow" target="_blank">这个笔记本</a>，你可以自己生成更多的样本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/6a275fdbd73044a91f080a1ebbfb51ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*a9I2bcIkqd2VBPcfbiBfjA.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">口袋妖怪精灵数据集的样本。</p></figure><p id="6158" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们的生成器接受64个随机数的输入向量，输出一个形状为4*96*96的向量(口袋妖怪pics是96*96像素，4个颜色通道)。生成器的输出层将是一个sigmoid激活，以便它生成0到1之间的数字来匹配原始图像中的像素值。PyTorch实现可能看起来像这样。随着单元数量的增加，您可以随意尝试添加更多的linear-batchnorm-relu块。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/17162962021aaecbc1e67715dd0a3466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1df1f0VsSbe-sFK.png"/></div></figure><h2 id="8e11" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">鉴别器👮‍♀️</h2><p id="9b75" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">鉴别器将是另一个小型神经网络，其任务是获取大小为4*96*96的输入向量，该输入向量包含真实图像或虚假的发生器输出，并分类为两者之一。我们可以这样实现它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="f0bb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">同样，随意堆叠更多的层，例如从<code class="fe od oe of og b">nn.Linear(4*96*96, 2048)</code>开始，每次继续将层大小分成两层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/17162962021aaecbc1e67715dd0a3466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1df1f0VsSbe-sFK.png"/></div></figure><h2 id="4f2d" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">培养</h2><p id="fab7" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">棘手的部分来了:如何训练这两个网络，使它们都能很好地学习自己的任务？关键是一前一后地训练它们，只用一个损失函数。损失函数的选择取决于鉴别器，因此我们可以使用二进制交叉熵损失，这是二进制图像分类的典型选择(在未来的帖子中，我将讨论使用更好的损失函数的更高级的GANs)。让我们首先初始化两个模型，损失和优化器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="d702" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个<code class="fe od oe of og b">PokemonDataset</code>物体是我创作的，你可以在GitHub 上找到它<a class="ae mp" href="https://github.com/MichalOleszak/gans/blob/main/gans/datasets.py" rel="noopener ugc nofollow" target="_blank">。现在，训练循环。我们对时期和批次进行迭代，对于每批训练数据，我们将梯度归零，计算鉴别器的损失，并更新模型的权重。接下来，我们对发电机做同样的事情。</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="998b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">剩下的问题是如何计算每个模型的损失。在上面的代码片段中，这是由定制的<code class="fe od oe of og b">get_disc_loss()</code>和<code class="fe od oe of og b">get_gen_loss()</code>函数处理的。让我们看看他们怎么做。</p><h2 id="e47e" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">鉴频器损耗</h2><p id="907c" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">第一，鉴频器的损耗。我们可以按照以下步骤计算它:</p><ul class=""><li id="2efb" class="nk nl it kw b kx ky la lb ld nm lh nn ll no lp np nq nr ns bi translated">产生一些随机噪声，并将其馈送到发生器。这会产生一批假图像。</li><li id="8b46" class="nk nl it kw b kx nu la nv ld nw lh nx ll ny lp np nq nr ns bi translated">使用鉴别器将这些假图像分类为假的或真的。然后，用它对一批真实图像进行分类。这就产生了两组分类:赝品和真品。</li><li id="3d50" class="nk nl it kw b kx nu la nv ld nw lh nx ll ny lp np nq nr ns bi translated">使用零(“假”)作为基本事实标签，将“假损失”计算为假图像鉴别器输出的二进制交叉熵损失。接下来，计算“真实损失”,作为鉴别器输出真实图像的二进制交叉熵损失，使用1(“真实”)作为基本事实标签。</li><li id="45ad" class="nk nl it kw b kx nu la nv ld nw lh nx ll ny lp np nq nr ns bi translated">将总损失计算为假损失和真损失的平均值。</li></ul><p id="0c94" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这由下面的函数来处理。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><h2 id="326f" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">发电机损耗</h2><p id="7bcc" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">现在，让我们对发电机的损耗进行编码。这个会简单得多。我们只需要生成噪声，将其馈送到生成器以获得假图像，使用鉴别器对它们进行分类，并使用1(“真实”)作为地面真相标签来计算这些分类的二进制交叉熵。我听到你问为什么是一个。回想一下，生成器的目标是欺骗鉴别器。当它产生假图像时，它希望它们被归类为真实的——每当不是这样时，生成器就会遭受损失。换句话说，如果鉴别器将每个发电机的输出分类为实数，那么发电机的损耗将为零。这个想法在下面的函数中实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="90a4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们有了所有的构建模块，我们可以运行训练循环。你可以在<a class="ae mp" href="https://github.com/MichalOleszak/gans/blob/main/notebooks/dense_gan.ipynb" rel="noopener ugc nofollow" target="_blank">这个笔记本</a>里自己运行(代码是根据Coursera的<a class="ae mp" href="https://www.coursera.org/specializations/generative-adversarial-networks-gans" rel="noopener ugc nofollow" target="_blank">生成对抗网络(GANs)专门化</a>由Sharon Zhou等人编写的)。在训练过程中，我们可能会时不时地给生成器输入一些噪声，看看它输出了什么。下面的图片显示了GAN生成的口袋妖怪在训练开始时，在几百个纪元后，以及在训练的很晚时候。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/21f24125628ea9bc801aacafafa5f8cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*szfFpnZdeWh8_Ds1vapyoQ.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">GAN在训练开始时(左)、训练后期(中)和后期(右)生成的口袋妖怪。</p></figure><p id="132b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">跟你预想的不太一样？我们来看看为什么！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/17162962021aaecbc1e67715dd0a3466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1df1f0VsSbe-sFK.png"/></div></figure><h2 id="8360" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">为什么这么模糊</h2><p id="b1e7" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">生成器很快了解到，它应该专注于图像的中心区域，并保持背景白色。在训练的早期，它一直在图像中间产生噪点。随着训练的进行，一些熟悉的形状变得清晰可见。甚至后来，一些假的口袋妖怪出现了，它们类似于训练数据中的那些，尽管是以一种模糊的方式(你可以认出每个人最喜欢的皮卡丘，在中间一行和最右边一列！).如果你已经期待一个更现实的输出，不要放弃希望。让我们看看模型的哪些部分需要改进。</p><p id="db97" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有几个，但其中两个最引人注目。首先，我们使用了一个简单的前馈网络来处理图像，这是相当次优的。切换到卷积神经网络应该会有很大帮助。第二，我们用于gan的二元交叉熵损失证明不是最佳选择；我会在另一篇文章中解释为什么会这样，以及什么样的损失函数会更好。</p><p id="9ecd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">先说前者。查看下一篇文章，在这篇文章中，我们将GAN向前推进了一步，在生成器和鉴别器中添加了卷积，以构建所谓的深度卷积GAN或DCGAN！</p><div class="oi oj gp gr ok ol"><a href="https://michaloleszak.medium.com/generative-adversarial-networks-102-dcgan-mode-collapse-ef119aa31a6f" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">生成性对抗网络102: DCGAN和模式崩溃</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">卷积简单的GAN以提高生成图像的质量。</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">michaloleszak.medium.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz ks ol"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/17162962021aaecbc1e67715dd0a3466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S1df1f0VsSbe-sFK.png"/></div></figure><h2 id="c0e5" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">感谢</h2><p id="1ddd" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">这个简单GAN的训练循环代码以及损失计算函数的灵感来自于Coursera的由Sharon Zhou等人提出的<a class="ae mp" href="https://www.coursera.org/specializations/generative-adversarial-networks-gans" rel="noopener ugc nofollow" target="_blank">生成对抗网络(GANs)专门化</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/4a293c2cfb73b4d4a2e3e25c1cf03858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*C7yCp195_PMYlQLU.png"/></div></figure><p id="d56a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">感谢阅读！</p><p id="620f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你喜欢这篇文章，为什么不在我的新文章上<a class="ae mp" href="https://michaloleszak.medium.com/subscribe" rel="noopener"> <strong class="kw iu">订阅电子邮件更新</strong> </a>？通过<a class="ae mp" href="https://michaloleszak.medium.com/membership" rel="noopener"> <strong class="kw iu">成为媒介会员</strong> </a>，你可以支持我的写作，并无限制地访问其他作者和我自己的所有故事。</p><p id="6880" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">需要咨询？你可以问我任何事情，也可以在这里 预定我1:1 <a class="ae mp" href="http://hiretheauthor.com/michal" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">。</strong></a></p><p id="529e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你也可以试试我的其他文章。不能选择？从这些中选择一个:</p><div class="oi oj gp gr ok ol"><a rel="noopener follow" target="_blank" href="/activation-functions-you-might-have-missed-79d72fc080a5"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">你可能错过的激活功能</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">你应该“嗖嗖”一下这些新发明，还是继续使用老掉牙的东西？</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pa l ow ox oy ou oz ks ol"/></div></div></a></div><div class="oi oj gp gr ok ol"><a rel="noopener follow" target="_blank" href="/monte-carlo-dropout-7fd52f8b6571"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">蒙特卡洛辍学</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">用一个小技巧免费改善你的神经网络，获得模型不确定性估计作为奖励。</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pb l ow ox oy ou oz ks ol"/></div></div></a></div><div class="oi oj gp gr ok ol"><a rel="noopener follow" target="_blank" href="/statistics-is-dead-long-live-statistics-df6c71262187"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">统计死了，统计万岁！</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">认识一下重采样，这是一种通用的现代统计方法</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pc l ow ox oy ou oz ks ol"/></div></div></a></div></div></div>    
</body>
</html>