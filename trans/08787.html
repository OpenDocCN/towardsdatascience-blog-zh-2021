<html>
<head>
<title>From «MFCCs xor GFCCs» to «MFCCs and GFCCs» : Urban Sounds Classification case study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从MFCCs xor GFCCs到MFCC和gfcc:城市声音分类案例研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-mfccs-xor-gfccs-to-mfccs-and-gfccs-urban-sounds-classification-case-study-a087ac007901?source=collection_archive---------28-----------------------#2021-08-13">https://towardsdatascience.com/from-mfccs-xor-gfccs-to-mfccs-and-gfccs-urban-sounds-classification-case-study-a087ac007901?source=collection_archive---------28-----------------------#2021-08-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="028c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">合并两种特征提取技术能提高声音分类模型的性能吗？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f1046cf0fe8c0fbd2336661ee1417b08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kc0eQ7ZZppczYcBKxaoNDg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://unsplash.com/@austindistel" rel="noopener ugc nofollow" target="_blank"> Austin Distel </a>拍摄，可在<a class="ae kv" href="https://unsplash.com/photos/97HfVpyNR1M" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>获得</p></figure><p id="5873" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人类天生具有识别周围环境声音的天赋，这要归功于声音从耳朵向其最深处——内耳——的传输，内耳负责将振动转化为电脉冲，然后传输到大脑，通过使用仿生方法，研究人员能够构想出一种称为特征提取技术的音频分类管道中的关键节点，它在我们身体的内耳中起着重要作用， 将信号作为输入并输出一组表征声音的数值，因此当我们将电脉冲传输到大脑时，这里我们将把提取的特征馈送到某个模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="ca73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">非常令人印象深刻的并行！不是吗？无论如何，在本文中，我们将主要关注两种特征提取技术，Mel频率倒谱系数(MFCCs)，这是该领域最受欢迎的选择，以及Gammatone频率倒谱系数(GFCCs)，这是不太受欢迎的。我们的目标是将它们的性能与一种将两者结合起来的方法进行比较，以便知道是否值得在以后的文章中深入研究。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h2 id="bfb3" class="mb mc iq bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">什么是MFCCs和GFCCs？</h2><p id="7c4d" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">在进入比较方法之前，让我们基于一些标准定义简单地谈论一下MFCCs和GFCCs背后的概念，因为我计划为它们中的每一个都写一篇完整的文章来解释背后的数学，因为我发现从数学角度来看这非常有趣。</p><ul class=""><li id="952e" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">MFCC:</strong>梅尔频率倒谱系数(图2)是共同构成MFC的系数，梅尔频率倒谱是声音的短期功率谱的表示。它们源自音频片段的一种倒谱表示(一种非线性“频谱”)。倒谱和梅尔频率倒谱之间的区别在于，在MFC中，频带在梅尔标度上是等间隔的，这比正常频谱中使用的线性间隔频带更接近人类听觉系统的响应。这种频率弯曲可以更好地表现声音。(<a class="ae kv" href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum" rel="noopener ugc nofollow" target="_blank">维基百科</a>)</li><li id="8bb1" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">gfcc:</strong>Gammatone频率倒谱系数(图3)是基于一组Gammatone滤波器组生成的系数，为了生成这些系数，我们需要信号的频率-时间表示，称为Cochlegram <strong class="ky ir">(相对于内耳的组成部分耳蜗)</strong>，它可以从gamma tone滤波器组获得，其计算阶段与MFCC有相当多的相似之处。</li></ul><div class="kg kh ki kj gt ab cb"><figure class="nn kk no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/a5dd8653e0f22d9fedb7379a9dba8972.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*wsdTuH9VbIVCOTgfMFKCRw.png"/></div></figure><figure class="nn kk no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/1766f9cf461644aad42983d5d42a900b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*is0xPFF3Vq5PflrBLHkbWQ.png"/></div></figure><figure class="nn kk no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/a9a685b271dea2045f5810ceead52f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*jajOLyoEtGh898W6xaPmyA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk nt di nu nv translated">图1:音频信号—图2 : <em class="nw">梅尔频率倒谱系数— </em>图3 : <em class="nw">伽马频率倒谱系数</em></p></figure></div><p id="f76f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以MFCCs和GFCCs，简单来说就是代表某种声音特征的系数。</p><h2 id="a34d" class="mb mc iq bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">我们将处理的数据集:</h2><p id="a025" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">我们将使用UrbanSound8K数据集，包含8732个标记的声音片段，每个片段不到4秒，不同于其他著名的音频数据集，每个音频文件的采样率不同(采样率:一个时间实例的音频样本组)，并被标记为10个类别之一:街道音乐、汽车喇叭、儿童玩耍、狗叫、钻探、发动机空转、枪击、手提钻、警笛和空调。</p><h2 id="31a8" class="mb mc iq bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">比较架构:</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/b2091e164a5d62900b9e9e9b2921b956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kx0t2AP2DHBebGUhv-uQWw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4:比较架构</p></figure><p id="ad3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经展示了数据集，为了了解三种特征提取技术中哪一种更可靠，我们将继续进行三种特征提取技术之间的比较方法(图4 ),给每种技术三次机会，通过音频分类领域中三种不同的常用模型来证明它们的可靠性，这样，如果我们最终选择一种特征提取技术而不是另一种，将会更加公平。</p><p id="3642" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此每个特征提取技术的输出将被馈送到:</p><ul class=""><li id="66fd" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">支持向量分类(SVC) </strong>这是一种基于间隔最大化原则的特殊线性分类器，可用于解决线性和非线性问题。</li><li id="4887" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">多层感知器分类器(MLP) </strong>它是一类前馈人工神经网络</li><li id="6ed0" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">K近邻</strong> <strong class="ky ir">分类器(KNN分类器)</strong>这是一种用于解决分类问题的监督机器学习算法</li></ul><h2 id="bf50" class="mb mc iq bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">评估指标:</h2><p id="2fca" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">为了评估我们的分类模型的有效性，我们将考察四个主要的性能指标:</p><ul class=""><li id="09a4" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">准确性</strong>:模型正确预测两个类别的能力</li><li id="7354" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">精度</strong>:模型从所有预测的阳性类别中正确检测出阳性类别的能力</li><li id="16b7" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">回忆(灵敏度):</strong>模型从所有实际阳性类别中正确检测出阳性类别的能力</li><li id="f67a" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir"> F1得分</strong>:精确度和召回率的调和平均值</li></ul><p id="13fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有这些性能指标都是基于以下变量定义的:</p><ul class=""><li id="e278" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">真阳性(TP) </strong>:预测为阳性类别的阳性类别</li><li id="dab0" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">假阳性(FP) </strong>:阴性类别预测为阳性类别</li><li id="c48c" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">真否定(TN) </strong>:否定类预测为否定类</li><li id="f9b8" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">假阴性(FN) </strong>:阳性类别预测为阴性类别</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/7c835d812529fa0fdfa3bf9b1af8bfb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*baUsEoAkGlmsu4VXlo6G9w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5:评估指标公式</p></figure><h2 id="839f" class="mb mc iq bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">模型的分数和结果解释:</h2><p id="ac8e" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">在设置了比较架构并确定了用于评估的指标后，我们比较了每个有限元模型显示的性能，以便我们可以首先为每种技术选择最佳的一种，然后确定谁是3个最佳记录分数中的最佳者。筛选结果如下所示(图6):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/7cf1a15d8d02769d1e631981216dcf2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w1Aig9qIXkj2ZvoSHDg8mQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图六:模特们的表演</p></figure><p id="216f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据使用不同特征提取技术的模型的性能，我们最终认识到多层感知器模型和MFCC&amp;GFCC技术的组合在9个可能的组合中获得了迄今为止最好的准确度、精确度、召回率和F1分数。</p><h2 id="0715" class="mb mc iq bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">下一步是什么？</h2><p id="c100" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">在确定MLP和MFCC&amp;GFCC的特征提取组合是该数据集最可靠的组合后，我们将在未来的技术文章中进一步调整其参数，以解释我们合并这两种特征提取技术的方式，并了解其性能可以提高到什么程度，因为正如我们刚刚看到的，它显示了一些非常好的结果，请继续关注😊。</p></div></div>    
</body>
</html>