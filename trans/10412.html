<html>
<head>
<title>Deploy your Tensorflow models on Heroku with a button click</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">只需点击一下按钮，即可在Heroku上部署您的Tensorflow模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-your-tensorflow-models-on-heroku-with-a-button-click-4fbb0252f870?source=collection_archive---------25-----------------------#2021-10-04">https://towardsdatascience.com/deploy-your-tensorflow-models-on-heroku-with-a-button-click-4fbb0252f870?source=collection_archive---------25-----------------------#2021-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7ea7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">自动化您的tensorflow模型服务</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/4a9d297b4d473e7fcc3b9c6f6e506095.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y5gbfyZsz6kSAdkrsPQClg.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com/@anilinverse?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">亚当·卢科姆斯基</a>在<a class="ae kw" href="https://unsplash.com/s/photos/rocket-animation?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="ea9b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在建立了这个卓越的模型之后，接下来呢？你如何向你的朋友炫耀它？你如何添加额外的一层神奇之处，帮助你超越Github中的一堆jupyter笔记本，让其他人也能与之互动？服务于您的模型使您离构建产品更近了一步，而不仅仅是拥有代码。</p><p id="b6fc" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">对于希望快速完成概念验证的爱好者和数据科学家来说，如果有一种方法可以以最少的工作量自动化您的模型部署，那么可以节省大量时间。在本文中，我将向您介绍一个工具，它可以让您轻松地将Tensorflow模型作为rest apis使用！</p><h2 id="d1dc" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">先决条件</h2><p id="d4fc" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">为了跟进，你需要一个Heroku账户和一个在AWS上的公开的s3 bucket。</p><h1 id="7dbd" class="mr lu iq bd lv ms mt mu ly mv mw mx mb jw my jx me jz mz ka mh kc na kd mk nb bi translated">让我们和克鲁斯一起建造吧！</h1><p id="4fea" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">欢迎来到克鲁斯！Cruise是一个简单的设置，它消除了在Heroku平台上部署和服务模型时需要了解TensorFlow服务和docker的顾虑。它让你只需点击一个按钮就能完成所有这些。</p><p id="2a29" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在本文中，我们将使用著名的MNIST数据集构建一个图像分类器模型，然后使用Cruise部署该模型。</p><h2 id="87b9" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated"><strong class="ak">步骤1:使用SavedModel格式构建并保存您的模型</strong></h2><p id="0e63" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">Tensorflow SavedModel使打包模型变得非常容易，以便使用<a class="ae kw" href="https://tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"> TFLite </a>和<a class="ae kw" href="https://www.tensorflow.org/tfx/serving/tutorials/Serving_REST_simple" rel="noopener ugc nofollow" target="_blank"> TensorFlow Serving </a>等工具进行共享或部署。它存储运行模型所必需的参数，而不需要训练代码，从而可以方便地重用模型。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="3d4a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在第58行，我们指定了保存模型的路径。我们还使用时间戳作为模型的名称，以确保每次运行时，我们都会保存模型的新版本。</p><h2 id="e1da" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">步骤2:创建Tensorflow服务器使用的配置文件。</h2><p id="2632" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">选择具有TensorFlow服务的模型的一种方法是通过配置文件。配置文件允许您方便地为服务器提供多个模型，还可以控制应该提供哪个(些)版本的模型。在<strong class="kz ir"> <em class="ne"> tf-models </em> </strong>文件夹中，创建<strong class="kz ir"> <em class="ne"> models.conf </em> </strong>文件:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="48dd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在配置文件中，我们已经指定了模型的名称，这个名称将在我们访问Heroku上的模型的最终url中使用。基本路径告诉Tensorflow服务在哪里可以找到我们模型的所有可能版本。模型版本策略有助于我们控制对可以提供哪些模型的访问。更多相关信息可在<a class="ae kw" href="https://www.tensorflow.org/tfx/serving/serving_config#serving_a_specific_version_of_a_model" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="be07" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">第三步:压缩tar.gz格式的模型文件，并保存在一个公共S3桶</h2><p id="549f" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">为了使用cruise，我们必须首先将我们保存的模型作为一个压缩文件放在一个公开可用的s3 bucket上。下面是一个简单的代码，可以用来压缩模型文件:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h2 id="321e" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">第四步:和克鲁斯一起上菜！</h2><p id="3b81" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">访问<a class="ae kw" href="https://github.com/JesuFemi-O/Cruise" rel="noopener ugc nofollow" target="_blank"> Cruise Repo </a>，点击deploy按钮，会将您重定向到Heroku，您需要输入一些值:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nf"><img src="../Images/68eebf8f60e359548c41b1aadd07ec6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OpO7sH4fuKHGg57yWl8DaA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">巡航部署示例。(图片由作者提供)</p></figure><p id="5d36" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">应用程序名称是您的heroku应用程序的名称，必须是唯一的，否则Heroku会标记错误。您可以选择列表中离您最近的任何地区。<strong class="kz ir"> MODEL_BASE_PATH </strong>指的是保存模型和配置文件的基本文件夹。在我们的例子中，我们将这个文件夹命名为<strong class="kz ir"> tf-models </strong>，并将我们的压缩文件命名为<strong class="kz ir">tf-models.tar.gz</strong>。</p><p id="25e9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"> MODEL_CONFIG_FILE </strong>指的是我们给配置文件起的名字。在我们的例子中，我们称之为<strong class="kz ir"> models.conf </strong>。</p><p id="de0b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最后，<strong class="kz ir"> TENSORFLOW_MODEL_URL </strong>引用s3提供的s3 bucket对象URL。请注意，我们必须使用https url，因为cruise在内部使用curl来下载文件，如果协议不是HTTP，就会标记一个错误。点击部署按钮，heroku设置您的应用程序，最终完成后，您可以查看应用程序:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ng"><img src="../Images/3d4dbaa71d4b910417c45815b5ba3a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_eXSYOLtZtZCFflY1FWUrw.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">成功部署巡航导弹(图片由作者提供)</p></figure><p id="4189" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">点击“查看”按钮可进入已部署应用程序的根页面，该页面返回“未找到”,因为Tensorflow服务器未使用该路径。要查看您部署的模型的健康状况，您可以导航到https:<a class="ae kw" href="https://cruise-cassava.herokuapp.com/v1/models/img_classifier" rel="noopener ugc nofollow" target="_blank">https://YOUR-APP.herokuapp.com/v1/models/img_classifier</a></p><p id="151a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">将<strong class="kz ir"> YOUR-APP </strong>替换为Heroku app的名称，将image_classifier替换为您在models.conf文件中为模型指定的任何名称，在我们的示例中，url将是:【https://cruise-mnist.herokuapp.com/v1/models/img_classifier】T2</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/92f0606a00b9d04fb26a6f437413c956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*R0Bo5JElqMcZzamIGXtEQw.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">模型健康终点(图片由作者提供)</p></figure><p id="6d61" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">要对我们的模型进行预测，我们只需发出如下请求:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="d0b9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">注意第20行的url。我们已经将'<strong class="kz ir"> <em class="ne"> :predict </em> </strong>'添加到我们之前的url中，指定我们想要在模型上执行的操作。现在你知道了！您可以在其他应用程序中轻松使用互联网上的实时模型！</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="fea5" class="mr lu iq bd lv ms np mu ly mv nq mx mb jw nr jx me jz ns ka mh kc nt kd mk nb bi translated">结论</h1><p id="b1c3" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">我构建Cruise的动机是找到一种将Tensorflow模型作为API自动部署的方法。如果您在一个必须向不同的人或团队提供模型的环境中工作，例如，软件工程师或您在一个团队中工作，并且需要一个工具来在实验时快速共享您的模型，那么使用Cruise进行部署是一个值得考虑的好方法！如果你有任何问题或者想要联系，这是我的LinkedIn。谢谢大家！</p></div></div>    
</body>
</html>