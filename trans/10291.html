<html>
<head>
<title>8+ Reinforcement Learning Project Ideas</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">8+强化学习项目创意</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/8-reinforcement-learning-project-ideas-3521e0ccd313?source=collection_archive---------12-----------------------#2021-09-30">https://towardsdatascience.com/8-reinforcement-learning-project-ideas-3521e0ccd313?source=collection_archive---------12-----------------------#2021-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3941" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">想通过强化学习获得实用的实践经验吗？这里有一些启发你的项目想法。</h2></div><p id="275f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章是强化学习(RL)项目想法的汇编。我尝试选择涵盖RL中一系列不同困难、概念和算法的项目。</p><h1 id="1cd2" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">1.用<a class="ae lw" href="https://gym.openai.com/" rel="noopener ugc nofollow" target="_blank"> OpenAI Gym </a>解决玩具问题(适合初学者)</h1><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/c34ae1761cc86fe506baaf62463d512a.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*h_rwlOT8PdfnGjk0GR7SjQ.png"/></div><p class="mf mg gj gh gi mh mi bd b be z dk translated"><a class="ae lw" href="https://gym.openai.com/envs/CartPole-v1/" rel="noopener ugc nofollow" target="_blank">来自OpenAI健身房的翻筋斗环境</a>(作者截图)</p></figure><p id="41de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lw" href="https://gym.openai.com/" rel="noopener ugc nofollow" target="_blank"> OpenAI Gym </a>已经成为研究人员和实践者之间强化学习框架的事实标准。从健身房图书馆解决玩具问题将有助于你熟悉这个流行的框架和简单的Q学习算法。好的起点包括<a class="ae lw" href="https://gym.openai.com/envs/CartPole-v1/" rel="noopener ugc nofollow" target="_blank">侧手翻</a>、<a class="ae lw" href="https://gym.openai.com/envs/LunarLander-v2/" rel="noopener ugc nofollow" target="_blank">月球着陆器</a>和<a class="ae lw" href="https://gym.openai.com/envs/Taxi-v3/" rel="noopener ugc nofollow" target="_blank">滑行</a>。</p><p id="cddc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你对一步一步的演练感兴趣，可以看看我的<a class="ae lw" href="https://www.gocoder.one/blog/rl-tutorial-with-openai-gym" rel="noopener ugc nofollow" target="_blank">关于Taxi的入门Q-learning教程</a>。</p><h1 id="bfaa" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">2.使用<a class="ae lw" href="https://gym.openai.com/envs/#atari" rel="noopener ugc nofollow" target="_blank"> OpenAI Gym </a>从pixel input玩雅达利游戏</h1><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/ab7f449faaf507acf9052f33722cf1bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*I1UNwR5EXjjOTiYO.jpg"/></div><p class="mf mg gj gh gi mh mi bd b be z dk translated"><a class="ae lw" href="https://gym.openai.com/envs/#atari" rel="noopener ugc nofollow" target="_blank">雅达利环境</a>编译(图片由作者提供)</p></figure><p id="e517" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">OpenAI Gym还包含一套<a class="ae lw" href="https://gym.openai.com/envs/#atari" rel="noopener ugc nofollow" target="_blank"> Atari游戏环境</a>作为其街机学习环境(ALE)框架的一部分。例子包括<a class="ae lw" href="https://gym.openai.com/envs/Breakout-v0/" rel="noopener ugc nofollow" target="_blank">越狱</a>、<a class="ae lw" href="https://gym.openai.com/envs/MontezumaRevenge-v0/" rel="noopener ugc nofollow" target="_blank">蒙特祖马复仇</a>和<a class="ae lw" href="https://gym.openai.com/envs/SpaceInvaders-v0/" rel="noopener ugc nofollow" target="_blank">太空入侵者</a>。</p><p id="dc15" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">环境观察以屏幕输入或RAM的形式提供(直接观察Atari 2600的1024位内存)。解决Atari环境将需要使用更复杂的RL算法和深度学习库，如TensorFlow或PyTorch。</p><p id="1f71" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mk">其他资源:</em></p><ul class=""><li id="5bd9" class="ml mm it kk b kl km ko kp kr mn kv mo kz mp ld mq mr ms mt bi translated">推荐阅读:<a class="ae lw" href="https://deepmind.com/research/publications/2019/playing-atari-deep-reinforcement-learning" rel="noopener ugc nofollow" target="_blank"> DeepMind原创雅达利DQN论文</a></li><li id="af27" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated">托马斯·西蒙尼尼的《太空入侵者朱庇特笔记本教程》</li><li id="af6d" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated"><a class="ae lw" href="https://www.digitalocean.com/community/tutorials/how-to-build-atari-bot-with-openai-gym" rel="noopener ugc nofollow" target="_blank">深度强化学习的偏差-方差:如何用OpenAI Gym为雅达利打造一个机器人</a></li></ul><h1 id="98ac" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">3.用<a class="ae lw" href="https://github.com/bulletphysics/bullet3" rel="noopener ugc nofollow" target="_blank"> PyBullet </a>模拟控制任务</h1><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/13c34de0c2aa9ac0aebbad1d59752f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4nIDsNNViuzU3aClq48vsA.jpeg"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated"><a class="ae lw" href="https://github.com/bulletphysics/bullet3" rel="noopener ugc nofollow" target="_blank"> PyBullet </a>人形例子(作者截图)</p></figure><p id="a72c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果强化学习应用于机器人是你感兴趣的领域，你可能已经见过OpenAI Gym的付费MuJoCo environments。对于一个免费的开源替代方案，我推荐查看一下<a class="ae lw" href="https://github.com/bulletphysics/bullet3" rel="noopener ugc nofollow" target="_blank"> PyBullet </a>。</p><p id="7624" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MuJoCo/PyBullet是物理引擎，提供类人机器人和其他生物的真实世界般的刚体模拟。它们可用于创建具有连续控制任务(如行走、跑步和游泳)的环境，使其可用于试验政策梯度方法，如DPG、TRPO和PPO。</p><p id="22a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">10月19日更新:</strong> <a class="ae lw" href="https://deepmind.com/blog/announcements/mujoco" rel="noopener ugc nofollow" target="_blank"> MuJuCo现已免费开源</a>！</p><h1 id="74e9" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">4.使用<a class="ae lw" href="https://github.com/Unity-Technologies/ml-agents" rel="noopener ugc nofollow" target="_blank"> Unity ML-Agents </a>创建您自己的强化学习环境(适合初学者)</h1><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ne"><img src="../Images/7712056cf8f1f264db33534ee97652f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkXryII1VyQyub8jtK6FCw.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated"><a class="ae lw" href="https://github.com/Unity-Technologies/ml-agents" rel="noopener ugc nofollow" target="_blank"> Unity ML-Agents </a>推块环境(作者截图)</p></figure><p id="de16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Unity ML-Agents是Unity游戏引擎的一个相对较新的插件。它允许游戏开发者为游戏训练智能NPC，并使研究人员能够创建图形和物理丰富的RL环境。要探索的项目创意包括:</p><ul class=""><li id="a6b4" class="ml mm it kk b kl km ko kp kr mn kv mo kz mp ld mq mr ms mt bi translated">尝试PPO、SAC、GAIL和Self-Play等算法，这些算法提供了现成的实现</li><li id="784a" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated">在Unity GUI中的18+环境库中训练代理，包括<a class="ae lw" href="https://github.com/Unity-Technologies/ml-agents/tree/dodgeball-env" rel="noopener ugc nofollow" target="_blank">躲避球</a>、足球和经典控制问题。</li><li id="7eaa" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated">创建您自己的自定义图形和物理丰富的3D RL环境</li></ul><p id="056f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mk">其他资源:</em></p><ul class=""><li id="2be5" class="ml mm it kk b kl km ko kp kr mn kv mo kz mp ld mq mr ms mt bi translated"><a class="ae lw" href="https://www.gocoder.one/blog/hands-on-introduction-to-deep-reinforcement-learning" rel="noopener ugc nofollow" target="_blank">构建3D排球RL环境</a></li><li id="f27d" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated"><a class="ae lw" href="https://www.immersivelimit.com/tutorials/reinforcement-learning-penguins-part-1-unity-ml-agents" rel="noopener ugc nofollow" target="_blank">强化学习企鹅</a></li><li id="af5a" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated"><a class="ae lw" href="https://learn.unity.com/course/ml-agents-hummingbirds" rel="noopener ugc nofollow" target="_blank">团结蜂鸟课程</a></li></ul><h1 id="6914" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">5.用<a class="ae lw" href="https://aws.amazon.com/deepracer/" rel="noopener ugc nofollow" target="_blank"> AWS DeepRacer </a>比赛自动驾驶汽车(适合初学者)</h1><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nf"><img src="../Images/fb4d47d18f52d89fcb528aea6beae8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jxN_DYu7USf8p53q.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">AWS DeepRacer联赛流(作者截图)</p></figure><p id="b437" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lw" href="https://aws.amazon.com/deepracer/" rel="noopener ugc nofollow" target="_blank"> AWS DeepRacer </a>是一款3D赛车模拟器，旨在帮助开发者使用亚马逊SageMaker开始使用RL。你需要为在AWS上培训和评估你的模型付费。作为AWS DeepRacer league 的一部分，它每月都会举办竞赛，颁发奖品并提供在re:Invent比赛的机会。</p><p id="c9b4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DeepRacer的独特之处在于，你可以花399美元购买一辆1/18比例的赛车，这样你就可以在现实世界中部署你的模型。</p><p id="f775" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其他一些与自动驾驶相关的开源项目:</p><ul class=""><li id="320b" class="ml mm it kk b kl km ko kp kr mn kv mo kz mp ld mq mr ms mt bi translated"><a class="ae lw" href="https://github.com/microsoft/AirSim" rel="noopener ugc nofollow" target="_blank"> AirSim </a></li><li id="d300" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated"><a class="ae lw" href="https://github.com/carla-simulator/carla" rel="noopener ugc nofollow" target="_blank">卡拉</a></li></ul><h1 id="ca47" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">6.用<a class="ae lw" href="https://minerl.io/" rel="noopener ugc nofollow" target="_blank">密涅尔</a>在《我的世界》开采钻石</h1><p id="28f4" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">MineRL 包含超过6000万帧记录的《我的世界》人类玩家数据的模仿学习数据集。目标是训练能够在开放世界中导航并克服固有挑战的代理，例如具有大量等级和稀疏回报的任务。</p><p id="8fad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MineRL提供了有用的入门教程以及一个有用的社区。作为额外的激励措施，作为NeurIPS 2021的一部分，MineRL目前正在举办两项竞赛:</p><ol class=""><li id="bf1b" class="ml mm it kk b kl km ko kp kr mn kv mo kz mp ld nl mr ms mt bi translated"><a class="ae lw" href="https://minerl.io/diamond/" rel="noopener ugc nofollow" target="_blank">钻石</a>:获得一颗钻石，前提是给定原始像素样本数据和时间训练的限制。</li><li id="99d3" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld nl mr ms mt bi translated"><a class="ae lw" href="https://minerl.io/basalt/" rel="noopener ugc nofollow" target="_blank">玄武岩</a>:解决近乎逼真的任务，比如盖房子或者找山洞(更适合新手)。</li></ol><h1 id="49b3" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">7.加入<a class="ae lw" href="https://aiarena.net/" rel="noopener ugc nofollow" target="_blank"> AIArena </a>星际争霸2建筑代理的社区</h1><p id="845e" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">如果你想训练代理人玩高度复杂的主流游戏，你应该去看看AIArena。他们为一个研究人员、从业者和爱好者的社区运行常规的流和梯，为星际争霸2构建脚本和深度学习代理。</p><p id="c96d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了星际争霸2，这里还有一些你可能感兴趣的其他主流RL框架游戏:</p><ul class=""><li id="b4f2" class="ml mm it kk b kl km ko kp kr mn kv mo kz mp ld mq mr ms mt bi translated"><a class="ae lw" href="https://rlgym.github.io/" rel="noopener ugc nofollow" target="_blank">火箭联赛</a></li><li id="644a" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated"><a class="ae lw" href="https://leaguesandbox.github.io/" rel="noopener ugc nofollow" target="_blank">英雄联盟</a></li><li id="71e4" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated"><a class="ae lw" href="https://games.mau.se/research/the-dota2-5v5-ai-competition/" rel="noopener ugc nofollow" target="_blank"> Dota 2 </a></li></ul><h1 id="0723" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">8.用<a class="ae lw" href="https://github.com/deepmind/open_spiel" rel="noopener ugc nofollow" target="_blank"> OpenSpiel </a>建造一个象棋机器人</h1><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nm"><img src="../Images/0ac7b0443c7e77c0c63c2c849e50eb95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0bVqehfTJE8S2ZSL"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">照片由<a class="ae lw" href="https://unsplash.com/@neon845b?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Jani Kaasinen </a>在<a class="ae lw" href="https://unsplash.com/s/photos/chess?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="c7fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你受到了像StockFish或AlphaGo这样的程序的启发，DeepMind的OpenSpiel 值得一看。它包含一系列游戏环境，包括国际象棋、围棋、双陆棋等等。</p><p id="a80d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想尝试树形搜索/规划(例如MCTS)，以及政策和价值网络，棋盘游戏中的RL是一个很好的探索空间。</p><h1 id="de79" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">额外的想法</h1><p id="10a1" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">以下是一些额外的项目想法，也值得一试:</p><ul class=""><li id="535a" class="ml mm it kk b kl km ko kp kr mn kv mo kz mp ld mq mr ms mt bi translated">用<a class="ae lw" href="https://github.com/tensortrade-org/tensortrade" rel="noopener ugc nofollow" target="_blank"> TensorTrade </a>预测股票价格</li><li id="a927" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated">用<a class="ae lw" href="https://www.pettingzoo.ml/" rel="noopener ugc nofollow" target="_blank"> PettingZoo </a>训练合作代理</li><li id="2657" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated">用<a class="ae lw" href="https://github.com/datamllab/rlcard" rel="noopener ugc nofollow" target="_blank"> RLCard </a>建造一个扑克机器人</li><li id="a950" class="ml mm it kk b kl mu ko mv kr mw kv mx kz my ld mq mr ms mt bi translated">参加<a class="ae lw" href="https://www.gocoder.one/blog/ai-game-competitions-list" rel="noopener ugc nofollow" target="_blank">人工智能编程竞赛</a>或<a class="ae lw" href="https://www.semrush.com/analytics/organic/overview?db=us&amp;searchType=url&amp;q=https%3A%2F%2Fwww.gocoder.one%2Fblog%2Freinforcement-learning-competitions&amp;date=20211112" rel="noopener ugc nofollow" target="_blank"> RL竞赛</a></li></ul><h1 id="82df" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">结束语</h1><p id="a916" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">在强化学习中有大量令人兴奋的项目可以探索。这个列表并不全面，但我希望它能给你自己的RL项目一些启发！</p></div></div>    
</body>
</html>