<html>
<head>
<title>Factor Analysis of Mixed Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">混合数据的因子分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/factor-analysis-of-mixed-data-5ad5ce98663c?source=collection_archive---------10-----------------------#2021-07-12">https://towardsdatascience.com/factor-analysis-of-mixed-data-5ad5ce98663c?source=collection_archive---------10-----------------------#2021-07-12</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="6739" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">对具有连续和分类特征的数据使用FAMD</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/520a8ab982911fa04eb6a227e2b345fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cZOAIFhVyvIwyB7ZeO_m7Q.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图片来自<a class="ae kz" href="https://unsplash.com/photos/YeUVDKZWSZ4" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><blockquote class="la lb lc"><p id="01ed" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">简介</strong></p></blockquote><p id="022b" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi md translated"><span class="l me mf mg bm mh mi mj mk ml di">大型数据集对于数据分析师或数据科学家来说可能是一场噩梦，因为其中存在许多线性相关的要素。不必要的数据特征会降低ML模型的性能并增加训练预算。有一些技术可以用来减少能够充分解释大部分方差的重要特征的数量。在本文中，我将介绍针对数据集的因子分析技术，我们可能有兴趣减少关键要素的数量，从而使用最有效的数据成分进行建模。</span></p><blockquote class="la lb lc"><p id="63e6" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv"> Scikit Learn的PCA </strong></p></blockquote><p id="158e" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">大型数据集必须使用简单的技术如主成分分析(PCA)来降低维数。这是以准确性为代价的，但增加模型训练的灵活性和数据可视化的简单性是核心目标。PCA不是分析数据集重要特征的“特征选择”。我在下面的文章中使用Shapash和Scikit-Learn描述了特性选择。</p><div class="mm mn gq gs mo mp"><a href="https://medium.com/geekculture/feature-selection-in-large-datasets-fc27a7e8e388" rel="noopener follow" target="_blank"><div class="mq ab fp"><div class="mr ab ms cl cj mt"><h2 class="bd iv gz z fq mu fs ft mv fv fx it bi translated">大型数据集中的特征选择</h2><div class="mw l"><h3 class="bd b gz z fq mu fs ft mv fv fx dk translated">使用Shapash和Scikit-Learn的SelectKBest</h3></div><div class="mx l"><p class="bd b dl z fq mu fs ft mv fv fx dk translated">medium.com</p></div></div><div class="my l"><div class="mz l na nb nc my nd kt mp"/></div></div></a></div><p id="c9d4" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">PCA来自一个完全不同的世界，但目标是一样的:减少维数。PCA通过标准化这些值、构建协方差矩阵并由此获得特征值和特征向量来获得分量。PCA得出解释数据集中大多数可变性的最终成分。因此，这些新组件可以被认为是原始值的线性组合或复合。第一个成分解释了最高的可变性，第二个成分具有第二高的解释比率。我们可能非常熟悉iris数据集，它有四个数字列和一个花卉种类的目标列。PCA适用于数据集的数字列，并且总是建议对连续变量执行PCA。当进行主成分分析时，它仅在两个维度上产生物种间的明显差异。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ne nf l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ng"><img src="../Images/498e010ff9badf74f30198a229fb3535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*7vkeTqXyL1jyOSveNxNqRQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">虹膜数据集上的主成分分析</p></figure><blockquote class="la lb lc"><p id="a8ca" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv"> Scikit Learn的因子分析</strong></p></blockquote><p id="fa82" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">Sci-kit-Learn还提供了另一种与PCA非常相似的降维方法。如前所述，主成分分析侧重于初始数据的线性组合，新的成分非常不相关。另一方面，因子分析指导对数据潜在特征的分析，并推导出成分。假设潜在因子保留在低维空间中，并且通过添加具有潜在因子的高斯噪声来获得新的观测值。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ne nf l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nh"><img src="../Images/895aa6b6217f0d0c8ea6708a5bdabfe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*uiJZ_GXGm4PLLOvCz2B9Gg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">虹膜数据集的因子分析</p></figure><p id="8a4e" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">结果与PCA输出非常相似，只是x轴和y轴刻度不同。</p><blockquote class="la lb lc"><p id="9740" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv"> Scikit Learn的独立成分分析</strong></p></blockquote><p id="7af8" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">Scikit-Learn提供了分析数据的选项，其中观察数据的潜在因素不是高斯型的。对于这种情况，我们可以使用FastICA模块。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ne nf l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ni"><img src="../Images/4f2afb52a7572e974ada779f1eefa065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*VzX6JXuBO1myxuKM2IeEsg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">虹膜数据集上的独立分量分析</p></figure><p id="69f3" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">这里，沿着独立组件2也可以清楚地区分物种。</p><blockquote class="la lb lc"><p id="603d" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">如果特征是绝对的呢？</strong></p></blockquote><p id="d02a" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">PCA对连续数据非常有效，但是真实世界的数据是连续数据和分类数据的混合。有时，分类数据使用一键编码方法进行编码，但不推荐使用这种方法。PCA背后的核心思想是以一定的准确性为代价来确定解释大部分可变性的成分。当我们通过编码获得二进制数据时，可变性的概念就崩溃了。</p><p id="69d6" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">PCA可能对编码数据起作用，但本质上这并不能使它成为一个好的分析。例如，住房数据有几个分类特征，这些特征首先被编码、标准化并输入PCA分析。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ne nf l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nh"><img src="../Images/3404e23f4387ed12a61ac8187f5b248e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*WQ98OIQ4y79-DghmL41VSg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">分类数据的主成分分析</p></figure><p id="3741" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">最初，这似乎是一个很好的分析，显示了两个最主要的组成部分，但这种编码不建议在categorial上使用。相反，应该利用混合数据的因子分析(FAMD)等技术。FAMD旨在处理混合类型的数据。</p><blockquote class="la lb lc"><p id="279e" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv"> FAMD利用王子</strong></p></blockquote><p id="4813" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">王子包有一些内置的因素分析方法，包括FAMD。我们可以继续用同样的住房数据。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ne nf l"/></div></figure><p id="2b0b" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">当选择“HouseStyle”作为拆分因子时，我们得到下图。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nj"><img src="../Images/d440f1616e0cf645afc4c0ce26f7ad83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iyM_bqM-tg6CbfD8bhECQg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">FAMD住房数据集</p></figure><p id="2999" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">显然，在数据点上有一些重叠，导致组分1仅解释了8%的可变性，而组分2解释了约3%的可变性。FAMD结合主成分分析和多成分分析技术进行分析。MCA代表多重对应分析，特别适用于多种分类因素。如果数据集按具有连续值和分类值的不同要素进行分组，则可以部署另一种称为MFA(多因素分析)的技术。</p><p id="f291" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">让我们选择葡萄酒数据集，它由两个分类变量和几个数字变量组成，描述列出的葡萄酒的质量。一旦将FAMD应用于该数据集并在“土壤”类型上进行分割，数据点就可区分。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nk"><img src="../Images/eda2c79aeb51d737e987880a5bfd9a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GiYrrCD9fW7g0pdke14n9g.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">FAMD数据集</p></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nl"><img src="../Images/fc2011add6d106ab9757f72af4eeb2a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*mV8TXEnuzbSyMNtEVg-PkA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">土壤上的FAMD分析分裂</p></figure><p id="90d4" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">显然，按土壤划分时，有不同的群体。第一个因素解释了26%，第二个因素解释了22%的可变性。</p><blockquote class="la lb lc"><p id="775d" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">结论</strong></p></blockquote><p id="ca17" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">在本文中，我讨论了使用FAMD技术对大型数据集进行降维。可以通过几种特征选择方法来分析数据集以提取最重要的特征，或者可以利用成分/因素分析技术。不建议对分类数据应用常规PCA。在处理混合数据时，FAMD是处理不必要因素和降低数据维数的推荐方法。</p><p id="8a23" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated"><a class="ae kz" href="https://github.com/mdsohelmahmood/data-science/blob/master/_notebooks/2021-07-11-Factor_Analysis_of_Mixed_Data.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a></p></div></div>    
</body>
</html>