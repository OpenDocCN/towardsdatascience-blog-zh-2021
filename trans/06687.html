<html>
<head>
<title>How to Extract Relevant Keywords with KeyBERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用KeyBERT提取相关关键词</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-extract-relevant-keywords-with-keybert-6e7b3cf889ae?source=collection_archive---------3-----------------------#2021-06-16">https://towardsdatascience.com/how-to-extract-relevant-keywords-with-keybert-6e7b3cf889ae?source=collection_archive---------3-----------------------#2021-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="94d5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">伯特的另一个应用</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/29940115078e46bc7c0f6830db2ee4d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*40HG1F1ZQwRC9h57XZ8HEw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="476f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有很多强大的技术可以执行关键词提取(例如<a class="ae lu" href="https://csurfer.github.io/rake-nltk/_build/html/index.html" rel="noopener ugc nofollow" target="_blank"> Rake </a>，<a class="ae lu" href="https://github.com/LIAAD/yake" rel="noopener ugc nofollow" target="_blank"> YAKE </a>！，<a class="ae lu" href="https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.YMjWGTYzZ_k" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>)。然而，它们主要基于文本的统计属性，并不一定考虑整个文档的语义方面。</p><p id="747b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">KeyBERT是一个简单易用的关键字提取技术，旨在解决这个问题。它利用了BERT语言模型，并依赖于🤗变形金刚图书馆。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/28dc04818f6225ed25f7d95b5450bd33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ElN8Y7h29-vZfOzJ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae lu" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank">https://github.com/MaartenGr/KeyBERT</a></p></figure><p id="fdd5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">KeyBERT由<a class="lw lx ep" href="https://medium.com/u/22405c3b2875?source=post_page-----6e7b3cf889ae--------------------------------" rel="noopener" target="_blank"> Maarten Grootendorst </a>开发和维护。所以，如果你有兴趣使用它，就去看看他的回购(并克隆它)。</p><p id="ec4f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我将简要介绍<a class="ae lu" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank"> KeyBERT </a>:它是如何工作的，以及你如何使用它</p><p id="c2d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ly"> PS:如果想看如何使用KeyBERT以及如何嵌入到Streamlit app中的视频教程，可以看看我的视频:</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lz ma l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者视频</p></figure><h1 id="d76f" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">KeyBERT:一种基于BERT的关键词提取技术</h1><p id="e8ed" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">你可以用pip安装KeyBERT。</p><pre class="kj kk kl km gt my mz na nb aw nc bi"><span id="3910" class="nd mc it mz b gy ne nf l ng nh">pip install keybert</span></pre><p id="7ba2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您需要其他来源的嵌入🤗变压器，你也可以安装它们:</p><pre class="kj kk kl km gt my mz na nb aw nc bi"><span id="9957" class="nd mc it mz b gy ne nf l ng nh">pip install keybert[flair]<br/>pip install keybert[gensim]<br/>pip install keybert[spacy]<br/>pip install keybert[use]</span></pre><p id="85be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">调用KeyBERT很简单:根据🤗变形金刚建模并对其应用<code class="fe ni nj nk mz b">extract_keywords</code>方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/4e5bdfd11b925cb86d03eb8b0558dbeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1rE3_iTR7agEs_s5"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:https://github.com/MaartenGr/KeyBERT</p></figure><h1 id="2ca8" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">KeyBERT如何提取关键词？</h1><p id="58cb" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">KeyBERT通过执行以下步骤提取关键词:</p><p id="7bf4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">1-使用预训练的BERT模型嵌入输入文档。你可以选择任何你想要的伯特模型🤗变形金刚。这将文本块转换成固定大小的向量，表示文档的语义方面</p><p id="eb34" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2-使用单词包技术(如TfidfVectorizer或CountVectorizer)从同一文档中提取关键字和表达式(n元语法)。这是一个经典步骤，如果您过去执行过关键词提取，您可能会很熟悉</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/1d3d65aa70ae839cab3c64fbc72b71bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Vg6abk6F1H6JfwDB"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="3ea6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3-然后将每个关键字嵌入到固定大小的向量中，使用与嵌入文档相同的模型</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/51f7d95d9255c96601c84d3ae63c025a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9B-eJJR6p4jb_-uA"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="690d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4-既然关键字和文档在同一空间中表示，KeyBERT计算关键字嵌入和文档嵌入之间的余弦相似性。然后，提取最相似的关键字(具有最高的余弦相似性得分)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/4ad891f4f6761e33893933e22bae6f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ocfR8WLpwRI_7tGi"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4b20" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个想法非常简单:您可以把它看作是经典关键字提取技术的增强版本，其中BERT语言模型加入了它的语义功能。</p><p id="1081" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">这还不止于此</strong> : KeyBERT包括两种方法来在结果关键字中引入多样性。</p><p id="8e0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 1 —最大相似度总和(MSS) </strong></p><p id="ef80" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要使用这个方法，首先要将top_n参数设置为一个值，比如20。然后从文档中提取2个top_n关键词。计算这些关键词之间的成对相似度。<strong class="la iu">最后，该方法提取彼此最不相似的最相关的关键词。</strong></p><p id="6b29" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里有一个来自KeyBERT知识库的例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/35ace73af27ee0b8172af38df26af03e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*41ojPc7ehmywO4rg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae lu" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank">https://github.com/MaartenGr/KeyBERT</a></p></figure><p id="3fc6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 2 —最大边际相关性(MMR) </strong>这种方法与前一种相似:它增加了一个多样性参数</p><p id="fc7f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在文本摘要任务中，MMR试图最小化冗余并最大化结果的多样性。</p><p id="05e6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它从选择与文档最相似的关键词开始。然后，它迭代地选择既与文档相似又与已经选择的关键词不相似的新候选</p><p id="bd4b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以选择低差异阈值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/b2b1717f8a0f0a24a49c7cf54f0b4363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_7s_667Gmi56BXXs"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae lu" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank">https://github.com/MaartenGr/KeyBERT</a></p></figure><p id="5258" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者一个高的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/5685efb977b9923c9589caa26e1e2b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T8y3VdKBjfMplyVz"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae lu" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank">https://github.com/MaartenGr/KeyBERT</a></p></figure><h1 id="6d11" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">到目前为止还不错，但是…</h1><p id="0ab7" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">不过，KeyBERT可能会遇到的一个限制是执行时间:如果您有大型文档并需要实时结果，KeyBERT可能不是最佳解决方案(除非您的生产环境中有专用的GPU)。原因是BERT模型是出了名的庞大，并且消耗大量资源，尤其是当它们必须处理大型文档时。</p><p id="c590" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可能会找到一些技巧来加快推断时间，方法是选择较小的模型(DistilBERT)，使用混合精度，甚至将您的模型转换为ONNX格式。</p><p id="d1bb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果这仍然对你不起作用，检查一下其他经典方法:尽管它们相对简单，但你会对它们的效率感到惊讶。</p><h1 id="ca20" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">感谢阅读！</h1><p id="15c3" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">今天到此为止。如果您正在执行关键词提取，我希望您会发现这个小方法对您的NLP项目有用。</p><p id="9b4c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在这里了解更多关于KeyBERT的信息:</p><div class="nr ns gp gr nt nu"><a href="https://github.com/MaartenGr/KeyBERT" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">马尔滕格尔/凯伯特</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">KeyBERT是一种简单易用的关键字提取技术，它利用BERT嵌入来创建关键字和…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">github.com</p></div></div><div class="od l"><div class="oe l of og oh od oi ks nu"/></div></div></a></div><div class="nr ns gp gr nt nu"><a rel="noopener follow" target="_blank" href="/keyword-extraction-with-bert-724efca412ea"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">用BERT提取关键词</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">一种提取关键词和关键短语的最小方法</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="oj l of og oh od oi ks nu"/></div></div></a></div><p id="764e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有这里:</p><div class="nr ns gp gr nt nu"><a href="https://www.preprints.org/manuscript/201908.0073/v1" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">具有自标记的自监督上下文关键词和关键短语检索</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">本文提出了一种新的自监督的关键字和关键短语检索和抽取方法</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">www.preprints.org</p></div></div><div class="od l"><div class="ok l of og oh od oi ks nu"/></div></div></a></div><p id="961c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">保重，</p><h1 id="9ee5" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">新到中？您可以每月订阅5美元，并解锁无限的文章— <a class="ae lu" href="https://ahmedbesbes.medium.com/membership" rel="noopener">点击此处。</a></h1></div></div>    
</body>
</html>