<html>
<head>
<title>How to Implement Deep Neural Networks for Radar Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何实现雷达图像分类的深度神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-implement-deep-neural-networks-for-radar-image-classification-acb1bfcd7f3?source=collection_archive---------14-----------------------#2021-06-06">https://towardsdatascience.com/how-to-implement-deep-neural-networks-for-radar-image-classification-acb1bfcd7f3?source=collection_archive---------14-----------------------#2021-06-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3ebd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用为计算机视觉开发的网络架构和技术</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a1849de45a0f48820ee1fd0547db2858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hoZXpIEI4-3J1YIP"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@prescott3?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">普雷斯科特·霍恩</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="6d23" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="103a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对家庭环境中的人和物进行基于雷达的识别和定位相对于计算机视觉具有一定的优势，包括增加用户隐私、低功耗、零光操作和更灵活的传感器放置。</p><p id="dda6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">可以使用支持向量机和逻辑回归等浅层机器学习技术对来自雷达的图像进行分类，在我之前的工作中，<a class="ae kv" rel="noopener" target="_blank" href="/teaching-radar-to-understand-the-home-ee78e7e4a0be">教雷达了解家</a>和<a class="ae kv" rel="noopener" target="_blank" href="/using-stochastic-gradient-descent-to-train-linear-classifiers-c80f6aeaff76">使用随机梯度下降训练线性分类器</a>我分享了如何应用其中的一些方法。</p><p id="6689" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在本文中，您将学习如何开发深度神经网络(DNN)并训练它们对雷达图像中的对象进行分类。此外，您将学习如何使用半监督生成对抗网络(SGAN) [1]，它只需要少量的标记数据来训练DNN分类器。这在处理雷达数据集时很重要，因为缺乏大型训练集，与基于相机的图像(例如，I <a class="ae kv" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> mageNet </a>)相比，这有助于使计算机视觉无处不在。</p><p id="a580" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从架构和训练方法的角度来看，最初为视觉图像分类开发的DNNs(或更具体地说，卷积神经网络)和SGANs都可以用于雷达应用。</p><h1 id="76a0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据集</h1><p id="bb41" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了帮助您理解本文中使用的技术和代码，本节提供了一个简短的数据集浏览。作为<a class="ae kv" href="https://github.com/goruck/radar-ml" rel="noopener ugc nofollow" target="_blank"> radar-ml </a>项目的一部分，数据集是从雷达样本中收集的，并在这里找到了<a class="ae kv" href="https://drive.google.com/drive/folders/12QKwuzniZkiqsEVBDx-ho9K6AbOiJz7w?usp=sharing" rel="noopener ugc nofollow" target="_blank"/>。该项目采用自主监督学习，其中标准的基于摄像机的对象检测技术用于自动标记人和对象的雷达扫描。</p><p id="3ce0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">数据集是以下形式的Python <code class="fe mp mq mr ms b">dict</code>:</p><p id="bf05" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe mp mq mr ms b">{‘samples’: samples, ‘labels’: labels}</code></p><p id="f8f5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe mp mq mr ms b">samples</code>是N个雷达投影中的一个<code class="fe mp mq mr ms b">list</code><code class="fe mp mq mr ms b">numpy.array</code>元组样本的形式:</p><p id="56c6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe mp mq mr ms b">[(xz_0, yz_0, xy_0), (xz_1, yz_1, xy_1),…,(xz_N, yz_N, xy_N)]</code></p><p id="6e19" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">其中雷达投影是投影到x、y和z轴的三维空间中扫描目标物体的最大返回信号强度。这些2-D表示通常是稀疏的，因为投影占据了扫描体积的一小部分。采样、存储和利用二维投影比直接使用三维源数据更有效。</p><p id="e90e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe mp mq mr ms b">labels</code>是N个<code class="fe mp mq mr ms b"> numpy.array</code>类标签中的一个<code class="fe mp mq mr ms b">list</code>，对应表格中的每个雷达投影样本；</p><p id="21fb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe mp mq mr ms b">[class_label_0, class_label_1,…,class_label_N]</code></p><p id="bfd4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下面的热图显示了典型单个样本的预测。红色表示返回信号最强的地方。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/e39c8ea7ae8abf2169a13e896edcc492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O068c-v85z_lxoCg_zDT9g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">狗(我的宠物波利)数据集样本的可视化</p></figure><p id="9aa1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这些数据是在我家的不同位置捕获的，旨在最大化检测到的对象(目前只有人、狗和猫)、距离和雷达传感器的角度的变化。</p><p id="6aff" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">数据集仅包含几千个样本(具有已知的标记误差)，并且在过度拟合之前只能用于训练少量时期的深度神经网络。标记误差将影响从该数据集训练的雷达分类器的准确性。虽然未来的努力将试图微调目标探测器以减少误差，但使用SGAN可以避免或最大限度地减少标记未来雷达观测的需要。在保持可接受的准确性的同时，减少训练分类器的标记数据点的数量，是在这个项目中探索使用SGANs的主要动机。</p><h1 id="84a8" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">模型架构</h1><p id="672c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如上所述，数据集包含三维雷达图像的二维表示的集合，幸运的是，计算机视觉领域的先前工作证明了在这种二维表示上设计和训练神经网络的可能性，这种二维表示匹配甚至优于在原始三维数据集上训练的网络，参见[2]和[3]。这项先前的工作启发了下面网络的发展。</p><p id="d558" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">所有模型和相关培训都是使用Keras API实现的，Keras API是TensorFlow的高级API，是<a class="ae kv" href="https://github.com/goruck/radar-ml" rel="noopener ugc nofollow" target="_blank"> radar-ml </a>项目的一部分。</p><h2 id="e756" class="mu kx iq bd ky mv mw dn lc mx my dp lg lx mz na li mb nb nc lk mf nd ne lm nf bi translated">深度神经网络(DNN)分类器</h2><p id="68dc" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">尽管人类无法识别，二维雷达图像投影的集合包含映射回被扫描物体的特征。三个2-D投影中的每一个都通过独立的2-D卷积层，这些卷积层学习这些特征并连续对图像进行下采样。来自这些层的输出被连接，然后被展平以形成单个特征向量，该特征向量被用作深度连接的密集层的输入，紧接着是分类层。下图中的这个架构。您可能会注意到，这种架构的一个分支类似于计算机视觉中使用的卷积神经网络(CNN)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/2b46e566a50cf700efcb9228ccaddece.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PL-toNa5QWUZvhFElKPa4Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">DNN分类器的体系结构</p></figure><p id="05c0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">该模型由<a class="ae kv" href="https://github.com/goruck/radar-ml" rel="noopener ugc nofollow" target="_blank"> radar-ml </a>资源库中的文件<a class="ae kv" href="https://github.com/goruck/radar-ml/blob/master/dnn.py" rel="noopener ugc nofollow" target="_blank"> dnn.py </a>中的Python模块实现。您可以在下面看到定义和编译该模型的代码片段。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">创建DNN分类器的Python代码片段</p></figure><h2 id="c978" class="mu kx iq bd ky mv mw dn lc mx my dp lg lx mz na li mb nb nc lk mf nd ne lm nf bi translated">半监督生成对抗网络</h2><p id="0df3" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">与建立地面事实相比，收集雷达图像用于模型训练相对简单，地面事实需要人在回路中、自主监督学习或半监督学习等技术，半监督学习在训练期间将少量标记数据与大量未标记数据相结合。使用半监督学习的动机是最小化与人类标记雷达扫描或使用复杂(可能容易出错)的自主监督学习相关的工作。</p><p id="ed16" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">生成对抗网络(GAN)是一种使用未标记数据集来训练图像生成器模型和图像鉴别器模型的架构。在某些情况下，您可以使用鉴别器模型来开发分类器模型。GANs已用于雷达信号生成[4]，并在计算机视觉应用中得到广泛使用[5]。</p><p id="a046" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">半监督GAN (SGAN)模型是GAN架构的扩展，它采用监督鉴别器、非监督鉴别器和生成器模型的共同训练。在这个项目中，监督鉴别器被用作归纳为新数据集的分类模型和生成雷达投影的真实示例的生成器模型(仅用作有效性检查)。</p><p id="30d2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">监督鉴频器架构如下图所示，您可能会注意到它类似于附近所示的DNN架构，但有一些例外，包括使用LeakyReLU(泄漏整流线性单元)而不是ReLU，这是GAN培训的最佳实践[7]。该模型包括批量标准化层，以帮助训练收敛，这通常是训练GANs的一个问题[6]。无监督鉴别器共享除最终输出图层之外的大多数图层，因此具有非常相似的架构。监督鉴别器的输出是一个具有softmax激活的密集层，它形成一个3级分类器，而无监督模型在softmax激活之前获取监督模型的输出，然后计算指数输出的归一化和[6]。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/9929aa6b13b04855d434433d5d83a0ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AbJbSGexYAuzPvNxCTLXyQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">监督鉴别器的体系结构</p></figure><p id="663d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">监督和非监督鉴别器模型都是由位于<a class="ae kv" href="https://github.com/goruck/radar-ml" rel="noopener ugc nofollow" target="_blank"> radar-ml </a>存储库中的<a class="ae kv" href="https://github.com/goruck/radar-ml/blob/master/sgan.py" rel="noopener ugc nofollow" target="_blank"> sgan.py </a>文件中的Python模块实现的。定义和编译下面模型的代码片段。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">创建监督和非监督鉴别器的Python代码片段</p></figure><p id="f224" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">生成器模型从潜在空间中获取一个向量(从标准正态分布中提取的噪声向量),并使用具有ReLU激活的转置卷积层的三个分支来连续上采样潜在空间向量，以形成三个雷达图像投影中的每一个。生成器被堆叠在鉴别器模型的顶部，并且在后者的权重被冻结的情况下被训练。下图描述了这种组合架构。请注意使用批量标准化图层来帮助模型训练收敛。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/cbec828c96b01cd0317d267ad8dc653b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3gKABYVc8mNbIxDoclnUQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GAN架构</p></figure><p id="45b1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">生成器和GAN由<a class="ae kv" href="https://github.com/goruck/radar-ml" rel="noopener ugc nofollow" target="_blank"> radar-ml </a>资源库中的文件<a class="ae kv" href="https://github.com/goruck/radar-ml/blob/master/sgan.py" rel="noopener ugc nofollow" target="_blank"> sgan.py </a>中的Python模块实现。下面是定义和编译模型的代码片段。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">创建生成器和GAN的Python代码片段</p></figure><h1 id="3bf3" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">模型训练和结果</h1><h2 id="f4b8" class="mu kx iq bd ky mv mw dn lc mx my dp lg lx mz na li mb nb nc lk mf nd ne lm nf bi translated">DNN</h2><p id="ebfc" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">DNN通过<code class="fe mp mq mr ms b">tf.keras.Model</code>类<code class="fe mp mq mr ms b">fit</code>方法训练，并由<a class="ae kv" href="https://github.com/goruck/radar-ml" rel="noopener ugc nofollow" target="_blank"> radar-ml </a>资源库中<a class="ae kv" href="https://github.com/goruck/radar-ml/blob/master/dnn.py" rel="noopener ugc nofollow" target="_blank"> dnn.py </a>文件中的Python模块实现。下面是训练函数的代码片段，没有显示预处理和过滤数据所需的步骤。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">DNN训练函数的Python代码片段</p></figure><p id="9ddd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">典型训练的结果如下。模型和数据集的当前状态能够获得80%到80%的验证集精度。需要做更多的工作来达到或超过SVM和逻辑回归模型在之前的工作中获得的90%的精度[8][9]。这将是今后努力的重点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">DNN培训结果</p></figure><h2 id="fb8c" class="mu kx iq bd ky mv mw dn lc mx my dp lg lx mz na li mb nb nc lk mf nd ne lm nf bi translated">斯甘</h2><blockquote class="nl nm nn"><p id="bbd2" class="lo lp no lq b lr mk jr lt lu ml ju lw np mm lz ma nq mn md me nr mo mh mi mj ij bi translated">生成对抗网络(GANs)很难训练。这是因为该架构包括一个生成器和一个鉴别器模型，它们在零和游戏中竞争。这意味着一个模型的改进是以另一个模型的性能下降为代价的。结果是一个非常不稳定的训练过程，经常会导致失败，例如，生成器总是生成相同的图像或生成无意义的图像。因此，在配置和训练您的GAN模型时，可以使用许多启发式方法或最佳实践(称为GAN hacks)。这些试探法是从业者多年来在一系列问题上测试和评估成百上千个配置操作组合来之不易的。</p><p id="2ab7" class="lo lp no lq b lr mk jr lt lu ml ju lw np mm lz ma nq mn md me nr mo mh mi mj ij bi translated">“用Python生成对抗性网络”，Jason Brownlee，2021。</p></blockquote><p id="639b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">您可以找到许多优秀的论文和文章，帮助您了解如何应用最佳实践来培训GANs。特别是，<a class="ae kv" href="https://www.linkedin.com/in/jasonbrownlee/?originalSubdomain=au" rel="noopener ugc nofollow" target="_blank"> Jason Brownlee </a>发表了许多务实的文章和论文，可以证明节省时间[7]。这些工作中的一部分被用于确定在雷达SGAN模型和数据集上工作得相当好的训练方法。如果你认真理解应用机器学习的<strong class="lq ir"> <em class="no">和</em> </strong>，可以考虑阅读他的在线文章和购买他的电子书。</p><p id="25ad" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">训练循环由<a class="ae kv" href="https://github.com/goruck/radar-ml" rel="noopener ugc nofollow" target="_blank"> radar-ml </a>存储库中的文件<a class="ae kv" href="https://github.com/goruck/radar-ml/blob/master/sgan.py" rel="noopener ugc nofollow" target="_blank"> sgan.py </a>中的Python模块实现。下面是训练循环的一个片段，没有显示预处理和过滤数据集所需的步骤以及几个帮助函数。该代码基于参考文献[7]。注意，鉴别器模型用1.5批样本更新，但是生成器模型每次迭代用一批样本更新。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SGAN训练循环的Python代码片段</p></figure><p id="7cab" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">由于GANs的随机性，你会发现每次跑步的训练结果都不一样，所以最好将几次跑步的结果平均起来。对于无监督的鉴别器和生成器，良好的训练会话将具有中等(~ 0.5)和相对稳定的损失，而有监督的鉴别器将在训练集上收敛到非常低的损失(&lt; 0.1) with high accuracy (&gt; 95%)。验证集的准确性结果往往在低到高的70%之间，每类仅使用50个监督样本时，损失在1.2左右徘徊。这是一个令人鼓舞的结果，但显然需要更多的建模工作和数据收集，以获得与该数据集上采用的其他机器学习方法相当的验证准确性，通常为约90% [8][9]。这将是这个项目今后工作的重点。典型的培训结果如下所示。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SGAN培训结果</p></figure><p id="8cae" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">您还应该查看生成器生成的图像，以确定它们是否有意义。在这种情况下，由于图像是3d物体的雷达扫描的2d投影，并且不能被人类识别，因此需要将生成的图像与来自原始数据集的示例进行比较，如上图所示。下图是一组生成的二维扫描。其中一个投影(X-Y平面)中的相似性是明显的，但在其他投影中不明显，至少对于这次训练运行是如此。这可以解释低准确性，并且找到使其他生成的投影在视觉上类似于训练集的方法留给了未来的练习。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/c84b4a7f28348d3a359a7e6186460a98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GaOriq4UXfW8jVmhzsMFUg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">生成的数据集样本的可视化</p></figure><h1 id="39ed" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="aaa6" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">您可以利用CNN、SGAN的模型架构以及为基于摄像机的计算机视觉开发的相关培训技术来开发神经网络，从而对雷达图像进行分类。考虑到雷达数据集的缺乏，您通常需要收集雷达数据集，这些数据集可能是资源密集型的，并且对于地面实况新雷达观测来说容易出错。您可以使用自我监督技术来利用未标记的数据，每个类只使用几十个或更少的标记样本和一个SGAN。通过这种方式，您可以使用大量未标记的数据开发雷达图像分类器。</p><p id="b657" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">以前的工作使用浅层机器学习模型，并在数据集上实现了比当前使用这里描述的网络和技术获得的更高的准确性。未来的努力是计划弥补这一差距，并增加数据集的大小，以在过度拟合之前获得更好的验证集准确性。</p><h1 id="c68c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><ol class=""><li id="3d4e" class="nt nu iq lq b lr ls lu lv lx nv mb nw mf nx mj ny nz oa ob bi translated"><a class="ae kv" href="https://arxiv.org/pdf/1606.01583.pdf%5D" rel="noopener ugc nofollow" target="_blank">生成对抗网络半监督学习</a>，2016。</li><li id="22c9" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" href="https://arxiv.org/abs/1505.00880" rel="noopener ugc nofollow" target="_blank">用于三维形状识别的多视角卷积神经网络</a>，2015。</li><li id="343e" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0245230" rel="noopener ugc nofollow" target="_blank">卷积神经网络多视角分类</a>，2021。</li><li id="53cb" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" href="https://arxiv.org/abs/2008.03346" rel="noopener ugc nofollow" target="_blank">雷达信号生成对抗网络<br/>代</a>，2019。</li><li id="f266" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank">深度卷积生成对抗网络的无监督表示学习</a>，2016。</li><li id="3c36" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" href="https://arxiv.org/abs/1606.03498" rel="noopener ugc nofollow" target="_blank">训练GANs的改进技术</a>，2016。</li><li id="498c" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" href="https://machinelearningmastery.com/generative_adversarial_networks/" rel="noopener ugc nofollow" target="_blank">用Python生成对抗性网络</a>，2021。</li><li id="3f8b" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/teaching-radar-to-understand-the-home-ee78e7e4a0be">教雷达了解家</a>，2020。</li><li id="a79e" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/using-stochastic-gradient-descent-to-train-linear-classifiers-c80f6aeaff76">利用随机梯度下降训练线性分类器</a>，2020。</li></ol></div></div>    
</body>
</html>