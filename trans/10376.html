<html>
<head>
<title>Entropy, explained simply</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">熵，简单地解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/entropy-how-to-explain-to-a-10-year-old-7bcc5315291b?source=collection_archive---------12-----------------------#2021-10-03">https://towardsdatascience.com/entropy-how-to-explain-to-a-10-year-old-7bcc5315291b?source=collection_archive---------12-----------------------#2021-10-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6b27" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">让不太直观的概念变得直观</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fee4d6dd6ad668d9a45ad7e7028bcd4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XR3jionunFkyy4z_"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">安妮·斯普拉特在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e522" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">熵是信息论的核心概念之一，对机器学习领域贡献巨大，主要由(但不限于)基于树的算法(决策树、随机森林、bagging、boosting等)作为其核心来决定要分割的特征(或基于熵构建的IG/Gini)</p><p id="9ab0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管它们有广泛的应用，巨大的影响，以及它们在数学上有多大的意义，但它们不是很直观</p><p id="7424" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你第一次听到熵这个词，这个故事将有助于理解它们背后的核心概念。如果你很了解它，也许想向你的侄子或侄女(或者不了解统计的人)解释，这个故事会有所帮助</p><h1 id="906e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">故事是这样的:</h1><p id="8f88" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">你坐在教室里，这是你最好的朋友的生日。你可以看到他走向每张桌子，分发巧克力，每个人都被要求从他的巧克力袋中挑选一块巧克力。假设他包里有两种不同口味的巧克力:</p><ol class=""><li id="5618" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">黑巧克力</li><li id="76f4" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">牛奶巧克力</li></ol><p id="e6a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在他来到你的桌前，让你从他的包里随机挑选一块巧克力</p><h1 id="e6ab" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">熵</h1><p id="e3f1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">假设你喜欢黑巧克力&amp;无论何时，你都喜欢黑巧克力胜过牛奶巧克力。因为他是你最好的朋友，他愿意就他包里的东西给你提示。让我们考虑以下场景</p><ol class=""><li id="5f8d" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">他说<em class="nd">“袋子里还剩6块巧克力，都是黑的”</em>你欣喜若狂，因为你确定你肯定会得到黑巧克力，所以马上跳了起来。没有惊喜的成分</li><li id="3be7" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">他说<em class="nd">“袋子里还剩6块巧克力，其中4块是深色的，另外2块是牛奶巧克力”</em>你仍然很有信心随机抽取的巧克力仍然是深色的，但你不再是100%有信心了。随机挑选巧克力的惊喜成分正在增加。</li><li id="c505" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">他说<em class="nd">“袋子里还剩6块巧克力，其中3块是黑色的，其余3块是牛奶巧克力”</em>。现在你担心了，因为你随机挑选的巧克力可能是。在这种情况下，出其不意的因素达到了顶峰。</li><li id="af80" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">他说<em class="nd">“袋子里还剩6块巧克力，其中4块是牛奶巧克力，剩下2块是黑巧克力”</em>。现在你更担心了，因为你随机挑选的巧克力很可能是牛奶巧克力。惊喜的成分很低(即使它对你不利)</li><li id="957c" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">他说<em class="nd">“包里还剩6块巧克力，都是牛奶巧克力”</em>。现在你很难过，因为你确定不管你选什么，都是牛奶巧克力。一点惊喜都没有了</li></ol><p id="0085" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的例子中，惊奇的元素只不过是熵。在情景3中，两种巧克力在袋子里的数量相等，这种惊喜的成分是最大的。当巧克力的比例变得有利于某一种巧克力时，你的惊奇感就会减少(不管你喜欢什么；) )</p><h1 id="89ae" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">我们学到了什么</h1><p id="61be" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">简单地说，熵是用数学表达的惊奇元素。二元分类的等式是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/af169a0558df0c91b28397491f0dcd4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4WokXxyGkTVTFL4u1nhEg.png"/></div></div></figure><p id="39bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中p(0)是一等品的比例&amp; p(1)是二等品的比例。当惊奇元素最大时，熵取最大值1，即在二进制类的情况下，当类分布为50%-50%时。每当一个类完全接管另一个类时，即100%-0%分布时，它取最小值零</p><p id="9ef2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">推广到多功能场景:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/49ad17fc2e4b1b215aa11a9d4c8b22dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G3k97nPmTm_15tUiv4hYtg.png"/></div></div></figure><p id="7de5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看待熵的另一种方式是帮助理解概率分布的不可预测性。在案例1和5中，分布是高度可预测的，而在案例3中，它是非常不可预测的</p><p id="ca4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总之，熵提供了对数据集中的不确定性或无序的度量，作为数据科学家/ML工程师，我们的目标是创建模型，以减少/最小化数据集标签系统中的熵(在分类问题的情况下)</p></div></div>    
</body>
</html>