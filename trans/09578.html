<html>
<head>
<title>Awesome PyTorch Lightning template</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">真棒PyTorch闪电模板</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/awesome-pytorch-lightning-template-485a75c2f47e?source=collection_archive---------13-----------------------#2021-09-06">https://towardsdatascience.com/awesome-pytorch-lightning-template-485a75c2f47e?source=collection_archive---------13-----------------------#2021-09-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="021a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">TLDR:py torch Lightning模板，包含了很多特性。<a class="ae kf" href="https://colab.research.google.com/drive/17CtsJtGCjp4YkykIpIoY0Kdb9nCadeFT?usp=sharing" rel="noopener ugc nofollow" target="_blank">链接到谷歌实验室这里</a>。</h2></div><p id="14da" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">认知状态:这个模板是几周学习的结果，而不是多年的经验。把这当成你朋友的课堂笔记，而不是老师的讲义。为了让你知道我是多么的不合格和固执己见，只要看看我没能解决的问题列表就知道了。如果你知道如何解决它们，请告诉我。</em></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/530b6abbf976405c8e3b8675a2b9bae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YUkUOOs2Fxod2T0XAVJAxQ.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">可怕的闪电照片。Marc Szeglat 在<a class="ae kf" href="https://unsplash.com/s/photos/lightning-fire?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="c2d3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">你是否曾经困惑过<a class="ae kf" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>的最佳实践是什么？比如，什么时候把你的张量发给GPU？或者什么时候打电话给zero_grad？或者，您是否尝试过做一些新的事情，比如添加一个类似SimCLR的管道，并且因为写得太差而不得不重写大部分代码？又或许，你在想别人的管道是什么样的？他们的效率是100%的吗？有哪些你一直缺失的简单小技巧和窍门？也许不是你，但我有。PyTorch闪电 (PL)前来救援。它基本上是一个关于你的代码应该如何构造的模板。</p><p id="b193" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">PL在他们的文档中有很多特性，比如:</p><ul class=""><li id="bc02" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/loggers.html" rel="noopener ugc nofollow" target="_blank">测井</a></li><li id="ae50" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#inspect-gradient-norms" rel="noopener ugc nofollow" target="_blank">检测坡度</a></li><li id="4fac" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/advanced/profiler.html" rel="noopener ugc nofollow" target="_blank">剖析器</a></li><li id="8b3d" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">等等。</li></ul><p id="aae9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">他们还有很多模板，例如:</p><ul class=""><li id="9688" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated">最简单的例子叫做<a class="ae kf" href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/bug_report_model.py" rel="noopener ugc nofollow" target="_blank">对无聊模型</a>进行调试</li><li id="73dc" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/starter/rapid_prototyping_templates.html" rel="noopener ugc nofollow" target="_blank">用于快速成型的划痕模型</a></li><li id="13e8" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://github.com/PyTorchLightning/pytorch-lightning/tree/master/pl_examples" rel="noopener ugc nofollow" target="_blank">基本例子</a>像<a class="ae kf" href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/basic_examples/simple_image_classifier.py" rel="noopener ugc nofollow" target="_blank"> MNIST </a></li><li id="85cc" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">类似<a class="ae kf" href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/domain_templates/generative_adversarial_net.py" rel="noopener ugc nofollow" target="_blank">生成性对抗网络</a>的高级例子</li><li id="68fa" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">甚至更多的东西在PL <a class="ae kf" href="https://www.pytorchlightning.ai/bolts" rel="noopener ugc nofollow" target="_blank">螺栓</a> ( <a class="ae kf" href="https://github.com/PyTorchLightning/lightning-bolts" rel="noopener ugc nofollow" target="_blank"> github </a>)</li></ul><p id="c2e5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">问题是所有这些例子都很简单。这对于演示或作为模板来说非常好。但是缺少一个更完整的例子来展示所有这些特性是如何集成的。尤其是对于深度学习领域的第一个编码项目的人来说，这就是:</p><h1 id="dbfc" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">模板</h1><p id="9e6d" class="pw-post-body-paragraph kg kh iq ki b kj mz jr kl km na ju ko kp nb kr ks kt nc kv kw kx nd kz la lb ij bi translated"><strong class="ki ir">点击此处链接至Google Colab。</strong></p><h1 id="c351" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">特征</h1><h2 id="cac9" class="ne mi iq bd mj nf ng dn mn nh ni dp mr kp nj nk mt kt nl nm mv kx nn no mx np bi translated">记录</h2><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nq"><img src="../Images/e60f38c3dc8f750cb614da79281db168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q0QcsPy0yzxSg5ZsW95dbw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><a class="ae kf" href="https://pytorch.org/docs/stable/tensorboard.html" rel="noopener ugc nofollow" target="_blank">张量板</a> HPARAMS选项卡。出于某种原因，<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html#logging-hyperparameters" rel="noopener ugc nofollow" target="_blank"> hp_metric </a>不工作，我无法修复它T_T(黑暗模式ftw！).(<em class="nr">图片作者</em>)。</p></figure><ul class=""><li id="59e1" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated">记录到<a class="ae kf" href="https://pytorch.org/docs/stable/tensorboard.html" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>和<a class="ae kf" href="https://en.wikipedia.org/wiki/Standard_streams" rel="noopener ugc nofollow" target="_blank"> stdout </a>用于冗余(这是我自己做的，^^).我还是不能什么都抄。一些信息只放入标准输出。这是一个问题，因为如果您使用超级计算集群，输出文件有难以描述的名称，这使得查找实验细节更加困难，特别是在遥远的未来。(我也在考虑登录到<a class="ae kf" href="https://wandb.ai/site" rel="noopener ugc nofollow" target="_blank"> WandB </a>)。</li><li id="9021" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">正确使用<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html#logging-hyperparameters" rel="noopener ugc nofollow" target="_blank"> hp_metric </a>以便我们可以在TensorBoard中选择最佳的超参数(还没有运行T_T。作为一个临时解决方案，它保存到一个. json中，该文件将被加载到pandas数据帧中)。</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ns"><img src="../Images/fccc46de1a580abe1dabb01980bde49d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c-lCPRepuUEdqCWPPR9oZQ.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">显示最低验证的损失曲线。该图是<a class="ae kf" href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/" rel="noopener ugc nofollow" target="_blank">诊断培训</a>中的问题的一种方式。(<em class="nr">图片作者</em>)。</p></figure><ul class=""><li id="65a8" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated"><a class="ae kf" href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/" rel="noopener ugc nofollow" target="_blank">损失曲线</a>(这是我自己做的^^).</li><li id="258a" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">整个脚本计时(如果你使用超级计算集群，用于估计WALLTIME)(这是我自己做的，^^).</li><li id="b5a0" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#inspect-gradient-norms" rel="noopener ugc nofollow" target="_blank">检查坡度规范</a>以防止<a class="ae kf" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失或爆炸坡度</a>。</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nt"><img src="../Images/8e45c45851470427e42395f166b869f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NCWvJvuf67mppkLEzAcEAQ.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">我们可以看到参数分布的演变(文字权重和偏差，而不是品牌)。(<em class="nr">图片作者</em>)。</p></figure><ul class=""><li id="1398" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated">将参数以直方图的形式记录到TensorBoard(这是我自己做的，^^).记录单个参数可能不现实，每个时期会有数百万个参数。</li><li id="468b" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#print-a-summary-of-your-lightningmodule" rel="noopener ugc nofollow" target="_blank">打印照明模块的摘要</a>。这是一个打印输出的例子，我不能重定向到TensorBoard文本。</li><li id="5932" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/requirements/collect_env_details.py" rel="noopener ugc nofollow" target="_blank">记录系统(硬件和软件)信息</a>。</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nu"><img src="../Images/f8c61bbe86398a39eba58ae7aaba63d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNa4l2HOXziUGEPSiL9JhA.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">你能在这幅图中找到这只虫子吗？很好！现在发现我的模板中的错误，需要帮助！<a class="ae kf" href="https://unsplash.com/@darthxuan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">玄阮</a>在<a class="ae kf" href="https://unsplash.com/s/photos/bug?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照。</p></figure><h2 id="1497" class="ne mi iq bd mj nf ng dn mn nh ni dp mr kp nj nk mt kt nl nm mv kx nn no mx np bi translated">排除故障</h2><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nv"><img src="../Images/b6c794bfc962a2e6fa9b7f8639c04277.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V3kjXPpe3X8G6SbmTfYU5g.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">PyTorch 号侧写员报告。(<em class="nr">图片作者</em>)。</p></figure><ul class=""><li id="3032" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/advanced/profiler.html#pytorch-profiling" rel="noopener ugc nofollow" target="_blank">剖析器</a> ( <a class="ae kf" href="https://pytorch.org/docs/master/profiler.html" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)找出哪些层/操作是一直在窃取你的时间和内存的瓶颈。请注意，这会减慢速度。差很多！因此，在进行超参数调整之前，请务必关闭此功能。</li><li id="8dfc" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#set-the-number-of-validation-sanity-steps" rel="noopener ugc nofollow" target="_blank">健全性检查</a>是默认开启的功能。很高兴知道这个存在。(我是吃了苦头才知道的)</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nw"><img src="../Images/861c62c31f1862155b4df36bad1d0ec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zyxqgo_YQgCy5SdYCpVGFw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">GPU内存日志。为什么会涨？(<em class="nr">图片作者</em>)。</p></figure><ul class=""><li id="af4c" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated">有两种方法来监控GPU。第一个只是<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#log-gpu-usage" rel="noopener ugc nofollow" target="_blank">监控内存</a>，而第二个可以<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.callbacks.GPUStatsMonitor.html#pytorch_lightning.callbacks.GPUStatsMonitor" rel="noopener ugc nofollow" target="_blank">监控多个统计数据</a>。我的模板就用第一个。</li><li id="d8da" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">有两种方法可以缩短纪元。第一种是通过<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#shorten-epochs" rel="noopener ugc nofollow" target="_blank">限制批次数量</a>。而第二个是<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#fast-dev-run" rel="noopener ugc nofollow" target="_blank"> fast_dev_run </a>，它限制了后台的批处理数量。我的模板直接调用限制参数。</li><li id="34e9" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html#make-model-overfit-on-subset-of-data" rel="noopener ugc nofollow" target="_blank">对数据子集进行模型过拟合</a></li></ul><p id="c4c5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">(错误:探查器与缩短时期冲突。)</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nx"><img src="../Images/51a30ef11a775c66d4a77811426e00f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGI1jruT9ecB5TVQG4sLPQ.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">想象一下这崎岖不平的地形。格拉汉姆·斯潘塞在<a class="ae kf" href="https://unsplash.com/s/photos/rugged?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片。</p></figure><h2 id="3a5f" class="ne mi iq bd mj nf ng dn mn nh ni dp mr kp nj nk mt kt nl nm mv kx nn no mx np bi translated">最佳化</h2><ul class=""><li id="3b14" class="lt lu iq ki b kj mz km na kp ny kt nz kx oa lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/early_stopping.html" rel="noopener ugc nofollow" target="_blank">提前停止</a>因为当模型已经收敛时，我们不要浪费资源。</li><li id="00b3" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/advanced/training_tricks.html#gradient-clipping" rel="noopener ugc nofollow" target="_blank">渐变裁剪</a></li><li id="816d" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">说到优化器，我过去只是简单地使用<a class="ae kf" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank"> Adam </a>，使用<a class="ae kf" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html" rel="noopener ugc nofollow" target="_blank"> ReduceLROnPlateau </a>，然后就到此为止(我甚至不为betas优化)。但这让我晚上睡不着觉，因为我总是怀疑自己，怀疑自己是否错过了巨大的进步。我知道这是一个非常活跃的研究领域。但是另一种选择是优化器超参数的维数灾难。这就是PL拯救我的地方。现在，我可以简单地将PL视为一个行业标准，使用所有提供的优化工具，睡得稍微轻松一些。这里有两个工具:<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/advanced/lr_finder.html" rel="noopener ugc nofollow" target="_blank">学习率查找器</a>，和<a class="ae kf" href="https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/" rel="noopener ugc nofollow" target="_blank">随机加权平均</a>。</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ob"><img src="../Images/022599a9a734db6bea173ab763a49194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S-fRjsQ_C_zHiyISOh9gyw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">激活分析:MNIST MLP隐藏层激活的前2个主成分。(<em class="nr">图片作者</em>)。</p></figure><h2 id="1d4e" class="ne mi iq bd mj nf ng dn mn nh ni dp mr kp nj nk mt kt nl nm mv kx nn no mx np bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html" rel="noopener ugc nofollow" target="_blank">保存和加载重量</a></h2><ul class=""><li id="51dd" class="lt lu iq ki b kj mz km na kp ny kt nz kx oa lb ly lz ma mb bi translated"><a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html#automatic-saving" rel="noopener ugc nofollow" target="_blank">保存最佳模型</a>和<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/test_set.html" rel="noopener ugc nofollow" target="_blank">测试它</a>。</li><li id="f589" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">一旦你完成了你的超参数搜索，你可能想要在会话结束后<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html#checkpoint-loading" rel="noopener ugc nofollow" target="_blank">加载一个检查点</a>来对最佳模型做类似<a class="ae kf" href="https://www.qualtrics.com/support/stats-iq/analyses/regression-guides/interpreting-residual-plots-improve-regression/" rel="noopener ugc nofollow" target="_blank">残差分析</a>或<a class="ae kf" href="https://arxiv.org/pdf/1506.02078.pdf" rel="noopener ugc nofollow" target="_blank">激活分析</a>(看上面漂亮的图)。</li><li id="fc50" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">(跟踪训练期间激活如何变化可能也有帮助，但我没有在这个模板中实现这一点。)</li></ul><h2 id="84b7" class="ne mi iq bd mj nf ng dn mn nh ni dp mr kp nj nk mt kt nl nm mv kx nn no mx np bi translated">超参数调谐:</h2><ul class=""><li id="3d94" class="lt lu iq ki b kj mz km na kp ny kt nz kx oa lb ly lz ma mb bi translated">在我的Google Colab模板中有一个网格搜索的例子。是的，我知道<a class="ae kf" href="https://dl.acm.org/doi/pdf/10.5555/2188385.2188395" rel="noopener ugc nofollow" target="_blank">随机搜索更好</a>，但这只是为了演示。</li><li id="846b" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">出于某种原因，我无法让TensorBoard上的hp_metric工作，所以我做了一个. json来解决这个问题。还包括一个代码片段来聚合。来自不同实验运行的json文件。</li><li id="7cf1" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">我还需要一个超参数优化器库，实现良好的算法，从离线文件读取和写入(因为我正在使用HPC)。目前为止最好的解决方案是<a class="ae kf" href="https://optuna.org/" rel="noopener ugc nofollow" target="_blank"> Optuna </a>，因为离线很容易<a class="ae kf" href="https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html#" rel="noopener ugc nofollow" target="_blank">并行化</a> <a class="ae kf" href="https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/001_rdb.html" rel="noopener ugc nofollow" target="_blank">。</a></li></ul><h1 id="cbb0" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">从这里去哪里？</h1><p id="f661" class="pw-post-body-paragraph kg kh iq ki b kj mz jr kl km na ju ko kp nb kr ks kt nc kv kw kx nd kz la lb ij bi translated">显然，我在谷歌上的模板还没有检查过。但是你可能想在<a class="ae kf" href="https://www.pytorchlightning.ai/bolts" rel="noopener ugc nofollow" target="_blank"> Bolts </a>中检查现有的模型，并为你自己的数据集制作你自己的<a class="ae kf" href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html" rel="noopener ugc nofollow" target="_blank"> LightningDataModule </a>。祝你好运！</p><h1 id="9d27" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">参考</h1><p id="5741" class="pw-post-body-paragraph kg kh iq ki b kj mz jr kl km na ju ko kp nb kr ks kt nc kv kw kx nd kz la lb ij bi translated">所有的图片，除了标题中注明的，都是我的。</p></div></div>    
</body>
</html>