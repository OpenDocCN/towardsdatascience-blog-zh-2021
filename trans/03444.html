<html>
<head>
<title>HDFS Simple Docker Installation Guide for Data Science Workflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学工作流程的HDFS简单Docker安装指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hdfs-simple-docker-installation-guide-for-data-science-workflow-b3ca764fc94b?source=collection_archive---------4-----------------------#2021-03-19">https://towardsdatascience.com/hdfs-simple-docker-installation-guide-for-data-science-workflow-b3ca764fc94b?source=collection_archive---------4-----------------------#2021-03-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4889" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Docker映像，在您的系统上轻松逐步安装和使用HDFS。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/400bf6882d5a6146059be8375a05d185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mpyrgqwMjfclV2oN1U2VIA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">卢克·切瑟在<a class="ae ky" href="/s/photos/big-data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2142" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">在</span>这篇小文章中，我们将讨论如何在你的计算机上设置基于Docker的Hadoop分布式文件系统，并将讨论一个简单的例子来演示这个用例。此外，一旦安装准备就绪，您就可以开始构建自己的map-reduce作业来使用Hadoop DFS。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="d153" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">从克隆HDFS项目开始</h2><p id="879d" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">首先，你需要<strong class="lb iu">克隆</strong>下面的<a class="ae ky" href="https://github.com/big-data-europe/docker-hadoop" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Git库</strong> </a>到你系统中你想要的目录。我更喜欢把它克隆到家里，以便演示和方便使用。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="734f" class="ml mm it nk b gy no np l nq nr">git clone <a class="ae ky" href="https://github.com/big-data-europe/docker-hadoop" rel="noopener ugc nofollow" target="_blank">https://github.com/big-data-europe/docker-hadoop</a></span></pre><p id="7117" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后使用<strong class="lb iu">更改目录</strong>命令进入项目库:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="2928" class="ml mm it nk b gy no np l nq nr">cd docker-hadoop</span></pre><p id="e6dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在执行一个"<strong class="lb iu"> ls -l </strong>"命令，您可以看到这个存储库中的所有文件，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/9e8e9c7c99f122aeee88b1f042dcc2be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fIk0NKcFZ-QHFDhmx6li9Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">命令“<strong class="bd nt"> ls -l </strong>的输出</p></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="7dc8" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">获取Docker图像并创建容器</h2><p id="2c92" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">之后，您需要启动在您的系统上设置HDFS所需的容器。为此，项目目录中有一个docker-compose.yml文件，您需要使用"<strong class="lb iu"> docker-compose up </strong>"命令从Docker hub下载并安装所需的映像，并基于<strong class="lb iu"> docker-compose.yml </strong>文件配置容器。“<strong class="lb iu"> -d </strong>”标志以分离模式运行容器。如果在本地找不到图像，Docker会从DockerHub下载它们，但是如果您想要手动下载它们，您可以使用“<strong class="lb iu"> docker-compose pull </strong>”。</p><blockquote class="nu nv nw"><p id="ce03" class="kz la nx lb b lc ld ju le lf lg jx lh ny lj lk ll nz ln lo lp oa lr ls lt lu im bi translated">注意:如果出现权限错误，请使用“<strong class="lb iu"> sudo </strong>”作为这些命令的前缀。</p></blockquote><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="2414" class="ml mm it nk b gy no np l nq nr"># download images required for setting up HDFS and spin up necessary # containers.<br/>docker-compose up -d</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/6e963cccc24303190a3962486655436f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*imp7aNRwfLkFqWGlaBR9kg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">命令"<strong class="bd nt"> sudo docker-compose up -d </strong>的输出</p></figure><p id="78c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的命令将从docker hub下载设置HDFS容器所需的所有Docker映像。根据您的网速，下载图像可能需要一点时间。</p><p id="306e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，要查看当前正在运行的Docker容器，使用命令列出所有活动的容器。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="e883" class="ml mm it nk b gy no np l nq nr"># List all the available running docker containers.<br/>docker container ls</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/6a51c4f6d89b478b528d89d369285708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXI5K5haTfTNRJ0Q_BSXhw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">命令"<strong class="bd nt"> sudo docker容器ls </strong>"的输出</p></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="9691" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">与namenode连接</h2><p id="80ba" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">一旦您将所有文件复制到Hadoop集群中的一个目录中(注意:在本例中，我已经将文件复制到了<strong class="lb iu"> /tmp </strong>)，现在您可以在bash模式下的交互式终端模式中使用以下命令进入<strong class="lb iu"> namenode </strong>中。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="ca7d" class="ml mm it nk b gy no np l nq nr"># Enter inside namenode and open its bash<br/>docker exec -it namenode /bin/bash</span></pre><p id="7884" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例:<strong class="lb iu">sudo docker CP my _ input . txt NameNode:/tmp/</strong></p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="dc8f" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">复制必要的JAR和输入文件</h2><p id="d66e" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">现在我们需要复制包含我们的<strong class="lb iu"> map-reduce作业</strong>的jar文件，并使用以下Docker命令将它们复制到HDFS的namenode(将运行您的作业)中:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="7109" class="ml mm it nk b gy no np l nq nr">docker cp &lt;file_name&gt; namenode:/&lt;path&gt;</span></pre></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="b327" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">与namenode交互</h2><p id="7583" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">在交互式终端中输入名称节点后，使用以下HDFS命令与<strong class="lb iu">名称节点</strong>进行交互。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="efb6" class="ml mm it nk b gy no np l nq nr"># HDFS list commands to show all the directories in root "/"<br/>hdfs dfs -ls /</span><span id="caaa" class="ml mm it nk b gy od np l nq nr"># Create a new directory inside HDFS using mkdir tag.<br/>hdfs dfs -mkdir -p /user/root</span><span id="e206" class="ml mm it nk b gy od np l nq nr"># Copy the files to the input path in HDFS.<br/>hdfs dfs -put &lt;file_name&gt; &lt;path&gt;</span><span id="1470" class="ml mm it nk b gy od np l nq nr"># Have a look at the content of your input file.<br/>hdfs dfs -cat &lt;input_file&gt;</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/c9c400e6d0619b1b373b09939e146a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6YvgsErL60RUyJ3j7h3j8A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述命令的输出</p></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="6121" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">运行Hadoop Map Reduce作业</h2><p id="dbfa" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">现在，您可以使用以下命令运行地图缩减作业:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="8225" class="ml mm it nk b gy no np l nq nr"># Run map reduce job from the path where you have the jar file.<br/>hadoop jar &lt;jar_file_name&gt; &lt;class_name&gt; input output</span></pre><p id="0626" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例:<strong class="lb iu">Hadoop jar word _ counter . jar org . Apache . Hadoop . examples . word count输入输出</strong></p><p id="6148" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦该命令成功运行<strong class="lb iu"/>，您会注意到map-reduce作业完成了它的执行，并在控制台上显示了关于该进程的一些信息。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="85c7" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">检查你的输出</h2><p id="57c5" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">作业成功执行后，您可以在HDFS使用cat命令检查输出:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="069f" class="ml mm it nk b gy no np l nq nr"># Check the content of the output file after running the job<br/>hdfs dfs -cat &lt;output_file&gt;</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/403f9086016e62a43995ac38a803015e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vGCp7NPhwI6z0CKmQN1K2A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">命令"<strong class="bd nt">HDFS DFS-cat output _ file/*</strong>的输出</p></figure><p id="a922" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您将看到您的单词计数器作业的词频应该打印在控制台上。</p><p id="fbf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">恭喜</strong>！您已经成功配置并创建了您的第一个Hadoop HDFS map-reduce作业！</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="7358" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">额外小费</h2><p id="60da" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">您可以在本地主机的端口9870上访问HDFS namenode的<strong class="lb iu"> UI仪表板</strong>。使用以下链接:</p><blockquote class="og"><p id="26c0" class="oh oi it bd oj ok ol om on oo op lu dk translated"><strong class="ak">http://&lt;your _ IP _ address&gt;:9870</strong></p></blockquote><figure class="or os ot ou ov kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/ff241f7629db8b0ed102975030c4fc48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CHE0ibFjn8mcksneeWDA-w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">NameNode UI:<strong class="bd nt">http://&lt;your _ IP _ address&gt;:9870</strong></p></figure><h2 id="49f6" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">结论:</h2><p id="5b68" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">因此，基本上HDFS的设置对于简单的数据科学工作流来说很简单，并且您在阅读本文后已经了解到，设置一个基于本地Docker的HDFS设置并开始编写自己的map-reduce作业来执行各种任务是多么简单。如果你不是很熟悉地图减少工作，所以我附上了一些有用的链接。尽情享受吧！</p><ol class=""><li id="826f" class="ow ox it lb b lc ld lf lg li oy lm oz lq pa lu pb pc pd pe bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/MapReduce" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/MapReduce</a></li><li id="3471" class="ow ox it lb b lc pf lf pg li ph lm pi lq pj lu pb pc pd pe bi translated"><a class="ae ky" href="https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html</a></li><li id="e813" class="ow ox it lb b lc pf lf pg li ph lm pi lq pj lu pb pc pd pe bi translated"><a class="ae ky" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html" rel="noopener ugc nofollow" target="_blank">https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html</a></li></ol><p id="bdfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望这篇文章对你有帮助！<br/> <strong class="lb iu">谢谢！</strong></p></div></div>    
</body>
</html>