<html>
<head>
<title>Head Pose Estimation using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行头部姿态估计</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/head-pose-estimation-using-python-d165d3541600?source=collection_archive---------3-----------------------#2021-09-13">https://towardsdatascience.com/head-pose-estimation-using-python-d165d3541600?source=collection_archive---------3-----------------------#2021-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="10ae" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">您所需要的只是OpenCV和Mediapipe库。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/35729944e7310e28c39cb893737fc38e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4c-jBF_Zasz2b7mw2ZNnqA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">玛利亚·特内娃在<a class="ae ky" href="https://unsplash.com/s/photos/distraction?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="9914" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="611f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">头部姿态估计是现有的计算机视觉任务之一。在这个任务中，我们想从物体的平移和旋转中知道物体的姿态。</p><p id="68b6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这项任务有很多应用。例如，我们可以检测驾驶员是否在注意道路。第二个例子是，我们可以检查学生是否从学习中分心。我们可以用它做很多应用。</p><p id="c456" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如你所知，我们只有二维图像。如何依靠图像本身来估计物体的姿态？我们可以使用一种称为n点透视(PnP)的解决方案。</p><p id="4721" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">PnP问题方程看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/c67bbf9f2d587b8c0b4ee671b7a747c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*xhYAGGnUeDIG1GhoMwFt_Q.png"/></div></figure><p id="1a50" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从这个方程，我们可以检索旋转和平移矩阵。但是在我们得到这些矩阵之前，这个方程需要三个输入，例如:</p><ul class=""><li id="f5f8" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">图像空间中的2D坐标</li><li id="dd5b" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">世界空间中的3D坐标</li><li id="9823" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">相机参数，如焦点、中心坐标和倾斜参数</li></ul><p id="7b8f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从这个等式中，我们得到两个主要问题:</p><ul class=""><li id="6c93" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">我们如何获得这些输入？</li><li id="1279" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">我们如何根据这些输入来估计物体的姿态呢？</li></ul><p id="994c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这篇文章将告诉你如何做。在本文中，我们将使用Python作为编程语言。此外，我们使用mediapipe库来检测面部关键点，使用OpenCV库来估计头部的姿态。</p><p id="b42b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这是我们将创建的预览:</p><div class="kj kk kl km gt ab cb"><figure class="nh kn ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/3a469f5ec415ca743822e7727cbedb64.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*DGacCWKuhP1kEUrtmasOnQ.png"/></div></figure><figure class="nh kn nn nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/3ed336b83d43c26bdcbb9b34befbf6dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*9Ed78HnxtDgP5P9nZG4q-g.png"/></div></figure><figure class="nh kn no nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/8a8e1c1f7506705693e99a544d4dadcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*FTIfvF2DaUJm19P4VF77Xw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk np di nq nr translated">图片由作者捕捉。</p></figure></div><p id="b8a1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">没有别的了，让我们开始吧！</strong></p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="08d5" class="kz la it bd lb lc nz le lf lg oa li lj jz ob ka ll kc oc kd ln kf od kg lp lq bi translated">履行</h1><h2 id="d1c9" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">安装库</h2><p id="d037" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们开始实现之前，第一步是安装库。在这种情况下，我们将使用pip安装OpenCV和Mediapipe库。在您的终端上，请编写以下命令:</p><pre class="kj kk kl km gt oq or os ot aw ou bi"><span id="56f0" class="oe la it or b gy ov ow l ox oy"><strong class="or iu">pip install opencv-python<br/>pip install mediapipe</strong></span></pre><h2 id="7d0c" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">加载库</h2><p id="1641" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">安装完库之后，下一步是将库加载到我们的代码中。我们将导入NumPy、OpenCV和Mediapipe库。请添加这行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="f813" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">初始化对象</h2><p id="2ba6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">加载完库之后，下一步是初始化几个对象。我们初始化了两个对象。它们是:</p><ul class=""><li id="37b3" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">Mediapipe库中的FaceMesh对象。该对象将检测人脸，也检测一个或多个人脸的关键点。</li><li id="8639" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">OpenCV库中的VideoCapture对象。该对象将用于从网络摄像机中检索图像。我们将对象的参数设置为0，用于从网络摄像头中检索图像。</li></ul><p id="9dcb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请添加这几行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="71a8" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">捕捉图像</h2><p id="14f0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们已经初始化了对象。下一步是从网络摄像头捕捉图像。为此，请添加以下代码行:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="b69b" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">处理图像</h2><p id="7d89" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们捕获图像之后，下一步是处理图像。供您参考，OpenCV和Mediapipe库读取它们的图像是不同的。</p><p id="ce44" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在OpenCV库上，图像在BGR颜色空间中。同时，mediapipe库需要一个具有RGB颜色空间的图像。</p><p id="2ef8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，我们需要首先将颜色空间转换为RGB，应用人脸标志检测，然后将其转换回BGR颜色空间。</p><p id="6a88" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请添加以下代码行(注意缩进):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="632e" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">检索2D和三维坐标</h2><p id="ebd3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">处理完图像后，下一步是检索关键点坐标。供您参考，mediapipe的面部标志检测算法可以从面部捕捉大约468个关键点。每个关键点都在三维坐标上。</p><p id="6b9e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于头部姿态估计，我们不必使用所有的关键点。相反，我们选择至少能代表一张脸的6个点。这些点在眼睛的边缘，鼻子，下巴和嘴巴的边缘。</p><p id="b2d5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要访问这些点，我们可以参考BlazeFace模型中使用的索引。我已经标记了索引。这是它的照片:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/0274b8b2e9cb20796981b15eaced395e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*maSvDKOM5pjNUEjIJ6x29g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">这张图片是从TensorFlow的GitHub库中检索出来的，并由作者进行了编辑。</p></figure><p id="1f2e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们提取这些关键点。对于2D坐标，我们将只取x和y轴坐标。对于三维坐标，我们检索所有的轴。</p><p id="426a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但是在我们提取这些关键点之前，我们必须用图像的宽度乘以x轴。此外，我们将y轴乘以图像的高度。</p><p id="d225" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此外，我们将获得机头坐标。我们这样做是为了显示我们鼻子在图像空间的投影。</p><p id="7a62" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们添加这几行代码，注意缩进:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="b944" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">获取摄像机矩阵</h2><p id="8c06" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们有了面部关键点的2D和3D坐标。下一步是得到相机矩阵。让我们再次回忆一下相机矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/c45a1dce14ffaa5ba025930d47ce2f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*YREHAKtpbFHwIFRNN37rUg.png"/></div></div></figure><p id="a7b5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正如你从上面看到的，我们需要几个参数。第一个是重点。我们可以通过获取图像的宽度来获得焦点(fx和fy)。</p><p id="a495" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们将采用的第二个参数是偏斜参数。该参数的符号为gamma。对于这个参数，我们将值设置为0。</p><p id="a919" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第三个参数是我们图像的中心坐标。我们将用图像的宽度设置u0，用图像的高度设置v0。</p><p id="723c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们通过生成一个NumPy数组来创建矩阵。现在让我们添加这几行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="5f8c" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">应用PnP问题</h2><p id="f1f8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在应用PnP问题之前，我们需要添加另一个矩阵。这是一个距离矩阵。这个矩阵只包含零，它的形状是4x1。现在，让我们通过添加这行代码来创建矩阵:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="9aba" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们有所有的输入，从2D坐标，三维坐标，相机参数矩阵，和空距离矩阵。让我们通过添加这行代码将PnP应用于我们的问题:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="1310" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">将旋转向量转换成矩阵</h2><p id="36c1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">从这个过程中，我们得到了平移向量和旋转向量。等等，旋转部分不是矩阵格式的。我们不能用它来恢复旋转角度。</p><p id="a494" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">别担心。我们可以用cv2把向量转换成矩阵。罗德里格斯函数。</p><p id="ead0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们添加这行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="fc8b" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">获取角度</h2><p id="f147" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们有了旋转矩阵。现在让我们检索每个轴上的旋转角度。为此，我们可以使用cv2。RQDecomp3x3函数用于提取角度。</p><p id="a747" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们添加这行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="ff0c" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">捕捉头部的方向并显示结果</h2><p id="121e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们现在要做的最后一步是确定我们的方向。我们显示方向并创建一条线来查看我们的鼻子在图像空间上的投影。</p><p id="7dbf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们添加这几行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="35ba" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过组合所有这些代码行，结果将如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/01d87d8c4c468e803fb588edf281959f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*2xYQb2WxiTALpjpTEJEjWA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GIF是作者捕获的。</p></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="1072" class="kz la it bd lb lc nz le lf lg oa li lj jz ob ka ll kc oc kd ln kf od kg lp lq bi translated">结束语</h1><p id="bc62" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">干得好！我们已经使用Python实现了头部姿态估计。我希望它能帮助你建立你的计算机视觉解决方案，尤其是头部姿态估计问题。</p><p id="24f2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你对我的文章感兴趣，可以在Medium上关注我。如果有任何问题，可以在<a class="ae ky" href="https://www.linkedin.com/in/alghaniirfan/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> LinkedIn </strong> </a>上联系我。</p><p id="b7a5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您在编写代码时遇到了困惑，您可以在这里查看完整的代码来帮助您:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="5269" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">感谢您阅读我的文章！</strong></p><h2 id="03fa" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">参考</h2><p id="0014" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1]<a class="ae ky" href="https://medium.com/analytics-vidhya/real-time-head-pose-estimation-with-opencv-and-dlib-e8dc10d62078" rel="noopener">https://medium . com/analytics-vid hya/real-time-head-pose-estimation-with-opencv-and-dlib-e8dc 10d 62078</a><br/>【2】<a class="ae ky" href="https://learnopencv.com/head-pose-estimation-using-opencv-and-dlib/" rel="noopener ugc nofollow" target="_blank">https://learnopencv . com/head-pose-estimation-using-opencv-and-dlib/</a></p></div></div>    
</body>
</html>