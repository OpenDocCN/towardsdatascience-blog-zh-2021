<html>
<head>
<title>ML From Scratch: Logistic and Softmax Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML从零开始:逻辑和Softmax回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-from-scratch-logistic-and-softmax-regression-9f09f49a852c?source=collection_archive---------17-----------------------#2021-06-14">https://towardsdatascience.com/ml-from-scratch-logistic-and-softmax-regression-9f09f49a852c?source=collection_archive---------17-----------------------#2021-06-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f7c6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过以类似于Scikit-Learn的方式从头开始实现logistic和softmax回归，获得对它们的深入理解</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/eb61b24080d0ed53b34f2c99aea910b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h_dBRgft99Pi9ykaWaDlmA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">封面照片——卢克·纽曼拍摄</p></figure><p id="e182" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个ML From Scratch系列中，我们使用面向对象编程创建了一个与Scikit-Learn风格相似的机器学习算法库。这意味着您可以pip安装该库，并以您已经熟悉的方式使用所有可用的模型。</p><p id="9105" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你从未从零开始实现过任何学习算法，我会给你三个好理由，让你现在就跟随并开始:</p><ol class=""><li id="8235" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">您将详细了解每个模型中的特殊细微差别，加深您的理解。</li><li id="2c86" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">您将通过记录代码和创建测试用例来提高您的编码技能，确保所有功能都按预期工作。</li><li id="24eb" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">您将对面向对象编程有更好的理解，从而改进您的机器学习项目工作流程。</li></ol><p id="e0d2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要查看Github回购，请访问<a class="ae mi" href="https://github.com/lukenew2/mlscratch" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><blockquote class="mj mk ml"><p id="db7b" class="ky kz mm la b lb lc ju ld le lf jx lg mn li lj lk mo lm ln lo mp lq lr ls lt im bi translated">这个项目旨在增加我们对学习算法的理解，而不是用于实际的数据科学工作。</p></blockquote><h2 id="ef52" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">装置</h2><p id="a995" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">为了使用类和函数进行测试，创建一个虚拟环境并pip安装项目。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="7b52" class="mq mr it np b gy nt nu l nv nw">    $ pip install mlscratch==0.1.0</span></pre><p id="c4b6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要下载本地存储库中的所有源代码，请创建一个虚拟环境，并在您的终端中运行以下命令。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="7017" class="mq mr it np b gy nt nu l nv nw">    $ git clone https://github.com/lukenew2/mlscratch<br/>    $ cd mlscratch<br/>    $ python setup.py install</span></pre><h1 id="1f2a" class="nx mr it bd ms ny nz oa mv ob oc od my jz oe ka nb kc of kd ne kf og kg nh oh bi translated">逻辑回归</h1><p id="7d4e" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated"><em class="mm"> Logistic回归</em>是分类中常用的回归算法。它估计一个实例属于一个特定类的概率。</p><p id="311f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果估计概率大于或等于50%，则模型预测该实例属于正类。如果概率小于50%，则模型预测负类。</p><h2 id="7678" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">估计概率</h2><p id="9789" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">逻辑回归就像线性回归模型一样工作。它计算特征数组的加权和(加上一个偏差项)，但不是像线性回归模型那样直接输出结果，而是输出该结果的<em class="mm">逻辑</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/ad1ee8cd39c217fc7860ded21c36e682.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*gOC25Xt9w7BrbqB-5MU1GQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式1。逻辑回归估计概率</p></figure><p id="ab6c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标为σ(*)的逻辑函数是一个sigmoid函数，它将其输入转换为0到1之间的数字。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/27ccf41542c0b7d0080a515351f5d7f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*0JPscMaNysfxK9OU4Oqwug.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式2。物流功能</p></figure><p id="08cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦模型估计了一个实例属于正类的概率，它就简单地根据以下规则进行预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/2c2520dcfa63c7b34f841e7ccecfe993.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*U0owZX3pER77eQl5cORr_A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式3。逻辑回归模型预测</p></figure><p id="5d75" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们从头开始的实现，我们需要创建一个sigmoid函数，它可以将我们的输入转换成概率。让我们看看这是如何做到的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块1。activations.py</p></figure><p id="8de6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里我们创建了一个类，并给了它一个方法。这个特殊的__call__方法让我们的类在被调用时表现得像一个函数。我们将在创建逻辑回归类时使用这个属性。</p><h2 id="504b" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">培训和成本函数</h2><p id="d550" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">既然我们已经知道了逻辑回归如何估计概率和进行预测的一切，让我们看看它是如何被训练的。</p><p id="c59e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练的目标是找到一组参数<strong class="la iu">θ</strong>，使得模型预测正面实例的高概率和负面实例的低概率。这个想法被成本函数<em class="mm">测井损失</em>捕获。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/bc718837fdd3f2b7164b4da994e33845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uk-goNZanDpTb6DjOXg5TQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式4。逻辑回归成本函数(对数损失)</p></figure><p id="c1bf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于我们将在实现中使用梯度下降，我们需要知道的是成本函数相对于模型参数<strong class="la iu">θ</strong>的偏导数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/6f7719f63e923bb9e95f7df1c2664b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mxV6NPRVzjexTOwA0CMyBA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式5。对数损失偏导数</p></figure><p id="8e3f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个方程非常类似于线性回归的成本函数偏导数。对于每个实例，它计算预测误差并将其乘以实例的特征值，然后计算所有实例的平均值。</p><p id="ad58" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用批量梯度下降实现逻辑回归时，我们不想计算所有实例的平均值。我们希望梯度向量包含所有的偏导数，允许我们在它们指向的相反方向更新我们的参数。</p><p id="5d52" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们进入实现。请阅读文档以理解每段代码的作用。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块2。物流. py</p></figure><p id="0aee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们走吧！我们有一个全功能的逻辑回归模型，可以执行二元分类。让我们编写一个测试用例来确保它正常工作。</p><h2 id="6803" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">测试案例——虹膜二元分类</h2><p id="32d5" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">在这个测试案例中，我们使用著名的iris数据集，并将其转换为二分类问题，执行训练/测试分割，进行一些预处理，然后训练我们的逻辑回归模型，并在测试集上测试准确度大于80%。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块3。test_logistic.py</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/728f2633d17d6d5f56ba8b0f7aa065c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r3r0caOSnOMi6dIi6b21Aw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。测试在0.92秒内通过</p></figure><p id="034e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，无论出于什么原因，如果我们对我们的代码进行了更改，我们总会有一个测试用例来确保我们的更改没有破坏模型。相信我，这会省去很多麻烦，尤其是当我们的代码库增长的时候。</p><h1 id="e43b" class="nx mr it bd ms ny nz oa mv ob oc od my jz oe ka nb kc of kd ne kf og kg nh oh bi translated">Softmax回归</h1><p id="daaa" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">我们实现的逻辑回归模型只支持二进制分类，但是可以推广到支持多个类。这被称为<em class="mm"> Softmax回归</em>。</p><p id="61cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">想法很简单:对于每个实例，Softmax回归模型计算每个类的分数，然后通过将<em class="mm"> softmax函数</em>应用于分数来估计实例属于每个类的概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/da3f10ef1e7c2e944bc1514aa9af819a.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*6rRxxqUnElsfdXV-QLT1EA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式6。Softmax函数(非标准化)</p></figure><p id="619e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个等式中:</p><ul class=""><li id="893e" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt or ma mb mc bi translated">k是类的数量。</li><li id="e045" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">s(x)是包含实例x的每个类的分数的向量。</li></ul><p id="489d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就像逻辑回归分类器一样，Softmax回归分类器预测估计概率最高的类。</p><h2 id="903a" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">实际问题:数值稳定性</h2><p id="0409" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">从头开始实现softmax函数有点棘手。当你划分可能非常大的指数时，你会遇到<em class="mm">数值稳定性</em>的问题。为了避免这种情况，我们使用了一个规范化技巧。请注意，如果我们将分数的上下部分乘以常数C，并将其推入总和，我们会得到以下等价表达式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/beb16819593391223fe834a595069686.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUfdjJpw6JWufFItzfaKEQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">方程式7。Softmax函数(归一化)</p></figure><p id="2009" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以自由选择C的值，但常见的选择是将log(C)设置为等于实例x的最大值的负值。这会移动这些值，因此最大值为零。让我们看看代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块4。activations.py</p></figure><p id="dd04" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，我们使用__call__方法将softmax类添加到与sigmoid类相同的模块中，这样我们的类在被调用时就像一个函数一样。</p><h2 id="a6b6" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">培训和成本函数</h2><p id="cb30" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">现在让我们来看看训练Softmax回归模型及其成本函数。这个想法和逻辑回归是一样的。我们需要一个模型来预测目标类的高概率和其他类的低概率。这个想法被成本函数<em class="mm">交叉熵</em>捕获。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/fd304ba0cd8b4c3bc9edf712a0e41bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HA947ypftv_d4EvRGOYM9g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式8。交叉熵代价函数</p></figure><p id="595f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个等式中:</p><ul class=""><li id="91d3" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt or ma mb mc bi translated">y是实例属于目标类的目标概率。在我们的例子中，这个值总是等于1或0，这取决于实例是否属于这个类。</li><li id="18de" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">在两个类别的情况下，交叉熵相当于对数损失。</li></ul><p id="738d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我们将使用梯度下降实现Softmax回归，所以我们需要这个成本函数关于<strong class="la iu">θ</strong>的梯度向量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/388133bb64a87cd8873928f6192f00e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SSGLMZGMUN3mxnA6WRTOaA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式9。交叉熵梯度向量</p></figure><p id="7187" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当计算梯度时，我们需要我们的目标类(y)与我们估计的概率(p)具有相同的维数。我们估计的概率将是(n_samples，n_classes)的形式，因为对于每个实例，我们将有一个与属于每个类的实例相关联的概率。</p><p id="6d39" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果我们有三个标记为0、1和2的类，我们需要将包含([1，2，0])的目标向量转换为如下所示的数组:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="7e01" class="mq mr it np b gy nt nu l nv nw">([[0, 1, 0],<br/>  [0, 0, 1],<br/>  [1, 0, 0]])</span></pre><p id="4644" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一列表示类别0，第二列表示类别1，第三列表示类别2。你可能已经注意到，我们可以通过<em class="mm">一键编码</em>我们的目标向量(y)来实现这一点。让我们看看代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块5。预处理. py</p></figure><p id="0c44" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们有了完成Softmax回归模型所需的所有帮助函数。代码有很好的文档记录，所以请阅读每个部分是做什么的解释。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块6。物流. py</p></figure><p id="e88f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就是这样！我们已经成功地将Softmax回归添加到我们的机器学习库中。让我们快速看一下测试用例，以确保它正常工作。</p><h2 id="ce41" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">测试案例——虹膜多类分类</h2><p id="b8e7" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">我们将使用iris数据集，但这次尝试以至少85%的准确率对所有三个类进行分类。首先，我们加载数据集，对其进行训练/测试拆分，执行标准化，然后训练我们的Softmax回归模型并预测测试集。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块7。test_logistic.py</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/10e74df47fde50cf938e4a4d317e2db0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IOvaOULDLAZfWSHry_-eYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。测试在1.83秒内通过</p></figure><p id="c9fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们完了！我们的测试用例通过了。我们成功地将Softmax回归添加到了我们的机器学习库中。</p><h1 id="84cc" class="nx mr it bd ms ny nz oa mv ob oc od my jz oe ka nb kc of kd ne kf og kg nh oh bi translated">包裹</h1><p id="1088" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">ML从头开始系列的这一部分到此结束。我们现在有一个机器学习库，其中包含用于回归和分类的最常见的线性模型，包括:</p><ul class=""><li id="934b" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt or ma mb mc bi translated">线性回归</li><li id="9e29" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">多项式回归</li><li id="588f" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">山脉</li><li id="f2ef" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">套索</li><li id="46b7" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">弹性网</li><li id="6228" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">逻辑回归</li><li id="0b85" class="lu lv it la b lb md le me lh mf ll mg lp mh lt or ma mb mc bi translated">Softmax回归</li></ul><p id="393e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一如既往，非常感谢您的阅读和反馈！</p></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><p id="bf34" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本系列的下一部分，我们将构建我们的库，并创建能够分类和回归的支持向量机。</p><p id="cb5c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mm">如果你喜欢这里的内容，请关注我！:-) </em></p><h2 id="2fcf" class="mq mr it bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">额外资源</h2><div class="pc pd gp gr pe pf"><a rel="noopener follow" target="_blank" href="/ml-from-scratch-linear-polynomial-and-regularized-regression-models-725672336076"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd iu gy z fp pk fr fs pl fu fw is bi translated">ML从零开始:线性、多项式和正则化回归模型</h2><div class="pm l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">towardsdatascience.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps ks pf"/></div></div></a></div></div></div>    
</body>
</html>