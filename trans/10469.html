<html>
<head>
<title>Do algorithms have politics?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">算法有政治吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/do-algorithms-have-politics-56beb25ce685?source=collection_archive---------30-----------------------#2021-10-05">https://towardsdatascience.com/do-algorithms-have-politics-56beb25ce685?source=collection_archive---------30-----------------------#2021-10-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2b49" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/fairness-and-bias" rel="noopener" target="_blank">公平和偏见</a></h2><div class=""/><div class=""><h2 id="9f21" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">神器有政治吗？这个问题已经是社会科学讨论了几十年的主题，直到今天仍然适用。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/84b78203851595cb763ba44927d1de02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YVOo63MZAzaQshTu"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@lazycreekimages?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">迈克尔·泽兹奇</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="bbbd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">神器有政治吗？这个问题本身就是兰登·温纳的技术政治理论(温纳，1980年)的标题，已经引起了几十年的讨论，今天仍然是相关的。在他有影响力的文章中，温纳提出了技术作为一种<em class="mb">物质</em>人工制品，可以体现政治理念的理论(温纳，1980)。这在当时是一个相当激进的概念——把一个物质艺术品想象成一个政治角色需要一个新的权力关系表达的概念。</p><p id="a17d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">事实上，这一理论一直备受争议，对温纳论文的回应一直反对赋予技术而非其他社会行为者的能动性(例如，Joerges，1999；伍尔加和库珀，1999年)。然而，他的理论强调了关注技术设计的特殊功能和特征的价值。Winner声称，技术可以体现特定形式的权力和权威，而不是被它们所处的环境政治化(Winner，1980)。他认为这很重要，因为它使我们能够理解技术设计选择的社会政治含义，而不是通过社会力量的镜头来分析一切。</p><p id="b747" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">尽管温纳在40多年前就发展了他的理论，他描述的概念今天仍然适用。事实上，最近<a class="ae le" href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206" rel="noopener ugc nofollow" target="_blank">提出的欧盟人工智能法规</a>强调了对人工智能偏见等技术政治问题的认识(欧盟委员会，2021)。诸如此类的法律反映了人们对歧视性算法越来越多的担忧，这在公共和私营部门都可以看到。例如，亚马逊2014年的招聘算法被发现不成比例地拒绝了女性的简历。他们通过惩罚包含“女子”一词的简历(例如女子象棋俱乐部)和带有全女子学院名称的简历(<a class="ae le" href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" rel="noopener ugc nofollow" target="_blank">路透社，2018 </a>)来做到这一点。</p><p id="2c4b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">亚马逊的算法不仅通过性别歧视的影响来支持Winner的理论，还通过性别歧视思想被编码到技术中的方式。首先，机器学习算法在过去(主要是男性)候选人的简历上进行训练，这使得该算法能够重现女性被排除在IT部门之外的历史。其次，使用性别作为相关变量允许算法在此基础上选择候选人。最后，决定设计一种算法，从一系列简历中选择最优秀的候选人，这赋予了该算法决定个人职业机会的能力。尽管这些都是由一系列人类参与者(他们应该对自己的产品负责)做出的设计决策，但该算法的材料特性和特征使其能够成为一个政治参与者，而不管亚马逊团队的意图如何。</p><blockquote class="mc"><p id="3a5f" class="md me iq bd mf mg mh mi mj mk ml ma dk translated">“它让我们能够理解技术设计选择的社会政治含义，而不是通过社会力量的镜头来分析一切。”</p></blockquote><p id="770c" class="pw-post-body-paragraph lf lg iq lh b li mm ka lk ll mn kd ln lo mo lq lr ls mp lu lv lw mq ly lz ma ij bi translated">因此，将Winner的技术政治理论<em class="mb"> </em>应用到<em class="mb"> </em>亚马逊的招聘算法有助于我们理解为什么技术的社会研究在今天仍然相关。亚马逊的算法不仅因为其所处的社会政治环境而具有性别歧视的影响，还因为政治理念被<em class="mb">镌刻在技术中的方式。这些技术特征——用于训练机器学习算法的数据库、被认为与之相关的变量，以及该算法被转化为雇佣/不雇佣决策的方式——具有非常现实和非常政治的意义。</em></p><p id="94a2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过理解技术如何体现政治理念，我们可以将技术的概念重新定义为“中性工具”，并开始重新思考如何更好地设计技术。在亚马逊的案例中，我们可能会考虑如何使用更多样化的数据集来训练招聘算法，如何让它们接受审计机制的检查，以标记偏见的例子，或者如何阻止它们在决定我们未来的环境中使用。正如兰登·温纳所说:我们不仅可以考虑“技术是如何被构建的”，还可以考虑[…]我们以技术为中心的世界可能被重建的方式。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="fb92" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="mb">参考书目:</em> </strong></p><p id="00a9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">j .达斯廷，2021。<em class="mb">亚马逊废弃了对女性有偏见的秘密人工智能招聘工具</em>。[在线]路透社。可从以下网址获取:&lt;https://www . Reuters . com/article/us-Amazon-com-jobs-automation-insight-iduskcn 1 MK 08g&gt;【2021年10月1日获取】。</p><p id="cb4b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">欧盟委员会，2021年。<em class="mb">欧洲议会和理事会制定人工智能协调规则(人工智能法案)并修订某些欧盟法案的提案</em>。[在线]欧盟委员会。可在:&lt;https://eur-lex.europa.eu/legal-content/EN/ALL/?购买uri = CELEX:52021 PC 0206&gt;【2021年10月3日访问】。</p><p id="8025" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Joerges，b .，1999年。政治有人工制品吗？。<em class="mb">科学的社会研究</em>，29卷3期，第411–431页。</p><p id="ed0f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">冠军，洛杉矶，1980年。神器有政治吗？。<em class="mb"/>，【在线】第109卷第1期，第121–136页。</p><p id="ff13" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">伍尔加和库珀，1999年。人工制品有矛盾心理吗？科学的社会研究，第29卷第3期，第433-449页。</p></div></div>    
</body>
</html>