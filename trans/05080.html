<html>
<head>
<title>Bias in Your Datasets: COVID-19 Case Study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据集中的偏见:新冠肺炎案例研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bias-in-your-datasets-covid-19-case-study-d065aa698b74?source=collection_archive---------31-----------------------#2021-05-04">https://towardsdatascience.com/bias-in-your-datasets-covid-19-case-study-d065aa698b74?source=collection_archive---------31-----------------------#2021-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4cf3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">偏见如何通过过度拟合来影响深度学习模型的性能？让我们关注医学图像的模型可解释性。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/dddb8aa93e2f7cfb8996c89d2ca94af4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1qhDvxBz4mHGqYPA_mlUuQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">胸部x光打开<a class="ae kv" href="https://www.shutterstock.com/fr/image-photo/doctor-checking-chest-xray-film-ward-560923156" rel="noopener ugc nofollow" target="_blank">快门架</a></p></figure><h1 id="09b6" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">动机</h1><p id="ab4d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在过去的几年里，大量的实验显示了人工智能(AI)在医学成像服务中的兴趣，特别是在放射学中。这是由于大型数据集的可用性、计算能力的巨大进步以及新的深度学习算法的出现而成为可能。然而，由于这些人工智能算法在实验阶段和真实条件下的实现之间的性能退化，这些技术今天没有广泛普及。对这一现象的解释之一与过度拟合有关:该算法不会在新数据上广泛传播。</p><p id="9dbf" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在这个项目中，我们想说明偏倚如何显著影响胸部X射线(CXR)图像分类模型的性能。除了对数据集进行简单的探索性分析，我们试图证明这些偏差的存在，并对其进行表征。</p><p id="9e0d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">主要目的是开发一种算法，该算法将从CXR图像中预测患者是否患有<strong class="lq ir">病毒性肺炎</strong>、<strong class="lq ir">新冠肺炎</strong>或无病(<strong class="lq ir">正常</strong>)。在这种情况下，使用了这三类中每一类的CXR图像的三个数据集，即具有平衡分布的3886个射线照相图像:<a class="ae kv" href="https://www.kaggle.com/tawsifurrahman/covid19-radiography-database" rel="noopener ugc nofollow" target="_blank">新冠肺炎射线照相数据库</a>【1，2】。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/bd047fbeaa64204532630a9619264ca8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*J5xZ7XmDXjaABa_FIgTWog.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">包含3个类别的数据集:COVID、NORMAL、PNEUMO(作者提供的图片)</p></figure><p id="da93" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">作为深度学习领域的新手，我们选择了一个简单的CNN模型来实现(LeNet)两个卷积层。你猜怎么着，我们得到了97%的测试准确率🎊！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/0877e419482cf323ea15319de8d6d062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2YJXXnVpK_2Obf7-PEE44Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用30个时期的(LeNet)模型实现97%的准确性(图片由作者提供)</p></figure><p id="c886" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们没有公布2021年诺贝尔医学奖的结果，而是问了自己以下问题:</p><blockquote class="mr ms mt"><p id="06a2" class="lo lp mu lq b lr mk jr lt lu ml ju lw mv mm lz ma mw mn md me mx mo mh mi mj ij bi translated">用一个简单的2层卷积神经网络模型检测胸部疾病几乎有97%的准确率是对的吗？</p></blockquote><p id="7b7f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mu">答案是否定的</em> </strong>。这就是为什么在训练<a class="ae kv" href="https://datascientest.com/transfer-learning" rel="noopener ugc nofollow" target="_blank">迁移学习</a>模型之前，深入研究数据集的偏差并尝试纠正它们是非常重要的。</p><h1 id="a039" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">我们的数据集中存在哪些偏见？</h1><p id="485e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">第一步是试图找出图像的差异和异质性。为此，比较了正常图像和COVID图像之间的亮度分布。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/52ff51d20194697fa997590053e0eeaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*HoQb-i3ftOmKbyUMeXYNRQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Covid/正常图像的亮度分布(图片由作者提供)</p></figure><p id="c504" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">观察到亮度分布的显著差异。因此，这个全局特性足以以“正确”的方式区分这两个类别，并为我们之前注意到的高性能提供了第一个解释(LeNet)。</p><h1 id="6459" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">让我们进一步分析…</h1><p id="b329" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了可视化数据集的偏差，我们已经开始寻找可以将3个类分开的局部特征。想法是将图像投影到更小的维度空间中，以观察3个类别的图像中的趋势。为此，图像被调整为28x28:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/ba65cf4f931c9817d824e996f7914c80.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*9Zj8-ZfRbwDz0--k0GnrXg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CXR图片尺寸调整为28x28像素(图片由作者提供)</p></figure><p id="76b9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">由于缺乏细节，理论上不可能检测出covid或肺炎。</p><p id="27b7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">t-SNE算法[3]是一种非线性聚类方法，可以通过连续迭代在二维或三维空间中表示一组高维空间的点。然后，数据可以以点云的形式可视化:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/3c67e60480c267925a2993b6b84bdb41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*a39T3o9QDA6lgj-R1NKo-Q.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用t-SNE算法可视化高维数据(来自<a class="ae kv" href="https://zaburo-ch.github.io/images/mnist_process.gif" rel="noopener ugc nofollow" target="_blank">https://zaburo-ch.github.io/images/mnist_process.gif</a></p></figure><p id="58a4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">t-SNE应用了像素强度的两个分量，数据集显示在这两个轴上。令人惊讶的是，使用无监督聚类方法和没有细节的图像，可以在2D投影上区分3个类别！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/e9fd77a07b416247f9e42579454fd48e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*fpqI9ruJHG93ThTgSg9lFA.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集的t-SNE可视化，然后进行SVM分类(图片由作者提供)</p></figure><p id="c374" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">事实上，通过在对应于两个t-SNE轴的两个变量上应用SVM，获得了84%的准确度。</p><p id="28d0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">t-SNE算法似乎可以从28x28的非细节图像中提取重要信息，使其能够进行良好的分类。为了便于解释，让我们用PCA做同样的事情。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/f4bc9223ccbb71784484bf5592d1a960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fn-0yRu6sUcbfEKI9eGx_g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集的PCA可视化(图片由作者提供)</p></figure><p id="b7d1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">投影的效率低于t-SNE方法，但我们注意到第一模式(x轴)可以正确地将Covid图像与非Covid图像分开。根据这一观察，我们可以显示向量“pca.components_[0]”，仅取系数的绝对值，并查看28x28热图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/38e29b69ec2ab14118ea1f787e348075.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*h07hb4amHG1mjkB173EeoQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第一个PCA组件的热图(图片由作者提供)</p></figure><p id="01c9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从上面的投影(第一主成分)可以看出，重要的像素位于图像的左右边缘。因此，边缘的亮度使我们能够正确地将数据集中的covid图像与非covid图像分开，这在我们的研究中代表了一种真正的偏差！</p><h1 id="95b0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">让我们更进一步…</h1><p id="b895" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对神经网络最常见的批评是难以提取和以人类可读的形式解释决策过程。它们通常被视为“黑匣子”。但这还不包括最近解决这个棘手问题的出版物:</p><blockquote class="mr ms mt"><p id="e979" class="lo lp mu lq b lr mk jr lt lu ml ju lw mv mm lz ma mw mn md me mx mo mh mi mj ij bi translated">卷积神经网络如何决定？</p></blockquote><p id="cda6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">Grad-CAM是2017年发布的一种方法[4]，有助于解读CNN的结果。它通过计算从决策反向传播到最后卷积层的梯度，提供由神经网络确定的类别的激活图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/4da0a3d6889c8a4805bb7bebf7200747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HyfU2X0Kb2DubFyMExBJlQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Grad-CAM架构(图片由作者提供)</p></figure><p id="388d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">Grad-CAM算法应用于具有12个随机COVID图像的第一个原型(LeNet ),激活图向我们显示网络主要使用图像的边缘来做出决策，而不是在肺部内部寻找有用的信息:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/278891b5dfe440036c336eb156189877.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*di4iRqpNZ8zcy8qtJ9zNhA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">绿色/黄色区域是基于网络决策的感兴趣区域，蓝色区域是不感兴趣区域。(图片由作者提供)</p></figure><h1 id="e5f0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">如何纠正这些偏见？</h1><p id="20b0" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在对数据集的偏差进行分析后，我们观察到分类算法主要基于图像边缘的像素来做出决定。因此，我们的想法是去除这些边缘，并且只关注具有分类所需信息的肺。</p><p id="d13f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这需要使用一个U-Net神经网络，该网络是根据CXR图像预先训练的，是专门为肺部分割开发的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/f4c07917005ef9ab9f397784285d357b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XbuSJ4_h2-iEzzLiwDG51A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">U-Net架构(图片由作者提供)</p></figure><p id="a9b5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下面的序列说明了经过所有预处理方法后的图像转换:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/46d5b43d1bbdc879714f451bc9117bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEBG8Bjc7wJl40Rwxgtl_Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">细分渠道(图片由作者提供)</p></figure><p id="65a9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">分割后，图像在肺部周围以10像素的边缘被裁剪。</p><p id="3dfe" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然后，均匀化和裁剪后的图像用于构建我们的新数据集，以训练和测试深度学习模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/c2ff6641c7604abcc098bcf73846f635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*dMXtI_knlpKJcVvkcX6Rvg.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预处理前后(图片由作者提供)</p></figure><h1 id="829a" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">最后，它有用吗？</h1><p id="5f81" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">通过对裁剪后的图像应用t-SNE方法，仍然可以在数据集中观察到偏差，因为无监督算法仍然能够分离类别😭：</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/01d4c80c6ca05f43366d3ce06c3f7f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kBvbMIqL9wjflgY_7YLAQg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预处理数据集上的t-SNE(图片由作者提供)</p></figure><h1 id="5061" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">预处理图像的迁移学习</h1><p id="603b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">测试了两个迁移学习模型:DenseNet121 (121个卷积层😮)和VGG16架构，两者都在庞大的Imagenet数据集上进行了预训练。</p><p id="a94c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">PS:因为CXR是黑白的，所以在输入之后插入了一个卷积层来给图像“上色”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/0e5abf5e264c9586bc3e32a858d2135f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Djg95eeszeat6ht1xp3JnA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练参数和准确度(图片由作者提供)</p></figure><p id="dc73" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">两个迁移学习模型的准确性低于LeNet的准确性，但是Grad-CAM激活图向我们显示，他们主要是在肺部做出决定。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/88ae8334204d1c90febac5b702c706f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQ5C0VEOGAzMYL-5q523lA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Grad-CAM激活图应用于VGG16，经过预处理(图片由作者提供)</p></figure><p id="281e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">您还可以使用您的图像测试这3个模型，并通过以下地址提供的Streamlit应用程序观察Grad-CAM激活图:<a class="ae kv" href="https://studio.datascientest.com/project/covid/" rel="noopener ugc nofollow" target="_blank">https://studio.datascientest.com/project/covid/</a>。</p><h1 id="b77f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结果</h1><ul class=""><li id="6b77" class="nk nl iq lq b lr ls lu lv lx nm mb nn mf no mj np nq nr ns bi translated">通过t-SNE和PCA方法降维突出数据集偏差。</li><li id="3ff8" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">通过分割肺来均衡直方图和从图像中去除边缘的流水线的开发。</li><li id="29db" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">用(Densenet121和VGG16)迁移学习。</li><li id="e9ed" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">使用最近的Grad-CAM方法可视化神经网络类激活图。</li></ul><h1 id="b241" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">思想</h1><ul class=""><li id="fe19" class="nk nl iq lq b lr ls lu lv lx nm mb nn mf no mj np nq nr ns bi translated">通过对每个类别使用不同来源的新图像，纠正预处理后仍然存在的偏差。</li><li id="9fcc" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">通过训练更多的epochs和解冻预训练网络的一些层来继续优化网络性能。</li><li id="d169" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">与放射科医生合作，评估grad-CAM卡在患者图像上的适用性</li><li id="50f6" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">除了图像之外，将患者信息添加到模型中:症状、病史、年龄、性别、位置、日期等；以便使该模型更加稳健并忠实于实际的医学诊断。</li></ul><h1 id="36a0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">道德</h1><blockquote class="mr ms mt"><p id="aa2a" class="lo lp mu lq b lr mk jr lt lu ml ju lw mv mm lz ma mw mn md me mx mo mh mi mj ij bi translated">拥有出色的性能是没有意义的，你必须限制数据集中的偏差！</p></blockquote><blockquote class="ny"><p id="5941" class="nz oa iq bd ob oc od oe of og oh mj dk translated"><strong class="ak"> <em class="oi">在深度学习中，决定算法是什么的主要是数据。</em> </strong></p></blockquote><h1 id="f0cd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw oj jx li jz ok ka lk kc ol kd lm ln bi translated">作者</h1><p id="ee92" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">巴蒂斯特·莫罗:<a class="ae kv" href="https://www.linkedin.com/in/baptistemoreau/" rel="noopener ugc nofollow" target="_blank">领英</a></p><p id="e9d1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">查迪·马斯里:<a class="ae kv" href="https://www.linkedin.com/in/chadi-masri/" rel="noopener ugc nofollow" target="_blank">领英</a></p><p id="3f0c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">卡莉玛·本尼亚:<a class="ae kv" href="https://www.linkedin.com/in/karima-bennia-7108009a/" rel="noopener ugc nofollow" target="_blank">领英</a></p><h1 id="fe51" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><p id="9b7b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1] CHOWDHURY，Muhammad EH，RAHMAN，Tawsifur，KHANDAKAR，Amith，<em class="mu">等</em>AI能否帮助筛查病毒性和新冠肺炎肺炎？。<em class="mu"> IEEE Access </em>，2020年，第8卷，第132665–132676页。</p><p id="a48d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[2] RAHMAN，Tawsifur，KHANDAKAR，Amith，QIBLAWEY，Yazan等.利用胸部X射线图像探索图像增强技术对新冠肺炎检测的影响.生物学和医学中的计算机，2021年，第132卷，第104319页。</p><p id="9436" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[3]范德马腾，劳伦斯和辛顿，杰弗里。使用t-SNE可视化数据。机器学习研究杂志，2008年，第9卷，第11期。</p><p id="3b5c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[4] SELVARAJU，Ramprasaath R .，COGSWELL，Michael，DAS，Abhishek，等. Grad-cam:通过基于梯度的定位从深度网络进行视觉解释.IEEE计算机视觉国际会议论文集。2017.第618-626页。</p></div></div>    
</body>
</html>