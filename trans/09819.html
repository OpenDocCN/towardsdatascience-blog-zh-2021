<html>
<head>
<title>Deep transfer learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-3e9bb53549f6?source=collection_archive---------23-----------------------#2021-09-14">https://towardsdatascience.com/transfer-learning-3e9bb53549f6?source=collection_archive---------23-----------------------#2021-09-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="50db" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">重用他人训练的模型的艺术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d2eab46989d580b652f44d5bbf9b3299.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rsgubd7aTgUdY65KPYATBA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h1 id="c881" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">介绍</h1><p id="c0b0" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">好的机器学习模型需要海量的<strong class="ls iu">数据</strong>和许多<strong class="ls iu">GPU</strong>或<strong class="ls iu">TPU</strong>来训练。而且大多数时候他们只能执行一个特定的任务。</p><p id="bd44" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">大学和大公司有时会发布他们的模型。但是很可能你想开发一个机器学习应用程序，但是没有适合你的任务的模型。</p><p id="985b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">但是不要担心，你不必收集大量的数据和花费大量的现金来开发自己的模型。可以用迁移学习来代替。这减少了训练时间，您可以用更少的数据获得良好的性能。</p><h1 id="8370" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">什么是迁移学习？</h1><p id="2a3f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在迁移学习中，我们使用模型在特定任务的训练中收集的知识来解决<a class="ae mr" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">不同但相关的任务</a>。该模型可以从以前的任务中学到的东西中获益，以便更快地学习新的任务。</p><p id="d0ff" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这里打个比方，说你要检测图像上的狗。在网上你可以找到一个可以检测猫的模型。因为这是一个足够相似的任务，你拍几张你的狗的照片，然后重新训练这个模型来探测狗。也许它会有偏见，只认出你的宠物，但我想你明白了😉。</p><p id="b074" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">也许模型已经学会了通过他们的皮毛或者他们有眼睛的事实来识别猫，这对于识别狗也是非常有帮助的。</p><p id="0707" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">迁移学习其实有<a class="ae mr" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="noopener ugc nofollow" target="_blank">两种</a>，特征提取和微调。</p><p id="aadc" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">一般来说，这两种方法遵循相同的程序:</p><ul class=""><li id="79ab" class="ms mt it ls b lt mm lw mn lz mu md mv mh mw ml mx my mz na bi translated">初始化预训练的模型(我们想要学习的模型)</li><li id="3b05" class="ms mt it ls b lt nb lw nc lz nd md ne mh nf ml mx my mz na bi translated">重塑最终图层，使其输出数量与新数据集中的类数量相同</li><li id="a55d" class="ms mt it ls b lt nb lw nc lz nd md ne mh nf ml mx my mz na bi translated">定义我们想要更新的图层</li><li id="52c0" class="ms mt it ls b lt nb lw nc lz nd md ne mh nf ml mx my mz na bi translated">在新数据集上训练</li></ul><h1 id="0f0c" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">特征抽出</h1><p id="ebf5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们考虑一个卷积神经网络架构，它具有滤波器、密集层和一个输出神经元。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/31f2dc284f851da5465448fd19144f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*U79dqQxPwbo7UEKg73Jeyw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="2c2c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">网络被训练来预测图像上有猫的概率。我们需要一个<strong class="ls iu">大数据集</strong>(有猫和没有猫的图像)<strong class="ls iu">训练时间长</strong>。这一步叫做“前期训练”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/2ffc69a9e1be521faa74d8b8afc67255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nf-KzsTvtBhjB3arE_qfjg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="b86c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">接下来是有趣的部分。我们再次训练网络，但是这一次使用包含狗的小图像数据集。在训练期间，除了输出层之外的所有层都被“冻结”。这意味着我们不会在培训期间更新它们。训练之后，网络输出狗在图像上可见的概率。与之前的预培训相比，该培训程序将<strong class="ls iu">花费更少的时间</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/f60c2a5a469a75100eb32595ba3eb8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8BWUjCEyp2EANd7BpvfuGQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="9779" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">或者，我们也可以“解冻”最后两个图层，即输出图层和密集图层。这取决于我们拥有的数据量。如果数据较少，我们可以考虑只训练最后一层。</p><h1 id="bf01" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">微调</h1><p id="21b9" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在微调中，我们从预先训练的模型开始，但是我们更新所有的权重。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/6fe0717406661679a36a6af92b545b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rv0lJgxauCvzHqc9iS5xJA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h1 id="2639" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">pytorch中的迁移学习示例</h1><p id="d147" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我将使用来自kaggle的数据集<a class="ae mr" href="https://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank">猫对狗</a>。数据集可以在<a class="ae mr" href="https://www.microsoft.com/en-us/download/details.aspx?id=54765" rel="noopener ugc nofollow" target="_blank">这里</a>找到。你总是可以使用不同的数据集。</p><p id="c657" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这里的任务与我上面的例子有点不同。用于识别哪些图像上有狗，哪些图像上有猫的模型。为使代码正常工作，您必须按以下结构组织数据:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/1032d9f01e246bdb57c437a8db5f1f4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*BCORpLl3duPziVzZnlMvCQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="4d87" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">你可以在这里找到关于猫和狗<a class="ae mr" href="https://medium.com/predict/using-pytorch-for-kaggles-famous-dogs-vs-cats-challenge-part-1-preprocessing-and-training-407017e1a10c" rel="noopener">的更详细的介绍。</a></p><h2 id="bcc7" class="nl kz it bd la nm nn dn le no np dp li lz nq nr lk md ns nt lm mh nu nv lo nw bi translated">设置</h2><p id="9fbe" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们从导入所需的库开始。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="7a16" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们检查一个CUDA兼容的CPU，否则我们将使用CPU。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="5ce9" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后我们加载torchvision的预训练ResNet50。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="1bf7" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">数据扩充是通过对图像应用不同的变换来完成的，从而防止过拟合。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="9b30" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们创建数据加载器，它将从内存中加载图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="8017" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">创建学习率计划程序，它将在培训过程中修改学习率。或者，您可以使用ADAM优化器，它可以自动调整学习速率，并且不需要调度程序。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><h2 id="6c6c" class="nl kz it bd la nm nn dn le no np dp li lz nq nr lk md ns nt lm mh nu nv lo nw bi translated">特征提取优化器</h2><p id="33aa" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这里将只为最后一层计算梯度，因此只训练最后一层。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="375b" class="nl kz it bd la nm nn dn le no np dp li lz nq nr lk md ns nt lm mh nu nv lo nw bi translated">用于微调的优化器</h2><p id="48bc" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在这里，所有的层将被训练。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="abb7" class="nl kz it bd la nm nn dn le no np dp li lz nq nr lk md ns nt lm mh nu nv lo nw bi translated">培养</h2><p id="d204" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们来定义一下训练循环。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="67de" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">最后，我们可以训练我们的模型。</p><p id="2717" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">要么使用<strong class="ls iu">特征提取</strong>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="a619" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">或者使用<strong class="ls iu">微调</strong>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><h1 id="27b5" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">不要太骄傲地使用迁移学习</h1><p id="9534" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">当我向人们推荐他们可以在他们的ML项目中使用迁移学习时，他们有时会拒绝，宁愿自己训练一个模型，而不是使用迁移学习。但是没有人应该为使用迁移学习而感到羞耻，因为:</p><ul class=""><li id="d8be" class="ms mt it ls b lt mm lw mn lz mu md mv mh mw ml mx my mz na bi translated">训练神经网络使用能量，因此增加了全球碳排放量。转移学习<strong class="ls iu">通过减少训练时间来拯救我们的星球</strong>。</li><li id="e36f" class="ms mt it ls b lt nb lw nc lz nd md ne mh nf ml mx my mz na bi translated">当训练数据不足时，迁移学习可能是您的模型表现良好的唯一选择。在计算机视觉中，通常缺乏训练数据。</li></ul><h1 id="2c6b" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">结论</h1><p id="8918" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">对于现代数据科学家来说，迁移学习是一个方便的工具。您可以使用其他人预先训练的模型，并对其执行迁移学习，以节省时间、计算机资源并减少训练所需的数据量。</p><h1 id="80d0" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">数据集</h1><h2 id="233c" class="nl kz it bd la nm nn dn le no np dp li lz nq nr lk md ns nt lm mh nu nv lo nw bi translated">猫和狗的数据集</h2><p id="6300" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">数据集可以在下找到。</p><p id="fb82" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">【https://www.tensorflow.org/datasets/catalog/cats_vs_dogs T4】</p><p id="4a99" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">并根据<a class="ae mr" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名4.0许可</a>进行许可。</p><h1 id="5b1e" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">来源</h1><p id="0050" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><a class="ae mr" rel="noopener" target="_blank" href="/what-is-deep-transfer-learning-and-why-is-it-becoming-so-popular-91acdcc2717a">什么是深度迁移学习，为什么它变得如此流行？</a></p><p id="e44f" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae mr" href="https://www.youtube.com/watch?v=yofjFQddwHE" rel="noopener ugc nofollow" target="_blank">吴恩达转移学习</a></p><p id="6b4d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae mr" href="https://lambdalabs.com/blog/demystifying-gpt-3/" rel="noopener ugc nofollow" target="_blank"> Lambda实验室，揭开gpt 3的神秘面纱</a></p><p id="956a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae mr" href="https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/?sh=a8d8db06b438" rel="noopener ugc nofollow" target="_blank">深度学习的碳排放</a></p><p id="c2dc" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae mr" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"> DALL E:从文本创建图像</a></p><h2 id="3447" class="nl kz it bd la nm nn dn le no np dp li lz nq nr lk md ns nt lm mh nu nv lo nw bi translated">想联系支持我？</h2><p id="edc9" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">LinkedIn<br/><a class="ae mr" href="https://www.linkedin.com/in/vincent-m%C3%BCller-6b3542214/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/vincent-m%C3%BCller-6b3542214/</a><br/>脸书<br/><a class="ae mr" href="https://www.facebook.com/profile.php?id=100072095823739" rel="noopener ugc nofollow" target="_blank">https://www.facebook.com/profile.php?id=100072095823739</a><br/>Twitter<br/><a class="ae mr" href="https://twitter.com/Vincent02770108" rel="noopener ugc nofollow" target="_blank">https://twitter.com/Vincent02770108</a><br/>Medium<br/><a class="ae mr" href="https://medium.com/@Vincent.Mueller" rel="noopener">https://medium.com/@Vincent.Mueller</a><br/>成为Medium会员并支持我(<em class="nz">你的部分会费直接交给我</em>)<br/><a class="ae mr" href="https://medium.com/@Vincent.Mueller/membership" rel="noopener">https://medium.com/@Vincent.Mueller/membership</a></p></div></div>    
</body>
</html>