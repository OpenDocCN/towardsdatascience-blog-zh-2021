<html>
<head>
<title>Stop Using One-vs-One or One-vs-Rest for Multi-Class Classification Tasks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">停止使用一对一或一对多分类任务</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stop-using-one-vs-one-or-one-vs-rest-for-multi-class-classification-tasks-31b3fd92cb5e?source=collection_archive---------11-----------------------#2021-11-14">https://towardsdatascience.com/stop-using-one-vs-one-or-one-vs-rest-for-multi-class-classification-tasks-31b3fd92cb5e?source=collection_archive---------11-----------------------#2021-11-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d5f1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">纠错输出码基本指南(ECOC)</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f46e8a3c79509521a0c7459a919dd2e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4jo0fPG2YEJgBTyB9qZl6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=475664" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a>从<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=475664" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄</p></figure><p id="221f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">诸如逻辑回归、支持向量机等机器学习算法可以对二进制类数据集进行分类，但在处理多类分类数据时，它会失败。多类分类任务具有超过2个基数的目标类标签。对于多类分类或多标签分类任务，我们需要使用某些技巧或技术以及机器学习算法来训练数据集。</p><p id="6e15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html" rel="noopener ugc nofollow" target="_blank">一对一</a>和<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html" rel="noopener ugc nofollow" target="_blank">一对一</a>就是这样两种可以处理多类或多标签分类任务的技术。One-vs-Rest分类器为目标类标签为<code class="fe lv lw lx ly b"><strong class="lb iu">‘c’</strong></code>基数的数据训练<code class="fe lv lw lx ly b"><strong class="lb iu">‘c’</strong></code>分类器，每个估计器适用于一个类，并针对所有其他类。而一对一分类器为每对类别训练一个分类器。纠错输出码(ECOC)与OvO和OvR分类器有很大不同。在本文中，我们将讨论ECOC如何在幕后工作，以及如何使用它来训练多类分类任务的模型。</p><h1 id="ea41" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">什么是ECOC？</h1><p id="a560" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">纠错输出码(ECOC)是一种为多类分类问题设计的集成分类技术。<a class="ae ky" href="https://www.kaggle.com/uciml/iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>和<a class="ae ky" href="https://www.kaggle.com/c/digit-recognizer/data" rel="noopener ugc nofollow" target="_blank"> MNIST数字识别数据集</a>是多类分类数据集的例子。ECOC、OvO和OvR技术结合多个二元估计器来开发多类分类模型。</p><p id="ef9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ECOC将多类目标类标签预处理成二进制代码(0和1的数组)。使用这种策略，目标类别标签在二进制码的欧几里德空间中表示，使用跟踪编码的码本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/69df60fca93fb8616178a2f591e4ba9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*h429mOMEi8R7SmFMkcij_Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，15位编码中10个类目标标签的表示</p></figure><p id="4be4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面提到的图像显示了10类目标标签的15位编码。每个目标标签被分配一个唯一的15位编码。码本矩阵跟踪每个目标类的比特编码。</p><p id="62dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开发者可以控制比特编码的维度。如果位编码的维数大于目标类别标签的基数，则一些分类器的预测可以被其他分类器校正。在这种情况下，要训练的估计量的数量比一对其余技术要多。</p><p id="c7c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们保持比特编码的维数小于目标类标签的基数，那么它训练的估计器相对比一对其余分类器要少。理论上，<code class="fe lv lw lx ly b"><strong class="lb iu">log2(n_classes)</strong></code>足以明确地表示目标类标签。对于10类目标标签log2(10)=4应该是选择。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/f93b7c72f4e1fb8ea6bb4baf003078d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*-ogCQaAQ3nNDxlcEDqu-Ng.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，以4位编码表示10个类目标标签</p></figure><p id="557b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在d维比特编码中对目标类标签进行编码之后，需要拟合“d”个估计量，一个二进制估计量用于编码的每个比特。在预测时，基本估计器预测编码目标类的每个相应比特，并且最接近这些点的目标嵌入类被认为是最终预测。</p><h1 id="2792" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">实施:</h1><p id="204f" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">Scikit-learn包附带了一个<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OutputCodeClassifier.html" rel="noopener ugc nofollow" target="_blank"> OutputCodeClassifier() </a>函数，该函数在一行Python代码中实现了ECOC分类器。参数code_size可用于决定目标类的位编码。介于0和1之间的值可以用于压缩模型，或者code_size &gt; 1可以使模型对错误更鲁棒。</p><p id="ae27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要调整code_size的值:</p><ul class=""><li id="36d5" class="my mz it lb b lc ld lf lg li na lm nb lq nc lu nd ne nf ng bi translated">0 &lt; code_size &lt;1: Train a compressed model where the number of estimators fitted is less than in the case of the One-vs-Rest classifier.</li><li id="c3c2" class="my mz it lb b lc nh lf ni li nj lm nk lq nl lu nd ne nf ng bi translated">code_size&gt; 1:训练误差校正模型，对误差稳健。拟合的估计量的数量多于一对其余分类器的情况。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，使用Scikit-learn API实现ECOC</p></figure><p id="8fb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以调整超参数code_size来改变目标类嵌入的维度。我使用带有逻辑回归模型的OutputCodeClassifier作为基本估计量，训练了一个20类分类数据集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/559511a87bd1f365d538897cda3d5bb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*GeowrxU4hVFi8snW98AYRA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，调优代码大小超参数上的性能指标分布</p></figure><p id="da3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的分布图中，我们可以观察到性能指标的增加，但随后，它变平了。代码大小= 10的值可以被认为是一个阈值。对于代码大小= 10，我们得到了25.9%的准确率、27.3%的精确度和26.5%的召回率。进一步增加嵌入维数对模型的性能没有影响。</p><h1 id="7c5e" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">结论:</h1><p id="387b" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">OutputCodeClassifier是一个方便的函数，可用于拟合实现ECOC算法的多类分类数据集。开发人员可以控制基分类器的数量，这与一对一或一对其余技术相比是一个额外的优势，在一对一或一对其余技术中，基估计器的数量取决于目标类的基数。</p><p id="db15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型的性能取决于基本估计量的数量。理论上，log2(n_classes)足以明确地表示目标类，但它可能不会导致健壮的模型。我们需要增加代码大小来适应一个不受错误影响的健壮模型。</p><blockquote class="np nq nr"><p id="55cb" class="kz la ns lb b lc ld ju le lf lg jx lh nt lj lk ll nu ln lo lp nv lr ls lt lu im bi translated">遵循我以前的一篇文章，更好地理解多标签分类和多输出回归任务</p></blockquote><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/essential-guide-to-multi-class-and-multi-output-algorithms-in-python-3041fea55214"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">Python中多类和多输出算法的基本指南</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">如何训练多学习任务的ML模型</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ks nz"/></div></div></a></div><h1 id="fd64" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">参考资料:</h1><p id="1d4e" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">[1] Scikit-learn文档:<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OutputCodeClassifier.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . multi class . output code classifier . html</a></p><p id="5bc2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]纽别杰夫文献:【https://newbedev.com/scikit_learn/modules/multiclass T2】</p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="31cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ns">喜欢这篇文章吗？成为</em> <a class="ae ky" href="https://satyam-kumar.medium.com/membership" rel="noopener"> <em class="ns">中等会员</em> </a> <em class="ns">继续无限制学习。如果你使用下面的链接，我会收到你的一小部分会员费，不需要你额外付费。</em></p><div class="nw nx gp gr ny nz"><a href="https://satyam-kumar.medium.com/membership" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">加入我的推荐链接-萨蒂扬库马尔媒体</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">satyam-kumar.medium.com</p></div></div><div class="oi l"><div class="ov l ok ol om oi on ks nz"/></div></div></a></div><blockquote class="ow"><p id="7e67" class="ox oy it bd oz pa pb pc pd pe pf lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>