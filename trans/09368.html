<html>
<head>
<title>How to make clustering explainable</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何让聚类变得可解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-make-clustering-explainable-1582390476cc?source=collection_archive---------8-----------------------#2021-08-31">https://towardsdatascience.com/how-to-make-clustering-explainable-1582390476cc?source=collection_archive---------8-----------------------#2021-08-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8567" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在本文中，我将解释如何使用SHAP值来更好地理解聚类</h2></div><h1 id="3942" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">聚类总是一个黑箱</h1><p id="44b3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了更好地理解不同类型的客户，业务案例中经常需要聚类。但这可能已经足够了。从业务的角度来看，仅仅知道我们有多少个集群以及谁属于哪个集群是不够的。我们需要知道到底是什么形成了这些不同的星团。换句话说，我们想要解释聚类的结果，不幸的是，它总是一个黑箱。我发现自己总是在这种情况下，我也很清楚一个人属于哪个群体，但我不确定他在这个群体中的原因以及他与其他群体成员的不同之处。</p><p id="d666" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这似乎并不明显。回到监督学习，SHAP值提供了一个通用框架，赋予机器学习可解释性，无论是玻璃盒模型还是黑盒模型。我不打算详细解释SHAP值，因为它已经做得很好了，我们几乎可以在互联网上的任何地方找到参考资料，例如<a class="ae ly" href="https://christophm.github.io/interpretable-ml-book/shap.html" rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/shap.htm</a>l。但不幸的是，SHAP值的计算要求我们的数据有标签。事实上，SHAP值被定义为样本的每个特征如何对输出标注的预测做出贡献。没有标签，SHAP很难实施。</p><p id="0783" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">为了在聚类和SHAP值之间架起一座桥梁，我想使用数据聚类的标签，并在此基础上构建SHAP值。我将通过研究一个例子来解释我的想法。详细代码请找到<a class="ae ly" href="http://Hello, sorry for the late reply. I was sick last month. Here is the link for the notebook: https://colab.research.google.com/drive/1BgJuRxRrEcreVwfbfwnFjoFeHonVriKc#scrollTo=eGie9OGPI-QE" rel="noopener ugc nofollow" target="_blank">笔记本</a>的链接。</p><h1 id="b14e" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">葡萄酒数据集聚类</h1><h2 id="54a2" class="lz kg iq bd kh ma mb dn kl mc md dp kp lg me mf kr lk mg mh kt lo mi mj kv mk bi translated">葡萄酒数据集</h2><p id="736c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我将在这里使用葡萄酒数据集:<a class="ae ly" href="https://www.kaggle.com/harrywang/wine-dataset-for-clustering" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/Harry Wang/wine-dataset-for-clustering</a>。这些数据是对意大利同一地区种植的葡萄酒进行化学分析的结果。分析确定了研究葡萄酒中发现的13种成分的数量。让我们先快速看一下桌子的头。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/1678ac6587414b466bd897bc29d6aa37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hv50KcQhUPXrXokl6iq9wQ.png"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">作者图片:葡萄酒数据集表的头</p></figure><p id="b2dd" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这里我也展示了所有特征的直方图。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nb"><img src="../Images/3d7d91e00b689c759ead6a2d362f77be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_pycuY1B6th7J-QmLNwhLA.png"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">按作者分类的图像:葡萄酒数据集所有特征的直方图</p></figure><h2 id="e8c1" class="lz kg iq bd kh ma mb dn kl mc md dp kp lg me mf kr lk mg mh kt lo mi mj kv mk bi translated">数据准备</h2><p id="f652" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在聚类算法之前，我们必须对特征进行归一化。我用了MinMaxScaler。</p><pre class="mm mn mo mp gt nc nd ne nf aw ng bi"><span id="b79d" class="lz kg iq nd b gy nh ni l nj nk">import pandas as pd<br/>from sklearn import preprocessing</span><span id="e434" class="lz kg iq nd b gy nl ni l nj nk">wine_value = wine_df.copy().values<br/>min_max_scaler = preprocessing.MinMaxScaler()<br/>wine_scaled = min_max_scaler.fit_transform(wine_value)<br/>wine_df_scaled = pd.DataFrame(wine_scaled, columns=wine_df.columns)</span></pre><p id="ef1b" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这是缩放前后酒精和灰分值的两个散点图。</p><div class="mm mn mo mp gt ab cb"><figure class="nm mq nn no np nq nr paragraph-image"><img src="../Images/d54fb70b01c2583f7d9a59a1682134af.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*99AIhyP-WdmAGOtoAMv7Tw.png"/></figure><figure class="nm mq ns no np nq nr paragraph-image"><img src="../Images/f6a25fb57bb3e38cf83d39243532734a.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*08MERRrpu6w8TlLYh6irQQ.png"/><p class="mx my gj gh gi mz na bd b be z dk nt di nu nv translated">作者图片:归一化前后两个特征的散点图</p></figure></div><h2 id="fcd8" class="lz kg iq bd kh ma mb dn kl mc md dp kp lg me mf kr lk mg mh kt lo mi mj kv mk bi translated">聚类算法</h2><p id="7f54" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们现在准备在这个葡萄酒数据集上实现聚类算法。我将使用K均值算法。我们可以很容易地对一系列聚类运行K-Means，并将失真收集到一个列表中。</p><pre class="mm mn mo mp gt nc nd ne nf aw ng bi"><span id="fb20" class="lz kg iq nd b gy nh ni l nj nk">from sklearn.cluster import KMeans<br/>distortions = []<br/>K = range(1,10)<br/>for k in K:<br/>    kmeanModel = KMeans(n_clusters=k)<br/>    kmeanModel.fit(scaled_wine_df)<br/>    distortions.append(kmeanModel.inertia_)</span></pre><p id="5b1a" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">绘制不同聚类值的失真，我们很清楚3是最合适的聚类数。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/2f9ee170c8a1a8032013e7e1de4ba451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*n7xjt33vWcJKN5nqV2WjdA.png"/></div><p class="mx my gj gh gi mz na bd b be z dk translated">作者图片:不同聚类值的扭曲。</p></figure><h1 id="6832" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">用SHAP值解释聚类结果</h1><p id="21b9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在创建了3个集群。K-means模型将简单地输出一个范围从0到2的数字，表示样本属于哪个聚类。仅此而已。由于数据集有13个特征，即使是完整的可视化也不是很明显。为了更好地解释聚类结果，下面是我要做的事情:拟合一个分类器模型，其输出正是由聚类提供的标签，并基于该分类器模型计算SHAP值。</p><p id="910e" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">我将使用随机森林分类器。最棒的是，在拟合RandomForest分类器之前不需要进行归一化，因此我们可以直接使用原始数据。由于分类器的目标是更好地理解聚类，并且不存在过度拟合的问题，所以我将使用所有数据集来进行拟合。</p><pre class="mm mn mo mp gt nc nd ne nf aw ng bi"><span id="42cd" class="lz kg iq nd b gy nh ni l nj nk">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.preprocessing import label_binarize<br/>kmeanModel = KMeans(n_clusters=3)<br/>y=kmeanModel.fit(scaled_wine_df).labels_<br/>y = label_binarize(y, classes=[0,1,2])<br/>clf=RandomForestClassifier()<br/>clf.fit(wine_df,y)</span></pre><p id="83cb" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">现在，SHAP终于准备好履行自己的职责了。我将让SHAP解释葡萄酒数据集的特性。</p><pre class="mm mn mo mp gt nc nd ne nf aw ng bi"><span id="a8c1" class="lz kg iq nd b gy nh ni l nj nk">import shap<br/>explainer= shap.TreeExplainer(clf)<br/>shap_values = explainer(wine_df).values</span></pre><h1 id="6214" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">SHAP告诉了我们什么？</h1><p id="4b8c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">以0组为例。让我们看看这两个标签的概要图。</p><p id="95c3" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">该汇总图上的每个点都是样本特征的Shapley值。x轴给出了SHAP值，而y轴由按重要性排序的要素决定。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nx"><img src="../Images/d4430f3df06657cc5b66c471005b68f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*cASlAQVco8Yppn3PtHP5Gg.jpeg"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">作者图片:标签0的SHAP值</p></figure><p id="abd3" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">我们可以看到，OD280、黄酮类化合物和色调是对定义该集群具有最积极影响的特征。我们可以想象一种葡萄酒含有相对大量的OD280、黄酮类化合物和色素。作为一个对酒非常无知的人，这个总结图确实让我对聚类结果有了更好的理解。</p><p id="2c60" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">在这篇文章的最后，我想说的是，聚类是一种非常好的解读无标签数据的方式。但是如何解释聚类的结果一直是个问题。借助SHAP值，我们可以更好地理解聚类。</p></div></div>    
</body>
</html>