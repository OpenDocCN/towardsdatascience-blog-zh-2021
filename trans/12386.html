<html>
<head>
<title>TensorFlow for Computer Vision — How To Increase Model Accuracy With Data Augmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于计算机视觉的张量流——如何通过数据扩充提高模型精度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-for-computer-vision-how-to-increase-model-accuracy-with-data-augmentation-27e553dff5eb?source=collection_archive---------30-----------------------#2021-12-16">https://towardsdatascience.com/tensorflow-for-computer-vision-how-to-increase-model-accuracy-with-data-augmentation-27e553dff5eb?source=collection_archive---------30-----------------------#2021-12-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="368b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">小数据集？没问题——通过数据扩充来扩展它，提高模型的预测能力</strong></h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bf50b0b1eae536d605f73a702bfe7423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w4_90P5i1CGsJFHl9aPmjg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jorgecesar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Jorge César </a>在<a class="ae ky" href="https://unsplash.com/s/photos/polaroid?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="b623" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://betterdatascience.com/does-a-more-complex-architecture-guarantee-a-better-model/" rel="noopener ugc nofollow" target="_blank">上周</a>，你看到更复杂的模型并不能提高预测能力。事实上，我们最终得到了一个更差的图像分类器！你能做些什么来提高准确度？嗯，有几件事，但是<strong class="lb iu">数据扩充</strong>是一个很好的起点。</p><p id="268d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天，您将了解关于 TensorFlow 数据增强的所有内容，它对影像数据集的作用，它为什么能提高预测性能，以及如何在自定义数据集上使用它。所以，事不宜迟，让我们直入主题吧！</p><p id="0e9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不想看书？请观看我的视频:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="3990" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在<a class="ae ky" href="https://github.com/better-data-science/TensorFlow" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上下载源代码。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="5200" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">入门-数据和库导入</h1><p id="60e8" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我们将使用 Kaggle 的<a class="ae ky" href="https://www.kaggle.com/pybear/cats-vs-dogs?select=PetImages" rel="noopener ugc nofollow" target="_blank">狗和猫的数据集</a>。它根据知识共享许可协议获得许可，这意味着您可以免费使用它:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/f41bd5987b947ea0931d767cec2bfa3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGVDaWnmtVm1XhImCEPedg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片 1-狗和猫的数据集(图片由作者提供)</p></figure><p id="1347" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集相当大-25，000 张图像均匀分布在各个类别之间(12，500 张狗图像和 12，500 张猫图像)。它应该足够大，可以训练一个像样的图像分类器。唯一的问题是——它不是为开箱即用的深度学习而构建的。您可以按照我以前的文章创建一个合适的目录结构，并将其分为训练集、测试集和验证集:</p><div class="nc nd gp gr ne nf"><a href="https://betterdatascience.com/top-3-prerequisites-for-deep-learning-projects" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd iu gy z fp nk fr fs nl fu fw is bi translated">用于图像分类的 TensorFlow 深度学习项目的三大先决条件|更好的数据…</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">想训练一个用于图像分类的神经网络？确保做到这一点首先识别图像中的对象是一个…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">betterdatascience.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt ks nf"/></div></div></a></div><p id="c4c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您还应该删除<em class="nu"> train/cat/666.jpg </em>和<em class="nu"> train/dog/11702.jpg </em>图像，因为它们已损坏，您的模型将无法使用它们进行训练。</p><p id="9625" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成后，您可以继续导入库。今天我们只需要几个——Numpy、TensorFlow、Matplotlib 和 PIL。下面的代码片段将它们全部导入，并声明了一个用于显示图像的函数:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="586a" class="oa mf it nw b gy ob oc l od oe">import numpy as np<br/>import tensorflow as tf<br/>from tensorflow.keras import layers<br/>import matplotlib.pyplot as plt<br/>from PIL import Image<br/></span><span id="36c8" class="oa mf it nw b gy of oc l od oe">def plot_image(img: np.array):<br/>    plt.figure(figsize=(6, 6))<br/>    plt.imshow(img, cmap='gray');</span></pre><p id="2031" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在将使用该函数从训练集中加载一个样本图像:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="308a" class="oa mf it nw b gy ob oc l od oe">img = Image.open('data/train/cat/1.jpg')<br/>img = np.array(img)<br/>plot_image(img=img)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/6a1b47bcd9b4edfbc71a7c71c7febb3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TwW-7jRUw8Y1tyVfUzu5sA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片 2 —来自训练集的样本图片(图片由作者提供)</p></figure><p id="7735" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们开始数据扩充所需的全部内容，接下来让我们开始吧。</p><h1 id="cb18" class="me mf it bd mg mh oh mj mk ml oi mn mo jz oj ka mq kc ok kd ms kf ol kg mu mv bi translated">使用 TensorFlow 进行数据扩充</h1><p id="57e2" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">简而言之，数据扩充是一种通过修改现有数据来增加数据量的技术。通过这样做，预测模型会比以前暴露更多的数据，并且在理论上，应该学会更好地建模。至少，如果您首先有一个像样的数据集，您应该期望准确性(或任何其他指标)有几个百分点的提高。</p><p id="e8b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow 的数据扩充通过对图像数据集随机应用不同的变换来工作。这些变换包括水平/垂直翻转、旋转、缩放、宽度/高度移动、剪切等。有关可用选项的完整列表，请参考<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank">官方文档</a>。</p><p id="88c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将声明一个模型，该模型将图像的大小调整为 224x224 像素，并将其基础矩阵的大小调整为 0–1 范围。为数据扩充声明一个模型并不是一种常见的做法，但是您将能够通过这种方式看到到底发生了什么:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="de57" class="oa mf it nw b gy ob oc l od oe">resize_and_scale = tf.keras.Sequential([<br/>    layers.Resizing(224, 224),<br/>    layers.Rescaling(1./255)<br/>])</span><span id="7f61" class="oa mf it nw b gy of oc l od oe">res = resize_and_scale(img)<br/>plot_image(img=res)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/fc49eaae328ac7a3c50cc2e8e7f6bc2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nCtkd9YxN9DxWgV8rkFuNQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3-调整大小和比例后的猫图像(图片由作者提供)</p></figure><p id="676d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里没有发生什么，但是您可以通过比较<em class="nu">图像 2 </em>和<em class="nu">图像 3 </em>上的轴记号来验证是否应用了变换。您还可以打印转换前后图像矩阵的最小值和最大值，但是我将由您来决定。</p><p id="b3eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们通过添加随机水平翻转和随机旋转来增加趣味。根据<code class="fe on oo op nw b">mode</code>参数，<code class="fe on oo op nw b">RandomFlip</code>层水平、垂直或同时水平和垂直翻转图像。一个<code class="fe on oo op nw b">RandomRotation</code>层以某种因子旋转图像。例如，如果因子设置为 0.2，则旋转角度计算为 0.2 * 2PI:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="1965" class="oa mf it nw b gy ob oc l od oe">augmentation = tf.keras.Sequential([<br/>    layers.RandomFlip(mode='horizontal'),<br/>    layers.RandomRotation(factor=0.2)<br/>])</span><span id="9f51" class="oa mf it nw b gy of oc l od oe">res = augmentation(img)<br/>plot_image(img=res)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/4587e8e8cdbcaeace5d6d857aeb71d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tb4sF-23Cry20ffrOgEmtQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4 —翻转和旋转后的猫图像(图片由作者提供)</p></figure><p id="7274" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这仍然是同一个图像，但肯定增加了更多的变化。我们将通过缩放和平移让事情变得更加有趣。一个<code class="fe on oo op nw b">RandomZoom</code>层顾名思义——基于一个因子缩放图像。例如，系数 0.2 表示 20%。一个<code class="fe on oo op nw b">RandomTranslation</code>层垂直或水平移动图像，这取决于两个相应的因素。<code class="fe on oo op nw b">height_factor</code>参数代表垂直移动，<code class="fe on oo op nw b">width_factor</code>代表水平移动:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="9648" class="oa mf it nw b gy ob oc l od oe">augmentation = tf.keras.Sequential([<br/>    layers.RandomFlip(mode='horizontal_and_vertical'),<br/>    layers.RandomRotation(factor=0.2),<br/>    layers.RandomZoom(height_factor=0.2, width_factor=0.2),<br/>    layers.RandomTranslation(height_factor=0.2, width_factor=0.2)<br/>])</span><span id="ab7f" class="oa mf it nw b gy of oc l od oe">res = augmentation(img)<br/>plot_image(img=res)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/d7b76e3043a56e9a66cc88431a26ce50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFVNHBQBlopth_3mbsrJtQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5 —翻转、旋转、缩放和平移后的猫图像(图片由作者提供)</p></figure><p id="df13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着我们添加更多的变换，图像变得越来越奇怪，但我们仍然可以将它们归类为一只猫。您看到的变换是随机的，为了验证这一说法，我们可以绘制一个 3x3 的图，显示 9 个随机变换的结果:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="2bbf" class="oa mf it nw b gy ob oc l od oe">plt.figure(figsize=(10, 10))</span><span id="7ed3" class="oa mf it nw b gy of oc l od oe">for i in range(9):<br/>    img_aug = augmentation(img)<br/>    ax = plt.subplot(3, 3, i + 1)<br/>    plt.imshow(img_aug)<br/>    plt.axis('off')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/f4a0a492284377103de68713f493c888.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0rPDyBXnRKBzpR54Vzrdw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 6–9 应用于同一张图像的随机变换(图片由作者提供)</p></figure><p id="d5fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有些有意义，有些没有意义——但图像本身并不难分类。接下来，我们来看看如何用 TensorFlow 的<code class="fe on oo op nw b">ImageDataGenerator</code>处理数据增强。</p><h1 id="0aa2" class="me mf it bd mg mh oh mj mk ml oi mn mo jz oj ka mq kc ok kd ms kf ol kg mu mv bi translated">使用 TensorFlow 的 ImageDataGenerator 进行数据扩充</h1><p id="4bad" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">您现在知道了单个转换对图像的影响，但是将数据扩充作为单独的<code class="fe on oo op nw b">Sequential</code>模型来编写并不常见。通常情况下，您会在用 TensorFlow 的<code class="fe on oo op nw b">ImageDataGenerator</code>类加载图像数据时应用这些变换。</p><p id="bfed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">记住</strong> —你应该只增加训练数据。</p><p id="4f10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以这种方式进行数据扩充更容易。下面的代码段对定型集应用了重缩放、旋转、平移、剪切、缩放和水平翻转，并且只对验证集进行了重缩放。<code class="fe on oo op nw b">fill_mode</code>参数告诉 TensorFlow 如何处理图像边界外的点，这些点是某些变换的副作用。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="cf56" class="oa mf it nw b gy ob oc l od oe">train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>    rescale=1/255.0,<br/>    rotation_range=20,<br/>    width_shift_range=0.2,<br/>    height_shift_range=0.2,<br/>    shear_range=0.2,<br/>    zoom_range=0.2,<br/>    horizontal_flip=True,<br/>    fill_mode='nearest'<br/>)</span><span id="69b2" class="oa mf it nw b gy of oc l od oe">valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>    rescale=1/255.0<br/>)</span></pre><p id="68f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们怎么知道这是否有效？简单地说——我们将可视化一批图像。首先，我们必须调用<code class="fe on oo op nw b">flow_from_directory()</code>函数来指定批量大小，以及其他参数:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="9fc6" class="oa mf it nw b gy ob oc l od oe">train_data = train_datagen.flow_from_directory(<br/>    directory='data/train/',<br/>    target_size=(224, 224),<br/>    class_mode='categorical',<br/>    batch_size=64,<br/>    seed=42<br/>)</span></pre><p id="ab1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe on oo op nw b">train_data</code>现在是一个 Python 生成器对象，所以对它调用<code class="fe on oo op nw b">next()</code>会返回第一批。下面是如何提取它并打印出其元素的形状:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="c467" class="oa mf it nw b gy ob oc l od oe">first_batch = train_data.next()<br/>first_batch[0].shape, first_batch[1].shape</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/613f1b7196068f2547eebe09c6b6c722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*hFHQBPhwzMtsVGYzJ5EFYA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 7——第一批的形状(图片由作者提供)</p></figure><p id="87c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，我们有 64 个图像，每个图像宽 224 像素，高 224 像素，有 3 个颜色通道。第二个元素代表标签。我们有 64 个这样的独热编码格式(猫= [1，0]，狗= [0，1])。</p><p id="1152" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用以下函数在 8x8 网格中可视化一批 64 个图像:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="a1c4" class="oa mf it nw b gy ob oc l od oe">def visualize_batch(batch):<br/>    n = 64<br/>    num_row, num_col = 8, 8<br/>    fig, axes = plt.subplots(num_row, num_col, figsize=(3 * num_col, 3 * num_row))<br/>    <br/>    for i in range(n):<br/>        img = np.array(batch[0][i] * 255, dtype='uint8')<br/>        ax = axes[i // num_col, i % num_col]<br/>        ax.imshow(img)<br/>        <br/>    plt.tight_layout()<br/>    plt.show()<br/></span><span id="9c5a" class="oa mf it nw b gy of oc l od oe">visualize_batch(batch=first_batch)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/fd664193f923d62173a4f9e0a7132971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kb5PqV6Hny1DLnCL-kmDiQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片 8 —一批 64 张图片(图片由作者提供)</p></figure><p id="1b3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们肯定有一些奇怪的问题，但总的来说，数据扩充通过增加我们数据集的多样性做了一件体面的工作。最后一步，我们将加载训练和验证图像:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="630d" class="oa mf it nw b gy ob oc l od oe">train_data = train_datagen.flow_from_directory(<br/>    directory='data/train/',<br/>    target_size=(224, 224),<br/>    class_mode='categorical',<br/>    batch_size=64,<br/>    seed=42<br/>)</span><span id="b03f" class="oa mf it nw b gy of oc l od oe">valid_data = valid_datagen.flow_from_directory(<br/>    directory='data/validation/',<br/>    target_size=(224, 224),<br/>    class_mode='categorical',<br/>    batch_size=64,<br/>    seed=42<br/>)</span></pre><p id="b389" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们训练模型所需要的。手指交叉它胜过<a class="ae ky" href="https://betterdatascience.com/train-image-classifier-with-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">以前的一个</a>！</p><h1 id="7d4a" class="me mf it bd mg mh oh mj mk ml oi mn mo jz oj ka mq kc ok kd ms kf ol kg mu mv bi translated">模型训练-使用 TensorFlow 进行数据增强能否提高准确性？</h1><p id="6f13" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我们将使用与第一次用卷积网络训练一个<a class="ae ky" href="https://betterdatascience.com/train-image-classifier-with-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">图像分类器</a>时相同的模型架构。它在验证集上达到了大约 75%的准确率。数据扩充应该有望把事情提高一个档次。</p><p id="93d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是模型训练代码，它有两个卷积/池模块，后面是一个密集层和一个输出层:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="73f2" class="oa mf it nw b gy ob oc l od oe">model = tf.keras.Sequential([<br/>    layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),<br/>    layers.MaxPool2D(pool_size=(2, 2), padding='same'),<br/>    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),<br/>    layers.MaxPool2D(pool_size=(2, 2), padding='same'),<br/>    layers.Flatten(),<br/>    layers.Dense(128, activation='relu'),<br/>    layers.Dense(2, activation='softmax')<br/>])</span><span id="9cfd" class="oa mf it nw b gy of oc l od oe">model.compile(<br/>    loss=tf.keras.losses.categorical_crossentropy,<br/>    optimizer=tf.keras.optimizers.Adam(),<br/>    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]<br/>)</span><span id="0f61" class="oa mf it nw b gy of oc l od oe">history = model.fit(<br/>    train_data,<br/>    validation_data=valid_data,<br/>    epochs=10<br/>)</span></pre><p id="7eba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意</strong>:我正面临一些 GPU 问题，所以模型是在 CPU 上训练的，因此训练时间很长。我的 RTX 3060Ti 通常在 22 秒内完成一个纪元。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/b3e7c13dbcd6d05d9d98099072f3b19b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kMfGjmqz6AeEaRgGVGJGAg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 9-模型训练结果(图片由作者提供)</p></figure><p id="c101" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据增强将验证准确性提高了近 3%!这无疑是朝着正确方向迈出的一步，但我们可以进一步改进。怎么会？用<strong class="lb iu">转移学习</strong>。您将在接下来的文章中了解到所有相关内容。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="4da6" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="eef0" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">这就是你要做的——如何轻松地从你的模型中获得额外的百分之几的准确度。在构建图像分类器时，数据扩充是一个强大的工具，但要小心使用。如果垂直翻转图像没有意义，就不要这样做。例如，水平和垂直翻转交通标志不会帮助您进行分类。这些通常是从上到下，从左到右读的。这同样适用于任何其他转型。</p><p id="4e54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我对即将发布的迁移学习文章感到兴奋，因为它是用有限的数据构建高精度模型的首选方法。敬请关注，了解所有相关信息！</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="ef8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nu">喜欢这篇文章吗？成为</em> <a class="ae ky" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="nu">中等会员</em> </a> <em class="nu">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="nc nd gp gr ne nf"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd iu gy z fp nk fr fs nl fu fw is bi translated">通过我的推荐链接加入 Medium-Dario rade ci</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">medium.com</p></div></div><div class="no l"><div class="ou l nq nr ns no nt ks nf"/></div></div></a></div></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="5c8d" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">保持联系</h1><ul class=""><li id="d1df" class="ov ow it lb b lc mw lf mx li ox lm oy lq oz lu pa pb pc pd bi translated">注册我的<a class="ae ky" href="https://mailchi.mp/46a3d2989d9b/bdssubscribe" rel="noopener ugc nofollow" target="_blank">简讯</a></li><li id="5aaa" class="ov ow it lb b lc pe lf pf li pg lm ph lq pi lu pa pb pc pd bi translated">订阅<a class="ae ky" href="https://www.youtube.com/c/BetterDataScience" rel="noopener ugc nofollow" target="_blank"> YouTube </a></li><li id="3e5e" class="ov ow it lb b lc pe lf pf li pg lm ph lq pi lu pa pb pc pd bi translated">在<a class="ae ky" href="https://www.linkedin.com/in/darioradecic/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上连接</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="f308" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nu">原载于 2021 年 12 月 16 日 https://betterdatascience.com</em><em class="nu">的</em> <a class="ae ky" href="https://betterdatascience.com/tensorflow-for-computer-vision-how-to-increase-model-accuracy-with-data-augmentation/" rel="noopener ugc nofollow" target="_blank"> <em class="nu">。</em></a></p></div></div>    
</body>
</html>