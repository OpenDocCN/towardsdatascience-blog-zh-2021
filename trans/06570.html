<html>
<head>
<title>Real-time Object Detection on CPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CPU上的实时目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-object-detection-on-cpu-9f77d32deeaf?source=collection_archive---------12-----------------------#2021-06-13">https://towardsdatascience.com/real-time-object-detection-on-cpu-9f77d32deeaf?source=collection_archive---------12-----------------------#2021-06-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7d28" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">利用OpenVino在CPU上实现实时目标检测。听起来很神奇，对吧？好吧，让我们真的去相信它。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/82e4ed46873e86bdf238ead1efab360a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Xku8uqY22j1us7kO"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">Marc-Olivier Jodoin 在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="bf85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一次有人问我是否有可能在CPU上进行实时物体检测，我对这个问题不屑一顾，心想:“一定是在开玩笑吧？”。</p><p id="7a09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">嗯，有可能！我试着去相信它。我们将介绍在CPU上以40帧/秒的速度实现对象检测。</p><p id="cb5d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我建议你读一点以下术语的意思，然后继续学习教程。你仍然可以在不理解这些术语的情况下，仅仅通过盲目地复制教程来完成，但这有什么乐趣呢，不是吗？</p><ul class=""><li id="704f" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lh li lj lk bi translated"><a class="ae lb" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank"> ONNX </a></li><li id="e84c" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated"><a class="ae lb" href="https://docs.openvinotoolkit.org/latest/index.html" rel="noopener ugc nofollow" target="_blank"> OpenVINO </a></li><li id="42c9" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated"><a class="ae lb" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank">暗网</a></li></ul><p id="40c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇博客假设你对上述术语的含义有所了解，并对深度学习和物体检测有一个大致的了解。我们将使用<strong class="jp ir"> yolov3-tiny </strong>使用darknet进行对象检测。让我们开始吧！</p><p id="a112" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们需要预先训练好的<strong class="jp ir">yolov 3-小权重</strong>，它可以从<a class="ae lb" href="https://pjreddie.com/media/files/yolov3-tiny.weights" rel="noopener ugc nofollow" target="_blank">这里</a>下载，它的<strong class="jp ir">配置文件</strong>可以从<a class="ae lb" href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg" rel="noopener ugc nofollow" target="_blank">这里</a>复制。</p><p id="4292" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来的步骤是将预训练的权重转换为onnx，然后转换为OpenVINO的IR格式，这是OpenVINO进行推理所需的xml、bin和映射文件。我们将通过4个连续的步骤来完成这项工作。</p><ol class=""><li id="7dee" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lq li lj lk bi translated">将YOLO重量转换为ONNX</li><li id="c20f" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lq li lj lk bi translated">使用Netron查找输出图层的名称</li><li id="6c73" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lq li lj lk bi translated">将ONNX转换为IR格式</li><li id="10b1" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lq li lj lk bi translated">使用OpenVINO运行推理</li></ol><h2 id="9206" class="lr ls iq bd lt lu lv dn lw lx ly dp lz jy ma mb mc kc md me mf kg mg mh mi mj bi translated">步骤1:将YOLO重量转换为ONNX</h2><p id="7e89" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">我将使用jkjung-avt的tensorrt_demos 库将yolo权重转换为onnx。这是我的个人偏好，因为我以前曾用它进行TensorRT转换。有许多其他存储库可以做同样的事情。我们将按照自述文件中提到的步骤将yolov3-tiny weights转换为onnx。我们开始吧！</p><pre class="km kn ko kp gt mp mq mr ms aw mt bi"><span id="4c08" class="lr ls iq mq b gy mu mv l mw mx">$ git clone <a class="ae lb" href="https://github.com/jkjung-avt/tensorrt_demos.git" rel="noopener ugc nofollow" target="_blank">https://github.com/jkjung-avt/tensorrt_demos.git</a></span><span id="db18" class="lr ls iq mq b gy my mv l mw mx">$ pip3 install onnx==1.4.1</span><span id="aab4" class="lr ls iq mq b gy my mv l mw mx">$ cd tensorrt_demos/yolo/</span></pre><p id="2bc8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将权重文件和cfg文件复制到这个目录，即tensorrt_demos存储库中的yolo目录。</p><ol class=""><li id="27b6" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lq li lj lk bi translated">将权重文件重命名为<strong class="jp ir"> yolov3-tiny-416.weights </strong></li><li id="f341" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lq li lj lk bi translated">将cfg文件重命名为<strong class="jp ir"> yolov3-tiny-416.cfg </strong></li><li id="6e69" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lq li lj lk bi translated">用这里给出的类名<a class="ae lb" href="https://github.com/pjreddie/darknet/blob/master/data/coco.names" rel="noopener ugc nofollow" target="_blank">创建一个名为<strong class="jp ir"> labels.txt </strong>的新文件。</a></li></ol><p id="fb7d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些步骤是必要的，因为存储库需要它们来为特定的模型和输入大小进行转换。</p><p id="41de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:我们使用416x416尺寸作为输入。如果您有自定义尺寸，可以对其进行修改。</strong></p><p id="d716" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">移动并重命名文件后，让我们运行脚本来进行实际的转换。</p><pre class="km kn ko kp gt mp mq mr ms aw mt bi"><span id="592b" class="lr ls iq mq b gy mu mv l mw mx">$ python3 yolo_to_onnx.py -m yolov3-tiny-416</span></pre><p id="3266" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将创建一个名为<strong class="jp ir"> yolov3-tiny-416.onnx. </strong>的输出文件。让我们执行下一步，找到需要转换为IR格式的模型输出层的名称。为了找到输出层的名称，我们将使用<a class="ae lb" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> netron </strong> </a>来帮助可视化模型图/架构。</p><h2 id="c0d1" class="lr ls iq bd lt lu lv dn lw lx ly dp lz jy ma mb mc kc md me mf kg mg mh mi mj bi translated">步骤2:使用Netron查找输出层的名称</h2><pre class="km kn ko kp gt mp mq mr ms aw mt bi"><span id="4f51" class="lr ls iq mq b gy mu mv l mw mx">$ pip3 install netron</span><span id="d469" class="lr ls iq mq b gy my mv l mw mx">$ netron<br/>Serving at <a class="ae lb" href="http://localhost:8080" rel="noopener ugc nofollow" target="_blank">http://localhost:8080</a></span></pre><p id="083e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">打开链接并上传onnx文件。它将显示如下所示的模型架构。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mz"><img src="../Images/ec97e8d065eee2174becf9a11f07816e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*28AO_Apa_8Z7sb5qxh5dvA.png"/></div></div></figure><p id="eb83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">向下滚动架构到输出节点并点击它。右侧将出现一个详细信息框，显示输出节点名称，如下所示。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mz"><img src="../Images/1b11d341f995dbbf50cbe0cdef6d790d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dbsKxuHfI_JLwn1ckCDiCQ.png"/></div></div></figure><p id="dfb7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">复制输出节点名称。我们需要名字来将onnx文件转换成IR格式。节点名称为:<code class="fe na nb nc mq b">016_convolutional,023_convolutional</code></p><h2 id="742a" class="lr ls iq bd lt lu lv dn lw lx ly dp lz jy ma mb mc kc md me mf kg mg mh mi mj bi translated">步骤3:将ONNX转换为IR格式</h2><p id="7921" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">我们需要设置OpenVINO及其依赖项来使用它。使用此<a class="ae lb" href="https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_linux.html" rel="noopener ugc nofollow" target="_blank">连杆</a>安装<strong class="jp ir"> OpenVINO 2021.1.110 </strong>。</p><p id="315f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:安装开发版本，而不是运行版本，因为它不包括模型转换脚本。</strong></p><p id="8123" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:我建议使用虚拟环境来安装这些包，因为它很容易管理依赖关系。</p><p id="3fe4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可能已经安装了这些软件包，但是如果您还没有安装，请使用pip安装下面给出的软件包。</p><pre class="km kn ko kp gt mp mq mr ms aw mt bi"><span id="0a2d" class="lr ls iq mq b gy mu mv l mw mx">$ cd /opt/intel/openvino_2021/python</span><span id="5e38" class="lr ls iq mq b gy my mv l mw mx">$ source /opt/intel/openvino_2021/bin/setupvars.sh</span><span id="9923" class="lr ls iq mq b gy my mv l mw mx">$ pip3 install networkx defusedxml test-generator==0.1.1</span><span id="7f45" class="lr ls iq mq b gy my mv l mw mx">$ cd /opt/intel/openvino_2021.1.110/deployment_tools/model_optimizer/install_prerequisites/</span><span id="3b91" class="lr ls iq mq b gy my mv l mw mx">$ ./install_prerequisites_onnx.sh</span></pre><p id="8d50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，设置和安装完成后，让我们运行脚本将ONNX文件转换为IR格式。用本地路径替换<code class="fe na nb nc mq b">model_dir</code>和<code class="fe na nb nc mq b">output_dir</code>。</p><pre class="km kn ko kp gt mp mq mr ms aw mt bi"><span id="5eba" class="lr ls iq mq b gy mu mv l mw mx">$ python3 /opt/intel/openvino_2021.1.110/deployment_tools/model_optimizer/mo.py --input_model /<strong class="mq ir">path_to_model_dir</strong>/yolov3-tiny-416.onnx -s 255 --reverse_input_channels --output 016_convolutional,023_convolutional --output_dir /<strong class="mq ir">path_to_output_dir</strong>/</span></pre><p id="a608" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将输出3个文件，即。绑定文件、xml文件和映射文件。这些文件是OpenVINO推理的中间表示。</p><h2 id="1a6f" class="lr ls iq bd lt lu lv dn lw lx ly dp lz jy ma mb mc kc md me mf kg mg mh mi mj bi translated">步骤4:使用OpenVINO运行推理</h2><p id="547b" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">随着所有的转换最终完成，让我们在我们的网络摄像头或图像上运行一个演示，以检查推理速度。</p><pre class="km kn ko kp gt mp mq mr ms aw mt bi"><span id="11c3" class="lr ls iq mq b gy mu mv l mw mx">$ git clone <a class="ae lb" href="https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo.git" rel="noopener ugc nofollow" target="_blank">https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo.git</a></span><span id="158e" class="lr ls iq mq b gy my mv l mw mx"><strong class="mq ir"># activate environment that you used to install the above packages before running below commands.</strong></span><span id="ffd8" class="lr ls iq mq b gy my mv l mw mx">$ cd /opt/intel/openvino_2021/python</span><span id="8ed3" class="lr ls iq mq b gy my mv l mw mx">$ source /opt/intel/openvino_2021/bin/setupvars.sh</span><span id="4329" class="lr ls iq mq b gy my mv l mw mx">$ cd /<strong class="mq ir">path_to_cloned_repository</strong>/pytorch_YOLO_OpenVINO_demo</span><span id="3be7" class="lr ls iq mq b gy my mv l mw mx">$ python3 yolo_openvino_demo.py -m /<strong class="mq ir">path_to_model_directory</strong>/yolov3-tiny-416.xml -i 'cam' -at yolov3 --labels /<strong class="mq ir">path_to_labels</strong>/labels.txt</span></pre><p id="2e92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你会看到比实时推断更快的输出视频。</p><p id="d198" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您没有网络摄像头，请使用下面的命令在视频上尝试一下。</p><pre class="km kn ko kp gt mp mq mr ms aw mt bi"><span id="e82b" class="lr ls iq mq b gy mu mv l mw mx">$ python3 yolo__openvino_demo.py -m /<strong class="mq ir">path_to_model_directory</strong>/yolov3-tiny-416.xml -i /<strong class="mq ir">path_to_video_dir</strong>/video.mp4 -at yolov3 --labels /<strong class="mq ir">path_to_labels</strong>/labels.txt</span></pre><p id="f76f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经成功地将yolov3-tiny转换为在CPU上进行实时推理。嗯，我会说40 FPS几乎是实时的两倍。如果我需要阐述任何观点或需要任何更正，请评论下来。</p><h2 id="772e" class="lr ls iq bd lt lu lv dn lw lx ly dp lz jy ma mb mc kc md me mf kg mg mh mi mj bi translated">参考</h2><div class="nd ne gp gr nf ng"><a href="https://pjreddie.com/darknet/yolo/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">YOLO:实时目标检测</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">你只看一次(YOLO)是一个最先进的，实时对象检测系统。在Pascal Titan X上，它处理…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">pjreddie.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu kv ng"/></div></div></a></div><div class="nd ne gp gr nf ng"><a href="https://onnx.ai/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">ONNX |主页</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">在您喜欢的框架中开发，而不用担心下游推理的影响。ONNX使您能够使用…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">onnx.ai</p></div></div></div></a></div><div class="nd ne gp gr nf ng"><a href="https://docs.openvinotoolkit.org/latest/index.html" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">OpenVINO工具包概述- OpenVINO工具包</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">open vino toolkit是一个全面的工具包，用于快速开发应用程序和解决方案，解决各种…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">docs.openvinotoolkit.org</p></div></div><div class="np l"><div class="nv l nr ns nt np nu kv ng"/></div></div></a></div><div class="nd ne gp gr nf ng"><a href="https://github.com/jkjung-avt/tensorrt_demos" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">jkjung-avt/tensorrt_demos</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">演示如何使用TensorRT优化Caffe/tensor flow/DarkNet/py torch模型并在NVIDIA上进行推理的示例…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">github.com</p></div></div><div class="np l"><div class="nw l nr ns nt np nu kv ng"/></div></div></a></div><div class="nd ne gp gr nf ng"><a href="https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">陈明昌/pytorch_YOLO_OpenVINO_demo</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">用于OpenVINO推理的Pytorch YOLO模型(YOLO-V3 / YOLO-V4 /缩放-YOLO-V4 / YOLO-V5)的集成。Windows 10…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">github.com</p></div></div><div class="np l"><div class="nx l nr ns nt np nu kv ng"/></div></div></a></div><div class="nd ne gp gr nf ng"><a href="https://github.com/lutzroeder/netron" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd ir gy z fp nl fr fs nm fu fw ip bi translated">lutzroeder/netron</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">Netron是神经网络、深度学习和机器学习模型的查看器。Linux:下载。AppImage文件或…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">github.com</p></div></div><div class="np l"><div class="ny l nr ns nt np nu kv ng"/></div></div></a></div></div></div>    
</body>
</html>