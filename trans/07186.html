<html>
<head>
<title>GANs from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gans-from-scratch-19e917edf3ea?source=collection_archive---------31-----------------------#2021-06-29">https://towardsdatascience.com/gans-from-scratch-19e917edf3ea?source=collection_archive---------31-----------------------#2021-06-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="af77" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">决斗神经网络</h2></div><p id="79bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">神经网络不仅限于学习数据；他们也可以学习创造它。其中一篇经典的机器学习论文是伊恩·j·古德费勒(Ian J. Goodfellow)、让·普盖-阿巴迪(Jean Pouget-Abadie)、迈赫迪·米尔扎(Mehdi Mirza)等人撰写的<a class="ae lb" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> <em class="lc">生成对抗网络</em> </a> (GANs) (2014)。gan采用两个对立的神经网络的形式，一个学习生成假样本，而另一个试图将真样本与假样本分开。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/28209922a3226806fc5165f991843b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lhcftRt9l_FuaiE7"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">VQGAN根据来自Flickr的数据训练生成的风景。这些图像都不是真实的。<a class="ae lb" href="https://compvis.github.io/taming-transformers/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="8af9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">复杂的GAN模型，如VQGAN和其他模型，可以生成任何东西，包括假的风景、人脸，甚至是<a class="ae lb" href="https://arxiv.org/abs/2106.10155v1" rel="noopener ugc nofollow" target="_blank">《我的世界》</a>世界。</p><p id="9859" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些是我对第一次介绍GANs的经典论文的笔记。</p><h1 id="9d2f" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">设置</h1><p id="852d" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">gan基本上是由两个神经网络模型组成的两部分二元分类问题。第一个被称为<strong class="kh ir">生成器</strong>的模型接受仅由噪声组成的输入，并创建与它正在学习伪造的数据形状相同的输出。另一个模型是<strong class="kh ir">鉴别器</strong>，它接受真实和生成的输入，并输出数据是真实还是虚假的预测。</p><h1 id="bb1d" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">失败</h1><p id="25f2" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">理解生成器和鉴别器之间博弈的关键是价值函数和<strong class="kh ir">二进制交叉熵</strong> (BCE)损失之间的联系。</p><p id="c10e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">论文中的等式解释了两者的目标。暂时忽略最小值/最大值部分，等式的其余部分描述了<strong class="kh ir">值函数、</strong> <em class="lc"> V(D，G) </em>。值函数是鉴频器输出的对数的期望值，<em class="lc"> D(x) </em>，其中<em class="lc"> x </em>取自真实数据加上对数的期望值1减去作用于所产生输出的鉴频器输出，<em class="lc"> D(G(z)) </em>，其中发生器的输入，<em class="lc"> z </em>取自噪声。</p><p id="51ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，再次查看最小值/最大值部分，生成器的目标是最小化值函数，而鉴别器的目标是最大化值函数。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mq"><img src="../Images/2c4ca4ea104c0fb1450afe364d8cbb1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fMkwZre-ije6MKcT"/></div></div></figure><p id="5877" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是价值函数和BCE有什么关系呢？下面是BCE损失的等式，其中<em class="lc"> y </em>是真实标签，ŷ是模型预测。因此，如果真数据的标签是1，假数据的标签是0，则价值函数变成假数据损失的总和(<em class="lc"> y=0 </em>和<em class="lc">ŷ=d(g(z)</em>)和真数据损失的总和(<em class="lc"> y=1 </em>和<em class="lc"> ŷ=D(x) </em>)。等式的一半抵消了每次损失。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/f44e1ed0717aa78ef66133137d8e61e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/0*vyJ0abIuQBOYRSSj"/></div></figure><p id="40c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于最小值/最大值约定，减号消失。下面绘制的价值函数说明了这一点。生成器的目标是让鉴别器将假数据误分类为真实数据，将真实数据误分类为假数据，对应于下面蓝色和金色曲线的低(最小)值。鉴别器的目标是正确地对每一个样本进行分类，这两个样本在两条曲线上都具有零值函数(最大值)。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/491d4ae299fbf9752bcc7519306db257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/0*YTvIiZg7GXklf6X9"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">GAN值函数，发生器工作以最小化这些曲线上的值，而鉴别器试图最大化它们</p></figure><h1 id="ec90" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">培养</h1><p id="e512" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">这两个模型一起训练。下面的代码展示了TensorFlow中的一个例子。首先，通过绘制一批噪声和一批真实数据来训练鉴别器。鉴频器损耗如前所述进行计算，并更新其权重。接下来，通过绘制另一批随机噪声并使其通过生成器来训练生成器。鉴别器对生成的数据进行分类，并根据生成器欺骗鉴别器的程度对其进行评分。基于该梯度更新发生器权重，并且重复该过程。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5c42" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着两个模型的训练，生成数据的分布(绿线)变得看起来像真实数据的分布(黑色虚线),直到鉴别器预测(蓝色虚线)不再能够区分，并预测真实和虚假输入的概率为50%。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mv"><img src="../Images/71d0b655c4f090715cd2dc5fb1de65cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F_FX2dgCDf66gxQl"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">变速发电机输出分配和分类(<a class="ae lb" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="d851" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是在不同训练阶段的一些生成器输出示例。我使用MNIST数数据集来构建GAN。随着时间的推移，随着生成器开始产生看起来像训练集的图像，鉴别器对其预测哪个样本是真的哪个样本是假的越来越没有信心。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mw"><img src="../Images/de8bac1cd736e2b69a153242c0e05754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FczylOm8TIwRr0MLkJLbJw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">不同时期的发电机输出</p></figure><p id="fa96" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">甘人很难训练。例如，在这个使用来自MNIST的单个示例的测试案例中，生成器在几百个步骤之后很快学会了复制示例5。然而，随着训练的继续，发电机输出迅速偏离。发电机也可以发散回学习率过高的噪声。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mx"><img src="../Images/7b5a9266667fe0a44e0f070967c25516.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6FkzhvpmraktxqjZALi4Q.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">不良培训设置导致的示例。发电机培训出现分歧。</p></figure><p id="ebd3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">管理两个网络之间的平衡也很困难。如果鉴别器太好，可能会导致训练问题，因此可能需要调整训练设置中的参数。</p><p id="b597" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最先进的GANs在生成现实内容方面非常强大，可以用于善意和恶意。希望这些笔记有助于理解它们的基本工作原理。</p><p id="fdaa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在这里找到我用来学习甘斯<a class="ae lb" href="https://github.com/tims457/ml_notebooks/blob/main/gans/gans.ipynb" rel="noopener ugc nofollow" target="_blank">的笔记本</a>。</p><h1 id="13a2" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">参考</h1><ul class=""><li id="bf93" class="my mz iq kh b ki ml kl mm ko na ks nb kw nc la nd ne nf ng bi translated"><a class="ae lb" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">甘纸</a></li><li id="4c50" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated"><a class="ae lb" href="https://www.youtube.com/watch?v=Z6rxFNMGdn0" rel="noopener ugc nofollow" target="_blank">伊恩·古德菲勒谈莱克斯·弗里德曼</a></li></ul></div></div>    
</body>
</html>