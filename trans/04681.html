<html>
<head>
<title>1,001 terms for improving AI won’t get us anywhere</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">1001条提高人工智能的条款不会让我们有任何进展</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/1-001-terms-for-improving-ai-wont-get-us-anywhere-8d0e433405bb?source=collection_archive---------28-----------------------#2021-04-22">https://towardsdatascience.com/1-001-terms-for-improving-ai-wont-get-us-anywhere-8d0e433405bb?source=collection_archive---------28-----------------------#2021-04-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ab9a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">应对人工智能挑战的竞争性定义概述</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/64c1e731f4a110f0d478ed3cd3bab92b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yk2Ld5b9OrL-6aVfaFaUBA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">格雷格·拉科齐在<a class="ae ky" href="https://unsplash.com/s/photos/meditation?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片。作者的修改。</p></figure><p id="d12d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有很多人在努力让人工智能和机器学习变得不那么糟糕。事实上，今年早些时候，我加入了一家初创公司，该公司希望帮助人们与人工智能建立更深层次的联系，为他们提供一种更直接的方式来控制算法能为他们做什么。我们称它为“<a class="ae ky" href="https://financialpost.com/technology/empathetic-ai-element-ai-co-founder-launching-new-platform-to-deliver-curated-online-content" rel="noopener ugc nofollow" target="_blank">移情人工智能</a>”。当我们试图给这个新术语赋予意义时，我开始好奇其他团体是如何称呼他们自己提出的算法解决方案的，这些算法对我们有利而不是不利。以下是我发现的概述。</p><h1 id="bcb9" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">移情人工智能</h1><p id="3478" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于我们Waverly来说，同理心是指让用户控制他们的算法，并帮助他们实现自己的愿望。我只找到了一家公司使用相同术语的另一个例子，但方式不同。2019年，Pega使用了术语<a class="ae ky" href="https://www.pega.com/insights/articles/potential-empathetic-ai" rel="noopener ugc nofollow" target="_blank">同理心AI </a>来销售其客户同理心顾问(Customer Empathy Advisor)解决方案，该解决方案可以帮助企业在提供销售报价之前收集客户输入。这与电子商务网站基于用户行为进行推荐的传统方法形成了对比。</p><p id="ea4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管Waverly和Pega都认为同理心是倾听人们，而不是基于大数据集主动推荐结果，但他们方法的关键区别是谁与人工智能交互。在Waverly，我们开发的工具旨在供用户直接使用，而Pega则为企业提供工具，为用户创建和调整推荐。</p><p id="9c3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> N.B .同理心AI不应该与</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/Artificial_empathy" rel="noopener ugc nofollow" target="_blank"> <em class="lv">人工同理心(AE) </em> </a> <em class="lv">混淆，人工同理心是一种旨在检测和响应人类情绪的技术，最常用于机器人和虚拟助手等系统中。今天这方面的实际例子并不多，但一些值得注意的尝试是具有有限模拟情感范围的机器人宠物，如</em> <a class="ae ky" href="https://www.pleoworld.com/pleo_rb/eng/index.php" rel="noopener ugc nofollow" target="_blank"> <em class="lv"> Pleo </em> </a> <em class="lv">、</em> <a class="ae ky" href="https://us.aibo.com" rel="noopener ugc nofollow" target="_blank"> <em class="lv">艾博</em> </a> <em class="lv">和</em><a class="ae ky" href="https://www.digitaldreamlabs.com/pages/cozmo" rel="noopener ugc nofollow" target="_blank"><em class="lv">Cozmo</em></a><em class="lv">。在软件方面，有人试图根据你的</em> <a class="ae ky" href="https://www.typingdna.com/focus" rel="noopener ugc nofollow" target="_blank"> <em class="lv">打字行为</em> </a> <em class="lv">或</em> <a class="ae ky" href="https://www.bloomberg.com/news/newsletters/2020-08-31/amazon-s-halo-wearable-can-read-emotions-is-that-too-weird" rel="noopener ugc nofollow" target="_blank"> <em class="lv">语调</em> </a> <em class="lv">等信号来推断人类的情绪。</em></p><h1 id="055a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">负责任的AI</h1><p id="8ead" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是投入巨资改善人工智能技术的大型组织最常用的术语。埃森哲、<a class="ae ky" href="https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6" rel="noopener ugc nofollow" target="_blank">微软</a>、<a class="ae ky" href="https://ai.google/responsibilities/responsible-ai-practices/" rel="noopener ugc nofollow" target="_blank">谷歌</a>和<a class="ae ky" href="https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html" rel="noopener ugc nofollow" target="_blank">普华永道</a>都有他们定义的负责任人工智能的某种框架或原则。(有趣的是，谷歌对这个术语的解释在他们自己的搜索引擎上排在第三位。)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mt"><img src="../Images/a276324c838063aafee629c516d0a9aa.png" data-original-src="https://miro.medium.com/v2/format:webp/1*sgJWAJFJMJY7RDiHtsqtwg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者截图</p></figure><p id="8030" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是这些公司如何诠释负责任的人工智能概念的概述:</p><ul class=""><li id="937a" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">埃森哲:在人工智能解决方案中建立信任的框架。这是为了帮助防止使用有偏见的数据和算法，确保自动化决策是合理的和可解释的，并帮助维护用户信任和个人隐私。</li><li id="f3f4" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu">微软</strong>:以人为本的道德原则，包括公平、可靠&amp;安全、隐私&amp;安全、包容、透明和责任。</li><li id="e332" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu">谷歌</strong>:在公平、可解释、隐私和安全的原则下，指导人工智能在研究和产品中的开发和使用的道德宪章。</li><li id="8884" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu">普华永道</strong>:一个解决责任五个维度(治理、可解释性&amp;可解释性、偏见&amp;公平性、稳健性&amp;安全性、道德规范&amp;监管)的工具包。</li></ul><p id="199f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然很难从每家公司提取一个简明的定义，但结合他们在人工智能中谈论“责任”时使用的不同术语，可以让我们了解这些公司关心什么——或者至少是他们认为可以卖给客户的东西。</p><h1 id="5e68" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">人工智能公平</h1><p id="78b3" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">你可能已经注意到，公平作为负责任的人工智能的子集反复出现，但是IBM有最大的资源专门用于这个概念，他们有<a class="ae ky" href="https://aif360.mybluemix.net" rel="noopener ugc nofollow" target="_blank">人工智能公平360 </a>开源工具包。公平的定义通常是指避免系统和数据集中不必要的偏差。</p><p id="b0df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">鉴于公众越来越关注与偏见和包容性相关的系统性问题，公平是创造更好的人工智能最相关的概念之一也就不足为奇了。尽管对这个术语的理解似乎很广泛，但围绕公平的影响仍有很多必要的对话。最近一篇关于HBR的文章试图证明公平不仅仅是道德的；这也将使公司更有利可图，生产率更高。为了更好地了解人工智能编程中最微小的决定如何能够在社会中引起巨大的涟漪，请查看Nicky Case的精彩互动演示<a class="ae ky" href="https://ncase.me/polygons/" rel="noopener ugc nofollow" target="_blank">多边形的寓言</a>。</p><h1 id="1f61" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">值得信赖的人工智能</h1><p id="8c18" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">2018年，欧盟组建了一个关于人工智能的高级别专家组，通过四个交付品为其人工智能战略提供建议。2019年4月，欧盟公布了第一个可交付成果，即一套<a class="ae ky" href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai" rel="noopener ugc nofollow" target="_blank">可信人工智能</a>的道德准则，该准则声称这项技术应该:</p><ol class=""><li id="2a8c" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu ni na nb nc bi translated">合法——遵守所有适用的法律法规</li><li id="8f6f" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu ni na nb nc bi translated">道德——尊重道德原则和价值观</li><li id="ed83" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu ni na nb nc bi translated">稳健——既从技术角度出发，又考虑到其社会环境</li></ol><p id="7ab9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该指导方针进一步细分为7个关键要求，涵盖了机构、透明度和隐私等主题。</p><p id="8c68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几乎整整一年后，德勤发布了商标为 <a class="ae ky" href="https://www2.deloitte.com/us/en/pages/deloitte-analytics/solutions/ethics-of-ai-framework.html" rel="noopener ugc nofollow" target="_blank">的<em class="lv">可信人工智能框架</em></a>。令人失望的是，他们甚至没有提及欧盟在声称对该术语拥有所有权之前所做的大量工作。然后他们重新利用它来创造他们自己的六个维度，看起来很像其他人所说的负责任的人工智能。对他们来说，Trustworthy AI公平公正、透明可解释、负责任、稳健可靠、尊重隐私、安全可靠。该框架甚至附带了一个图表，可以轻松添加到任何高管的PowerPoint演示文稿中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mt"><img src="../Images/ba7d5f9daa6a3c1deac1eefd009d7445.png" data-original-src="https://miro.medium.com/v2/format:webp/1*At2SlcECtGmzJwwfVkhYJQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://www2.deloitte.com/us/en/pages/deloitte-analytics/solutions/ethics-of-ai-framework.html" rel="noopener ugc nofollow" target="_blank">德勤</a></p></figure><p id="3318" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，在2020年末，Mozilla发布了他们关于<a class="ae ky" href="https://foundation.mozilla.org/en/insights/trustworthy-ai-whitepaper/" rel="noopener ugc nofollow" target="_blank">可信人工智能</a>的白皮书，其中有他们自己的定义。</p><blockquote class="nj nk nl"><p id="cbeb" class="kz la lv lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated">Mozilla将可信赖的人工智能定义为明显值得信任的人工智能，考虑责任、代理以及个人和集体福祉的技术。</p></blockquote><p id="1d0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管他们承认这是欧盟在可信度方面工作的延伸，但与EU-建立的对可信人工智能的理解的偏离，延续了公司在沟通上不结盟的趋势。</p><h1 id="0952" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">可解释的人工智能(XAI)和可解释的人工智能</h1><p id="c829" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果技术最终隐藏在一个黑盒子里，无法理解，那么所有这些不同的框架和原则都没有任何意义。这就是为什么上面讨论的许多框架都提到了可解释的人工智能。</p><p id="a209" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些术语指的是一个算法的代码能被理解到什么程度，以及可以用什么工具来理解它。它们经常被互换使用，比如在维基百科的页面上，可解释性被列为可解释性的一个子集。其他人有不同的观点，比如本文的作者，他讨论了两者之间的差异，并在一个光谱上提出了这些术语。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mt"><img src="../Images/c8c9888f805425bc491ded6ffe3ef71f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*hF6zGrp9k-6I7rAbVx8dsA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">归功于<a class="np nq ep" href="https://medium.com/u/4ae48256fb37?source=post_page-----8d0e433405bb--------------------------------" rel="noopener" target="_blank">康纳·奥沙利文</a></p></figure><p id="e85f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这些术语的技术性质，我对它们的区别的理解是有限的。然而，似乎需要在“可解释的人工智能”(XAI)和“可解释的模型”之间进行区分。上面的图表描述了算法可以基于的不同模型，而维基百科页面谈论的是更广泛的XAI概念。在这一点上，它感觉像是吹毛求疵，而不是为大多数人提供澄清，所以我将把这场辩论留给专家。</p><h1 id="7b81" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">竞争的定义会让我们付出代价</h1><p id="5a44" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">当我评估所有这些术语时，我发现自己困惑多于放心。该行业正在使用在日常语言中具有相当分量的词汇，但在人工智能的背景下以相对任意的方式重新定义它们。虽然有一些共同的努力来创造共同的理解，最明显的是围绕欧盟准则，每个公司的定义的范围和重点是不同的，这可能会导致沟通和公众理解的问题。</p><p id="97bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一个社会，我们似乎同意我们需要符合人类最大利益的人工智能系统，但我们仍然找到了一种方法，让它成为一场比赛，看谁因这个想法而不是解决方案而获得荣誉。事实上，人工智能研究和部署公司OpenAI(其使命是确保人工智能造福全人类)的一项分析表明，竞争压力实际上可能会推动公司在安全方面<a class="ae ky" href="https://openai.com/blog/cooperation-on-safety/" rel="noopener ugc nofollow" target="_blank"><em class="lv">投资</em>不足，并导致集体行动问题。</a></p><p id="4584" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然结盟是理想的，但在这个早期阶段的多样性是走向集体理解的自然一步。当务之急是，我们不要陷入试图找到让我们的公司听起来不错的术语，而是采取必要的步骤来创建为我们所有人提供有利结果的人工智能系统。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><p id="d332" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">如果你想直接在你的收件箱里收到我写的东西，</em> <a class="ae ky" href="https://www.charliegedeon.com/" rel="noopener ugc nofollow" target="_blank"> <em class="lv">点击这里</em>💌</a>T10。</p></div></div>    
</body>
</html>