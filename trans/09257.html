<html>
<head>
<title>A Guide to Estimator Efficiency</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">估计效率指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-guide-to-estimator-efficiency-bae31a06e570?source=collection_archive---------15-----------------------#2021-08-27">https://towardsdatascience.com/a-guide-to-estimator-efficiency-bae31a06e570?source=collection_archive---------15-----------------------#2021-08-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="24b9" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="e2b7" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用真实世界的数据集解释效率的概念及其用法</h2></div><p id="4bbf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在本文中，我们将讨论以下主题:</p><ul class=""><li id="52df" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj lp lq lr ls bi translated">什么是效率？</li><li id="0556" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">什么是统计估计量，如何定义它的效率？</li><li id="fab4" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">如何计算一个估计量的效率？</li><li id="f357" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="kq ja">如何利用效率建立更好的回归模型？</strong></li></ul><p id="50ed" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们开始吧！</p><h1 id="7ccf" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">什么是效率？</h1><p id="0c23" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">用外行人的话说:</p><blockquote class="mv"><p id="5669" class="mw mx iq bd my mz na nb nc nd ne lj dk translated">效率是衡量你投入的每单位时间、精力或金钱能从一件事情中得到多少使用的标准。</p></blockquote><p id="99de" class="pw-post-body-paragraph ko kp iq kq b kr nf ka kt ku ng kd kw kx nh kz la lb ni ld le lf nj lh li lj ij bi translated">几乎任何事情的效率都可以用有用产出与总投入的<strong class="kq ja">比</strong>来表示:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/cd09b7b1ada163e669208a404f872d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*eXf2rQQ7mzhF3_ujPD6yzg.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">效率的一般定义(图片由作者提供)</p></figure><p id="b788" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是效率的两个例子:</p><ul class=""><li id="d491" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj lp lq lr ls bi translated"><strong class="kq ja">电动机的效率:</strong>直流电动机的效率是在其轴上测得的功率输出与泵入其中的总DC电功率之比。</li><li id="7466" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated"><strong class="kq ja">生产效率:</strong>一个国家乃至整个地球的生产效率，往往以其GDP与人口之比来衡量，又称<strong class="kq ja">人均GDP。</strong>2020年地球的人均GDP为<a class="ae nw" href="https://data.worldbank.org/indicator/NY.GDP.PCAP.CD" rel="noopener ugc nofollow" target="_blank">10925美元</a>。</li></ul><p id="1a6b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">效率是一个无量纲的量。</strong>但也有例外。在某些领域，尤其是在经济学领域，效率有一个维度，通常是货币维度，如人均GDP。</p><p id="7ec4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当表示为无量纲量时，<strong class="kq ja">效率是一个在0.0到1.0之间变化的实数</strong>，表示任何设备的有用输出至多与泵入设备的总输入一样高。</p><p id="b306" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有了这个背景，让我们把注意力转向统计科学中定义的效率。我们将首先介绍统计科学中的一个基本工具，即统计估计量。</p><h1 id="697d" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">什么是统计估计量？</h1><p id="ad47" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">让我们陈述一下评估者的非正式定义:</p><blockquote class="mv"><p id="e00a" class="mw mx iq bd my mz na nb nc nd ne lj dk translated">估计量是一种统计方法，用于估计总体中某些参数(如平均值或中值)的真实但未知的值。这是通过使用构成值样本的数据点中包含的信息来实现的。</p></blockquote><h2 id="27fe" class="nx lz iq bd ma ny nz dn me oa ob dp mi kx oc od mk lb oe of mm lf og oh mo iw bi translated">估计量的例子</h2><p id="47ce" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">给定一个<em class="oi"> n </em>值<em class="oi">【y _ 1，y_2，…，y _ n】</em>的样本，这里有一些总体均值<em class="oi"> μ </em>估计量的例子(有好有坏):</p><p id="ebf7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">随机选择的均值(不好！):</strong></p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/92784e4d6f9f5c349bd4b78b921e2cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*xGZU48KjwkoM9i9ebQVrPA.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">该估计器通过指定从样本中随机选择的值为<em class="ok"> μ(作者图片)</em>来估计总体<em class="ok">T1】平均值<em class="ok"> μ </em></em></p></figure><p id="4cce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">n个值的平均值(好):</strong></p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/f0803d7adbc184f7378bf14ec26a1acb.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*pCGis-G9KYAmM11AuE45AA.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">该估计器通过取<em class="ok"> n </em>个样本值<em class="ok">(图片由作者提供)</em>的平均值来估计总体<em class="ok"> μ </em>的平均值</p></figure><p id="ce02" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae nw" rel="noopener" target="_blank" href="/understanding-estimation-bias-and-the-bias-variance-tradeoff-79ba42ab79c">可以证明</a>n值平均<em class="oi">估计量比随机选择估计量具有更好的性质。具体来说，n值平均值估计量比随机选择估计量具有更低的方差，并且它是总体均值<em class="oi"> μ </em>  <em class="oi">的<a class="ae nw" rel="noopener" target="_blank" href="/the-consistent-estimator-913fab06f4f3">一致估计量。</a></em></em></p><h2 id="a013" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated"><strong class="ak">线性模型的估计器</strong></h2><p id="a1a5" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">让我们来看看一个常用回归模型中使用的估计量。以下估计器估计条件均值<em class="oi"> μ </em>，即以回归变量向量<strong class="kq ja"> <em class="oi"> X </em> </strong>为条件的均值，采用一组特定的观察值<em class="oi">【X _ 1，x_2，…x_m】。μ_cap </em>是使用<strong class="kq ja"> <em class="oi"> θ_cap </em> </strong>计算的估计条件均值，θ_cap  是拟合模型系数的向量。</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi or"><img src="../Images/ba8d4ed8c4c243b3fd6e63177b939852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*Tz8r1RRFrbqsq68LOXfSLA.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">线性模型的估计量(图片由作者提供)</p></figure><p id="99ac" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在让我们把注意力回到手头的话题:效率。</p><p id="95da" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">和其他事情一样，计算统计估计量的效率是可能的。</p><h1 id="c78b" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">估计量的效率</h1><p id="ced9" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">考虑一个估计器<em class="oi"> T </em>，它被设计用来估计(预测)一些总体参数<em class="oi"> θ。</em>我们刚刚复习了几个<em class="oi"> T </em>和<em class="oi"> θ的例子。</em>例如，T =总体均值的n值平均值估计量<em class="oi"> μ </em> <em class="oi">即θ=μ。</em>这种估计器的效率<em class="oi"> T </em>表示为两个方差的比值，如下所示:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="ot ou di ov bf ow"><div class="gh gi os"><img src="../Images/c17b64bf34ba2271909f46a2fff8257b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f89vrWUP2vuj3B_kibNWeQ.png"/></div></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">总体参数θ估计量T的效率(图片由作者提供)</p></figure><p id="bcd0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为什么<em class="oi"> T </em>对<em class="oi"> θ </em>的估计会有方差？这是因为，在现实世界中，<em class="oi"> T </em>无法访问整个群体的值。事实上，如果是这样的话，<em class="oi"> T </em>将不再需要“估计”任何东西。相反，在现实中，<em class="oi"> T </em>总是呈现一个值的样本。并且每次<em class="oi">测试</em>对该样本进行处理时，都有可能产生对总体参数<em class="oi"> θ </em>的不同估计。例如，如果您向n值平均值估计器<em class="oi"> T </em>提供100个数据样本，每个样本的大小为<em class="oi"> n </em>，那么估计器将产生总体平均值<em class="oi"> μ </em>的100个估计值。这100个对<em class="oi"> μ </em>的估计会显示出真实总体均值<em class="oi"> μ </em>附近的一些差异。这个方差叫做<em class="oi"> T </em>的方差。</p><p id="362a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有了上面的想法，很容易看出，如果你要为同一个总体参数<em class="oi"> θ </em>设计两种不同类型的估计量<em class="oi"> T1 </em>和<em class="oi"> T2 </em>，那么它们有可能(实际上很有可能)会各自表现出不同的特征方差。假设<em class="oi"> Var(T1) &gt; Var(T2) </em>。现在，假设有人对<em class="oi"> θ </em>提出了第三种估计量<em class="oi"> T3 </em>，使得<em class="oi"> Var(T3) </em>甚至低于<em class="oi"> T2 </em>，以此类推。人们可能有理由怀疑，如果给定一个总体参数be，那么<em class="oi"> θ的估计量所显示的方差是否有一个下界。原来在一定条件下，恰好存在这样一个下界，它被称为</em> <a class="ae nw" href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound" rel="noopener ugc nofollow" target="_blank"> <strong class="kq ja">克莱姆-拉奥界</strong> </a> <strong class="kq ja">。</strong></p><p id="32d3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">将我们的注意力转回效率方程，我们看到上式中的分子是<a class="ae nw" href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound" rel="noopener ugc nofollow" target="_blank"> <strong class="kq ja">克拉姆-拉奥界限</strong> </a>。</p><p id="bbac" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">假设你设计了一个估计量<em class="oi"> T </em>，它的实际方差等于克拉美–拉奥界，那么这意味着你的估计量的效率是完美的1.0。在所有其他情况下，估计器的效率范围为<em class="oi">【0到1.0】</em>。</p><h1 id="65d3" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">无偏估计量的效率</h1><p id="d0d2" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">如果估计量为<a class="ae nw" rel="noopener" target="_blank" href="/understanding-estimation-bias-and-the-bias-variance-tradeoff-79ba42ab79c"> <strong class="kq ja">无偏</strong> </a>，则<a class="ae nw" href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound" rel="noopener ugc nofollow" target="_blank">克莱姆-拉奥界</a>是估计量的<a class="ae nw" rel="noopener" target="_blank" href="/an-intuitive-look-at-fisher-information-2720c40867d8"> <strong class="kq ja">费希尔信息</strong> </a> <em class="oi"> I(T(θ)) </em>的倒数。</p><p id="6c02" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，对于某总体参数<em class="oi"> θ </em>的一个<em class="oi">无偏</em>估计量<em class="oi"> T </em>，则<em class="oi"> T(θ) </em>的效率表示为:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/d680de39e499b6dc86c7eca919e00b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*MthZb2cCSxfqOoRXDQc7BQ.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">总体参数θ的一个<strong class="bd oy">无偏</strong>估计量T的效率(图片由作者提供)</p></figure><p id="066a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">费希尔信息可能是一个需要理解的复杂概念。我们将按以下方式描述它:</p><h2 id="f7b8" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated">费希尔信息</h2><p id="fe0c" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">假设你正在处理一个随机变量<em class="oi"> T </em>，假设它遵循某种概率分布<em class="oi"> f(。)</em>，如正态或泊松分布。假设函数<em class="oi"> f(。)</em>接受某个参数<em class="oi"> θ。</em>θ的例子有正态分布的平均值<em class="oi"> μ </em>，或者泊松分布的平均事件率<em class="oi"> λ </em>。那么<em class="oi"> T </em>的Fisher信息提供了一种方法来衡量<em class="oi"> T </em>包含的关于θ 的<em class="oi">真实总体值的信息量(比如总体的真实均值)。</em></p><h1 id="0220" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">理解估计量效率概念的三种不同方式</h1><p id="0033" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">估计量的效率是对其特征不止一个方面的度量。以下是考察评估者效率的三种相关方法:</p><h2 id="0b03" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated"><strong class="ak">估计器效率作为其精度的度量</strong></h2><p id="6dff" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">与完全有效的估计量相比，<em class="oi">估计量的效率是对其估计的参数的真实总体值的“紧密”程度的衡量。</em>完全有效的估计量是其方差等于该类估计量的<a class="ae nw" href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound" rel="noopener ugc nofollow" target="_blank">克拉美-罗界</a>的估计量。因此，效率的概念直接基于估计者预测的变化程度。<em class="oi">估计者预测的方差概念非常重要，我们将很快说明如何使用真实世界的数据集来计算它。</em></p><h2 id="7b33" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated"><strong class="ak">作为所需最小样本量决定因素的估计效率</strong></h2><p id="c29f" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">估计器的效率也是对你需要多少(或多少，取决于你的观点)数据点来达到期望的估计质量水平的一种度量。评估的质量可以用多种方法来衡量。一种流行的度量是损失函数，例如<strong class="kq ja">均方误差(MSE) </strong>。这里的想法是，一个高效的估计器将需要比它的低效率兄弟更小的样本，以生成等于或低于MSE的期望阈值的预测。</p><p id="bd07" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于获取数据总是一件昂贵的事情，所有其他事情大致相同，它可以帮助您获得一个高效的估计器，而不是追逐问题的最大数据集。</p><h2 id="3556" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated"><strong class="ak">估计量效率作为比较两个估计量的一种方式</strong></h2><p id="e343" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">efficiency属性还为您提供了一种比较样本问题和相同样本数据集的两个竞争估计量的估计精度(和准确度)的方法。或者，估计器的效率为建模者提供了一种方法，如果他们选择的估计器需要匹配精度(或准确度——记住它们是<a class="ae nw" href="https://en.wikipedia.org/wiki/Accuracy_and_precision" rel="noopener ugc nofollow" target="_blank">而不是同一个东西</a>,就可以确定样本大小需要多大(或多小)!)的竞争估计量。</p><h2 id="1f40" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated">一个重要的特例</h2><p id="7357" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">两个估算器的效率可以通过简单地比较各自估算器预测的方差来进行比较，即方差较低的一个被认为更有效，<strong class="kq ja">假设满足以下条件</strong>:</p><ol class=""><li id="2460" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj oz lq lr ls bi translated">这两个估计量用于预测总体的同一个参数。例如，两者都是总体均值的估计量。</li><li id="6399" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj oz lq lr ls bi translated">这两个估计器属于同一类，即由这两个估计器产生的预测遵循相同的概率分布。例如，由两个估计器产生的估计是泊松分布的。在这种情况下，两个估计量对于它们正在估计的总体参数具有相同的Fisher信息。</li><li id="9ee9" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj oz lq lr ls bi translated">这两种估计量都是它们所估计的总体参数的无偏估计量。在这种情况下，它们的Fisher信息的倒数就是方差的Cramer-Rao界，这又使得两个估计量的方差的Cramer-Rao界相同。</li></ol><p id="9406" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当上述三个条件成立时，效率方程的分子，即方差的下限，对于两个估计量是相同的。因此，可以通过简单地比较它们各自预测的方差来比较这些估计量的效率。</p><p id="b8aa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，我们得到了以下重要结果:</p><blockquote class="mv"><p id="0cba" class="mw mx iq bd my mz na nb nc nd ne lj dk translated">在一组无偏估计量中，如果某个总体参数<em class="ok"> θ </em>的预测服从相同的概率分布，那么预测方差最小的估计量就是最有效的估计量。</p></blockquote></div><div class="ab cl pa pb hu pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="ij ik il im in"><p id="eca6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们现在来看看如何计算n值平均值估计量的效率方程的分子和分母。</p><p id="880c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们从分母开始:估计者预测的<strong class="kq ja">方差</strong>。</p><h1 id="1008" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">估计量的方差是什么意思，如何计算？</h1><p id="d6b8" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">使用以下思维实验可以最好地理解评估者预测的方差概念:</p><p id="0292" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">假设您希望在夏季的几个月中估计某个公共海滩上每立方毫升海水中的细菌平均数量。为此，你在一天的不同时间在海滩收集<em class="oi"> 100个</em>水样，并测量每个样本中的细菌数量。这是你的细菌计数样本数据集:<em class="oi">【y _ 1，y_2，…，y _ 100】</em>。接下来，您决定使用n值平均值估计器来估计平均细菌数，并使用这个观察到的样本平均值<em class="oi"> y_bar </em>作为您对总体平均值<em class="oi"> μ </em>的估计。总之，您使用n值样本平均值<em class="oi"> y_bar </em>作为总体平均值<em class="oi"> μ </em>的估计值。</p><p id="e808" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是现在假设，你的一个朋友在海滩上随机选择的100个地方收集了另一组水样。他们将获得第二组100个细菌计数:<em class="oi"> [y_1，y_2，…，y_100]而另一个样本意味着y_bar_2。</em>假设<em class="oi"> 200 </em>人重复这个过程，他们会在他们自己当中，以<em class="oi"> 200 </em>的样本结束<em class="oi"> y_bar_1，y_bar_2，…，y_bar_200 </em>。这些<em class="oi"> 200 </em>样本均值本身将围绕真实总体均值<em class="oi"> μ分布(近似正态分布)。因此可以计算这些样本均值的方差。</em></p><p id="c782" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，总体均值μ的n值均值估计值本身是一个随机变量，它遵循一个既有均值又有方差的概率分布。</p><p id="300a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae nw" rel="noopener" target="_blank" href="/understanding-estimation-bias-and-the-bias-variance-tradeoff-79ba42ab79c">可以看出</a>n值平均值估计量是总体均值的<a class="ae nw" rel="noopener" target="_blank" href="/understanding-estimation-bias-and-the-bias-variance-tradeoff-79ba42ab79c">无偏</a>估计量，即它的期望值实际上是总体均值<em class="oi"> μ </em>。此外，该估计量是<a class="ae nw" rel="noopener" target="_blank" href="/the-consistent-estimator-913fab06f4f3">一致的</a>，这意味着它的预测将收敛于总体均值<em class="oi"> μ </em>作为<em class="oi"> n → N </em>，即整个总体的大小。在海滩示例的情况下，<em class="oi"> N </em>可以被安全地认为是无穷大。</p><p id="d21f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae nw" rel="noopener" target="_blank" href="/understanding-estimation-bias-and-the-bias-variance-tradeoff-79ba42ab79c">还可以看出</a>n个值的平均值估计量的预测方差是<em class="oi"> σ /n </em>，其中<em class="oi"> σ </em>是我们为了构建大小为<em class="oi"> n </em>的样本而使用的基础总体值的方差。</p><p id="6168" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">事实上，估计量方差的概念对于效率的计算非常重要，我们将用一个真实的例子来说明它。</p><h1 id="7361" class="ly lz iq bd ma mb mc md me mf mg mh mi kf mj kg mk ki ml kj mm kl mn km mo mp bi translated">估计量方差的真实例子</h1><p id="7ac6" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">我们将使用从<a class="ae nw" href="https://www.zillow.com/research/data/" rel="noopener ugc nofollow" target="_blank"> Zillow Research </a>根据其<a class="ae nw" href="https://www.zillow.com/research/contact-us/" rel="noopener ugc nofollow" target="_blank">免费使用条款</a>下载的以下30K+数据点数据集:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="ot ou di ov bf ow"><div class="gh gi ph"><img src="../Images/f0234c811dcc752637c53b8434243daa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FXRisXkhQFD4x4WyS3r2Bg.png"/></div></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">房价同比百分比变化预测(来源:<a class="ae nw" href="https://www.zillow.com/research/data/" rel="noopener ugc nofollow" target="_blank"> Zillow Research </a></p></figure><p id="7499" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">数据集中的每一行都包含对美国特定地理位置的房价年同比百分比变化的预测。该值在列<strong class="kq ja"> ForecastYoYPctChange </strong>中。</p><p id="a924" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们的目标是估计全美房价同比百分比变化的平均预测值，即人口平均值<em class="oi"> μ </em>。</p><p id="ce47" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">假设我们不能一次性访问这个30K行的完整数据集。相反，我们碰巧只能进入100个随机选择的地点。我们需要使用100点样本来估计全美房价年同比百分比变化的平均预测。</p><p id="ae68" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下Python代码阐释了这项任务。</p><ul class=""><li id="7eaa" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj lp lq lr ls bi translated">我们将把数据集加载到内存中</li><li id="841a" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">接下来，我们将随机选择100个数据点进行替换。“with replacement”技术确保每个数据点独立于任何其他点进行选择。这种技术会在我们的样本中导致重复，但是当值的总体很大时，重复的机会是最小的。从好的方面来看，需要使用替换技术进行采样，以使统计数学能够很好地工作。</li><li id="553d" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj lp lq lr ls bi translated">最后，我们将使用n值平均值估计器来估计总体平均值<em class="oi"> μ </em>。</li></ul><pre class="nl nm nn no gt pi pj pk pl aw pm bi"><span id="6751" class="nx lz iq pj b gy pn po l pp pq"><strong class="pj ja">import </strong>math<strong class="pj ja"><br/>import </strong>pandas <strong class="pj ja">as </strong>pd<br/><strong class="pj ja">import </strong>numpy <strong class="pj ja">as </strong>np<br/><strong class="pj ja">from </strong>matplotlib <strong class="pj ja">import </strong>pyplot <strong class="pj ja">as </strong>plt<br/><strong class="pj ja">from </strong>scipy.stats <strong class="pj ja">import </strong>norm</span><span id="8b7a" class="nx lz iq pj b gy pr po l pp pq"><strong class="pj ja">#Load the data file</strong><br/>df = pd.<strong class="pj ja">read_csv</strong>(<strong class="pj ja">'zhvf_uc_sfrcondo_tier_0.33_0.67_month.csv'</strong>, <strong class="pj ja">header</strong>=0, <strong class="pj ja">infer_datetime_format</strong>=True, <strong class="pj ja">parse_dates</strong>=[<strong class="pj ja">'</strong>ForecastedDate<strong class="pj ja">'</strong>])</span><span id="ada5" class="nx lz iq pj b gy pr po l pp pq"><strong class="pj ja">#Randomly select 100 data points with replacement<br/></strong>df_sample = df.<strong class="pj ja">sample</strong>(<strong class="pj ja">n</strong>=100, <strong class="pj ja">replace</strong>=True)</span><span id="631a" class="nx lz iq pj b gy pr po l pp pq"><strong class="pj ja">#Print the mean of the sample. This is our estimate of the population mean mu<br/>print</strong>('Estimate of population mean mu='+<strong class="pj ja">str</strong>(df_sample['ForecastYoYPctChange'].<strong class="pj ja">mean</strong>()))</span></pre><p id="5fb0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，让我们重复上述过程100次，以产生总体均值<em class="oi"> μ的100个独立估计。</em>我们将绘制这100个平均值，看看预测值的分布情况:</p><pre class="nl nm nn no gt pi pj pk pl aw pm bi"><span id="747b" class="nx lz iq pj b gy pn po l pp pq">means = []<br/>for i in <strong class="pj ja">range</strong>(100):<br/>    df_sample = df.<strong class="pj ja">sample</strong>(<strong class="pj ja">n</strong>=100, <strong class="pj ja">replace</strong>=True)<br/>    means.<strong class="pj ja">append</strong>(df_sample['ForecastYoYPctChange'].<strong class="pj ja">mean</strong>())</span><span id="1a16" class="nx lz iq pj b gy pr po l pp pq"><strong class="pj ja">#Plot the distribution<br/></strong>plt.<strong class="pj ja">hist</strong>(means, <strong class="pj ja">bins</strong>=25)<br/>plt.<strong class="pj ja">show</strong>()</span></pre><p id="4b7b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们看到下面的情节:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="ot ou di ov bf ow"><div class="gh gi ps"><img src="../Images/12944b14da9b0edf9b7ac461a0b80be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8EOFZ774ZrxkvfGwzzyCBw.png"/></div></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">样本均值的频率分布(图片由作者提供)</p></figure><p id="34a9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果我们继续这种抽取大小为<em class="oi"> n (=100) </em>的样本的做法，我们会发现频率分布将在真实总体均值<em class="oi"> μ处开始达到峰值。</em></p><p id="d6f5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这是10，000个样本平均值的频率分布:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="ot ou di ov bf ow"><div class="gh gi pt"><img src="../Images/0fe1fd5a4f8f37e9445507a8129cdeb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s7Xa3rmkFjfqpdBfREQtuw.png"/></div></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">10000个样本均值的频率分布(图片由作者提供)</p></figure><p id="aea2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们得出了以下重要的观察结果:</p><blockquote class="mv"><p id="b695" class="mw mx iq bd my mz na nb nc nd ne lj dk translated">n值平均值估计器的预测本身是一个随机变量，它遵循一个具有平均值和方差的概率分布。</p></blockquote><p id="89ea" class="pw-post-body-paragraph ko kp iq kq b kr nf ka kt ku ng kd kw kx nh kz la lb ni ld le lf nj lh li lj ij bi translated">如果估计量是无偏的，其预测的均值将与真实总体均值<em class="oi"> μ </em>相同，因为预测的数量趋于无穷大:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/eab2555b9a60df20624041b466dee9cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/format:webp/1*51sPXUNZOJJpW8ALG0iMxg.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">如果估计量是无偏的，其预测的期望值<strong class="bd oy"> <em class="ok"> μ_cap </em> </strong> <em class="ok">等于总体均值μ(图片由作者提供)</em></p></figure><p id="3f94" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们感兴趣的是估计者预测的方差。</p><p id="3748" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下是均值估计器10，000次预测的方差:</p><pre class="nl nm nn no gt pi pj pk pl aw pm bi"><span id="423d" class="nx lz iq pj b gy pn po l pp pq">print('Variance of the estimator='+str(np.<strong class="pj ja">var</strong>(means)))</span></pre><p id="1d7d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">它打印出以下内容:</p><pre class="nl nm nn no gt pi pj pk pl aw pm bi"><span id="97a2" class="nx lz iq pj b gy pn po l pp pq">Variance of the estimator=<strong class="pj ja">0.020872772633239996</strong></span></pre><p id="3dc7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">上述对方差的深入研究也给我们带来了意想不到的红利。它使我们能够估计房价变化预测总体的方差<em class="oi"> σ </em>。回想一下，n值均值估计量的方差是<em class="oi"> σ /n </em>，其中<em class="oi"> σ </em>是基础总体的方差，<em class="oi">n =样本量=100 </em>。所以我们可以估计总体的方差为<strong class="kq ja"> 2.08728。</strong></p><h2 id="0644" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated">绕回来…</h2><p id="d1c4" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">让我们回到估计器<em class="oi"> T </em>的效率等式，它产生某个总体参数<em class="oi"> θ </em>的无偏估计:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/d680de39e499b6dc86c7eca919e00b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*MthZb2cCSxfqOoRXDQc7BQ.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">总体参数θ的<strong class="bd oy">无偏</strong>估计量T的效率(图片由作者提供)</p></figure><p id="f805" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">到目前为止，我们已经对估计者预测中的方差概念有了一些了解，也就是上式中的分母。</p><p id="5a24" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了计算分子，我们需要知道有关估计量的费雪信息。为了知道费雪信息，我们需要知道估计量的预测的概率分布。</p><p id="01ec" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于我们用来估计房价同比变化的n值平均值估计值，我们知道以下信息:</p><ol class=""><li id="1ad7" class="lk ll iq kq b kr ks ku kv kx lm lb ln lf lo lj oz lq lr ls bi translated">n值均值估计器<strong class="kq ja">的预测在估计数趋于无穷大的渐近情况下近似正态分布</strong>(这一点可以证明)。</li><li id="1819" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj oz lq lr ls bi translated">n值平均值估计器生成总体平均值<em class="oi"> μ </em>的无偏估计。因此，n值平均值估计器预测的<strong class="kq ja">均值就是总体均值<em class="oi">μ</em>T7】。</strong></li><li id="5493" class="lk ll iq kq b kr lt ku lu kx lv lb lw lf lx lj oz lq lr ls bi translated">估计者预测的<strong class="kq ja">方差是<em class="oi">σ/n</em>T11】其中<em class="oi"> σ </em>是价格变化的潜在总体的方差，而<em class="oi"> n </em>是取平均值的样本大小。在我们的例子中，<em class="oi"> n=100 </em>。</strong></li></ol><p id="f79e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，我们可以对<em class="oi"> μ </em>的n值平均值估计量的概率分布陈述如下:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/24cd4c2b7d989ca6702ba0abeabcd717.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*vPbGUM3oG5oUscXrcJt0ow.png"/></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">n值均值估计器的预测值呈正态分布，均值等于总体均值μ，方差等于总体方差<em class="ok"> σ，按样本大小n缩放(图片由作者提供)</em></p></figure><p id="3d6f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可以证明，正态分布且已知方差<em class="oi"> σ </em>的未知总体均值<em class="oi"> μ </em> <strong class="kq ja"> </strong>的一个估计量的Fisher信息，就是1/ <em class="oi"> σ。</em></p><p id="638a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">因此，总体均值<em class="oi"> μ </em>的n值均值估计量的Fisher信息为<em class="oi"> n/σ。</em> </strong></p><p id="a10a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">再次回忆一下，这个估计器预测的方差是<em class="oi"> σ /n </em>。</p><p id="06ee" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，总体参数<em class="oi"> μ </em>的n值均值估计的效率为:</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="ot ou di ov bf ow"><div class="gh gi pw"><img src="../Images/d19ffbf77a640cac1935b1f020e2b016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JpsU4_Iy4-Zn8a5mwvMlZw.png"/></div></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">总体平均值的n值平均值估计量的效率<em class="ok"> μ是完美的1.0(图片由作者提供)</em></p></figure><p id="766d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这是一个重要的结果。它表明n值平均值估计量尽管简单，却是一个有效的估计量。</p><blockquote class="mv"><p id="7da2" class="mw mx iq bd my mz na nb nc nd ne lj dk translated">总体均值<em class="ok"> μ </em>的n值均值估计量是一种有效的估计量。</p></blockquote></div><div class="ab cl pa pb hu pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="ij ik il im in"><h1 id="744f" class="ly lz iq bd ma mb px md me mf py mh mi kf pz kg mk ki qa kj mm kl qb km mo mp bi translated">相关阅读</h1><div class="qc qd gp gr qe qf"><a rel="noopener follow" target="_blank" href="/understanding-estimation-bias-and-the-bias-variance-tradeoff-79ba42ab79c"><div class="qg ab fo"><div class="qh ab qi cl cj qj"><h2 class="bd ja gy z fp qk fr fs ql fu fw iz bi translated">理解估计偏差和偏差-方差权衡</h2><div class="qm l"><h3 class="bd b gy z fp qk fr fs ql fu fw dk translated">另外，如何根据偏差、方差和均方差来比较估计量</h3></div><div class="qn l"><p class="bd b dl z fp qk fr fs ql fu fw dk translated">towardsdatascience.com</p></div></div><div class="qo l"><div class="qp l qq qr qs qo qt nq qf"/></div></div></a></div><div class="qc qd gp gr qe qf"><a rel="noopener follow" target="_blank" href="/the-consistent-estimator-913fab06f4f3"><div class="qg ab fo"><div class="qh ab qi cl cj qj"><h2 class="bd ja gy z fp qk fr fs ql fu fw iz bi translated">一致估计量</h2><div class="qm l"><h3 class="bd b gy z fp qk fr fs ql fu fw dk translated">回归建模器指南</h3></div><div class="qn l"><p class="bd b dl z fp qk fr fs ql fu fw dk translated">towardsdatascience.com</p></div></div><div class="qo l"><div class="qu l qq qr qs qo qt nq qf"/></div></div></a></div><div class="qc qd gp gr qe qf"><a rel="noopener follow" target="_blank" href="/an-intuitive-look-at-fisher-information-2720c40867d8"><div class="qg ab fo"><div class="qh ab qi cl cj qj"><h2 class="bd ja gy z fp qk fr fs ql fu fw iz bi translated">对费希尔信息的直观观察</h2><div class="qm l"><h3 class="bd b gy z fp qk fr fs ql fu fw dk translated">它的含义，以及为什么它是这样计算的</h3></div><div class="qn l"><p class="bd b dl z fp qk fr fs ql fu fw dk translated">towardsdatascience.com</p></div></div><div class="qo l"><div class="qv l qq qr qs qo qt nq qf"/></div></div></a></div></div><div class="ab cl pa pb hu pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="ij ik il im in"><h1 id="5a50" class="ly lz iq bd ma mb px md me mf py mh mi kf pz kg mk ki qa kj mm kl qb km mo mp bi translated">引用和版权</h1><p id="31b4" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated"><a class="ae nw" href="https://royalsocietypublishing.org/author/Fisher%2C+R+A" rel="noopener ugc nofollow" target="_blank"> Fisher R. A. </a>，(1922)论理论统计的数学基础，<em class="oi">伦敦皇家学会哲学汇刊。A辑，包含数学或物理性质的论文。</em>222309–368。【http://doi.org/10.1098/rsta.1922.0009 T4】</p><h2 id="be2c" class="nx lz iq bd ma ny om dn me oa on dp mi kx oo od mk lb op of mm lf oq oh mo iw bi translated">形象</h2><p id="2e64" class="pw-post-body-paragraph ko kp iq kq b kr mq ka kt ku mr kd kw kx ms kz la lb mt ld le lf mu lh li lj ij bi translated">本文中的所有图片的版权归<a class="ae nw" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC-BY-NC-SA </a>所有，除非图片下方提到了不同的来源和版权。</p></div><div class="ab cl pa pb hu pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="ij ik il im in"><p id="981a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="oi">如果您喜欢这篇文章，请关注我的</em><a class="ae nw" href="https://timeseriesreasoning.medium.com/" rel="noopener"><strong class="kq ja"><em class="oi">Sachin Date</em></strong></a><em class="oi">以获得关于回归、时间序列分析和预测主题的提示、操作方法和编程建议。</em></p></div></div>    
</body>
</html>