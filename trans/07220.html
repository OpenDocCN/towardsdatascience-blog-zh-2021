<html>
<head>
<title>Topic Modelling: A Deep Dive into LDA, hybrid-LDA, and non-LDA Approaches</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主题建模:深入研究LDA、混合LDA和非LDA方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modelling-a-deep-dive-into-lda-hybrid-lda-and-non-lda-approaches-d17d45ddaaaf?source=collection_archive---------28-----------------------#2021-06-30">https://towardsdatascience.com/topic-modelling-a-deep-dive-into-lda-hybrid-lda-and-non-lda-approaches-d17d45ddaaaf?source=collection_archive---------28-----------------------#2021-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ac72" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在你写一行代码之前，你需要知道的是</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/de4a16b4930d6213d243bff284224b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CDJdCRHOCNSlzVCt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@raphaelphotoch?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Raphael Schaller </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="6861" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题建模是我发现在我的角色中最需要的自然语言处理技术之一。最近，我看到它作为实体提取而流行起来，然而，它的目的仍然是一样的——在文本语料库中进行模式识别。</p><p id="2279" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将对可用于对短格式文本进行主题建模的技术进行深入的回顾。短格式文本通常是用户生成的，由缺乏结构、存在噪声和缺乏上下文来定义，导致机器学习建模困难。</p><p id="45d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章是我的<a class="ae ky" rel="noopener" target="_blank" href="/sentiment-analysis-a-deep-dive-into-the-theory-methods-and-applications-322f984f2b48">情感分析深度探索</a>的第二部分，是我做的关于主题建模和情感分析的<a class="ae ky" href="https://local.cis.strath.ac.uk/wp/extras/msctheses/papers/strath_cis_publication_2733.pdf" rel="noopener ugc nofollow" target="_blank">系统文献综述的结果。</a></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="cb93" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">概观</h1><p id="9853" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">主题建模是一种<a class="ae ky" href="https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?TB_iframe=true&amp;width=370.8&amp;height=658.8" rel="noopener ugc nofollow" target="_blank">文本处理技术</a>，旨在通过找出并展示文本数据中被识别为主题的模式来克服信息过载。它实现了<a class="ae ky" href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-1/issue-1/A-correlated-topic-model-of-Science/10.1214/07-AOAS114.full" rel="noopener ugc nofollow" target="_blank">改进的用户体验</a>，允许分析师在已识别主题的引导下快速浏览文本语料库或集合。</p><p id="fbed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题建模<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0167404817300603&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=16150203952534417719&amp;ei=pUTcYPbkKtyLy9YPx5K8qAM&amp;scisig=AAGBfm3pKQ2rYCPj7vq25qyjN6b2jla1ew" rel="noopener ugc nofollow" target="_blank">通常通过无监督学习</a>进行，运行模型的输出是所发现主题的概述。</p><p id="d23a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检测话题可以在<a class="ae ky" href="http://ceur-ws.org/Vol-2311/paper_4.pdf" rel="noopener ugc nofollow" target="_blank">在线和离线模式</a>下完成。当在线完成时，它的目标是随着时间的推移发现出现的动态话题。离线时，它是回顾性的，将语料库中的文档视为一批，一次检测一个主题。</p><p id="d7d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题检测和建模有四种主要方法:</p><ul class=""><li id="6f71" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">基于键盘的方法</li><li id="1990" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">概率主题建模</li><li id="31b6" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">衰老理论</li><li id="89f6" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">基于图表的方法。</li></ul><p id="9490" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">方法也可以通过用于主题识别的技术进行<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417416301038&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=5259186730874098934&amp;ei=MUvcYLudDtyDy9YPheGKmAE&amp;scisig=AAGBfm0_96cGJAj0XjYeSimNrGRqQJybMw" rel="noopener ugc nofollow" target="_blank">分类，这产生了三个组:</a></p><ul class=""><li id="ecb7" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">使聚集</li><li id="a7dd" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">分类</li><li id="873c" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">概率技术。</li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="6026" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">1.潜在狄利克雷分配</h1><p id="a7ea" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">LDA(潜在狄利克雷分配)是一个<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf%3FTB_iframe%3Dtrue%26width%3D370.8%26height%3D658.8&amp;hl=en&amp;sa=T&amp;oi=gsb-ggp&amp;ct=res&amp;cd=0&amp;d=17756175773309118945&amp;ei=C03cYNimGYjCmwG3s6r4Cg&amp;scisig=AAGBfm0y2e28PKlP3viZcQEbvTwTTHlHJQ" rel="noopener ugc nofollow" target="_blank">贝叶斯分层概率生成模型</a>，用于收集离散数据。它基于文档中单词和主题的可交换性假设进行操作。它<a class="ae ky" href="https://scholar.google.com/scholar_url?url=http://proceedings.mlr.press/v84/wang18a.html&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=260075222128407753&amp;ei=ME3cYLPSHNC5mAHv2o2QBA&amp;scisig=AAGBfm2rHNvY0l9wYMjz3m9c5TjygJkazA" rel="noopener ugc nofollow" target="_blank">将</a>文档建模为主题的离散分布，后面的主题被视为文档中术语的离散分布。</p><p id="c784" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最初的LDA方法使用变分期望最大化(VEM)算法来为LDA推断主题。后来<a class="ae ky" href="https://scholar.google.com/scholar_url?url=http://proceedings.mlr.press/v84/wang18a.html&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=260075222128407753&amp;ei=XU3cYPnGHIOHy9YPvfyVwAo&amp;scisig=AAGBfm2rHNvY0l9wYMjz3m9c5TjygJkazA" rel="noopener ugc nofollow" target="_blank">基于Gibbs抽样的随机抽样推断被引入</a>。这改进了实验中的性能，并且已经被更频繁地用作模型的一部分。</p><p id="b133" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首次引入LDA的Blei和他们的同事们展示了它相对于概率LSI模型的优越性。<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.taylorfrancis.com/chapters/edit/10.4324/9780203936399-10/meaning-context-walter-kintsch&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=4005447354759878017&amp;ei=zU_cYN_KKcvhmQG794zoBg&amp;scisig=AAGBfm23vQNpOLti-d4vqgSfwgrxzMPZhA" rel="noopener ugc nofollow" target="_blank"> LSI(潜在语义索引)使用线性代数和单词袋表示法</a>来提取意思相似的单词。</p><h2 id="7a90" class="nn md it bd me no np dn mi nq nr dp mm li ns nt mo lm nu nv mq lq nw nx ms ny bi translated">LDA的好处——LDA有什么好处？</h2><ol class=""><li id="b264" class="mz na it lb b lc mu lf mv li nz lm oa lq ob lu oc nf ng nh bi translated"><strong class="lb iu">战略业务优化</strong></li></ol><p id="c6fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在所有审查的技术中，LDA最常被列为模型的一部分，并被认为对战略业务优化有价值。</p><p id="f55e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。通过更好地理解用户生成的文本来提高竞争优势。</strong></p><p id="c28b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一项<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/8614146/&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=2&amp;d=15741880252452956632&amp;ei=qVDcYPSRMsvhmQG794zoBg&amp;scisig=AAGBfm3wGYF00Q3FDtK9ngeI5Az62L9BhQ" rel="noopener ugc nofollow" target="_blank"> 2018研究</a>证明了LDA作为一种通过从用户在线评论中提取信息并随后根据情感对主题进行分类来提高公司竞争优势的方法的价值。</p><p id="c6b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。提高公司对用户的了解。</strong></p><p id="3771" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于LDA的主题建模也被用于<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S092523121630604X&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=2&amp;d=8328834636591876070&amp;ei=F1HcYMe-K8vhmQG794zoBg&amp;scisig=AAGBfm1bCO2t0aWzokbN5pKeC5LZJBCsQA" rel="noopener ugc nofollow" target="_blank">描述用户的个性特征</a>，基于他们的在线文本出版物。</p><p id="a41b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" href="https://local.cis.strath.ac.uk/wp/extras/msctheses/papers/strath_cis_publication_2733.pdf" rel="noopener ugc nofollow" target="_blank">我自己的研究</a>中，我使用LDA主题建模，根据用户在社交媒体上发布的与产品或公司相关的简短的用户生成文本，在用户的客户旅程阶段对用户进行分类。</p><p id="496d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4。了解客户投诉，提高客户服务效率。</strong></p><p id="eb41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在一项<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S095741741930154X&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=2&amp;d=5697469705519407606&amp;ei=fVTcYJmkOIjCmwG3s6r4Cg&amp;scisig=AAGBfm0X_vugU_Z6Cteo2qvVA9x3RiWg_g" rel="noopener ugc nofollow" target="_blank"> 2019年的研究中，</a> LDA主题建模用于分析消费者金融保护局的消费者投诉。预先确定的标签用于分类，这通过任务自动化提高了投诉处理部门的效率。</p><h2 id="71f5" class="nn md it bd me no np dn mi nq nr dp mm li ns nt mo lm nu nv mq lq nw nx ms ny bi translated">LDA的局限性——LDA被批评了什么？</h2><ol class=""><li id="b1e4" class="mz na it lb b lc mu lf mv li nz lm oa lq ob lu oc nf ng nh bi translated"><strong class="lb iu">无力伸缩。</strong></li></ol><p id="c189" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LDA因其所基于的技术的线性而被批评为不能缩放。</p><p id="ee48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其他变体，如pLSI，LSI的概率变体，<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417416301464&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=17965918767627044979&amp;ei=zFfcYKzrJK3CsQKW_J7gDA&amp;scisig=AAGBfm2beLSNGietxuQH1UH6E7UMSadMOw" rel="noopener ugc nofollow" target="_blank">通过使用统计基础</a>和生成数据模型来解决这一挑战。</p><p id="a730" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。假设文件可交换性</strong></p><p id="703f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然LDA很有效并且经常使用，但是它对文档可交换性的假设受到了批评。在主题随时间演变的情况下，这可能是限制性的。</p><p id="7cbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。通常忽略共现关系。</strong></p><p id="370c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于LDA的模型因通常忽略所分析文档之间的共现关系而受到批评<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Solomia-Fedushko/publication/331276764_Proceedings_of_the_Sixth_International_Conference_on_Computer_Science_Engineering_and_Information_Technology_CCSEIT_2016_Vienna_Austria_May_2122_2016/links/5c6fcd63299bf1268d1bc2b0/Proceedings-of-the-Sixth-International-Conference-on-Computer-Science-Engineering-and-Information-Technology-CCSEIT-2016-Vienna-Austria-May-2122-2016.pdf%23page%3D212&amp;hl=en&amp;sa=T&amp;oi=gsb-ggp&amp;ct=res&amp;cd=0&amp;d=8926787121599265886&amp;ei=PlncYLGBAa3CsQKW_J7gDA&amp;scisig=AAGBfm0h1_4gOYZMJNFjwqf9dIblCE5zBg" rel="noopener ugc nofollow" target="_blank">。这导致检测到不完整的信息，并且无法通过上下文或其他桥接术语发现潜在的共现关系。</a></p><p id="b366" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为什么这很重要？这可以防止重要但罕见的主题被检测到。</p><p id="bb60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种批评也出现在对后来一项研究的分析中，作者提出了一个专门为在线社交网络主题建模定制的模型。他们证明，与LDA相比，即使应用于神经嵌入特征表示的浅层机器学习聚类技术也能提供更有效的性能。</p><p id="b480" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4。不适合用户生成的简短文本。</strong></p><p id="419c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1877050917315235&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=656547531701379292&amp;ei=t1ncYOLQA9yDy9YPheGKmAE&amp;scisig=AAGBfm2XoXN1TusTewLlFSI1hF8AIFW3Vg" rel="noopener ugc nofollow" target="_blank"> Hajjem和Latiri (2017) </a>批评LDA方法不适合短格式文本。他们提出了一个混合模型，该模型利用了信息检索领域的典型机制。</p><p id="c89a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://link.springer.com/content/pdf/10.1007/978-3-319-50496-4_59.pdf&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=1&amp;d=12584422342234601625&amp;ei=5lncYMzIBtC5mAHv2o2QBA&amp;scisig=AAGBfm1LdH_lfLmUw7ON3ippk_hdqC2UNQ" rel="noopener ugc nofollow" target="_blank">LDA-混合方法也被提出</a>来解决这些限制。然而，即使它们在短格式文本上的表现也不是最优的，这使得LDA在嘈杂、非结构化的社交媒体数据中的效率受到质疑。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="ac00" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">2.混合LDA方法</h1><p id="2227" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">为了解决LDA的一些突出的局限性，引入了学习单词的向量表示的模型。</p><p id="90cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过学习单词和隐藏主题的向量表示，它们被证明在短格式文本上具有更有效的分类性能。</p><p id="08b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Yu和Qiu提出了一种混合模型，其中使用Dirichlet多项式混合和词向量工具扩展了用户-LDA主题模型，当在微博(即短)文本数据上与其他混合模型或单独的LDA模型相比时，产生了最佳的性能。</p><p id="f9f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个概念上类似的方法可以应用于Twitter数据。这就是<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/8607040/&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=1&amp;d=11520210757019649284&amp;ei=o27cYL_uJNC5mAHv2o2QBA&amp;scisig=AAGBfm3LKvoBP4St24SaqqxlwIHFxyRcKg" rel="noopener ugc nofollow" target="_blank">层次潜在狄利克雷分配(hLDA) </a>，旨在通过使用word2vec(即向量表示技术)自动挖掘推文主题的层次维度。通过这样做，它提取数据中单词的语义关系，以获得更有效的维度。</p><p id="eded" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其他方法，如<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0950705118304076&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=13654315554949747121&amp;ei=9W7cYPypIoXSmAHGkZCwCQ&amp;scisig=AAGBfm1tsEQtbcxiUtod_CxwVaAPdych2Q" rel="noopener ugc nofollow" target="_blank">非负矩阵分解(NMF) </a>模型也被认为在类似配置下对短文本的性能优于LDA。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="caa9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">3.LDA替代方案</h1><p id="6d06" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">除了LDA，在主题发现领域还有许多其他的发展。考虑到他们缺乏学术关注，他们似乎有一些关键的局限性，仍然没有得到解决。</p><p id="6afa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在2017年的一项研究中，提出了一种用于主题检测的<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0004370217300735&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=2&amp;d=13965082245195253395&amp;ei=4nPcYOT_IYXSmAHGkZCwCQ&amp;scisig=AAGBfm23mROSJXWPy2LuJmafZM_iBjoOZA" rel="noopener ugc nofollow" target="_blank">分层方法</a>，其中单词被视为二元变量，只允许出现在层次结构的一个分支中。尽管与LDA相比是有效的，但是由于表征数据的语言模糊性，这种方法不适合在UGC或社交媒体短文本上应用。</p><p id="af1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/8318929/&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=7717772120239817391&amp;ei=eHTcYNPkCYOHy9YPvfyVwAo&amp;scisig=AAGBfm3EKNwMg1QNMzuyEkDCnOt1rVI3Aw" rel="noopener ugc nofollow" target="_blank">高斯混合模型</a>也可以用于新闻文章的主题建模。该模型旨在将文本表示为概率分布，作为发现主题的手段。虽然比LDA好，但它在UGC短文本的主题发现中可能再次表现得不太一致。原因是短格式文本缺乏结构和数据稀疏性。</p><p id="0876" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个基于<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417416301038&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=5259186730874098934&amp;ei=Z3XcYITLH9yLy9YPx5K8qAM&amp;scisig=AAGBfm0_96cGJAj0XjYeSimNrGRqQJybMw" rel="noopener ugc nofollow" target="_blank">形式概念分析(FCA </a>)的模型被提出用于Twitter数据的主题建模。这种方法显示了基于来自先前主题的信息的新主题检测的便利性。然而，它不能很好地概括，这意味着它不可靠，对主题敏感，这是它没有受过训练的。</p><p id="fc16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其他模型，如TG-MDP(主题图马尔可夫决策过程)，考虑了文本数据的语义特征，并以较低的时间复杂度自动选择最优主题集。这种方法仅适用于离线主题检测(如前所述，这种方法不太常见)。尽管如此，当与基于LDA的算法(GAC，LDA-GS，KG)进行基准测试时，它提供了有希望的结果。</p><p id="e230" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些模型可以用来做什么？—你可能想知道。</p><ul class=""><li id="72b1" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated"><a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S0957417416301567&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=1190096410935930586&amp;ei=WXbcYKzhLK3CsQKW_J7gDA&amp;scisig=AAGBfm3aftTLdkXWZcc2Xw5jCB_SWu2boA" rel="noopener ugc nofollow" target="_blank">在Twitter、Reddit和其他网站等微博社区中发现新兴话题</a></li><li id="da0b" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">观察<a class="ae ky" href="https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/8513750/&amp;hl=en&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;d=4295391264651091058&amp;ei=hnbcYL_lL9yLy9YPx5K8qAM&amp;scisig=AAGBfm3pApLB6HHUzQYFdX3loVfCiiu5_A" rel="noopener ugc nofollow" target="_blank">话题在一段时间内的演变</a></li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="a4f1" class="nn md it bd me no np dn mi nq nr dp mm li ns nt mo lm nu nv mq lq nw nx ms ny bi translated">最后的想法</h2><p id="a774" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">总的来说，尽管有许多方法可以进行主题建模，但是LDA已经发展成为最常用的方法。</p><p id="1efe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到它的局限性，许多混合方法后来被开发出来，以提高主题的准确性和相关性。这些方法经常挑战LDA的概率层次结构。</p><p id="61bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也开发了非LDA方法，然而，它们不太适合于简短形式的文本分析。</p><p id="bb16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在以后的一篇文章(本系列的第三部分)中，我将分析用于短文本的最佳主题建模和情感分析算法。</p></div></div>    
</body>
</html>