<html>
<head>
<title>Package PyTorch Models in a Self-Contained Format</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">以自包含格式打包PyTorch模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/package-pytorch-models-in-a-self-contained-format-badbe10b7ae5?source=collection_archive---------29-----------------------#2021-09-29">https://towardsdatascience.com/package-pytorch-models-in-a-self-contained-format-badbe10b7ae5?source=collection_archive---------29-----------------------#2021-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="281a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在机器之间移动你的模型，而不是Python代码。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8e3da556697c20157062297e4a927d47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ID_sgL0cw-2vUlKukkHsyQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克劳迪奥·施瓦茨在<a class="ae ky" href="https://unsplash.com/s/photos/package?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="4da3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch在2016年开始了它卑微的旅程，并迅速成为深度学习研究人员的首选工具。然而，PyTorch现在已经不仅仅是一个原型工具了。它已经发展成为一个成熟的生产就绪框架，正在扩大其在商业领域的粉丝基础。</p><p id="79e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">而这恰恰是它的创造者和维护者的目标；成为学术界和工业界的事实标准。研究人员和机器学习工程师应该能够高效地运行PyTorch，从本地Jupyter服务器到云平台，从多节点GPU集群到边缘的智能设备。</p><p id="b296" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，PyTorch在我看来有一个显著的缺点:它存储模型的方式。你会问，PyTorch模型的推荐存储方式是什么？一言以蔽之，你要保留的是模型的参数，而不是模型本身。从文档中:</p><blockquote class="lv lw lx"><p id="100c" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">当保存用于推理的模型时，只需要保存训练模型的学习参数。用<code class="fe mc md me mf b">torch.save()</code>函数保存模型的<em class="it"> state_dict </em>将为您以后恢复模型提供最大的灵活性，这就是为什么它是保存模型的推荐方法。</p></blockquote><p id="75cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">缺点是什么？您应该在服务器中再次定义模型的架构，反序列化<code class="fe mc md me mf b">state_dict</code>并将参数加载到模型中。如果您有办法将所有需要的东西打包到一个归档文件中，在服务器中解压缩，然后完成您的工作，这不是很好吗？好吧，我有一些好消息:现在你可以了！</p><blockquote class="lv lw lx"><p id="57ee" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><a class="ae ky" href="https://www.dimpo.me/newsletter?utm_source=medium&amp;utm_medium=article&amp;utm_campaign=torch_package" rel="noopener ugc nofollow" target="_blank">学习率</a>是为那些对AI和MLOps的世界感到好奇的人准备的时事通讯。你会在每周五收到我关于最新人工智能新闻和文章的更新和想法。在这里订阅<a class="ae ky" href="https://www.dimpo.me/newsletter?utm_source=medium&amp;utm_medium=article&amp;utm_campaign=torch_package" rel="noopener ugc nofollow" target="_blank"/>！</p></blockquote></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="2280" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">火炬.包装</h1><p id="cec3" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated"><code class="fe mc md me mf b"><em class="ly">torch.package</em></code>是一种将PyTorch模型打包成独立、稳定格式的新方法。包是一个档案，包括模型的参数和元数据以及它的架构。</p><p id="93e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，<code class="fe mc md me mf b">torch.package</code>增加了对创建包含任意PyTorch代码的密封包的支持。这意味着您可以使用它来打包您想要的任何东西(例如，PyTorch数据加载器、数据集等)。).</p><p id="9d48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一种很好的方式来重现您的训练结果，并使用您喜欢的工具为模型服务。</p><p id="3509" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么，让我们来看看如何使用这个强大的工具。</p><h2 id="69ac" class="nk mo it bd mp nl nm dn mt nn no dp mx li np nq mz lm nr ns nb lq nt nu nd nv bi translated">装置</h2><p id="257b" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated"><code class="fe mc md me mf b">torch.package</code>模块是核心PyTorch 1.9的一部分，所以我们首先需要检查并安装PyTorch的正确版本。使用下面的命令来完成此操作:</p><pre class="kj kk kl km gt nw mf nx ny aw nz bi"><span id="50af" class="nk mo it mf b gy oa ob l oc od">!pip uninstall -y torch<br/>!pip install -f https://download.pytorch.org/whl/test/cpu/torch_test.html torch</span></pre><h2 id="ada3" class="nk mo it bd mp nl nm dn mt nn no dp mx li np nq mz lm nr ns nb lq nt nu nd nv bi translated">包装你的模型</h2><p id="4095" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">在这个故事中，我们将使用<code class="fe mc md me mf b">torch.package</code>封装然后导入<a class="ae ky" href="https://pytorch.org/hub/facebookresearch_pytorch-gan-zoo_dcgan/" rel="noopener ugc nofollow" target="_blank">一个DCGAN模型</a>，可以用来生成时装模型。这个预先训练好的模型托管在火炬中心。要下载它，请复制下面的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="cef2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们来测试一下。使用下面的代码生成时装模特的随机图像，使用您刚刚下载的DCGAN:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="7a17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果应该是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/1050965e7da7ea83fd23f97e7c39072b.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*NGXL-k4TGH9mglo56Sl48g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="6bbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们包装模型。我们将创建<code class="fe mc md me mf b">PackageExporter</code>来创建一个归档文件，其中包含在另一台机器上运行模型所需的一切。为此，复制以下代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="1819" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行上面的代码会产生一个错误:</p><pre class="kj kk kl km gt nw mf nx ny aw nz bi"><span id="cc7c" class="nk mo it mf b gy oa ob l oc od">PackagingError:<br/>* Module did not match against any action pattern. Extern, mock, or intern it.<br/>models.DCGAN<br/>models.utils.config<br/>models.loss_criterions.ac_criterion     models.loss_criterions.base_loss_criterions     models.networks.DCGAN_nets</span></pre><p id="b50d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着什么？为了创建一个密封的包，<code class="fe mc md me mf b">PackageExporter</code>将试图访问将要被酸洗的模块和对象所需的所有依赖关系的源代码。</p><p id="4cda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在此过程中，它将跳过标记为<code class="fe mc md me mf b">extern</code>或<code class="fe mc md me mf b">mock</code>的依赖项，并将标记为<code class="fe mc md me mf b">intern</code>的依赖项包含在存档中。在这种情况下，我们需要包括<code class="fe mc md me mf b">models</code>。为此，请修改您的代码，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="b736" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们有另一个问题:</p><pre class="kj kk kl km gt nw mf nx ny aw nz bi"><span id="a28a" class="nk mo it mf b gy oa ob l oc od">PackagingError:<br/>* Module did not match against any action pattern. Extern, mock, or intern it.<br/>numpy</span></pre><p id="0ea8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，NumPy不是我们想要打包的模型的一部分。因此，我们可以安全地排除它:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="b289" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这个命令，您已经成功地创建了您的包！</p><h2 id="de9f" class="nk mo it bd mp nl nm dn mt nn no dp mx li np nq mz lm nr ns nb lq nt nu nd nv bi translated">加载您的模型</h2><p id="daf2" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">要将你的模型加载回内存，你应该使用<code class="fe mc md me mf b">PackageImporter</code>。这比以前简单；只需复制下面的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="972e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了测试一切工作正常，您可以再次调用您之前定义的<code class="fe mc md me mf b">run_model</code>函数并检查结果。一切都应该井然有序！</p><p id="f59e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，您可以使用这个<a class="ae ky" href="https://colab.research.google.com/drive/1lFZkLyViGfXxB-m3jqlyTQuYToo3XLo-" rel="noopener ugc nofollow" target="_blank"> colab </a>实验并运行完整的示例。</p><h1 id="b977" class="mn mo it bd mp mq oh ms mt mu oi mw mx jz oj ka mz kc ok kd nb kf ol kg nd ne bi translated">结论</h1><p id="5281" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">PyTorch在2016年开始了它卑微的旅程，并迅速成为深度学习研究人员的首选工具。然而，PyTorch现在已经不仅仅是一个原型工具了。它已经发展成为一个成熟的生产就绪框架，正在扩大其在商业领域的粉丝基础。</p><p id="d654" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，研究人员和ML工程师必须能够为本地Jupyter服务器到云平台，从多节点GPU集群到边缘智能设备高效运行PyTorch。</p><p id="bfcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了实现这一点，PyTorch 1.9引入了一种新的打包机制:模块<code class="fe mc md me mf b">torch.package</code>。</p><p id="0048" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个故事中，您看到了什么是<code class="fe mc md me mf b">torch.package</code>模块，以及如何使用它来保存和检索模型。玩得开心！</p><h1 id="4308" class="mn mo it bd mp mq oh ms mt mu oi mw mx jz oj ka mz kc ok kd nb kf ol kg nd ne bi translated">关于作者</h1><p id="ad5f" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">我叫<a class="ae ky" href="https://www.dimpo.me/?utm_source=medium&amp;utm_medium=article&amp;utm_campaign=torch_package" rel="noopener ugc nofollow" target="_blank">迪米特里斯·波罗普洛斯</a>，我是一名为<a class="ae ky" href="https://www.arrikto.com/" rel="noopener ugc nofollow" target="_blank">阿里克托</a>工作的机器学习工程师。我曾为欧洲委员会、欧盟统计局、国际货币基金组织、欧洲央行、经合组织和宜家等主要客户设计和实施过人工智能和软件解决方案。</p><p id="ff0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有兴趣阅读更多关于机器学习、深度学习、数据科学和数据运算的帖子，请在Twitter上关注我的<a class="ae ky" href="https://towardsdatascience.com/medium.com/@dpoulopoulos/follow" rel="noopener" target="_blank"> Medium </a>、<a class="ae ky" href="https://www.linkedin.com/in/dpoulopoulos/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ky" href="https://twitter.com/james2pl" rel="noopener ugc nofollow" target="_blank"> @james2pl </a>。</p><p id="7a60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所表达的观点仅代表我个人，并不代表我的雇主的观点或意见。</p></div></div>    
</body>
</html>