<html>
<head>
<title>Adapting to changes of data by building MLOps pipeline in Vertex AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Vertex AI中构建MLOps流水线以适应数据的变化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/adapting-to-changes-of-data-by-building-mlops-pipeline-in-vertex-ai-3f8ebd19a869?source=collection_archive---------7-----------------------#2021-08-11">https://towardsdatascience.com/adapting-to-changes-of-data-by-building-mlops-pipeline-in-vertex-ai-3f8ebd19a869?source=collection_archive---------7-----------------------#2021-08-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f802" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="f0ce" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">这篇文章展示了如何为物体检测任务建立一个机器学习管道。目的是演示如何使用Vertex AI的AutoML和Cloud函数实现MLOps来准备数据漂移情况。</h2></div><h1 id="aab8" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">动机</h1><p id="9c5c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我有一个三岁的女儿，我意识到她的脸每个月都在发生巨大的变化。谷歌照片已经在通过跟踪人们面部的变化来识别面部方面做得非常出色。然而，我想我可以更进一步，比如对她没有戴面具的照片进行分类，然后进行分层预测。这将是下一篇文章的主题。</p><p id="4c6f" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">此外，我认为这是MLOps的一个很好的例子，因为我和我的妻子像平常的父母一样给她拍了很多照片。这意味着我有足够的数据来建立一个模型，并且这些数据已经包含了潜在的数据漂移，因为我有她在婴儿、一岁、两岁时的照片。</p><h1 id="f9d5" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">构建管道和触发器</h1><p id="9260" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们需要Vertex AI、Google云存储、云功能来建立机器学习管道和触发器。Vertex AI不是一个单一的服务，而是许多不同的AI相关服务的组合。具体来说，这篇文章的项目利用了Vertex AI的数据集、AutoML、笔记本、管道、模型和端点特性。</p><p id="166f" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">图1显示了如何构建整个管道的分步说明。理解机器学习系统蓝图的最佳方式是考虑组成工作流的组件。让我们一个一个来。请记住，每个组件并不代表一个独立的作业，而是按顺序连接在一起。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/a7c70eff16587db682d34729129e5dad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HJP9KWImrg-1mn61"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图1 </strong>:管道设置——作者图片</p></figure><h2 id="f2d1" class="my kp iq bd kq mz na dn ku nb nc dp ky lp nd ne la lt nf ng lc lx nh ni le iw bi translated">数据准备</h2><p id="afa9" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">数据是机器学习的心脏，没有数据我们什么都做不了。所以，毫无疑问，我们首先需要准备数据集。Vertex AI提供了托管数据集功能。您可以简单地从本地存储中导入数据，或者如果您已经在现有的GCS存储桶中有了数据集，您可以只指向GCS位置。</p><p id="1606" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">然而，如你所知，数据本身是不够的。我们需要标签/注释。顶点AI数据集允许您在导入原始数据时直接导入标注。您只需要确保标签以建议的方式形成。你可以在这里找到如何根据数据类型制作自己的标签文件<a class="ae nj" href="https://cloud.google.com/vertex-ai/docs/datasets/datasets" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="df12" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">为了让您了解它的样子，下面显示了一个CSV格式的图像分类任务标签的示例(您也可以使用JSONL)。</p><pre class="mi mj mk ml gt nk nl nm nn aw no bi"><span id="4f14" class="my kp iq nl b gy np nq l nr ns">[ML_USE], GCS_FILE_PATH,[LABEL]</span></pre><p id="5908" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">您可以找到另一个CSV格式的对象检测示例。</p><pre class="mi mj mk ml gt nk nl nm nn aw no bi"><span id="eeee" class="my kp iq nl b gy np nq l nr ns">[ML_USE],GCS_FILE_PATH,[LABEL],[BOUNDING_BOX]*</span></pre><p id="f4cc" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在这里，您可以简单地忽略ML_USE，但是如果您想要手动地将数据分割成训练/验证/测试集，它可以是训练集、验证集或测试集。BOUNDING_BOX是8个值的列表，每两个是一对。所以你可以猜测它代表了边界框每条边的坐标。基本上，顺序必须遵循X_MIN，Y_MIN，X_MAX，Y_MIN，X_MAX，Y_MAX，X_MIN，Y_MAX。</p><h2 id="613f" class="my kp iq bd kq mz na dn ku nb nc dp ky lp nd ne la lt nf ng lc lx nh ni le iw bi translated">培养</h2><p id="f132" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">根据数据集训练模型有多种选择。这篇文章特别展示了如何利用顶点AI AutoML特性来实现MLOps。以下是我选择AutoML的三个原因。首先，我不必关心建模。我所要做的就是以AutoML能够识别的正确格式准备数据集。幸运的是，Vertex AI数据集与Vertex AI AutoML完美匹配，因此没有额外的工作量。</p><p id="06e6" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">第二，当数据集演变时，我们不能保证当前最先进的模型足够好。我们可能必须通过为数据工程、建模和超参数调整编写不同版本的代码来运行多个实验。AutoML主要显示顶级结果。这是因为内部算法可能会随着时间的推移由谷歌工程师修改和维护，它可能会保证我们几乎总是利用可靠的最先进的AutoML建模技术。</p><p id="d512" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">最后但同样重要的是，将顶点AI AutoML集成到顶点AI管道中是很简单的。Vertex AI Pipeline只是Kubeflow Pipeline的一个包装器服务，Google定义了一堆Kubeflow组件，平滑地融合到标准的Kubeflow Pipeline中。这意味着您可以在为自定义组件编写标准Python代码并连接它们的同时利用Vertex AI AutoML。</p><h2 id="7e81" class="my kp iq bd kq mz na dn ku nb nc dp ky lp nd ne la lt nf ng lc lx nh ni le iw bi translated">部署和监控</h2><p id="bad5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">部署可以被视为一个操作与两个独立的操作的组合，即模型导出和服务于端点。顶点AI通过顶点AI模型和端点支持这两者。顶点人工智能模型是一个中心位置，所有训练好的模型和它们的版本一起被管理。您可以使用指标查看训练结果，用它测试一个简单的预测。</p><p id="9e40" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">一旦您认为您已经准备好为真实世界的用户部署模型，您就可以用选择的模型创建一个端点。实际上，Vertex AI Endpoint管理的是Google Kubernetes引擎中模型的端点。这意味着您不必关心模型的可伸缩性。在企业的早期阶段，只能为几个节点提供服务，但是当企业变得太大而无法用几个节点处理用户请求时，这个数字会平稳增长。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/bc4b38845f479bf9218ec58d3d4bb7a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H3MQU-lgVlRlmkFO"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图2</strong>:Vertex AI端点的模型监控能力——作者图片</p></figure><p id="dc5c" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">Vertex AI Endpoint还提供了预测/秒、请求/秒、延迟和预测错误百分比的监控功能。您需要额外的努力来处理概念/数据漂移问题，但这足以查看预测请求中是否有错误，预测延迟是否超过预期，顶点AI的吞吐量是否不够。Vertex AI为表格模型和定制模型提供了额外的监控功能，以深入检查模型行为，但很可能在不久的将来会支持AutoML模型。</p><h2 id="003c" class="my kp iq bd kq mz na dn ku nb nc dp ky lp nd ne la lt nf ng lc lx nh ni le iw bi translated">管道和触发器</h2><p id="a9d0" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">您可以单独进行数据集创建、模型训练、端点实例化和模型部署。然而，更好的方法是构建一个管道，以一致的方式完成所有这些工作。AutoML很可能保证你有最好的模型。这意味着我们所要做的就是准备更多的数据，并在您目睹模型性能下降时触发管道。</p><p id="7261" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">那么什么可以触发流水线运行来学习新的数据集呢？当然，应该有一个事件监听系统来检测数据集中的变化。这就是云功能的用武之地。每当指定的GCS存储桶发生变化时，云功能可以监听修改事件。有了这种能力，我们可以在记录更多数据时简单地运行管道。</p><h1 id="a136" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">初始操作流程</h1><p id="5809" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">作为演示MLOps的初始阶段，我们需要一个基础数据集。如图3所示，创建数据集需要多个步骤。首先，您需要选择数据类型和任务类型。对于这个项目，我选择了“<strong class="li ja"><em class="nt"/></strong>”类别下的“图像目标检测”。其次，您可以从本地文件系统上传图像，或者如果您已经将图像上传到GCS bucket，您可以简单地选择它。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/92365fdf49753b78efdc68dd4717a4a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aijyGuUh2J6n6yP3"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图3 </strong>:创建顶点人工智能数据集——作者图片</p></figure><p id="5ffc" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">此外，如果您有一个额外的标签文件，您可以从与图3相同的UI上传它。对于这个项目，我没有任何标签，只是在上传了一堆图片后点击了“继续”。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nu"><img src="../Images/c3542d1b1156fe5fe1165c02fc7542e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfRl-oGL0bcBusnRMeGsog.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图4 </strong>:顶点人工智能数据集中的标记能力——作者图片</p></figure><p id="5067" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">幸运的是，顶点AI数据集在浏览器中提供了很好的标记工具，如图4所示。有了这个功能，我只需简单地拖放鼠标位置，就可以标记大约100张图像。这样做之后，您就有了一个完整的数据集，这意味着数据和相关联的标签都存储在GCS存储桶中。</p><p id="9e49" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">现在，我们已经准备好用数据集构建我们的初始管道。我们可以直接在终端或最喜欢的ide中编写管道代码，但是在Jupyter笔记本中运行初始管道通常是个好主意。因为它提供了一个很好的交互环境，我们可以通过反复修改代码来进行编辑和实验。此外，顶点人工智能笔记本可以让你忽略所有关于GCP授权过程的麻烦，因为它已经在GCP环境中运行。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/da497997946e080448583567676fefb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VB3xQ2hdahmUqhd9"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图5 </strong>:顶点AI管道中构建和运行管道的初始阶段——作者图片</p></figure><p id="10c7" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">图5显示了初始管道运行的工作流是如何在笔记本中进行的。作为第一步，我们需要导入必要的库并设置一些必需的变量，如下面的代码所示。</p><pre class="mi mj mk ml gt nk nl nm nn aw no bi"><span id="963d" class="my kp iq nl b gy np nq l nr ns"><strong class="nl ja">from</strong> google.cloud <strong class="nl ja">import</strong> aiplatform<br/><strong class="nl ja">from</strong> google_cloud_pipeline_components <strong class="nl ja">import</strong> aiplatform <strong class="nl ja">as </strong>gcc_aip</span><span id="3f77" class="my kp iq nl b gy nv nq l nr ns"><strong class="nl ja">from </strong>kfp.dsl <strong class="nl ja">import </strong>pipeline<br/><strong class="nl ja">from</strong> kfp.v2 <strong class="nl ja">import</strong> compiler<br/><strong class="nl ja">from</strong> kfp.v2.google.client <strong class="nl ja">import</strong> AIPlatformClient</span><span id="42d0" class="my kp iq nl b gy nv nq l nr ns">PROJECT_ID = “YOUR_GCP_PROJECT_ID”<br/>REGION = “GCP_REGION_TO_RUN_PIPELINE” <br/>PIPELINE_ROOT = “LOCATION_RUN_METADATA_IS_GOING_TO_BE_STORED”<br/>DATASET_META_PATH = “LOCATION_DATASET_METADATA_IS_STORED”</span></pre><p id="0d1b" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">我们需要三个五库三包。下面的两个代码示例展示了它们的用法。第一个代码块显示了如何定义包含三个管道组件的管道。注意<strong class="li ja"><em class="nt">@ component</em></strong>decorator用来表示函数管道是整个管道定义到Kubeflow管道的地方。我们可以用<strong class="li ja"><em class="nt">@ component</em></strong>decorator将三个组件分离成单独的函数，并在管道中挂钩。然而，我把所有东西都放在一个地方，以使这个示例尽可能简单。</p><p id="3b53" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated"><strong class="li ja"><em class="nt">ImageDatasetCreateOp</em></strong>组件用于导入我们通过顶点AI数据集定义的数据集。为了实例化这个组件，我们需要告诉三件事，即GCP项目ID、存储标签文件的GCS路径和任务类型。</p><pre class="mi mj mk ml gt nk nl nm nn aw no bi"><span id="080a" class="my kp iq nl b gy np nq l nr ns">@pipeline(name=”my-pipeline”)<br/><strong class="nl ja">def</strong> <strong class="nl ja">pipeline</strong>(project: str = PROJECT_ID):<br/>   ds_op = gcc_aip.ImageDatasetCreateOp(<br/>      project=project,<br/>      display_name=”DATASET_NAME_TO_APPEAR”,<br/>      gcs_source=DATASET_META_PATH,<br/>      import_schema_uri=\<br/>         aiplatform.schema.dataset.ioformat.image.bounding_box,<br/>   )</span><span id="3287" class="my kp iq nl b gy nv nq l nr ns">   training_job_run_op = gcc_aip.AutoMLImageTrainingJobRunOp(<br/>      project=project,<br/>      display_name=”my-daughter-od-training”,<br/>      prediction_type=”object_detection”,<br/>      model_type=”CLOUD”,<br/>      base_model=<strong class="nl ja">None</strong>,<br/>      dataset=ds_op.outputs[“dataset”],<br/>      model_display_name=”my-daughter-od-model”,<br/>      training_fraction_split=0.6,<br/>      validation_fraction_split=0.2,<br/>      test_fraction_split=0.2,<br/>      budget_milli_node_hours=20000,<br/>   )</span><span id="6ddd" class="my kp iq nl b gy nv nq l nr ns">   endpoint_op = gcc_aip.ModelDeployOp(<br/>      project=project, model=training_job_run_op.outputs[“model”]<br/>   )</span></pre><p id="eecb" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">下一个组件是<strong class="li ja"><em class="nt">autolimagetrainingjobrunop</em></strong>。这是每个图像相关任务的统一组件。如您所见，您可以在prediction_type参数中指定特定的任务类型。还要注意model_type设置为“<strong class="li ja"><em class="nt"/></strong>”。这告诉AutoML计算出要生成哪种结果模型。例如，如果你想得到一个低延迟的更轻的模型，你可以将model_type不同地设置为“<strong class="li ja"><em class="nt">CLOUD _ LOW _ LATENCY _ 1</em></strong>”。有多种选择，所以请查看API <a class="ae nj" href="https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.AutoMLImageTrainingJob" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多信息。对于这个项目，我只是把它作为标准的平均模型。</p><p id="cfad" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在<strong class="li ja"><em class="nt">autolimagetrainingjobrunop</em></strong>组件中还有三个参数需要考虑。您可以直接指定训练/验证/测试分割比率。尽管您可以在数据集准备阶段指定哪些图像应属于哪个数据集，但如果您在此组件中显式设置它们，它将忽略信息并根据比率随机分配数据。如果你不能自己决定拆分，这是一个很好的开始方式。<strong class="li ja"><em class="nt">buget _ milli _ node _ hours</em></strong>是何时停止训练的约束。因为如果你永远训练，AutoML可以无限增长模型的大小，你必须决定何时停止训练过程。否则，你将付出大量的金钱，却没有任何准确性的提高。最后，必须告诉AutoML将在哪个数据集上进行训练，这是通过dataset参数完成的。需要知道的重要一点是，数据集参数设置了<strong class="li ja"><em class="nt">ImageDatasetCreateOp</em></strong>和<strong class="li ja"><em class="nt">autolimagetrainingjobrunop</em></strong>之间的连接和依赖关系，因为训练作业必须在数据集创建操作之后执行。</p><p id="89b0" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">最后一个组件是<strong class="li ja">T17】ModelDeployOpT19】。尽管名称如此，但它能够创建端点并将训练好的模型部署到端点。我们可以显式地分别执行这两个操作，但是用一个组件来执行它们会更方便。您需要做的就是指定要部署什么模型，这是通过模型参数设置的。同样，该参数设置了<strong class="li ja"><em class="nt">autolimagetrainingjobrunop</em></strong>和<strong class="li ja"><em class="nt">ModelDeployOp</em></strong>之间的连接和依赖关系。</strong></p><pre class="mi mj mk ml gt nk nl nm nn aw no bi"><span id="025f" class="my kp iq nl b gy np nq l nr ns">compiler.Compiler().compile(<br/>   pipeline_func=pipeline, package_path=PIPELINE_SPEC_PATH<br/>)</span><span id="1e58" class="my kp iq nl b gy nv nq l nr ns">api_client = AIPlatformClient(project_id=PROJECT_ID, region=REGION)</span><span id="7ad0" class="my kp iq nl b gy nv nq l nr ns">response = api_client.create_run_from_job_spec(<br/> PIPELINE_SPEC_PATH,<br/> pipeline_root=PIPELINE_ROOT,<br/> parameter_values={“project”: PROJECT_ID},<br/>)</span></pre><p id="4a1a" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">管道完全定义好了，接下来我们要用<strong class="li ja"> <em class="nt">编译器来编译。编译器()。编译</em> </strong>方法。编译的作用是通过查找管道函数定义来构造管道规范。在管道规范中，记录了许多隐藏的部分，比如作业依赖关系、使用哪种云机器类型和哪个容器映像等等。通过指定<strong class="li ja"> <em class="nt"> package_path </em> </strong>参数，编译器在JSON文件中输出管道规范。有了JSON文件，运行管道所需要做的就是将JSON文件传递给Vertex AI客户端的<strong class="li ja"><em class="nt">create _ run _ from _ job _ spec</em></strong>方法。这对于流水线的自动触发和重用是非常重要的。</p><p id="7444" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">用JSON文件向Vertex AI发送请求后，您将拥有在Vertex AI管道中运行的初始管道。当管道运行完成时，您可以分别通过顶点AI模型、端点UI面板找到训练好的模型、端点以及部署到端点的模型。</p><h1 id="8ac2" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">观察意外的数据漂移</h1><p id="e203" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">构建一个简单的应用程序来将图像发送到端点以进行预测是很简单的，但是您可以使用Vertex AI Model中的测试功能轻松地测试您的模型。我使用这个特性是因为我可以在GCP控制台上很容易地看到预测的结果。</p><p id="fd58" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">为了测试模型应该不能像预期的那样检测到我女儿三岁时的脸，我给了模型一些图像，如图6所示。然而，我得到了意想不到的结果，模型已经成功地检测出她长大的脸。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nw"><img src="../Images/156409288d1dfaae8bacb195961d4d6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hPqyARZfkQRAgHRtJcIErw.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图6 </strong>:意外结果(1)。经过训练的模型在3岁时就能认出自己的脸，尽管这张脸是在婴儿的照片上训练出来的——作者的照片</p></figure><p id="2ee4" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">我继续用最近的图像测试这个模型，我意识到新冠肺炎疫情已经在去年发生了。我发现她的很多照片都戴着面具，也有一些照片戴着太阳镜。这是我最初对这个项目进行头脑风暴时的意外情况，我很快就将这种情况视为数据漂移问题。如图7所示，经过训练的模型捕捉到了错误的位置和不同孩子的脸。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nx"><img src="../Images/e43c5d32558d27c2a516078c2d4ad0ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JbeqznMU9_ixoL62WIzx8Q.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图7 </strong>:意想不到的结果(2)。有很多我没有预料到的图片——作者的图片</p></figure><p id="2e4d" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在收集和标记新数据后，可以手动运行管道。然而，如果能实现一个自动系统，在我们有新数据时触发管道运行，那就更好了，因为我们已经创建了JSON规范文件。</p><p id="f972" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">图8显示了发生数据漂移时的工作流程。你可以看到，我们不再需要Vertex AI笔记本了，流水线运行也不是直接从笔记本上执行的。相反，我们可以创建并部署一个小函数，在云函数上触发，它监听指定的GCS存储桶中的变化事件。需要注意的一点是，有一个单独的GCS桶用于存储最终数据集的元数据。逐个标注数据集时，元数据会频繁更改，您不希望每次更改时都运行管道。相反，当我们认为已经完成时，我们可以将最终的元数据文件导出到一个单独的GCS bucket中。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/fbd5ba863a70edb2407dbf984b0e19bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vEmPfVWjkERxw8LU"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图8 </strong>:发生数据漂移时的操作流程——作者图片</p></figure><p id="77e7" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">下面的代码块显示了云函数的所有代码。这很简单，因为我们已经有了管道规范JSON文件。每当属于一个指定的GCS桶的任何文件有任何改变时，vertex_ai_pipeline_trigger函数被调用。因此，我们需要编写一个简单的过滤条件语句。以下代码确保在导出时对顶点AI数据集支持的扩展名为<strong class="li ja"> <em class="nt"> jsonl </em> </strong>的文件进行任何更改时运行管道。</p><pre class="mi mj mk ml gt nk nl nm nn aw no bi"><span id="0822" class="my kp iq nl b gy np nq l nr ns"><strong class="nl ja">from</strong> kfp.v2.google.client <strong class="nl ja">import</strong> AIPlatformClient</span><span id="ff5e" class="my kp iq nl b gy nv nq l nr ns">PROJECT_ID = “YOUR_GCP_PROJECT_ID”<br/>REGION = “GCP_REGION_TO_RUN_PIPELINE” <br/>PIPELINE_ROOT = “LOCATION_RUN_METADATA_IS_GOING_TO_BE_STORED”<br/>PIPELINE_SPEC_PATH = “LOCATION_PIPELINE_SPEC_IS_STORED”</span><span id="3c23" class="my kp iq nl b gy nv nq l nr ns"><strong class="nl ja">def</strong> <strong class="nl ja">vertex_ai_pipeline_trigger</strong>(event, context):<br/>   print(‘File: {}’.format(event[‘name’]))<br/>   print(‘Extension: {}’.format(event[‘name’].split(“.”)[-1]))</span><span id="f87b" class="my kp iq nl b gy nv nq l nr ns">   <strong class="nl ja">if</strong> event[‘name’].split(“.”)[-1] == “jsonl”:<br/>      print(“target file extension”)</span><span id="cfd3" class="my kp iq nl b gy nv nq l nr ns">      api_client = AIPlatformClient(<br/>         project_id=PROJECT_ID, <br/>         region=REGION<br/>      )<br/>      print(“api_client is successfully instantiated”)</span><span id="6e4e" class="my kp iq nl b gy nv nq l nr ns">      response = api_client.create_run_from_job_spec(<br/>         PIPELINE_SPEC_PATH,<br/>         pipeline_root=PIPELINE_ROOT,<br/>         parameter_values={“project”: PROJECT_ID},<br/>      )<br/>      print(‘response: {}’.format(response))</span></pre><p id="f7fb" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在条件语句中，运行管道的代码与我们在笔记本部分看到的完全相同。你可能想知道我们是否需要额外的认证过程来从其他GCP服务访问Vertex AI。不过可以精简，因为云功能和Vertex AI都是GCP服务。</p><pre class="mi mj mk ml gt nk nl nm nn aw no bi"><span id="130c" class="my kp iq nl b gy np nq l nr ns">gcloud functions deploy YOUR_FUNCTION_NAME \<br/> — trigger-resource YOUR_TRIGGER_BUCKET_NAME \<br/> — trigger-event providers/cloud.storage/eventTypes/object.finzlize</span></pre><p id="1797" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在编写了包含上面代码块的python文件后，我们可以用下面的shell命令将其部署到Cloud Function。这个命令应该运行在python文件所在的同一个目录下，并且“<strong class="li ja"><em class="nt">YOUR _ FUNCTION _ NAME</em></strong>”应该与python文件中定义的实际函数名相匹配。请在官方<a class="ae nj" href="https://cloud.google.com/functions/docs/calling/storage" rel="noopener ugc nofollow" target="_blank">文档</a>中找到关于该命令的更多信息。此外，确保将requirements.txt包含在包含任何必要库的同一目录中。在这个项目中，包含了<strong class="li ja"><em class="nt">Google-cloud-AI platform</em></strong>来访问Vertex AI APIs。</p><h1 id="7a28" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">更新数据集以补充</h1><p id="9551" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">通过编写和部署云函数，收集和标记更多的数据，并将元数据导出到适当的GCS存储桶，就可以为更新的数据集获得新的模型。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ny"><img src="../Images/509b3fa4bd8034c0cd4fec2a94076b32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MxY3uPxr9_o0r_DCcwiU_A.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图9 </strong>:收集并标注更多数据以覆盖口罩佩戴情况—图片由作者提供</p></figure><p id="e4ea" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">图9显示我已经包含了更多我女儿戴面具的图片。我还附上了更多她最近拍摄的照片，以便模特能更好地认出她。</p><h1 id="ae4b" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">决赛成绩</h1><p id="e57d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">当点击右上角的导出元数据按钮时，云函数被触发，它自动触发管道。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nz"><img src="../Images/5189102058b6a289dc05e38399882ba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Q7fHCRwKWdoPNuYiPAIcw.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">图10 </strong>:模型被重新训练后，它识别所有预期的案例——作者图片</p></figure><p id="b589" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">图10显示了我用新收集的数据集得到的最终模型。正如你所看到的，它不仅能识别出我女儿在婴儿时期的脸，还能识别出她最近的脸，而且它还能成功地识别出她戴着面具的脸，即使照片中还有其他孩子。</p><h1 id="3541" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">结论</h1><p id="5ee7" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这篇文章中，我们通过一个实际的用例探索了如何用Vertex AI构建一个简单但可扩展的MLOps管道。Vertex AI允许您在浏览器中准备自己的数据集。你可以通过笔记本服务与顶点人工智能API进行交互。在修复了代码库之后，您可以运行初始管道并创建JSON规范文件，该文件包含了在没有实际代码的情况下如何运行管道的所有细节。最后，您可以将结合GCS的云函数与Vertex AI集成，以便在数据集发生任何变化时自动运行。</p></div></div>    
</body>
</html>