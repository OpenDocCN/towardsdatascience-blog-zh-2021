<html>
<head>
<title>Three Grand Challenges in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的三大挑战</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/three-grand-challenges-in-machine-learning-771e1440eafc?source=collection_archive---------16-----------------------#2021-10-28">https://towardsdatascience.com/three-grand-challenges-in-machine-learning-771e1440eafc?source=collection_archive---------16-----------------------#2021-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cb11" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">问题保证不会失去它们的味道。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/41ca3f033bfd4bdf05d76a4135d715f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ouTIoifRjexBwayU"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://unsplash.com/@polarmermaid?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">安妮·尼加德</a></p></figure><p id="4969" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习的世界不再像过去那样充满生机。对优化器、超参数和架构进行修补已经没有十年前那种开拓性的感觉了，而且选择一个问题空间来关注可能会令人生畏。由于<strong class="lb iu">扩展</strong>和<a class="ae ky" rel="noopener" target="_blank" href="/the-quiet-semi-supervised-revolution-edec1e9ad8c">半监督</a>和<strong class="lb iu">少量学习</strong>的进步，ML 取得了又一次巨大的飞跃，反思接下来哪些重大挑战值得我们共同关注，特别是<em class="lv">那些可能无法通过单独扩展解决的挑战</em>是很有趣的。这些都是雄心勃勃的问题，我怀疑这些问题不会通过渐进式进展或仅仅是更大的模型来解决，在这些问题上，积极的研究可能会产生最大的差异影响，即使是在预算方面。以下是三个，排名不分先后:</p><p id="0749" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">感知:逆向视频游戏问题</strong></p><p id="3d78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那些从事计算机视觉工作的人可能对<strong class="lb iu">逆向 3D 图形</strong>问题很熟悉:获取一个场景的感官输出(图像、视频)并对图形引擎渲染该场景所需的内容进行逆向工程:在 3D 坐标中解析每个对象和场景元素(地板、墙壁)，并为纹理和照明信息加分。</p><p id="efb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这个问题通常被视为计算机视觉的本质，但我认为它还不足以描述其实际目标。特别是，它没有结合我们希望从感知系统中获得的两个非常重要的特征，即<strong class="lb iu">语义</strong>和<strong class="lb iu">未来预测</strong>。</p><p id="30da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">语义是一个明显的例子:我们关心的是<strong class="lb iu">什么</strong>，而不仅仅是<strong class="lb iu">在哪里</strong>。未来预测更加微妙，因为它与计算机视觉作为<strong class="lb iu">状态估计</strong>的核心目的有关:计算机视觉通常作为<a class="ae ky" href="https://worldmodels.github.io/" rel="noopener ugc nofollow" target="_blank">世界模型</a>有用，这是一种代理用来计划未来行动的表示。世界是动态的:事物在移动，人们在走动，任何使用你的感官来估计世界的状态都需要考虑到环境可能的变化。<strong class="lb iu">行为预测</strong>，理解一个场景的物理和社会动态，是问题的固有部分，通常与非常微妙的视觉线索联系在一起，帮助通知这些预测。它也是所有机器人应用的关键，特别是自动驾驶汽车，它需要能够推理场景中每个智能体的意图。</p><p id="090d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是为什么我把感知的巨大挑战称为<strong class="lb iu">逆向视频游戏</strong>问题:不仅预测静态场景，还预测其功能语义和可能的未来。你应该能够拍摄一段视频，通过你的计算机视觉模型运行它，得到一个场景的表示，你不仅可以解析它，还可以像视频游戏引擎一样，从任何角度及时向前滚动，生成可信的未来行为。它将尊重物理学(射向目标的球将遵循其正常轨迹)、语义学(桌子可以移动，门可以打开)和场景中的代理(人、汽车将有合理的<a class="ae ky" href="https://en.wikipedia.org/wiki/Non-player_character" rel="noopener ugc nofollow" target="_blank"> NPC </a>行为)。</p><p id="839d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算机视觉挑战的这种框架也是对计算机视觉中不幸趋势的一种很好的解毒剂，这种趋势主要集中在<strong class="lb iu">相机框架</strong>而不是<strong class="lb iu">世界框架</strong>中的推理:知道我的传感器上的这个像素是猫的像素远不如能够在世界坐标中定位猫有用。它还让我们更接近利用计算机视觉的进步来端到端地学习下游任务。3D、增强现实和视频也变得越来越容易获得，像<a class="ae ky" href="https://paperswithcode.com/method/nerf" rel="noopener ugc nofollow" target="_blank"> NeRF </a>这样的进步开始以一种可分解的方式将 3D 感知的所有组件真正联系在一起。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="bea5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">语义:基于常识的语言理解</p><p id="c02f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这个世界似乎指责像伯特和 GPT-3 这样的“大型”语言模型产生了无意义的，往往是滑稽的，有时是冒犯性的声明，但退一步考虑这里可能有一个归因错误是有用的:以前的语言模型同样有偏见和问题，但它们全面的糟糕掩盖了这种影响，使它们能够避开公众的审查。</p><p id="ccf6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">问题是他们变好了。非常好。而我们自然语言工具包的其余部分，也就是将这些模型与现实世界联系起来的部分，并没有跟上步伐。<a class="ae ky" href="https://en.wikipedia.org/wiki/Knowledge_graph" rel="noopener ugc nofollow" target="_blank">知识图表</a>作为验证事实的来源没有跟上步伐。<strong class="lb iu">多模态学习</strong>作为一种基础来源还没有跟上步伐。<strong class="lb iu">常识推理</strong>还没跟上。我们今天的巨大挑战是纠正这一点:找到新的、可扩展的方法来将这些语言模型锚定在现实中，向它们灌输常识和逻辑，并确保它们的世界观基于事实而不是互联网迷因。如果像<a class="ae ky" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"> Dall-E </a>和<a class="ae ky" href="https://openai.com/blog/openai-codex/" rel="noopener ugc nofollow" target="_blank"> Codex </a>这样的实验有任何启示的话，那么可能有许多未被探索的方法来整合信息来源，在不牺牲规模的情况下为语言提供结构和基础。我无法想象今天对 NLU 来说还有比这更重要、更紧迫的目标，否则我们将面临<a class="ae ky" rel="noopener" target="_blank" href="/artificial-special-idiocy-cae849c014e1">人工特殊白痴</a>——人工通用智能不太为人所知的表亲——在这一领域获得永久优势的风险。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="6a76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">推理:在风险和长期视野下做出决策</strong></p><p id="e0bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管在过去的几年里投入了令人难以置信的集体精力，强化学习仍然很难。我越来越多地将我们在该领域缺乏实际进展归咎于对模拟基准的关注，因为它们掩盖了现实世界决策制定面临的许多关键挑战:</p><p id="44de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">不确定性下的推理</strong>是一个显而易见的问题:完美的状态知识在实践中永远无法获得，不确定性因其对任何依赖于环境反馈的足够“聪明”的决策系统的连锁灾难性影响而臭名昭著。真实的观察是嘈杂的，在干扰物的海洋中包含很少与任务相关的信息，并且你采取的行动很少会让你准确地到达你认为它们会到达的地方。现实世界的过程通常既不是完全可观测的，也不是马尔可夫的。研究简化的模型是没问题的，除非你从研究范围中剔除的是问题的本质。</p><p id="9180" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">风险</strong>和<strong class="lb iu">安全</strong>让不确定性问题变得更加困难，因为他们通常不可能对<a class="ae ky" href="https://en.wikipedia.org/wiki/Black_swan_theory" rel="noopener ugc nofollow" target="_blank">进行分布式推理</a>。管理它们通常涉及到在问题定义中引入硬约束:你不能观察或训练不安全的事件，你必须在熟悉的 ML 数据驱动框架之外对它们进行推理。我们现代的全可微 ML 工具包讨厌约束:我们喜欢可以反向传播的平滑损失函数，我们可以直接使<a class="ae ky" href="https://github.com/google/brax" rel="noopener ugc nofollow" target="_blank">可微，间接使</a><a class="ae ky" href="https://arxiv.org/abs/1903.02993" rel="noopener ugc nofollow" target="_blank">可微，或者隐式使</a><a class="ae ky" href="https://arxiv.org/abs/2109.00137" rel="noopener ugc nofollow" target="_blank">可微。但是安全很难被顺利地推理出来，尽管它经常是在实践中阻止自动决策部署的关键因素。</a></p><p id="1f25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">长期视野</strong>通常是天真的“折扣奖励”决策框架崩溃的地方，也是经典规划(随机或组合搜索)大放异彩的地方。经典的规划方法，因为它们通常被公式化为一个优化问题，倾向于完全避免将一般化作为一级目标，结果经常过度适应问题的特定实例。他们也不总是进行端到端的培训，而这是对复杂系统进行微调的关键能力。如果我们希望解决终身学习的整体问题，我们需要找到更好的方法来共同思考概括和长期规划。</p><p id="424d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于那些实现起来非常缓慢的简单效应的推理来说，长时间的视野也是一个挑战:对于复杂的过程来说，比如说，涉及到人们的偏好和习惯，通常只需要几个月或几年的时间常数就能达到它们的固定点。天真的探索，甚至是在这个尺度上通过时间进行反向传播，通常都是不切实际的:很难进行许多年的实验，或者对这样长期的纵向数据进行干预。这对于我们做出明智决策的能力有着直接和重大的影响，当考虑到所有长期影响时，这些决策可能会产生深远的社会影响。这也是为什么最近几年<a class="ae ky" href="https://danieltakeshi.github.io/2020/06/28/offline-rl/" rel="noopener ugc nofollow" target="_blank">的离线 RL </a>方法引起了如此大的兴趣，因为它们有望解除一些与长期强化相关的系统级复杂性。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="ab52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从科学好奇心和潜在社会影响的角度来看，我想不出今天还有什么更重要、更根本的问题需要解决。这就是为什么我也认为机器人学和 ML 的<strong class="lb iu">交叉点的研究是如此相关，不考虑它对机器人产业的直接影响。这是所有这些挑战的缩影:现实世界 3D 视觉最无情的基准，作为接地最终来源的智能的物理体现，以及在风险和不确定性下进行长期规划的复杂案例研究。</strong></p></div></div>    
</body>
</html>