<html>
<head>
<title>Fast AutoML with FLAML + Ray Tune</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有火焰+光线调节的快速自动控制</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-automl-with-flaml-ray-tune-64ff4a604d1c?source=collection_archive---------9-----------------------#2021-08-25">https://towardsdatascience.com/fast-automl-with-flaml-ray-tune-64ff4a604d1c?source=collection_archive---------9-----------------------#2021-08-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="cc29" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="383c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">微软研究人员已经开发了<a class="ae ko" href="https://github.com/microsoft/FLAML" rel="noopener ugc nofollow" target="_blank"> FLAML(快速轻量级AutoML) </a>，它现在可以利用<a class="ae ko" href="https://docs.ray.io/en/master/tune/tutorials/overview.html" rel="noopener ugc nofollow" target="_blank">射线调整</a>进行分布式超参数调整，以在集群上扩展FLAML的资源高效&amp;易于并行化的算法</h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/580cc031164310887f2434368f08f7c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ndil4UUgV7HDDE6w.gif"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">FLAML的算法之一CFO调整XGBoost的叶子数和树数。这两个热图显示了所有配置的损失和成本分布。黑点是在CFO中评估的点。由线连接的黑点是在评估时产生更好损耗性能的点(图片由作者提供)。</p></figure><p id="0ab6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">作者</strong> : <a class="ae ko" href="https://twitter.com/qingyun_wu" rel="noopener ugc nofollow" target="_blank">吴青云</a>，<a class="ae ko" href="https://www.linkedin.com/in/chi-wang-49b15b16/" rel="noopener ugc nofollow" target="_blank">王驰</a>，<a class="ae ko" href="https://www.linkedin.com/in/yard1/" rel="noopener ugc nofollow" target="_blank">安东尼·鲍姆</a>，<a class="ae ko" href="https://twitter.com/richliaw" rel="noopener ugc nofollow" target="_blank">理查德·廖</a>和<a class="ae ko" href="https://twitter.com/GalarnykMichael" rel="noopener ugc nofollow" target="_blank">迈克尔·加拉内克</a></p><p id="c26b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae ko" href="https://github.com/microsoft/FLAML" rel="noopener ugc nofollow" target="_blank"> FLAML </a>是微软研究院的一个轻量级Python库，它使用<a class="ae ko" href="https://arxiv.org/abs/2005.01571" rel="noopener ugc nofollow" target="_blank">尖端</a>算法，以一种高效且经济的方式找到精确的机器学习模型，该算法旨在节省资源并易于并行化。FLAML还可以利用<a class="ae ko" href="https://docs.ray.io/en/master/tune/index.html" rel="noopener ugc nofollow" target="_blank">光线调整</a>进行分布式超参数调整，以在集群中扩展这些AutoML方法。</p><p id="8414" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇博客强调了:</p><ul class=""><li id="a4c7" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">对经济的自动化方法的需求</li><li id="af6c" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">带火焰的经济型汽车</li><li id="5aa1" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">如何使用光线调节来扩展FLAML的优化算法</li></ul><h1 id="b684" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">经济型自动化方法的需求</h1><p id="d7ed" class="pw-post-body-paragraph lf lg iq lh b li nh ka lk ll ni kd ln lo nj lq lr ls nk lu lv lw nl ly lz ma ij bi translated">众所周知，AutoML是一项耗费资源和时间的操作，因为它需要反复试验才能找到性能良好的超参数配置。由于可能的配置值的空间通常非常大，因此需要一种经济的AutoML方法来更有效地搜索它们。</p><p id="cdea" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">AutoML中超参数搜索的高资源和时间消耗归结于以下两个因素:</p><ol class=""><li id="6242" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma nm mh mi mj bi translated">需要大量候选超参数配置(试验)来寻找性能良好的配置</li><li id="b509" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma nm mh mi mj bi translated">每个超参数的高“评估”成本，因为评估涉及用给定的训练数据训练和验证机器学习模型。</li></ol><p id="f851" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了解决这两个因素，微软的研究人员开发了<a class="ae ko" href="https://github.com/microsoft/FLAML" rel="noopener ugc nofollow" target="_blank"> FLAML </a>(快速轻量级AutoML)。</p><p id="44e9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">什么是FLAML？</strong></p><p id="5f12" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">FLAML是一个新发布的库，包含最先进的超参数优化算法。FLAML利用搜索空间的结构来同时优化成本和模型性能。它包含由微软研究院开发的两种新方法:</p><ul class=""><li id="a5f5" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">成本节约优化(CFO)</li><li id="e1c7" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">混合搜索</li></ul><p id="baaa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">成本节约优化(CFO)是一种以成本感知方式进行搜索过程的方法。该搜索方法从低成本的初始点开始，并逐渐向更高成本的区域移动，同时优化给定的目标(如模型损失或精度)。</p><p id="a4f7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Blendsearch是CFO的扩展，结合了CFO的节俭和贝叶斯优化的探索能力。像CFO一样，BlendSearch需要一个低成本的初始点作为输入(如果这样的点存在)，并从那里开始搜索。然而，与CFO不同，BlendSearch不会等待本地搜索完全收敛后再尝试新的起点。</p><p id="bf44" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">FLAML中的经济HPO方法受到两个关键见解的启发:</p><ol class=""><li id="988f" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma nm mh mi mj bi translated">许多机器学习算法具有超参数，这些超参数会导致训练成本的巨大变化。例如，有10棵树的XGBoost模型比有1000棵树的模型训练起来要快得多。</li><li id="9089" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma nm mh mi mj bi translated">参数的“成本”通常是“连续和一致的”——评估树=10比评估树=100更便宜，树= 100本身比评估树=500更便宜。</li></ol><p id="d4fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">总之，这些见解提供了关于成本空间中超参数的有用的<em class="nn">结构信息</em>。这些方法，即CFO和BlendSearch，能够有效地利用这些见解来降低沿途发生的成本，而不影响收敛到最优解。</p><p id="6ba5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">【FLAML管用吗？</p><p id="002c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在最新的<a class="ae ko" href="https://openml.github.io/automlbenchmark/" rel="noopener ugc nofollow" target="_blank"> AutoML基准测试</a>中，<a class="ae ko" href="https://arxiv.org/pdf/1911.04706.pdf" rel="noopener ugc nofollow" target="_blank"> FLAML </a>能够在超过62%的任务上仅使用10%的计算资源实现与最先进的AutoML解决方案相同或更好的性能。</p><p id="1691" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">FLAML的性能归功于其经济的优化方法。新的HPO方法(CFO，BlendSearch)利用搜索空间的结构来选择搜索顺序，以获得良好的性能和低成本。在预算有限的情况下，这可以大大提高搜索效率。</p><p id="3627" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">图1显示了从FLAML和最先进的超参数调节库<a class="ae ko" href="https://github.com/optuna/optuna" rel="noopener ugc nofollow" target="_blank"> Optuna </a>获得的典型结果，用于调节具有9维超参数的LightGBM。你可以看到FLAML能够在更短的时间内实现更好的解决方案。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi no"><img src="../Images/89bec8cd49d617511b417c85c9c2d7cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*hQ-tC3Gw4ioxzp6U.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图一。在<a class="ae ko" href="https://www.openml.org/d/23517" rel="noopener ugc nofollow" target="_blank">分类数据集</a>上调整LightGBM的验证损失(1-auc)曲线。线条和阴影区域显示了10次运行的验证损失的平均值和标准偏差。该图中的结果是在没有并行化的情况下从1个cpu的实验中获得的(图片由作者提供)。</p></figure><p id="120a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面的代码示例展示了如何用几行代码开始使用FLAML(假设提供了训练数据集并保存为<code class="fe np nq nr ns b">X_train</code>、<code class="fe np nq nr ns b">y_train</code>)。任务是用60秒的时间预算调整LightGBM模型的超参数。</p><pre class="kq kr ks kt gt nt ns nu nv aw nw bi"><span id="a1f2" class="nx mq iq ns b gy ny nz l oa ob"><strong class="ns ja">from</strong> flaml <strong class="ns ja">import</strong> AutoML<br/>automl = AutoML()<br/>automl.fit(X_train=X_train, y_train=y_train, time_budget=60, estimator_list=['lgbm'])<br/><br/>''' retrieve best model and best configuration found'''<br/>print('Best ML model:', automl.model)<br/>print('Best hyperparameter config:', automl.best_config)</span></pre><p id="6bb9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这个例子中，我们在默认的搜索空间中搜索LightGBM，FLAML中已经提供了这个搜索空间。FLAML提供了丰富的定制选项，如学习者类别、搜索空间、评估标准等。</p><h1 id="edaa" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">演练示例</h1><p id="7024" class="pw-post-body-paragraph lf lg iq lh b li nh ka lk ll ni kd ln lo nj lq lr ls nk lu lv lw nl ly lz ma ij bi translated">现在我们用一个玩具例子来展示CFO在用两个超参数调优XGBoost时的成本节约行为:树的数量和叶的数量。</p><pre class="kq kr ks kt gt nt ns nu nv aw nw bi"><span id="1577" class="nx mq iq ns b gy ny nz l oa ob">'''create an XGBoost learner class with a customized search space'''<br/><strong class="ns ja">from</strong> flaml.model <strong class="ns ja">import</strong> XGBoostSklearnEstimator<br/><strong class="ns ja">from</strong> flaml <strong class="ns ja">import</strong> tune<br/><br/><strong class="ns ja">class</strong> <strong class="ns ja">MyXGB</strong>(XGBoostSklearnEstimator):<br/>​​    '''XGBoostSklearnEstimator with a customized search space'''<br/>    @classmethod<br/>    <strong class="ns ja">def</strong> <strong class="ns ja">search_space</strong>(cls, data_size, **params):<br/>        upper = min(2**15, int(data_size))<br/>        <strong class="ns ja">return</strong> {<br/>            'n_estimators': {<br/>                'domain': tune.lograndint(lower=4, upper=upper),<br/>                'low_cost_init_value': 4,<br/>            },<br/>            'max_leaves': {<br/>                'domain': tune.lograndint(lower=4, upper=upper),<br/>                'low_cost_init_value': 4,<br/>            },<br/>        }<br/><br/>'''Use CFO in FLAML to tune XGBoost'''<br/><strong class="ns ja">from</strong> flaml <strong class="ns ja">import</strong> AutoML<br/>automl = AutoML()<br/>automl.add_learner(learner_name='my_xgboost', learner_class=MyXGB)<br/>automl.fit(X_train=X_train, y_train=y_train, time_budget=15, estimator_list=['my_xgboost'], hpo_method='cfo')</span></pre><h1 id="c1df" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">CFO和BlendSearch如何工作</h1><p id="9bf8" class="pw-post-body-paragraph lf lg iq lh b li nh ka lk ll ni kd ln lo nj lq lr ls nk lu lv lw nl ly lz ma ij bi translated">下面两张gif分别演示了CFO在损失和评估成本(即评估时间)空间的搜索轨迹。CFO从一个低成本的初始点(通过搜索空间中的<code class="fe np nq nr ns b">low_cost_init_value</code>指定)开始，并按照其随机化的局部搜索策略执行局部更新。采用这样的策略，CFO可以快速向低损耗区移动，表现出良好的收敛特性。此外，CFO倾向于避免探索高成本区域，直到必要时。该搜索策略进一步基于<a class="ae ko" href="https://arxiv.org/abs/2005.01571" rel="noopener ugc nofollow" target="_blank">可证明的收敛速度和期望的有界成本</a>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/580cc031164310887f2434368f08f7c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ndil4UUgV7HDDE6w.gif"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图二。CFO在为XGBoost调整树叶的数量和树的数量。这两个热图显示了所有配置的损失和成本分布。黑点是在CFO中评估的点。由线连接的黑点是在评估时产生更好损耗性能的点(图片由作者提供)。</p></figure><p id="7882" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">BlendSearch进一步将CFO中使用的这种局部搜索策略与全局搜索相结合。它利用了CFO的节俭和贝叶斯优化等全局搜索方法的空间探索能力。具体来说，BlendSearch维护一个全局搜索模型，并根据全局模型提出的超参数配置，随着时间的推移逐渐创建局部搜索线程。它进一步根据实时性能和成本来区分全局搜索线程和多个局部搜索线程的优先级。它可以进一步提高CFO在具有复杂搜索空间(例如，包含多个不相交、不连续子空间的搜索空间)的任务中的效率。</p><h1 id="292b" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">FLAML与贝叶斯优化性能</h1><p id="53b0" class="pw-post-body-paragraph lf lg iq lh b li nh ka lk ll ni kd ln lo nj lq lr ls nk lu lv lw nl ly lz ma ij bi translated">图3显示了FLAML中经济的HPO方法的典型行为(CFO在该图中标记为“LS ”),对比了使用11个超参数调整XGBoost的贝叶斯优化(BO)方法。</p><p id="c2f4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从图3(a)中，我们观察到BO中建议配置的评估时间可能非常长。当总资源有限时，例如1个cpu小时(或更少)，BO不能给出令人满意的结果(图3(b))。</p><p id="ad64" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">FLAML的CFO(标记为LS)和BlendSearch在快速找到好的配置方面具有明显的优势:它们能够专注于具有低评估时间的配置，同时导航具有良好性能(即低损失)的配置。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/16470c0c468f4d931df98b9615b6e056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*djfSKKtGmNIat0Fn.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图3。(a)是由不同方法提出的超参数配置的散点图，x轴和y轴是评估时间和损失。超参数配置的评估时间是在训练数据上使用超参数配置训练机器学习模型并在验证数据集上验证其性能所花费的时间。这种损失就是验证损失。(b)显示了在挂钟时间内通过不同方法获得的最佳损耗。(<a class="ae ko" href="https://openreview.net/pdf?id=VbLH04pRA3" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><h1 id="642c" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">如何利用Ray Tune的分布式调优来扩展CFO和BlendSearch</h1><p id="0f80" class="pw-post-body-paragraph lf lg iq lh b li nh ka lk ll ni kd ln lo nj lq lr ls nk lu lv lw nl ly lz ma ij bi translated">为了加速超参数优化，您可能想要并行化<strong class="lh ja"> </strong>您的超参数搜索。例如，BlendSearch能够在并行设置中很好地工作:它利用多个搜索线程，这些线程可以独立执行，而不会明显降低性能。对于诸如贝叶斯优化的现有优化算法来说，这种期望的特性并不总是真实的。</p><p id="4d29" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了实现并行化，FLAML与Ray Tune进行了集成。Ray Tune是一个Python库，通过允许您大规模利用尖端优化算法来加速超参数调整。Ray Tune还允许您将超参数搜索从笔记本电脑扩展到集群，而无需更改代码。您可以在FLAML中使用光线调节，或者在光线调节中运行FLAML的超参数搜索方法，以并行化您的搜索。下面的代码示例展示了前一种用法，只需在FLAML中配置<code class="fe np nq nr ns b">n_concurrent_trials</code>参数即可实现。</p><pre class="kq kr ks kt gt nt ns nu nv aw nw bi"><span id="8967" class="nx mq iq ns b gy ny nz l oa ob">'''Use BlendSearch for hyperparameter search, and Ray Tune for parallelizing concurrent trials (when n_concurrent_trials &gt; 1) in FLAML to tune XGBoost'''<br/><strong class="ns ja">from</strong> flaml <strong class="ns ja">import</strong> AutoML<br/>automl = AutoML()<br/>automl.add_learner(learner_name='my_xgboost', learner_class=MyXGB)<br/>automl.fit(X_train=X_train, y_train=y_train, time_budget=15, estimator_list=['my_xgboost'], hpo_method='bs', n_concurrent_trials=8)</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi no"><img src="../Images/afac1c373a5fc63e6f161e097fb87285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*egZ5O6Rdzrl_5Hon.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">Logo来源(<a class="ae ko" href="https://github.com/dmlc/xgboost" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>、<a class="ae ko" href="https://github.com/microsoft/FLAML" rel="noopener ugc nofollow" target="_blank"> FLAML </a>、<a class="ae ko" href="https://github.com/ray-project/ray" rel="noopener ugc nofollow" target="_blank"> Ray Tune </a>)</p></figure><p id="c0dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面的代码显示了后一种用法，这是一个如何将BlendSearch与Ray Tune结合使用的端到端示例。</p><pre class="kq kr ks kt gt nt ns nu nv aw nw bi"><span id="5b22" class="nx mq iq ns b gy ny nz l oa ob"><strong class="ns ja">from</strong> ray <strong class="ns ja">import</strong> tune <br/><strong class="ns ja">from</strong> flaml <strong class="ns ja">import</strong> CFO, BlendSearch<br/><strong class="ns ja">import</strong> time<br/><br/><strong class="ns ja">def</strong> <strong class="ns ja">training_func</strong>(config):<br/>    '''evaluate a hyperparameter configuration'''<br/>    # we use a toy example with 2 hyperparameters<br/>    metric = (round(config['x'])-85000)**2 - config['x']/config['y']<br/><br/>    # usually the evaluation takes a non-neglible cost<br/>    # and the cost could be related to certain hyperparameters<br/>    # in this example, we assume it's proportional to x<br/>    time.sleep(config['x']/100000)<br/>    # use tune.report to report the metric to optimize    <br/>    tune.report(metric=metric) <br/><br/># provide the search space<br/>search_space = {<br/>        'x': tune.lograndint(lower=1, upper=100000),<br/>        'y': tune.randint(lower=1, upper=100000)<br/>    }<br/><br/># provide the low cost partial config<br/>low_cost_partial_config={'x':1}<br/><br/># set up BlendSearch<br/>blendsearch = BlendSearch(<br/>    metric="metric", mode="min",<br/>    space=search_space,<br/>    low_cost_partial_config=low_cost_partial_config)<br/><br/>blendsearch.set_search_properties(config={"time_budget_s": 60})<br/><br/>analysis = tune.run(<br/>    training_func,    # the function to evaluate a config<br/>    config=search_space,<br/>    metric='metric',    # the name of the metric used for optimization<br/>    mode='min',         # the optimization mode, 'min' or 'max'<br/>    num_samples=-1,    # the maximal number of configs to try, -1 means infinite<br/>    time_budget_s=60,   # the time budget in seconds<br/>    local_dir='logs/',  # the local directory to store logs<br/>    search_alg=blendsearch  # or cfo<br/>    )<br/><br/>print(analysis.best_trial.last_result)  # the best trial's result<br/>print(analysis.best_config)  # the best config</span></pre><p id="5301" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其他关键光线调节功能包括:</p><ul class=""><li id="2344" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">与Tensorboard和重量/偏差等实验跟踪工具自动集成</li><li id="54be" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">对GPU的支持</li><li id="cc35" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">提前停止</li><li id="a00d" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">一个scikit-learn API，可以轻松地与<a class="ae ko" href="https://www.anyscale.com/blog/distributed-xgboost-training-with-ray" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>、<a class="ae ko" href="https://www.anyscale.com/blog/introducing-distributed-lightgbm-training-with-ray" rel="noopener ugc nofollow" target="_blank"> LightGBM </a>、<a class="ae ko" href="https://github.com/ray-project/tune-sklearn" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>等集成。</li></ul><h1 id="06e6" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">基准测试结果</h1><p id="802a" class="pw-post-body-paragraph lf lg iq lh b li nh ka lk ll ni kd ln lo nj lq lr ls nk lu lv lw nl ly lz ma ij bi translated">我们进行了一项实验，以检查BlendSearch在高度并行化的设置中与Optuna(使用多变量TPE采样器)和随机搜索相比表现如何。我们使用了来自<a class="ae ko" href="https://www.openml.org/s/218" rel="noopener ugc nofollow" target="_blank"> AutoML基准</a>的12个数据集的子集。使用ROC-AUC(多类数据集的加权一对一对比)使用三重交叉验证，平行进行16次试验，每次优化运行20分钟。用不同的随机种子重复运行三次。复制代码可以在这里找到<a class="ae ko" href="https://github.com/Yard1/Blendsearch-on-Ray-benchmark" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi no"><img src="../Images/fe786b974f967de16947c866f9b1c860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*N-y0YbBsbkvUrOiS.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><p id="828b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">BlendSearch在12个数据集的6个中获得了最佳交叉验证分数。此外，BlendSearch比随机搜索平均提高了2.52%，而Optuna的平均提高为1.96%。值得注意的是，BlendSearch使用单变量Optuna-TPE作为其全局搜索器——使用多变量TPE最有可能进一步提高分数。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/1afb48a4e4c52d232b0f2e09fa155285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SnPL5Jzz-tuyoLtb.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><p id="28bb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，由于其成本节约的方法，BlendSearch在相同的时间限制内，平均评估的试验次数是其他搜索者的两倍。这表明BlendSearch和其他算法之间的差距将随着时间预算的增加而增加。</p><h1 id="f071" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">结论</h1><p id="2270" class="pw-post-body-paragraph lf lg iq lh b li nh ka lk ll ni kd ln lo nj lq lr ls nk lu lv lw nl ly lz ma ij bi translated">FLAML是一个新发布的库，包含<a class="ae ko" href="https://arxiv.org/abs/2005.01571" rel="noopener ugc nofollow" target="_blank">最先进的</a>超参数优化算法，该算法利用搜索空间的结构来同时优化成本和模型性能。FLAML还可以利用<a class="ae ko" href="https://docs.ray.io/en/latest/tune/index.html" rel="noopener ugc nofollow" target="_blank">射线调优</a>进行分布式超参数调优，从而在集群中扩展这些经济的AutoML方法。</p><p id="0803" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有关FLAML的更多信息，请参见<a class="ae ko" href="https://github.com/microsoft/FLAML" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>和<a class="ae ko" href="http://aka.ms/flaml" rel="noopener ugc nofollow" target="_blank">项目页面</a>。如果你想了解雷的最新消息，可以考虑<a class="ae ko" href="https://twitter.com/raydistributed" rel="noopener ugc nofollow" target="_blank">关注twitter上的@ Ray distributed</a>和<a class="ae ko" href="https://anyscale.us5.list-manage.com/subscribe?u=524b25758d03ad7ec4f64105f&amp;id=d94e960a03" rel="noopener ugc nofollow" target="_blank">注册时事通讯</a>。</p></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><p id="1d5a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="nn">原载于</em><a class="ae ko" href="https://www.anyscale.com/blog/fast-automl-with-flaml-ray-tune" rel="noopener ugc nofollow" target="_blank"><em class="nn">https://www.anyscale.com</em></a><em class="nn">。</em></p></div></div>    
</body>
</html>