<html>
<head>
<title>Pytorch Conv2d Weights Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch Conv2d砝码说明</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-conv2d-weights-explained-ff7f68f652eb?source=collection_archive---------2-----------------------#2021-11-26">https://towardsdatascience.com/pytorch-conv2d-weights-explained-ff7f68f652eb?source=collection_archive---------2-----------------------#2021-11-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/f1ea49bbc69d609b54ae2bc1ee9b5b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*pz3r3rQC9zf7QwK42ZKY9Q.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">作者图片</p></figure><div class=""/><div class=""><h2 id="f38d" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">了解重量尺寸、可视化、参数数量和臭名昭著的尺寸不匹配</h2></div><p id="03de" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在我使用Pytorch的过程中，我发现的最常见的问题之一是在向我的模型上传权重时出现尺寸不匹配错误。如您所知，Pytorch在您保存模型权重时不会保存模型的计算图(与TensorFlow相反)。因此，当您训练具有不同配置(不同深度、宽度、分辨率……)的多个模型时，经常会拼错权重文件，并为您的目标模型上传错误的权重。</p><p id="7a2f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这个拼写错误转化为Conv2d权重的臭名昭著的Pytorch错误:大小不匹配。这就是你要的:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="0cdd" class="ly lz je lu b gy ma mb l mc md">In [11]: conv_layer = nn.Conv2d(3, 15, 5,5)<br/>In [12]: conv_layer.load_state_dict(weights)<br/>----------------------------------------------------------<br/>RuntimeError    Traceback (most recent call last)</span><span id="128c" class="ly lz je lu b gy me mb l mc md">[... Traceback ommited for this post... @jvgd]</span><span id="666c" class="ly lz je lu b gy me mb l mc md">RuntimeError: Error(s) in loading state_dict for Conv2d:<br/> size mismatch for weight: copying a param with shape torch.Size([10, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([15, 3, 5, 5]).<br/> size mismatch for bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([15]).</span></pre><p id="ffe9" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">听起来熟悉吗？如果是这样，我可能会有一些见解与您分享，关于Pytorch Conv2d权重如何以及您如何理解它们。</p><h1 id="8a71" class="mf lz je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">Conv2d</h1><p id="4382" class="pw-post-body-paragraph kt ku je kv b kw mw kf ky kz mx ki lb lc my le lf lg mz li lj lk na lm ln lo im bi translated">Conv2d层可能是计算机视觉中最常用的层(至少在变形金刚出现之前是这样)。如果您曾经在Pytorch中实例化过该层，您可能会编写类似以下的代码:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="2f46" class="ly lz je lu b gy ma mb l mc md">In [5]: conv_layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5)</span></pre><p id="c67a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">你和我通常会使用该层，而不会过多地检查它，但既然我们在这里弄脏了我们的手，让我们看看引擎盖下。如果继续检查层权重，您可以检查权重尺寸:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="e708" class="ly lz je lu b gy ma mb l mc md">In [6]: conv_layer.weight.shape<br/>Out[6]: torch.Size([10, 3, 5, 5])</span></pre><p id="e4fe" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">那么这个怎么解读呢？</p><p id="6d14" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为什么权重张量有4个维度？不应该是二维张量，因为它是二维平面上的卷积。好吧，让我们先把它形象化，然后再分析它。</p><figure class="lp lq lr ls gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/edbb44d22dfe5f17a8424c6afd3e3b09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kjQ0K0zy61qoHr29P0MHgA.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">作者图片</p></figure><p id="5d01" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你给这个卷积层输入一个图像[H，W，3]，你会得到一个输出特征图[H '，W '，10]。这个操作的卷积层的权重可以如上图所示。</p><p id="886f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在图中可以看到5×5核是如何与来自输入图像的所有3个通道(R、G、B)进行卷积的。从这个意义上来说，我们需要5×5内核来为每个输入通道设置权重。这自然转化为形状张量[3，5，5]。</p><p id="004f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在输出端，我们设置了10个通道的输出特性图。这意味着，对于每个卷积步骤，我们都希望得到[1，1，10]的输出(图中的紫色张量)。这种从输入到输出通道的扩展由额外的权重支持。所以我们卷积层权重的最终张量是:[3，5，5，10](按照我们习惯的从左向右读)。</p><p id="5065" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">那么，为什么代码片段中的权重输出形状具有[10，3，5，5]的形状呢？公平的问题。这是由于实现问题。您已经知道Pytorch采用渠道优先的方法。这意味着为了处理一个输入图像，你需要把它转换成一个张量[C，H，W]。这对我们来说并不自然，但有助于实现。因此，当我们读取Pytorch卷积层的权重形状时，我们必须将其视为:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="dbaa" class="ly lz je lu b gy ma mb l mc md">[out_ch, in_ch, k_h, k_w]</span></pre><p id="a4bd" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其中k_h和k_w分别是内核高度和宽度。</p><p id="232d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">好的，但是卷积层不是也有偏差参数作为权重吗？是的，你是对的，让我们检查一下:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="0ef6" class="ly lz je lu b gy ma mb l mc md">In [7]: conv_layer.bias.shape<br/>Out[7]: torch.Size([10])</span></pre><p id="5077" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">偏置项it只是添加到卷积输出的输出通道的相同维度的单个向量。视觉上:</p><figure class="lp lq lr ls gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ng"><img src="../Images/a96b467a08ea8fcfa5183420a0166673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DugyKd1di3p_ms4p94_WSw.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">作者图片</p></figure><p id="bcbe" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">所以最后，我们考虑了所有的事情:</p><ul class=""><li id="9a17" class="nh ni je kv b kw kx kz la lc nj lg nk lk nl lo nm nn no np bi translated">[H，W，3]的输入张量</li><li id="2181" class="nh ni je kv b kw nq kz nr lc ns lg nt lk nu lo nm nn no np bi translated">由[3，5，5，10]的张量卷积</li><li id="4f96" class="nh ni je kv b kw nq kz nr lc ns lg nt lk nu lo nm nn no np bi translated">给出[H '，W '，10]的输出特征图</li><li id="4a13" class="nh ni je kv b kw nq kz nr lc ns lg nt lk nu lo nm nn no np bi translated">其中层偏置[10]被添加到每个通道分量</li></ul><p id="8ea1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这就是所有的重量。那么，下一个问题是:我用这一层给我的模型增加了多少参数？这个问题的答案非常简单。首先让我们用数字计算一下:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="5efe" class="ly lz je lu b gy ma mb l mc md">In [8]: sum(param.numel() for param in conv_layer.parameters())<br/>Out[8]: 760</span></pre><p id="3ead" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">您可能已经猜到，这只是重量尺寸加上偏差的结果:</p><figure class="lp lq lr ls gt iv gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/179bb7129273aec4470ab0c6ea0054d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*ngOssNsgGAvay-ZSaQlrHg.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">作者图片</p></figure><p id="bf2c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">计算每个卷积层的参数数量的自然概括是:</p><figure class="lp lq lr ls gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nw"><img src="../Images/aa593656954d75e360ee9d382c405895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*QaYb6POTLpgE7qwq-sa_QA.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">作者图片</p></figure></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="3a84" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">看过这一切之后，我们可以回到介绍帖子的错误:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="8f78" class="ly lz je lu b gy ma mb l mc md">RuntimeError: Error(s) in loading state_dict for Conv2d:<br/> size mismatch for weight: copying a param with shape torch.Size([10, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([15, 3, 5, 5]).<br/> size mismatch for bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([15]).</span></pre><p id="bc5d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">了解了Pytorch Conv2d层之后，我们已经知道错误告诉了我们什么:</p><ul class=""><li id="cbfc" class="nh ni je kv b kw kx kz la lc nj lg nk lk nl lo nm nn no np bi translated">我们正在尝试加载卷积层的权重，该卷积层期望3个通道的输入图像，并且将返回10的具有核[5，5]的特征图</li><li id="17b9" class="nh ni je kv b kw nq kz nr lc ns lg nt lk nu lo nm nn no np bi translated">然而，当前模型有一个卷积层，与前一个模型类似，它期望一个具有[5，5]内核的3通道输入图像，但它将返回15的特征图，而不是10的特征图</li></ul><p id="e6a5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">所以最后，这几乎总是由拼写错误引起的，但是如果我们要调试我们的模型，我们需要真正挖掘它们内部是如何构建的。</p><p id="378d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">今天我们已经看到了Conv2d层，在未来，如果我能够腾出一些时间，我会写另一篇关于其他著名Pytorch层的帖子。</p></div></div>    
</body>
</html>