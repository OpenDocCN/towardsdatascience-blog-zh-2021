<html>
<head>
<title>Top 5 GPT-3 Successors You Should Know in 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年你应该知道的五大GPT三代接班人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/top-5-gpt-3-successors-you-should-know-in-2021-42ffe94cbbf?source=collection_archive---------8-----------------------#2021-06-12">https://towardsdatascience.com/top-5-gpt-3-successors-you-should-know-in-2021-42ffe94cbbf?source=collection_archive---------8-----------------------#2021-06-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6f90" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能</h2><div class=""/><div class=""><h2 id="428c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">AI进步很快，这里有你需要知道的最新机型。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ffa82cc021d788d7e0774bf7261637a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PiQDGZWZ1LjjvUbv"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">朱迪·纽迈耶在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="a203" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们与今年人工智能向我们展示的相比，GPT-3已经很老了。自2017年《变形金刚》问世以来，它在从语言到视觉的各种任务中都取得了巨大成功。GPT-3去年彻底改变了世界，从那时起，多个突破性的模型已经出现。各个国家和公司都沉浸在建造越来越好的模型的竞赛中。</p><p id="5f96" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">前提是更大的模型、更大的数据集和更强的计算能力构成了人工智能主导的三位一体。即使这个范例有重要的批评者，它的成功是不可否认的。</p><p id="a553" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我将回顾2021年以来最重要的5种基于变压器的模型。我将从GPT 3号开始这个列表，因为它意义重大，然后按时间顺序继续——最后一个是两周前发表的！</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="fd45" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">GPT 3号——人工智能摇滚明星</h1><p id="8687" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">OpenAI于2020年5月在一篇题为<a class="ae lh" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> <em class="ni">的论文中提出了GPT-3，语言模型是很少出手的学习者</em> </a>。2020年7月，该公司发布了一个供开发人员使用的测试版API，该模型一夜之间成为人工智能明星。</p><p id="0216" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3是第三代语言型号系列的第三个版本。它的主要特点是<strong class="lk jd">多任务和元学习</strong> <strong class="lk jd">能力</strong>。在570GB的互联网文本数据上以无监督的方式进行训练，它能够通过看到几个例子(少数镜头)来学习它没有训练过的任务。它也可以从零和一次设置中学习，但性能通常会更差。</p><p id="23a3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT 3号展示了疯狂的语言生成能力。它可以对话(模仿活着或死去的历史人物)，写诗、歌、小说和散文。<strong class="lk jd">它可以</strong> <strong class="lk jd">写代码</strong>，乐谱，乳胶格式的方程式。它显示了适度的推理、逻辑和常识水平。它可以思考未来、生命的意义和自身。</p><p id="56e5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除此之外，GPT-3在标准化基准测试中表现出色，在一些测试中达到了SOTA。它在生成性任务上表现最为突出，比如写新闻文章。对于这项任务，它达到了人类的水平，<strong class="lk jd">让试图将它的文章与人造文章分开的法官感到困惑。</strong></p><p id="e839" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是我为<em class="ni">写的一篇关于GPT 3号的完整概述，面向数据科学:</em></p><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/gpt-3-a-complete-overview-190232eb25fd"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd jd gy z fp nr fr fs ns fu fw jc bi translated">GPT-3 —全面概述</h2><div class="nt l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz lb nm"/></div></div></a></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="4487" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">开关变压器——万亿参数先锋</h1><p id="7b7e" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">2021年1月谷歌发表了论文<a class="ae lh" href="https://arxiv.org/abs/2101.03961" rel="noopener ugc nofollow" target="_blank"> <em class="ni"> Switch Transformers:缩放至万亿参数模型，具有简单有效的稀疏性</em> </a> <em class="ni">。</em>他们提出了开关变压器<strong class="lk jd">，</strong>一种新的神经网络，其目标是<strong class="lk jd">在不增加计算成本的情况下促进更大模型的创建。</strong></p><p id="55f9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">区别于以前模型的特征是专家混合算法的简化。混合专家(MoE)由一个系统组成，通过该系统，进入模型的表征(输入的基本部分)被发送到神经网络(专家)的不同部分进行处理。因此，为了处理给定的令牌，只有模型的一个子部分是活动的；我们有一个稀疏模型。这降低了计算成本，使它们能够达到万亿参数的水平。</p><p id="bc77" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在最初的MoE中，每个代币都被送到至少两个专家那里进行比较。有了Switch Transformer，Google简化了路由过程，因此每个令牌只发送给一个专家。<strong class="lk jd">这进一步降低了计算和通信成本。</strong>谷歌表明，大型开关变压器将优于大型密集模型(如GPT-3，尽管他们没有比较两者)。这是减少大型预训练模型碳足迹的一个巨大里程碑，这些模型在语言方面是最先进的，现在也是视觉任务。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="226b" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">富有创造力的艺术家</h1><p id="115e" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">OpenAI于2021年2月在一篇名为<a class="ae lh" href="https://arxiv.org/pdf/2102.12092.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ni">零镜头文本到图像生成</em> </a> <em class="ni">的论文中提出了DALL E。</em>该系统以西班牙画家萨瓦尔多·达利和皮克斯可爱的机器人瓦力命名，是GPT-3(120亿个参数)的缩小版，专门训练文本-图像对。用OpenAI的研究人员的话说:“通过语言操纵视觉概念现在触手可及。”</p><p id="f47f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">达尔·E利用“语言的组合结构”探索了图像生成的可能性它将书面句子的意思与它可能具有的潜在视觉表现结合起来。不过，像GPT-3一样，它高度依赖于句子的措辞，以避免在图像中出错。它的力量依赖于它的零射击能力；它可以执行未经训练的生成任务，而不需要例子。</p><p id="e38e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在其他功能中，它可以根据书面提示从头开始生成图像，重新生成图像的隐藏部分，控制对象的属性，或将它们集成到单个图像中。更令人印象深刻的是，DALL E还可以<strong class="lk jd">在高抽象层次上组合概念</strong>(当被告知“一只竖琴制成的蜗牛”时，它通常会将蜗牛画成以竖琴为壳)，并进行图像到图像的转换(当被告知“顶部的一只猫与底部的草图完全相同”时，它会画出一只与原始图片相似的猫)。</p><p id="3bda" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">达勒展示了一种艺术的雏形。从对书面语言的松散解释描述中，它创造了一种视觉现实。我们可能比以往任何时候都更接近一个人工智能版本的“一图胜千言”。</strong></p><p id="d0ab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是OpenAI的一篇博文，展示了DALL E的能力:</p><div class="nj nk gp gr nl nm"><a href="https://openai.com/blog/dall-e/" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd jd gy z fp nr fr fs ns fu fw jc bi translated">DALL E:从文本中创建图像</h2><div class="oa l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">DALL E是GPT-3的一个120亿参数版本，经过训练，可以使用以下数据集从文本描述中生成图像</h3></div><div class="nt l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">openai.com</p></div></div><div class="nu l"><div class="ob l nw nx ny nu nz lb nm"/></div></div></a></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="b966" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">LaMDA——下一代聊天机器人</h1><p id="52eb" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">谷歌在2021年5月的年度I/O会议上展示了LaMDA。LaMDA有望凭借其惊人的对话技巧<strong class="lk jd">革新聊天机器人技术</strong>。现在还没有论文或者API，只能等出点结果了。</p><p id="3c95" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">LaMDA代表<strong class="lk jd">La</strong>language<strong class="lk jd">M</strong>odel，代表<strong class="lk jd">D</strong>ialogue<strong class="lk jd">A</strong>applications，是Meena的继任者，Meena是谷歌在2020年推出的另一个人工智能。LaMDA接受了对话训练，并进行优化以最大限度地减少困惑，这是一种衡量模型在预测下一个令牌时有多自信的方法。困惑与人类对对话技巧的评价高度相关。</p><p id="0018" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">LaMDA作为一个明智、具体、有趣且符合事实的聊天机器人而脱颖而出。与之前的产品相比，它可以在开放式的对话中做出有意义的回应。这可以使他们变得具体，避免像“我不知道”这样总是有效的回答它可以做出“有见地和意想不到的”回应，让对话保持有趣。当涉及到事实知识时，它会给出正确的答案。</p><p id="4c4a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是我为<em class="ni">写的一篇关于LaMDA的完整评论，关于数据科学:</em></p><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/googles-lamda-the-next-generation-of-chatbots-62294be58426"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd jd gy z fp nr fr fs ns fu fw jc bi translated">谷歌的LaMDA:下一代聊天机器人</h2><div class="nt l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="oc l nw nx ny nu nz lb nm"/></div></div></a></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="1d3f" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">妈妈——搜索引擎的大脑</h1><p id="ae06" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">谷歌与LaMDA一起推出了MUM，这是一个旨在改革搜索引擎的系统，其方式与几年前BERT的方式类似，但更具影响力。与LaMDA一样，除了谷歌的演示和博客帖子外，没有进一步的信息，所以我们必须等待更多信息。</p><p id="e7fd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">妈妈代表多任务型<strong class="lk jd"> U型</strong>n型<strong class="lk jd"> M型</strong>型。它是一个多任务和多模态语言模型，比它的前身BERT强大1000倍。它已经接受了75种语言和许多任务的训练，这使它对世界有了更好的了解。然而，它的多模式能力使MUM比以前的型号更强大。它可以处理文本+图像信息和任务，这使它具有GPT-3和LaMDA都没有的多功能性。</p><p id="3dde" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">妈妈能够处理复杂的搜索查询，如“你已经徒步过亚当斯山。现在你想明年秋天去富士山远足，你想知道要做哪些不同的准备。”有了今天的搜索引擎，一个精确而明智的答案将需要大量的搜索和信息汇编。妈妈可以帮你做，给你一个有针对性的答案。更令人惊讶的是，因为它是多模态的，“最终，你可能会拍下你的登山靴，然后问，”我可以用它们去富士山吗？"</p><p id="666e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是我为<em class="ni">写的关于妈妈的一篇完整的评论:</em></p><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/will-googles-mum-kill-seo-d283927f0fde"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd jd gy z fp nr fr fs ns fu fw jc bi translated">谷歌妈妈会扼杀SEO吗？</h2><div class="nt l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="od l nw nx ny nu nz lb nm"/></div></div></a></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="a98a" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">武道2.0——最大的神经网络</h1><p id="53cc" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">6月1日，BAAI年会推出了悟道2.0——翻译过来就是<em class="ni">悟</em>。这个令人惊叹的人工智能拥有一年前属于GPT-3的最大神经网络的头衔。武道2.0拥有惊人的1.75万亿参数，10x GPT-3。</p><p id="4316" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">武道2.0是在4.9TB的高质量文本和图像数据上训练出来的。相比之下，GPT-3是在570GB的文本数据上训练的，几乎少了10倍。武道2.0顺应多模态趋势，能够执行文字+图像任务。为了训练它，研究人员发明了FastMoE，这是谷歌MoE的继任者，它“使用简单，灵活，高性能，支持大规模并行训练。”我们可能会在未来的模型中看到其他版本的MoE。</p><p id="7c87" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它的多模态特性允许Wu Dao 2.0管理大量的任务。它能够处理和生成文本，识别和生成图像，以及混合任务，如为图像添加字幕和根据文本描述创建图像。它还可以预测蛋白质的3D结构，像<a class="ae lh" href="https://venturebeat.com/2020/11/30/deepmind-claims-its-ai-can-predict-how-proteins-will-fold-with-state-of-the-art-accuracy/" rel="noopener ugc nofollow" target="_blank"> DeepMind的AlphaFold </a>。它甚至创造了一个可以不断学习的虚拟学生。她会写诗，会画画，将来还会学编码。</p><p id="76f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">悟道2.0在一些标准语言和视觉基准上达到了SOTA水平，如LAMBADA、SuperGLUE、MS COCO或Multi 30K，超过了GPT-3、DALL E、CLIP和CL。这些惊人的成就使悟道2.0成为当今最强大、最全能的人工智能。然而，另一个更大的人工智能出现在地平线上只是时间问题。睁大眼睛！</p><p id="ce2f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里是我为<em class="ni">写的一篇关于悟道2.0的完整评论:</em></p><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd jd gy z fp nr fr fs ns fu fw jc bi translated">GPT三号吓到你了？遇见武道2.0:1.75万亿参数的怪兽</h2><div class="nt l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="oe l nw nx ny nu nz lb nm"/></div></div></a></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="f796" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://mindsoftomorrow.ck.page/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> <em class="ni">订阅</em> </strong> </a> <strong class="lk jd"> <em class="ni">获取更多关于AI、哲学、认知科学的内容！</em>T13】</strong></p></div></div>    
</body>
</html>