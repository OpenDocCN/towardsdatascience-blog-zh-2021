<html>
<head>
<title>6 recommendations for optimizing a Spark job</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化Spark作业的6条建议</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/6-recommendations-for-optimizing-a-spark-job-5899ec269b4b?source=collection_archive---------0-----------------------#2021-11-24">https://towardsdatascience.com/6-recommendations-for-optimizing-a-spark-job-5899ec269b4b?source=collection_archive---------0-----------------------#2021-11-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dcc5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">六项建议的指导方针，可快速优化您的Spark工作</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/617ba0d99e2b0da362806c40cb4779a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8FI3p5NqXsHnVTvThr1Eg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">用例的省时优化示例。作者图片</em></p></figure><p id="1709" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae ls" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> <em class="lt"> Spark </em> </a>是目前<strong class="ky ir">处理大数据集</strong>的必备工具。这项技术已经成为数据工程中许多商业应用的首选。这一势头得到了<strong class="ky ir">托管服务</strong>的支持，如<a class="ae ls" href="https://databricks.com/spark/about" rel="noopener ugc nofollow" target="_blank"> <em class="lt">数据块</em> </a>，它们降低了与购买和维护分布式计算集群相关的部分成本。最著名的云提供商也提供<em class="lt"> Spark </em>集成服务(<a class="ae ls" href="https://aws.amazon.com/emr/features/spark/?nc1=h_ls" rel="noopener ugc nofollow" target="_blank"> AWS EMR </a>、<a class="ae ls" href="https://azure.microsoft.com/en-gb/services/hdinsight/" rel="noopener ugc nofollow" target="_blank"> Azure HDInsight </a>、<a class="ae ls" href="https://cloud.google.com/dataproc" rel="noopener ugc nofollow" target="_blank"> GCP Dataproc </a>)。</p><p id="95c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark通常用于对数据进行转换，在大多数情况下是结构化的。它在两种情况下特别有用。<strong class="ky ir">当要处理的数据对于可用的计算和内存资源来说太大时</strong>。这就是我们所说的<em class="lt">大数据</em>现象。最后，当一个人想通过使用同一网络中的<strong class="ky ir">几台机器<strong class="ky ir">来加速计算</strong>时，这也是一种选择。在这两种情况下，主要关心的是优化<strong class="ky ir">火花作业</strong>的计算时间。</strong></p><p id="7414" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了应对这个问题，我们经常增加分配给一个<em class="lt">计算集群</em>的资源。从云提供商那里租赁计算能力很容易，这鼓励了这种趋势。</p><p id="0684" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">本文</strong>的目的是提出一个在资源有限的情况下优化Spark作业的<strong class="ky ir">策略。事实上，在使用团簇弹性之前，我们可以影响许多<strong class="ky ir">火花配置</strong>。因此，这种策略可以先进行测试。</strong></p><p id="00d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了<strong class="ky ir">避免对最佳配置设置的彻底搜索</strong>，这自然是非常昂贵的，这篇文章将展示可行的解决方案，以最大化我们减少计算时间的机会。每一步都将通过一个尽可能合理的<strong class="ky ir">建议来实现</strong>。</p><p id="1f1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">提出的策略被认为是贪婪的，也就是说，我们在过程的每个阶段都做出最佳选择，而不会走回头路。这种方法由六条建议的<strong class="ky ir">指南来说明。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/cc353d814f556d38ada2a7ae048c389c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hMydna6c6V7Oaf50EemZ5w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">指导方针的六条建议。作者图片</em></p></figure><p id="9c40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目的是提供一个<strong class="ky ir">清晰的方法，易于在各种用例上测试</strong>。然后，有必要在一个可共享的示例上测试这些建议，并给出一个<strong class="ky ir"> <em class="lt">模板代码</em> </strong>，允许在另一个<em class="lt"> Spark作业</em>上重复这个实验。</p><p id="0c3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">在玩具用例上的应用</strong></p><p id="310e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了评估本文中提出的优化策略，我们使用了一个玩具用例来设计一个Spark作业。这个过程根据天气和人口变量对法国城市进行分组。这个任务在机器学习中叫做<a class="ae ls" href="https://en.wikipedia.org/wiki/Cluster_analysis" rel="noopener ugc nofollow" target="_blank">无监督分类或者聚类</a>。该示例说明了Spark流水线的共同特征，即数据预处理阶段(加载、清理、不同源的合并、特征工程)、对<em class="lt">机器学习</em>模型参数的估计，以及最终将结果存储到磁盘。关于这个实验的更多细节可以在<a class="ae ls" href="https://github.com/sgrah-oss/6-recommendations-for-optimizing-a-spark-job" rel="noopener ugc nofollow" target="_blank">代码库</a>上找到。</p><p id="b442" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过一步一步地遵循本文中详细介绍的建议，我们可以观察优化提示和技巧对下图的影响。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/617ba0d99e2b0da362806c40cb4779a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8FI3p5NqXsHnVTvThr1Eg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="67e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">找到的配置设置很可能是一个<strong class="ky ir">次优解决方案</strong>。然而，它提供了一个比穷举搜索更快的选择，尤其是在大数据处理环境中。</p><h1 id="5adf" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">关于Spark和一些有用概念的快速提醒</h1><p id="3054" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated"><strong class="ky ir">三言两语擦出火花</strong></p><p id="e16f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Apache Spark是用于大规模数据处理的<strong class="ky ir">分析引擎</strong>。它提供了一个接口，用于通过隐式<strong class="ky ir">数据并行</strong>和<strong class="ky ir">容错</strong>对整个集群进行编程，并将<strong class="ky ir">中间结果存储在存储器</strong> (RAM和磁盘)中。</p><p id="e258" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark的核心处理广泛使用了<strong class="ky ir">函数编程</strong>来解决<em class="lt">大数据</em>中的放大问题。因此，<strong class="ky ir">源代码</strong>主要在<strong class="ky ir"> Scala </strong>中编码是很自然的。</p><p id="d519" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，Spark也在更高的层次上提供了Python、Java、R和SQL 中的<strong class="ky ir">API，在大多数情况下提供了几乎等同的可能性而没有任何性能损失(例如除了<a class="ae ls" href="https://docs.databricks.com/spark/latest/spark-sql/udf-python.html" rel="noopener ugc nofollow" target="_blank"> UDF </a>函数)。该项目是根据Apache 2.0 </strong>许可的<strong class="ky ir">开源</strong>和<strong class="ky ir">。</strong></p><p id="4baf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图描述了分布式计算集群中<em class="lt"> Spark </em>处理的经典操作。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/78ed14d12ce8f431215b0ea89fcbef20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UeNRlmH00Xb1uxlyijMzhg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="56f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="lt">火花驱动器</em>，也称为主节点，<strong class="ky ir">协调处理的执行及其在<em class="lt">火花执行器</em>(也称为<em class="lt">从节点</em>)之间的分配</strong>。驱动程序不一定由计算集群托管，它可以是一个外部客户端。<em class="lt">集群管理器</em>实时管理集群的可用资源。它比Spark应用程序有更好的概述，如果可用，它将请求的资源分配给Spark驱动程序。在本文中，将不讨论集群管理器的使用。</p><p id="190a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">分解火花作业</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/e6ad65cba3fe9987f4618612d2fd01d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FdGrw0cwu-z5qaeMm88Hww.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="6331" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark作业是由<strong class="ky ir">任务</strong>组成的一系列<strong class="ky ir">阶段</strong>。更准确地说，它可以用一个<strong class="ky ir">有向无环图(DAG) </strong>来表示。<em class="lt"> Spark作业</em>的一个例子是<a class="ae ls" href="https://en.wikipedia.org/wiki/Extract,_transform,_load" rel="noopener ugc nofollow" target="_blank"> <em class="lt">提取转换日志(ETL) </em> </a>数据处理流水线。<em class="lt">阶段</em>通常由执行节点之间的网络中的数据传输来界定，例如两个表之间的连接操作。最后，<strong class="ky ir">任务是Spark中分配给数据分区的执行单元</strong>。</p><p id="616b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">懒评</strong></p><p id="65d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="lt">懒评</em>是大数据处理常用的一招。事实上，当数据超过内存资源时，需要一种策略来优化计算。<em class="lt">惰性评估</em>表示仅当<em class="lt">火花动作</em>运行时触发处理，而不是<em class="lt">火花转换</em>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/f6fbad65e57637df9efb96ef6b6fd8e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_bn5Tgc_40l5x5KwdnDug.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">火花动作和转换的例子。作者图片</em></p></figure><p id="8ba8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">在调用</strong>动作之前，不会执行转换。这允许Spark准备一个<a class="ae ls" href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html" rel="noopener ugc nofollow" target="_blank">逻辑和物理</a>执行计划来有效地执行动作。</p><p id="393d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们举一个例子来理解为什么这很有用。在几次转换后，调用一个动作将一个<em class="lt">数据帧</em>的第一行返回给<em class="lt">驱动器</em>。然后，Spark 可以通过管理内存和计算来重新组织之前转换的执行计划，从而更快地获得第一个转换后的行。事实上，只有包含该<em class="lt">数据帧</em>第一行的数据的<em class="lt">分区</em>需要被处理。这大大减少了不必要的内存和计算处理。</p><p id="e0c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">宽窄变换</strong></p><p id="da48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="lt">火花变换</em>分为两类:<strong class="ky ir">宽</strong>和<strong class="ky ir">窄</strong>变换。这两种类型的区别在于需要在执行节点之间重新分配网络中的数据分区。这一重大事件在Spark术语中被称为<strong class="ky ir">洗牌</strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/9ee40433a85f9accf6e942cac827b19d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u69zDQgxukpRQTiZZ6Alqg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="2eb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">需要<em class="lt">洗牌</em>的宽变换</strong>自然是<strong class="ky ir">最贵的</strong>。处理时间会更长，这取决于集群中交换的数据的大小和网络延迟。</p><h1 id="88b4" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">如何修改Spark作业的配置设置？</h1><p id="2d02" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">有三种方法可以修改Spark作业的配置:</p><ul class=""><li id="ad61" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">通过使用Spark根文件夹中的<strong class="ky ir">配置文件</strong>。例如，我们可以自定义以下模板文件:<br/><em class="lt">conf/spark-defaults . conf . template<br/>conf/log4j . properties . template<br/>conf/Spark-env . sh . template<br/></em>这些更改会影响Spark集群及其所有应用程序。</li><li id="db04" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">使用<strong class="ky ir">命令行</strong>使用<strong class="ky ir"> — conf </strong>参数<br/>例如:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/ae58590aef16bb40324004bbdbd5917e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m3pm7UfCI_FQpm1LQR5DBg.png"/></div></div></figure><ul class=""><li id="8c93" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">直接在<strong class="ky ir">中输入火花应用代码<br/> </strong> Ex:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/9b3fa4bea7f853d69888dfd0a3a4cd65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2JT2aRSJpzVCKAyIFV7y_Q.png"/></div></div></figure><ul class=""><li id="a7fa" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">首先考虑配置文件中定义的值。接下来，参数作为参数传递给<em class="lt"> spark-submit </em>。最后是那些直接在应用程序代码中配置的。</li></ul></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="47b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些配置参数在<em class="lt"> Spark GUI </em>的<em class="lt">环境选项卡</em>中是只读的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/a7d9f9378894cc4ab273b933ebfbfad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*spuEA37aoT93L4UZQGJJcg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="5703" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在与本文相关的代码中，参数直接在Spark应用程序代码中定义。</p><h1 id="ecb5" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">预备步骤:衡量优化是否必要</h1><p id="7c6c" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">在项目中，优化流程是一个耗时且成本高昂的步骤。必须事先说明理由。<br/>通常，约束与用例相关联，并在与涉众的<strong class="ky ir">服务水平协议</strong> ( <a class="ae ls" href="https://fr.wikipedia.org/wiki/Service-level_agreement" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> SLA </strong> </a>)中定义。我们监控相关指标(例如处理时间、分配的内存)，同时检查它们是否符合SLA。<br/>估计优化应用程序并达到目标所需的时间并不容易。它通常需要软件工程方面的经验。本文并没有假装这样做，而是旨在建议可以快速使用的行动。<br/>另一方面，这些建议提供了需要改进的地方。从一个人治疗的<em class="lt">简介</em>开始可能会很有趣。这将针对最相关的建议进行触发。</p><h1 id="3116" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">建议1:使用Apache Parquet文件格式</h1><p id="1051" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated"><strong class="ky ir"> Apache </strong> <strong class="ky ir"> Parquet格式</strong>正式成为<strong class="ky ir">面向列的存储</strong>。其实更多的是行列存储之间的<a class="ae ls" href="https://youtu.be/1j8SdS7s_NY?t=645" rel="noopener ugc nofollow" target="_blank">混合格式</a> <strong class="ky ir">。用于<strong class="ky ir">表格数据</strong>。同一列中的数据是连续存储的。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/61a467efc1ae0b47484a83217d9ce1f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sfUoxVqzqtfaYBZZS8ry4w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="5fc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当对列的子集和大型的<em class="lt">数据框架</em>执行查询(<em class="lt">转换</em>)时，这种格式特别合适。这是因为它<strong class="ky ir">仅将与所需列相关联的数据加载到存储器</strong>中。<br/>此外，由于压缩<strong class="ky ir">方案</strong>和<strong class="ky ir">编码</strong>根据类型化而特定于每一列的<strong class="ky ir">，因此它改善了这些二进制文件的读/写及其在磁盘上的大小。<br/>这些优势使其成为<em class="lt"> CSV </em>格式的一个非常有趣的替代方案。这是Spark </strong>推荐的<strong class="ky ir">格式，也是写的默认格式。<br/>如果Spark与<a class="ae ls" href="https://databricks.com/spark/about" rel="noopener ugc nofollow" target="_blank"> <em class="lt">数据块</em> </a>一起使用，另一个特别有趣的格式是delta格式，它提供了<a class="ae ls" href="https://docs.databricks.com/delta/quick-start.html#optimize-a-table" rel="noopener ugc nofollow" target="_blank">自动优化工具</a>。在本文中，我们将重点介绍Spark的开源版本。然而，强烈建议感兴趣的读者探索Spark与Databricks生态系统的集成。</strong></p><h1 id="ed11" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">建议2:最大化Spark中的并行性</h1><p id="2024" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">Spark的效率基于其大规模并行处理多个任务的能力。因此，我们越是促进任务的分解，任务完成得就越快。这就是为什么<strong class="ky ir">优化Spark作业通常意味着并行读取和处理尽可能多的数据</strong>。而要实现这个目标，就需要<strong class="ky ir">把一个数据集分割成几个分区</strong>。</p><p id="75e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对<em class="lt">数据集</em>进行分区是一种将数据排列成磁盘上连续数据块的可配置、可读子集的方式。然后，可以独立并行地读取和处理这些分区。正是这种独立性使得海量数据处理成为可能。理想情况下，Spark为每个任务和每个CPU内核组织一个线程。每个任务都与一个分区相关。因此，第一直觉是配置至少与可用CPU核心数量一样多的分区。在执行Spark作业的大部分时间里，所有内核都应该被占用。如果它们中的一个在任何时候可用，它应该能够处理与剩余分区相关联的作业。目标是通过将Spark作业阶段分成大量任务来避免瓶颈。这种流动性在分布式计算集群中至关重要。下图说明了网络中机器之间的这种划分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/906a8eaa62d26f5eef13db05e7e50ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DvLEA5p7ppld7kiznqbeIw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="c677" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以创建分区:</p><ul class=""><li id="902b" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">读取数据时通过设置<strong class="ky ir"><em class="lt">spark . SQL . files . maxpartitionbytes</em></strong>参数(默认为128 MB)。<br/>一个好的情况是数据已经存储在磁盘的几个分区中。例如，<em class="lt"> parquet格式的数据集</em>，其文件夹包含大小在100到150 MB之间的数据分区文件。</li><li id="2065" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">直接在Spark应用程序代码中使用Dataframe API。一个例子:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/ed495bd6992f9e9823dda95e4524a030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YOq2mxJXt_ghJ_hEojxQsg.png"/></div></div></figure><p id="e0f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这最后一种方法<em class="lt">联合</em>减少了分区的数量，同时避免了网络中的<em class="lt">洗牌</em>。</p><p id="5f88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人们可能想通过降低参数<strong class="ky ir"><em class="lt">spark . SQL . files . maxpartitionbytes</em></strong>的值来增加分区的数量。但是，这种选择会导致<strong class="ky ir">小文件问题</strong>。由于文件系统执行的操作(例如，打开、关闭、列出文件)，会导致<em class="lt"> I/O </em>性能下降，这种情况通常会随着像<em class="lt"> HDFS </em>这样的分布式文件系统而加剧。如果分区数量太大，也会出现调度问题。</p><p id="49a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在实践中，这个参数应该根据可用资源根据经验来定义。</p><h1 id="9834" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">建议3:小心洗牌操作</h1><p id="7c0d" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">在<em class="lt"> Spark </em>中有一种特殊类型的分区叫做<strong class="ky ir">洗牌分区</strong>。这些分区是在涉及混洗的作业阶段创建的，即当执行<strong class="ky ir">宽转换</strong>(例如groupBy()、join())时。这些分区的设置<strong class="ky ir">会影响网络和读/写磁盘资源</strong>。</p><p id="2d53" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以修改<strong class="ky ir"><em class="lt">spark . SQL . shuffle . partitions</em></strong>的值来控制分区的数量。默认情况下，该值设置为200，对于某些处理来说，这个值可能太高了，会导致执行节点之间在网络中交换太多的分区。该参数应根据数据的大小进行调整。直觉可能是以至少等于集群中CPU核心数量的值开始<strong class="ky ir">。</strong></p><p id="cc77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark将混洗操作的中间结果存储在执行器机器的本地磁盘上，因此磁盘的质量，尤其是I/O质量非常重要。例如，使用SSD磁盘将显著提高此类转换的性能。</p><p id="deb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下表描述了我们也可以影响的主要参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/498952c7a4bdf547b581668084e0334f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pGL7i8B1ALEUosUhbXqYEQ.png"/></div></div></figure><h1 id="e851" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">建议4:使用广播散列连接</h1><p id="9870" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">几个<em class="lt">数据帧</em>之间的连接是一个常见的操作。在分布式环境中，执行节点之间在网络中交换大量数据来执行连接。根据表的大小，这种交换会导致网络延迟，从而降低处理速度。Spark提供了几种连接策略来优化这种操作。其中有一个如果可以选择的话特别有意思:<strong class="ky ir">广播哈希加入(BHJ) </strong>。</p><p id="5e31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当合并的<em class="lt">数据帧</em>中的<strong class="ky ir">数据帧“足够”小，可以在所有执行节点</strong>(广播操作)的内存中复制时，这种技术是合适的。下图说明了这种策略的工作原理。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/6982b14f4c048d452d9c5ddf492e5465.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4ZFPDQJpU-fCkt0waPCMQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="239e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二个<em class="lt">数据帧</em>被传统地分解成分布在集群节点中的分区。通过复制最小的表，<strong class="ky ir">除了预先广播该表之外，连接不再需要集群中的任何重要数据交换</strong>。这种策略极大地提高了连接的速度。要修改的Spark配置参数是<strong class="ky ir"><em class="lt">Spark . SQL . autobroadcasthashjoin</em></strong>。默认值为10 MB，即如果两个表中的一个小于该大小，则选择该方法。如果有足够的内存可用，那么增加这个值或将它设置为-1以强制Spark使用它可能会非常有用。</p><h1 id="7afc" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">建议5:缓存中间结果</h1><p id="4e44" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">为了优化计算和管理内存资源，Spark使用<em class="lt">惰性评估</em>和<em class="lt"> DAG </em>来描述作业。这提供了在动作之前快速<strong class="ky ir">重新计算步骤的可能性，如果必要的话</strong>，因此只执行DAG的一部分。为了充分利用这一功能，非常明智的做法是<strong class="ky ir">存储昂贵的中间结果</strong>，如果有几个操作在DAG的下游使用它们的话。实际上，如果一个动作正在运行，其计算可以基于这些中间结果，因此在该动作之前仅重放DAG的子部分。</p><p id="b4af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们以下面的DAG为例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/a941793e7ff500e2259e66e43794d5fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Xo4tfQWz-1bl9PCJMZNfw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="259d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了获得这两个动作的结果，在下面的两个Dag中描述了处理。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/619a894ea9ab0f835fa17889cfac3f9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YKXYsDu9vqCMZvF6fgNi8g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="6f70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了加速执行，可以决定缓存中间结果(例如连接的结果)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/6bcf73094c8e23e14759745268937661.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WdlPUm5FIjtX1dbjrY5tZw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="4fe5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在简化了第二个动作的处理。请注意，在第一次操作期间，结果尚未存储在内存中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/22d0957b5b511cd638f43e6fb051c848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Un0GGaQWtTZcaBDT3rTFFA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="d900" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果这种缓存可以加速作业的执行，那么当这些结果被写入内存和/或磁盘时，我们就要付出<strong class="ky ir">的代价。应该在处理流水线的不同位置测试节省的总时间是否超过成本。当DAG上有多条路径时，这一点尤其重要。</strong></p><p id="58cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">缓存两列模拟表节省时间的示例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/d00d10759a9680c44645c44f6b546fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ak4LBWs72Yv71Z74onU8Q.png"/></div></div></figure><blockquote class="oe of og"><p id="3dd7" class="kw kx lt ky b kz la jr lb lc ld ju le oh lg lh li oi lk ll lm oj lo lp lq lr ij bi translated">注意:缓存和任何<em class="iq">火花转换</em>一样，是在运行<em class="iq">动作</em>时执行的。<strong class="ky ir">如果该动作的计算仅涉及数据的一个子部分，则仅存储该子部分的中间结果</strong>。在前面的示例中，如果调用了收集第一行的<em class="iq"> take(1) </em> <em class="iq">操作</em>，那么只有包含第一行的分区会被缓存。</p></blockquote><p id="d310" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以使用以下命令缓存表:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/55ddcf05446121094980d21de4eb36c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yTJE2eRE_c50axI2GBxm9Q.png"/></div></div></figure><p id="1542" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下表描述了不同的缓存选项:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/aaa5fa0c62ef799150eef72f7645c13b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vr4rjHxwIqVbssio8Zsdnw.png"/></div></div></figure><p id="fd2f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">选项的完整列表可在<a class="ae ls" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence" rel="noopener ugc nofollow" target="_blank">此处</a>获得。</p><h1 id="50cd" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">建议6:管理执行器节点的内存</h1><p id="6302" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">Spark执行器的内存分解如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/4bac6fe16e12d8e2ee8a43efb48a5cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LClDoeW2y7qkH353s3iBZQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="7934" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">默认情况下，<strong class="ky ir"><em class="lt">spark . memory . fraction</em></strong>参数设置为0.6。这意味着一旦保留的内存被移除，60%的内存被分配用于执行，40%用于存储。默认情况下这是300 MB，用于防止<em class="lt">内存不足(OOM) </em>错误。</p><p id="4645" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以修改以下两个参数:</p><ul class=""><li id="13a9" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><strong class="ky ir"><em class="lt">spark . executor . memory</em>T25】</strong></li><li id="98b5" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">T27】spark . memory . fractionT29】</strong></li></ul><h1 id="1c7c" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">结论</h1><p id="bae2" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">在本文中，我们详细介绍了一个优化<em class="lt"> Spark作业</em>的策略。其主要目标是<strong class="ky ir">为那些希望优化流程但时间有限的人提供一个框架</strong>。贪婪方法的六个建议的指导方针旨在最大化减少计算时间的可能性。下图通过关联每个阶段的建议总结了建议的方法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/d1595f45a3fbd328506305b8a529f6f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0a3eoFBqKLS-lajp4uk4_w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="2ad3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个过程中每一步的价值都是根据Spark的操作来解释的。事实上，即使对配置提出了一些建议，理解它在引擎盖下如何工作也是至关重要的。每个用例都有自己的特点，没有一种方法是通用的。在这方面，本文介绍了Spark中的优化。</p><p id="22ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">更进一步</strong></p><ul class=""><li id="f4e4" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">本文旨在避免在集群中系统地使用动态资源分配来加速处理。尽管如此，研究它当然是有趣的。Spark提供了以下参数来根据工作负载管理集群的弹性:<br/><em class="lt">spark . dynamic allocation . enabled，<br/>spark . dynamic allocation . minexecutors，spark . dynamic allocation . schedulerbacklogtimeout，spark . dynamic allocation . max executors，spark . dynamic allocation . executorid time out</em></li><li id="e8dc" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">Spark中还有很多其他的表连接策略:<a class="ae ls" href="https://databricks.com/fr/session/optimizing-apache-spark-sql-joins" rel="noopener ugc nofollow" target="_blank">https://databricks . com/session/optimizing-Apache-Spark-SQL-joins</a></li><li id="f346" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">当然，Spark非常重视优化其处理。为了更深入地了解内部工作和当前项目，以下链接可能会有用:<a class="ae ls" href="https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html" rel="noopener ugc nofollow" target="_blank">钨项目</a>、<a class="ae ls" href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html" rel="noopener ugc nofollow" target="_blank"> Catalyst优化器</a>和<a class="ae ls" href="https://medium.com/swlh/spark-sql-adaptive-query-execution-3adc68973c91" rel="noopener">自适应查询执行</a>(3.0版本中的新特性)</li></ul><p id="c3a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读；)</p></div></div>    
</body>
</html>