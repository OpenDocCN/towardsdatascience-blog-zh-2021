<html>
<head>
<title>Complete Step-by-Step Gradient Descent Algorithm from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始完成逐步梯度下降算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/complete-step-by-step-gradient-descent-algorithm-from-scratch-acba013e8420?source=collection_archive---------0-----------------------#2021-09-10">https://towardsdatascience.com/complete-step-by-step-gradient-descent-algorithm-from-scratch-acba013e8420?source=collection_archive---------0-----------------------#2021-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c54a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">实践教程</h2><div class=""/><div class=""><h2 id="b8e6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">以及恒定学习速率和线搜索的实现</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9dee896c0f09f1a53153a45c9c94c4b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BVMamoNudzn9UlAE"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">梯度下降算法就像一个球滚下山坡。克劳迪奥·泰斯塔在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="263c" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj jd">Table of Contents </strong>(read till the end to see how you can get the complete python code of this story)</span><span id="7995" class="ln lo it lj b gy lt lq l lr ls">· <a class="ae lh" href="#0050" rel="noopener ugc nofollow">What is Optimization?</a><br/>· <a class="ae lh" href="#04b4" rel="noopener ugc nofollow">Gradient Descent (the Easy Way)</a><br/>· <a class="ae lh" href="#9f3c" rel="noopener ugc nofollow">Armijo Line Search</a><br/>· <a class="ae lh" href="#86f7" rel="noopener ugc nofollow">Gradient Descent (the Hard Way)</a><br/>· <a class="ae lh" href="#774e" rel="noopener ugc nofollow">Conclusion</a></span></pre><h1 id="0050" class="lu lo it bd lv lw lx ly lz ma mb mc md ki me kj mf kl mg km mh ko mi kp mj mk bi translated">什么是优化？</h1><p id="39af" class="pw-post-body-paragraph ml mm it mn b mo mp kd mq mr ms kg mt mu mv mw mx my mz na nb nc nd ne nf ng im bi nh translated"><span class="l ni nj nk bm nl nm nn no np di">如果</span>你研究机器学习的时间足够长，你可能会听说过诸如SGD或Adam这样的术语。它们是许多优化算法中的两种。优化算法是机器学习的核心，负责机器学习模型从数据中学习的复杂工作。事实证明，优化已经存在很长时间了，甚至在机器学习领域之外。</p><blockquote class="nq"><p id="e261" class="nr ns it bd nt nu nv nw nx ny nz ng dk translated">人们优化。投资者寻求创建能够避免过度风险、同时实现高回报率的投资组合。制造商的目标是在生产过程的设计和操作中实现最大效率。工程师调整参数以优化他们设计的性能。</p></blockquote><p id="6547" class="pw-post-body-paragraph ml mm it mn b mo oa kd mq mr ob kg mt mu oc mw mx my od na nb nc oe ne nf ng im bi translated">Jorge Nocedal的数值优化书的第一段已经解释了很多。它继续说，即使是自然优化。物理系统趋向于最小能量状态。孤立的化学系统中的分子相互反应，直到它们的电子总势能最小。光线沿着最小化其传播时间的路径行进。</p><p id="f50e" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">为了理解什么是优化，首先，我们必须确定<em class="ok">目标</em>，它可能是回报率、能量、旅行时间等。该目标取决于被称为<em class="ok">变量</em>的系统的某些特征。我们的目标是找到优化目标的变量的值。在某种程度上，变量通常是受约束的。</p><p id="8cf9" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">从数学上来说，优化是通过搜索适当的变量<em class="ok"> x </em>来最大化或最小化目标函数<em class="ok"> f(x) </em>的过程，该过程受到一些约束<em class="ok"> cᵢ </em>的约束，可以简洁地写成如下。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/c9483bd7c1a793c454c58206107bd689.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*QRr40PITaa275fxOqB3U2g.png"/></div></figure><p id="8576" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">其中ℰ和ℐ分别是平等和不平等约束的指数集。</p><p id="f576" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">乍一看，这种数学陈述确实令人望而生畏，也许是因为它是对优化的一般描述，在这里没有太多可以推断的。但是不要担心，到我们得到代码的时候，一切都会清楚的。</p><div class="om on gp gr oo op"><a rel="noopener follow" target="_blank" href="/complete-step-by-step-conjugate-gradient-algorithm-from-scratch-202c07fb52a8"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd jd gy z fp ou fr fs ov fu fw jc bi translated">从头开始完成逐步共轭梯度算法</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">和一般函数优化的实现</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd lb op"/></div></div></a></div><h1 id="04b4" class="lu lo it bd lv lw lx ly lz ma mb mc md ki me kj mf kl mg km mh ko mi kp mj mk bi translated">梯度下降(最简单的方法)</h1><p id="5351" class="pw-post-body-paragraph ml mm it mn b mo mp kd mq mr ms kg mt mu mv mw mx my mz na nb nc nd ne nf ng im bi translated">现在，我们如何求解<strong class="mn jd"> min </strong>函数？多亏了微积分，我们有了一个叫做<em class="ok">梯度</em>的工具。想象一下山顶上有一个球。我们知道这座山在不同的地方有不同的坡度。由于重力的作用，球会沿着山坡的曲线下降。它往哪边走？到最陡的坡度。一段时间后，球将到达局部最小值，此时地面相对于其周围环境是平坦的。</p><p id="3f1f" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">这就是梯度下降的本质。我们可以将球的平滑路径量化为微小的步长。在第<em class="ok"> k </em>步，我们会有两个量:步长<em class="ok"> αₖ </em>和方向<em class="ok"> pₖ </em>。为了看到渐变下降的效果，让我们首先导入一些库。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="ffeb" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">首先，我们将定义一个简单的目标函数<em class="ok">f(x)= x2x 3</em>，其中<em class="ok"> x </em>是实数。由于梯度下降使用梯度，我们也将定义<em class="ok"> f </em>的梯度，它正好是<em class="ok"> f </em>的一阶导数，即∇<em class="ok">f(x)= 2x 2</em>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="406f" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">接下来，我们定义python函数，用于在优化过程中绘制目标函数和<em class="ok">学习路径</em>。我们所说的学习路径就是每个下降步骤后的点<em class="ok"> x </em>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="b219" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">从下面的图中，我们可以很容易地看到<em class="ok"> f </em>在<em class="ok"> x = 1 </em>处有一个最小值(因此<em class="ok"> f(x) = -4 </em>)。假设我们从<em class="ok"> x = -4 </em>(下面用红点表示)开始，我们将看看梯度下降是否能定位到局部最小值<em class="ok"> x = 1 </em>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/6b257635fd4c6bff130aeab50ae6eaa5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*rxPFmL14rX2ZDESYh0t0tw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure><p id="2237" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">定义一个简单的梯度下降算法如下。对于步骤<em class="ok"> k </em>开始时的每个点<em class="ok"> xₖ </em>，我们保持步长<em class="ok"> αₖ </em>不变，并将方向<em class="ok"> pₖ </em>设置为梯度值的负值(在<em class="ok"> xₖ </em>处最陡下降)。我们使用公式采取步骤</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/f6d4a978e55aeec365ae7410eaa3b799.png" data-original-src="https://miro.medium.com/v2/resize:fit:294/format:webp/1*ajNWHNgpnTUrn5hSJkjHBA.png"/></div></figure><p id="8f80" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">而梯度仍然高于某个容差值(在我们的例子中为1 × 10⁻⁵)，并且步数仍然低于某个最大值(在我们的例子中为1000)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="aa1f" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">从<em class="ok"> x = -4 </em>开始，我们用不同的场景在<em class="ok"> f </em>上运行梯度下降算法:</p><ul class=""><li id="b23a" class="pi pj it mn b mo of mr og mu pk my pl nc pm ng pn po pp pq bi translated"><em class="ok"> αₖ = 0.1 </em></li><li id="01ba" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> αₖ = 0.9 </em></li><li id="ac35" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> αₖ = 1 × 10⁻⁴ </em></li><li id="a853" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> αₖ = 1.01 </em></li></ul></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="c3b5" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">情景1: αₖ = 0.1</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="b7bb" class="ln lo it lj b gy lp lq l lr ls">Solution found:<br/>  y = -4.0000<br/>  x = 1.0000</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/3816f5f66d863385dc84c07091d58aaf.png" data-original-src="https://miro.medium.com/v2/format:webp/1*nsNXk6UDRtHITGu1DNhPmw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="7e96" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">情景2: αₖ = 0.9</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="721d" class="ln lo it lj b gy lp lq l lr ls">Solution found:<br/>  y = -4.0000<br/>  x = 1.0000</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/e8fcf58bac0c424de4d687786406e906.png" data-original-src="https://miro.medium.com/v2/format:webp/1*pa_X-eVwriEid35lXEi9MA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="85c6" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">情景3: αₖ = 1 × 10⁻⁴</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="8674" class="ln lo it lj b gy lp lq l lr ls">Gradient descent does not converge.</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/6e37c2e3d9b2701d1d96e8f4837e2f3f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*SaOaZVva2MoYeVdvqpSesw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="cadf" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">情景4: αₖ = 1.01</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="520c" class="ln lo it lj b gy lp lq l lr ls">Gradient descent does not converge.</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/414e07c005959918634c6f62a725bf69.png" data-original-src="https://miro.medium.com/v2/format:webp/1*d9TJdetlDtU2B8zWLkD1cw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><p id="176e" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">这是我们得到的信息:</p><ul class=""><li id="a8e2" class="pi pj it mn b mo of mr og mu pk my pl nc pm ng pn po pp pq bi translated">第一个场景像魔咒一样收敛。即使步长是恒定的，方向也向零减小，因此导致收敛。</li><li id="4ed0" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated">第二种情况也是收敛的，即使学习路径由于大步长而在解附近振荡。</li><li id="6719" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated">第三个场景走向解决方案。但是步长太小，以至于迭代次数达到最大。增加<code class="fe qn qo qp lj b">max_iter</code>将会解决问题，尽管需要更长的时间才能找到解决方案。</li><li id="6fe3" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated">第四种情况由于大步长而发散。在这里，我们设置<code class="fe qn qo qp lj b">max_iter</code> = 8，以使可视化更令人愉快。</li></ul><p id="426e" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">总之，解<em class="ok"> x = 1 </em>可以通过具有合适步长的梯度下降来达到。</p><p id="ad02" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">你可能会想，为什么我们不用精确的解析解:对<em class="ok"> f </em>求导，然后求解<em class="ok"> x </em>使得导数为零。对于我们之前的例子，我们会发现使<em class="ok"> f </em>最小的<em class="ok"> x </em>将满足∇<em class="ok">f(x)= 2x 2 = 0</em>，即<em class="ok"> x = 1 </em>。</p><p id="1323" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">是的，这是一条路。但是当你面对一个优化问题时，这并不是一个推荐的技术，在这个优化问题中,<em class="ok"> f </em>的导数很难计算或者不可能求解。</p><h1 id="9f3c" class="lu lo it bd lv lw lx ly lz ma mb mc md ki me kj mf kl mg km mh ko mi kp mj mk bi translated">阿米霍线搜索</h1><p id="8065" class="pw-post-body-paragraph ml mm it mn b mo mp kd mq mr ms kg mt mu mv mw mx my mz na nb nc nd ne nf ng im bi translated">现在，我们可以从梯度下降算法中改进什么？我们之前看到，步长<em class="ok"> α </em>在整个步骤中保持不变，错误选择<em class="ok"> α </em>可能会导致步骤发散。我们能为每个步进方向寻找最佳的<em class="ok"> α </em>吗？</p><p id="a9f0" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">进入<em class="ok">线搜索</em>。</p><p id="45b8" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">在线搜索策略中，该算法选择一个方向<em class="ok"> pₖ </em>(可以像最速下降-∇ <em class="ok"> f(x) </em>一样简单)并且沿着这个方向从当前迭代<em class="ok"> xₖ </em>开始搜索具有更低函数值的新迭代。沿着<em class="ok"> pₖ </em>移动的距离可以通过近似求解以下一维最小化问题来找到步长<em class="ok"> α </em>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qq"><img src="../Images/970b7c0a38fa9f9d5a7b855000824752.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*0v3n-kMN07XlxPlyTqfOKw.png"/></div></figure><p id="c504" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">如前所述，通过精确求解，我们将从方向<em class="ok"> pₖ </em>中获得最大收益，但是精确的最小化可能是昂贵的，并且通常是不必要的。取而代之的是，线搜索算法产生有限数量的试验步长，直到它找到一个宽松地接近最小的<em class="ok"> f(xₖ + α pₖ) </em>。在新的点<em class="ok"> xₖ₊₁ = xₖ + α pₖ </em>，计算新的搜索方向和步长，并重复该过程。</p><p id="37d9" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">一个流行的不精确线搜索条件规定，<em class="ok"> αₖ </em>应该首先在目标函数<em class="ok"> f </em>中给出一个<em class="ok">足够的减少量</em>，如所谓的<em class="ok">阿米霍条件</em>所测量的:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qr"><img src="../Images/e78526ae9c2510bdabb1907d494e5858.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*Dqzpj9SWadOJBiVUf1oRGQ.png"/></div></figure><p id="dae9" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">对于某些常数<em class="ok"/>∈<em class="ok">(0，1) </em>。换句话说，<em class="ok"> f </em>的减少应与步长<em class="ok"> αₖ </em>和方向导数∇ <em class="ok"> fₖpₖ </em>成比例。在迭代<em class="ok"> xₖ </em>时，我们从一些初始的<em class="ok"> αₖ </em>开始，当阿米霍条件不满足时，我们简单地用一些收缩因子<em class="ok"> ρ </em>收缩<em class="ok"> αₖ </em>。收缩过程将在某一点终止，因为对于足够小的<em class="ok"> αₖ </em>，阿米霍条件总是满足的。</p><p id="8b4f" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">下面是Armijo行搜索的代码。注意我们用<em class="ok"> ρ = 0.5 </em>和<em class="ok"> c₁ = 1 × 10⁻⁴ </em>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="e40b" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">现在我们准备实现Armijo线搜索到梯度下降算法。</p><h1 id="86f7" class="lu lo it bd lv lw lx ly lz ma mb mc md ki me kj mf kl mg km mh ko mi kp mj mk bi translated">梯度下降(艰难的道路)</h1><p id="1424" class="pw-post-body-paragraph ml mm it mn b mo mp kd mq mr ms kg mt mu mv mw mx my mz na nb nc nd ne nf ng im bi translated">首先，我们定义一个更难求解的目标函数:<a class="ae lh" href="https://en.wikipedia.org/wiki/Griewank_function" rel="noopener ugc nofollow" target="_blank">格里万克函数</a>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qs"><img src="../Images/86f3feedb559ab5a8a829bff751827e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*iIfAWzz7BZj68K6a7d-I_Q.png"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="44ef" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">我们将使用Griewank函数的二维版本(<em class="ok"> n = 2 </em>)。为了说明一些问题，我们可以将这个函数绘制如下。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/fe33e8f9f046143a0e05b329e775e6dd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Sr9xu5sT7kKQT_cdhtjraA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure><p id="0cfa" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">我们可以看到这个函数有很多局部最优解。我们应该预料到梯度下降算法会陷入这些局部极小值之一。我们还可以注意到，全局最小值在<em class="ok"> x = </em> [ <em class="ok"> 0，0 </em> ]处，其中<em class="ok"> f(x) = 0 </em>。</p><p id="8ac8" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">最后，让我们最后一次构建梯度下降算法。如前所述，我们使用来自阿米霍线搜索的<em class="ok"> pₖ = - </em> ∇ <em class="ok"> f(xₖ) </em>作为方向和<em class="ok"> αₖ </em>作为步长。此外，将采取措施，直到满足以下停止标准之一:</p><ul class=""><li id="77ff" class="pi pj it mn b mo of mr og mu pk my pl nc pm ng pn po pp pq bi translated">目标函数的梯度的范数足够接近零，也就是说，</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qt"><img src="../Images/a4c633f16d02a11cc1922c78238cc6f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*uJjW4BBNCp1vUWSHPIv6Sg.png"/></div></figure><ul class=""><li id="ecc8" class="pi pj it mn b mo of mr og mu pk my pl nc pm ng pn po pp pq bi translated">采取的步骤数是1000</li></ul><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="0121" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">然后，我们创建一个python函数来创建两个图:</p><ul class=""><li id="950f" class="pi pj it mn b mo of mr og mu pk my pl nc pm ng pn po pp pq bi translated"><em class="ok"> x </em>的学习路径以及<em class="ok"> f(x) </em>的轮廓图</li><li id="bac9" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated">每走一步<em class="ok"> f(x) </em>的值</li></ul><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="b90a" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">对于初始值<em class="ok"> x₀ </em>，我们使用不同的场景对<em class="ok"> f </em>运行梯度下降算法:</p><ul class=""><li id="3f36" class="pi pj it mn b mo of mr og mu pk my pl nc pm ng pn po pp pq bi translated"><em class="ok"> x₀ = </em> [ <em class="ok"> 0，3 </em> ]</li><li id="b997" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> x₀ = </em> [ <em class="ok"> 1，2 </em> ]</li><li id="3980" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> x₀ = </em> [ <em class="ok"> 2，1 </em> ]</li><li id="30c2" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> x₀ = </em> [ <em class="ok"> 1，3 </em> ]</li><li id="5356" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> x₀ = </em> [ <em class="ok"> 2，2 </em> ]</li><li id="1496" class="pi pj it mn b mo pr mr ps mu pt my pu nc pv ng pn po pp pq bi translated"><em class="ok"> x₀ = </em> [ <em class="ok"> 3，1 </em></li></ul></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="9e56" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">场景1: x₀ = [0，3]</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="4f3c" class="ln lo it lj b gy lp lq l lr ls">Initial condition: y = 1.5254, x = [0 3] </span><span id="3b01" class="ln lo it lj b gy lt lq l lr ls">Iteration: 1 	 y = 1.1245, x = [0.0000 2.3959], gradient = 0.7029<br/>Iteration: 2 	 y = 0.6356, x = [0.0000 1.6929], gradient = 0.6591<br/>Iteration: 3 	 y = 0.2558, x = [0.0000 1.0338], gradient = 0.4726<br/>Iteration: 4 	 y = 0.0778, x = [0.0000 0.5612], gradient = 0.2736<br/>Iteration: 5 	 y = 0.0206, x = [0.0000 0.2876], gradient = 0.1430<br/>Iteration: 6 	 y = 0.0052, x = [0.0000 0.1447], gradient = 0.0723<br/>Iteration: 7 	 y = 0.0013, x = [0.0000 0.0724], gradient = 0.0362<br/>Iteration: 8 	 y = 0.0003, x = [0.0000 0.0362], gradient = 0.0181<br/>Iteration: 9 	 y = 0.0001, x = [0.0000 0.0181], gradient = 0.0090<br/>Iteration: 10 	 y = 0.0000, x = [0.0000 0.0090], gradient = 0.0045<br/>Iteration: 11 	 y = 0.0000, x = [0.0000 0.0045], gradient = 0.0023<br/>Iteration: 12 	 y = 0.0000, x = [0.0000 0.0023], gradient = 0.0011<br/>Iteration: 13 	 y = 0.0000, x = [0.0000 0.0011], gradient = 0.0006<br/>Iteration: 14 	 y = 0.0000, x = [0.0000 0.0006], gradient = 0.0003<br/>Iteration: 15 	 y = 0.0000, x = [0.0000 0.0003], gradient = 0.0001<br/>Iteration: 16 	 y = 0.0000, x = [0.0000 0.0001], gradient = 0.0001<br/>Iteration: 17 	 y = 0.0000, x = [0.0000 0.0001], gradient = 0.0000<br/>Iteration: 18 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000<br/>Iteration: 19 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000</span><span id="4e6e" class="ln lo it lj b gy lt lq l lr ls">Solution: 	 y = 0.0000, x = [0.0000 0.0000]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/ed6124145ac4cbe8931a10c5278f633c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*mZqhQcTocf9fdY3AL-7tHQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="87f9" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">场景2: x₀ = [1，2]</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="c1df" class="ln lo it lj b gy lp lq l lr ls">Initial condition: y = 0.9170, x = [1 2] </span><span id="3031" class="ln lo it lj b gy lt lq l lr ls">Iteration: 1 	 y = 0.7349, x = [0.8683 1.6216], gradient = 0.5225<br/>Iteration: 2 	 y = 0.4401, x = [0.5538 1.2044], gradient = 0.5705<br/>Iteration: 3 	 y = 0.1564, x = [0.2071 0.7513], gradient = 0.3932<br/>Iteration: 4 	 y = 0.0403, x = [0.0297 0.4004], gradient = 0.1997<br/>Iteration: 5 	 y = 0.0103, x = [0.0012 0.2027], gradient = 0.1011<br/>Iteration: 6 	 y = 0.0026, x = [0.0000 0.1016], gradient = 0.0508<br/>Iteration: 7 	 y = 0.0006, x = [0.0000 0.0508], gradient = 0.0254<br/>Iteration: 8 	 y = 0.0002, x = [0.0000 0.0254], gradient = 0.0127<br/>Iteration: 9 	 y = 0.0000, x = [0.0000 0.0127], gradient = 0.0063<br/>Iteration: 10 	 y = 0.0000, x = [0.0000 0.0063], gradient = 0.0032<br/>Iteration: 11 	 y = 0.0000, x = [0.0000 0.0032], gradient = 0.0016<br/>Iteration: 12 	 y = 0.0000, x = [0.0000 0.0016], gradient = 0.0008<br/>Iteration: 13 	 y = 0.0000, x = [0.0000 0.0008], gradient = 0.0004<br/>Iteration: 14 	 y = 0.0000, x = [0.0000 0.0004], gradient = 0.0002<br/>Iteration: 15 	 y = 0.0000, x = [0.0000 0.0002], gradient = 0.0001<br/>Iteration: 16 	 y = 0.0000, x = [0.0000 0.0001], gradient = 0.0000<br/>Iteration: 17 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000<br/>Iteration: 18 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000<br/>Iteration: 19 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000</span><span id="7923" class="ln lo it lj b gy lt lq l lr ls">Solution: 	 y = 0.0000, x = [0.0000 0.0000]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/72336ef35de60c7b834203b97dd5528d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*43BSVXcPJ_Z8ksd4dGs6ww.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="d296" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">场景3: x₀ = [2，1]</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="7413" class="ln lo it lj b gy lp lq l lr ls">Initial condition: y = 1.3176, x = [2 1] </span><span id="d3cc" class="ln lo it lj b gy lt lq l lr ls">Iteration: 1 	 y = 0.8276, x = [1.3077 1.1907], gradient = 0.6583<br/>Iteration: 2 	 y = 0.4212, x = [0.6639 1.0529], gradient = 0.5903<br/>Iteration: 3 	 y = 0.1315, x = [0.2104 0.6750], gradient = 0.3682<br/>Iteration: 4 	 y = 0.0320, x = [0.0248 0.3570], gradient = 0.1784<br/>Iteration: 5 	 y = 0.0081, x = [0.0008 0.1803], gradient = 0.0900<br/>Iteration: 6 	 y = 0.0020, x = [0.0000 0.0903], gradient = 0.0452<br/>Iteration: 7 	 y = 0.0005, x = [0.0000 0.0451], gradient = 0.0226<br/>Iteration: 8 	 y = 0.0001, x = [0.0000 0.0225], gradient = 0.0113<br/>Iteration: 9 	 y = 0.0000, x = [0.0000 0.0113], gradient = 0.0056<br/>Iteration: 10 	 y = 0.0000, x = [0.0000 0.0056], gradient = 0.0028<br/>Iteration: 11 	 y = 0.0000, x = [0.0000 0.0028], gradient = 0.0014<br/>Iteration: 12 	 y = 0.0000, x = [0.0000 0.0014], gradient = 0.0007<br/>Iteration: 13 	 y = 0.0000, x = [0.0000 0.0007], gradient = 0.0004<br/>Iteration: 14 	 y = 0.0000, x = [0.0000 0.0004], gradient = 0.0002<br/>Iteration: 15 	 y = 0.0000, x = [0.0000 0.0002], gradient = 0.0001<br/>Iteration: 16 	 y = 0.0000, x = [0.0000 0.0001], gradient = 0.0000<br/>Iteration: 17 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000<br/>Iteration: 18 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000<br/>Iteration: 19 	 y = 0.0000, x = [0.0000 0.0000], gradient = 0.0000</span><span id="0714" class="ln lo it lj b gy lt lq l lr ls">Solution: 	 y = 0.0000, x = [0.0000 0.0000]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/f4557125f5a570e47511e05e04600742.png" data-original-src="https://miro.medium.com/v2/format:webp/1*eZftRW1fQ0QMKTl3hByXCQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="2c85" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">场景4: x₀ = [1，3]</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="7835" class="ln lo it lj b gy lp lq l lr ls">Initial condition: y = 1.2852, x = [1 3] </span><span id="6e6a" class="ln lo it lj b gy lt lq l lr ls">Iteration: 1 	 y = 1.0433, x = [1.4397 2.6729], gradient = 0.3230<br/>Iteration: 2 	 y = 0.9572, x = [1.7501 2.5838], gradient = 0.2763<br/>Iteration: 3 	 y = 0.8638, x = [1.9986 2.7045], gradient = 0.4098<br/>Iteration: 4 	 y = 0.6623, x = [2.3024 2.9796], gradient = 0.5544<br/>Iteration: 5 	 y = 0.3483, x = [2.6813 3.3842], gradient = 0.5380<br/>Iteration: 6 	 y = 0.1116, x = [3.0054 3.8137], gradient = 0.3231<br/>Iteration: 7 	 y = 0.0338, x = [3.1265 4.1133], gradient = 0.1618<br/>Iteration: 8 	 y = 0.0141, x = [3.1396 4.2745], gradient = 0.0818<br/>Iteration: 9 	 y = 0.0091, x = [3.1400 4.3564], gradient = 0.0411<br/>Iteration: 10 	 y = 0.0078, x = [3.1400 4.3974], gradient = 0.0205<br/>Iteration: 11 	 y = 0.0075, x = [3.1400 4.4179], gradient = 0.0103<br/>Iteration: 12 	 y = 0.0074, x = [3.1400 4.4282], gradient = 0.0051<br/>Iteration: 13 	 y = 0.0074, x = [3.1400 4.4333], gradient = 0.0026<br/>Iteration: 14 	 y = 0.0074, x = [3.1400 4.4359], gradient = 0.0013<br/>Iteration: 15 	 y = 0.0074, x = [3.1400 4.4372], gradient = 0.0006<br/>Iteration: 16 	 y = 0.0074, x = [3.1400 4.4378], gradient = 0.0003<br/>Iteration: 17 	 y = 0.0074, x = [3.1400 4.4381], gradient = 0.0002<br/>Iteration: 18 	 y = 0.0074, x = [3.1400 4.4383], gradient = 0.0001<br/>Iteration: 19 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000<br/>Iteration: 20 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000<br/>Iteration: 21 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000</span><span id="91ea" class="ln lo it lj b gy lt lq l lr ls">Solution: 	 y = 0.0074, x = [3.1400 4.4384]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/4d57ab12bcf38288ca2c15778b1bfe83.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ERpUYyymne8RZfcfm8RYaw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="9864" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">场景5: x₀ = [2，2]</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="3563" class="ln lo it lj b gy lp lq l lr ls">Initial condition: y = 1.0669, x = [2 2] </span><span id="37d7" class="ln lo it lj b gy lt lq l lr ls">Iteration: 1 	 y = 0.9886, x = [1.8572 2.2897], gradient = 0.2035<br/>Iteration: 2 	 y = 0.9414, x = [1.9025 2.488 ], gradient = 0.2858<br/>Iteration: 3 	 y = 0.8372, x = [2.0788 2.713 ], gradient = 0.4378<br/>Iteration: 4 	 y = 0.6117, x = [2.3753 3.035 ], gradient = 0.5682<br/>Iteration: 5 	 y = 0.2941, x = [2.7514 3.461 ], gradient = 0.5082<br/>Iteration: 6 	 y = 0.0894, x = [3.0423 3.8777], gradient = 0.2863<br/>Iteration: 7 	 y = 0.0282, x = [3.1321 4.1495], gradient = 0.1438<br/>Iteration: 8 	 y = 0.0127, x = [3.1398 4.2931], gradient = 0.0726<br/>Iteration: 9 	 y = 0.0087, x = [3.1400 4.3657], gradient = 0.0364<br/>Iteration: 10 	 y = 0.0077, x = [3.1400 4.4021], gradient = 0.0182<br/>Iteration: 11 	 y = 0.0075, x = [3.1400 4.4203], gradient = 0.0091<br/>Iteration: 12 	 y = 0.0074, x = [3.1400 4.4294], gradient = 0.0045<br/>Iteration: 13 	 y = 0.0074, x = [3.1400 4.4339], gradient = 0.0023<br/>Iteration: 14 	 y = 0.0074, x = [3.1400 4.4362], gradient = 0.0011<br/>Iteration: 15 	 y = 0.0074, x = [3.1400 4.4373], gradient = 0.0006<br/>Iteration: 16 	 y = 0.0074, x = [3.1400 4.4379], gradient = 0.0003<br/>Iteration: 17 	 y = 0.0074, x = [3.1400 4.4382], gradient = 0.0001<br/>Iteration: 18 	 y = 0.0074, x = [3.1400 4.4383], gradient = 0.0001<br/>Iteration: 19 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000<br/>Iteration: 20 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000<br/>Iteration: 21 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000</span><span id="984e" class="ln lo it lj b gy lt lq l lr ls">Solution: 	 y = 0.0074, x = [3.1400 4.4384]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/eb0d0570421ffdcb536a5362f1520c21.png" data-original-src="https://miro.medium.com/v2/format:webp/1*HYIV0hCWD7EgWfGbjQltwQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><h2 id="7600" class="ln lo it bd lv qd qe dn lz qf qg dp md mu qh qi mf my qj qk mh nc ql qm mj iz bi translated">场景6: x₀ = [3，1]</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="5057" class="ln lo it lj b gy lp lq l lr ls">Initial condition: y = 1.7551, x = [3 1] </span><span id="d4e8" class="ln lo it lj b gy lt lq l lr ls">Iteration: 1 	 y = 1.5028, x = [2.8912 1.4543], gradient = 0.6001<br/>Iteration: 2 	 y = 1.1216, x = [2.7619 2.0402], gradient = 0.6522<br/>Iteration: 3 	 y = 0.7074, x = [2.7131 2.6906], gradient = 0.6214<br/>Iteration: 4 	 y = 0.3449, x = [2.8471 3.2973], gradient = 0.5273<br/>Iteration: 5 	 y = 0.1160, x = [3.0458 3.7858], gradient = 0.3246<br/>Iteration: 6 	 y = 0.0361, x = [3.1298 4.0993], gradient = 0.1683<br/>Iteration: 7 	 y = 0.0147, x = [3.1397 4.2673], gradient = 0.0854<br/>Iteration: 8 	 y = 0.0092, x = [3.1400 4.3528], gradient = 0.0429<br/>Iteration: 9 	 y = 0.0079, x = [3.1400 4.3956], gradient = 0.0214<br/>Iteration: 10 	 y = 0.0075, x = [3.1400 4.4170], gradient = 0.0107<br/>Iteration: 11 	 y = 0.0074, x = [3.1400 4.4278], gradient = 0.0053<br/>Iteration: 12 	 y = 0.0074, x = [3.1400 4.4331], gradient = 0.0027<br/>Iteration: 13 	 y = 0.0074, x = [3.1400 4.4358], gradient = 0.0013<br/>Iteration: 14 	 y = 0.0074, x = [3.1400 4.4371], gradient = 0.0007<br/>Iteration: 15 	 y = 0.0074, x = [3.1400 4.4378], gradient = 0.0003<br/>Iteration: 16 	 y = 0.0074, x = [3.1400 4.4381], gradient = 0.0002<br/>Iteration: 17 	 y = 0.0074, x = [3.1400 4.4383], gradient = 0.0001<br/>Iteration: 18 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000<br/>Iteration: 19 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000<br/>Iteration: 20 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000<br/>Iteration: 21 	 y = 0.0074, x = [3.1400 4.4384], gradient = 0.0000</span><span id="45c3" class="ln lo it lj b gy lt lq l lr ls">Solution: 	 y = 0.0074, x = [3.1400 4.4384]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/dcf5b9a3f50628b182b13c1dc516f438.png" data-original-src="https://miro.medium.com/v2/format:webp/1*fHJad9Y74AZ1Ku9J91OEhQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><p id="33b8" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">在前3种情况下，算法收敛到全局最小值，其中<em class="ok"> f(x) = 0 </em>，尽管第一种情况似乎浪费了太多步骤，因为对于这种情况<em class="ok"> x₀ </em>的第一个坐标已经是0。</p><p id="9610" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">在最后3种情况下，算法陷入局部最小值，其中<em class="ok"> f(x) = 0.0074 </em>，因为<em class="ok"> x₀ </em>离坐标<em class="ok"> 0，0 </em>太远。这并不奇怪，因为线搜索方法通过朝向函数值减小且梯度的范数接近零的方向来寻找<em class="ok"> f </em>的最小值，因此当该方法获得梯度非常接近零的坐标时，该点被认为是函数最小值，而不管最小值是局部的还是全局的。</p><p id="b94f" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">如果我们对原始目标函数<em class="ok">f(x)= x</em><em class="ok">2x</em><em class="ok">3</em>应用这个版本的梯度下降，我们会得到以下结果。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pe pf l"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="c15a" class="ln lo it lj b gy lp lq l lr ls">Initial condition: y = 21.0000, x = -4 </span><span id="9aa1" class="ln lo it lj b gy lt lq l lr ls">Iteration: 1 	 y = -4.0000, x = 1.0, gradient = 0.0000</span><span id="abed" class="ln lo it lj b gy lt lq l lr ls">Solution: 	 y = -4.0000, x = 1.0</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/6e628a92292f50c98fbf3e14ea748f64.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xdS99tLmhLz_AFtTXYMJLw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="http://dwiuzila.medium.com/membership" rel="noopener">作者</a></p></figure><p id="21b5" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">解决方法一步到位！</p><p id="0a46" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">对此你怎么看？是因为新的梯度下降版本对于这个功能来说太大材小用了吗？还是这只是巧合，改变<em class="ok"> ρ </em>等参数不会产生比原来简单的梯度下降更好的结果？请在下面的回复部分告诉我你的想法！</p><h1 id="774e" class="lu lo it bd lv lw lx ly lz ma mb mc md ki me kj mf kl mg km mh ko mi kp mj mk bi translated">结论</h1><p id="b60c" class="pw-post-body-paragraph ml mm it mn b mo mp kd mq mr ms kg mt mu mv mw mx my mz na nb nc nd ne nf ng im bi translated">在本文中，我们了解了梯度下降算法在优化问题中的工作，从简单的高中教科书问题到现实世界的机器学习成本函数最小化问题。简单的实现假设一个恒定的学习速率，而较难的实现使用Armijo线搜索来搜索学习速率。算法本身是最基本的，并且根据目标函数的性质有许多变化和实现。像许多其他优化算法一样，梯度下降算法可能会陷入局部最小值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qu"><img src="../Images/e1a6e3674ab93bcb99796285f9d0175c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6HsoGpmIb1oibJc_JWbqJA.gif"/></div></div></figure></div><div class="ab cl pw px hx py" role="separator"><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb qc"/><span class="pz bw bk qa qb"/></div><div class="im in io ip iq"><p id="4859" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">🔥你好！如果你喜欢这个故事，想支持我这个作家，可以考虑 <a class="ae lh" href="https://dwiuzila.medium.com/membership" rel="noopener"> <strong class="mn jd"> <em class="ok">成为会员</em> </strong> </a> <em class="ok">。每月只需5美元，你就可以无限制地阅读媒体上的所有报道。如果你注册使用我的链接，我会赚一小笔佣金。</em></p><p id="bd58" class="pw-post-body-paragraph ml mm it mn b mo of kd mq mr og kg mt mu oh mw mx my oi na nb nc oj ne nf ng im bi translated">🔖<em class="ok">想了解更多关于经典机器学习模型如何工作以及如何优化其参数的信息？或者MLOps大型项目的例子？有史以来最优秀的文章呢？继续阅读:</em></p><div class="om on gp gr oo"><div role="button" tabindex="0" class="ab bv gv cb fp qv qw bn qx lb ex"><div class="qy l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw qz ra fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l qz ra fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="rd re gw l"><h2 class="bd jd wg pi fp wh fr fs ov fu fw jc bi translated">从零开始的机器学习</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi wi au wj wk wl sx wm an eh ei wn wo wp el em eo de bk ep" href="https://dwiuzila.medium.com/list/machine-learning-from-scratch-b35db8650093?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wq l fo"><span class="bd b dl z dk">8 stories</span></div></div></div><div class="rq dh rr fp ab rs fo di"><div class="di ri bv rj rk"><div class="dh l"><img alt="" class="dh" src="../Images/4b97f3062e4883b24589972b2dc45d7e.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*CWNoicci28F2TUQc-vKijw.png"/></div></div><div class="di ri bv rl rm rn"><div class="dh l"><img alt="" class="dh" src="../Images/b1f7021514ba57a443fe0db4b7001b26.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*wSRsSHYnIiGJFAqC"/></div></div><div class="di bv ro rp rn"><div class="dh l"><img alt="" class="dh" src="../Images/deb73e42c79667024a46c2c8902b81fa.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*HVEz7KwzO0tv1Q4d"/></div></div></div></div></div><div class="om on gp gr oo"><div role="button" tabindex="0" class="ab bv gv cb fp qv qw bn qx lb ex"><div class="qy l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw qz ra fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l qz ra fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="rd re gw l"><h2 class="bd jd wg pi fp wh fr fs ov fu fw jc bi translated">高级优化方法</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi wi au wj wk wl sx wm an eh ei wn wo wp el em eo de bk ep" href="https://dwiuzila.medium.com/list/advanced-optimization-methods-26e264a361e4?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wq l fo"><span class="bd b dl z dk">7 stories</span></div></div></div><div class="rq dh rr fp ab rs fo di"><div class="di ri bv rj rk"><div class="dh l"><img alt="" class="dh" src="../Images/15b3188b0f29894c2bcf3d0965515f44.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*BVMamoNudzn9UlAE"/></div></div><div class="di ri bv rl rm rn"><div class="dh l"><img alt="" class="dh" src="../Images/3249ba2cf680952e2ccdff36d8ebf4a7.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*C1fv3HJdh1RBspwN"/></div></div><div class="di bv ro rp rn"><div class="dh l"><img alt="" class="dh" src="../Images/a73f0494533d8a08b01c2b899373d2b9.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*QZvzgiM2VnhYyx8M"/></div></div></div></div></div><div class="om on gp gr oo"><div role="button" tabindex="0" class="ab bv gv cb fp qv qw bn qx lb ex"><div class="qy l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw qz ra fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l qz ra fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="rd re gw l"><h2 class="bd jd wg pi fp wh fr fs ov fu fw jc bi translated">MLOps大型项目</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi wi au wj wk wl sx wm an eh ei wn wo wp el em eo de bk ep" href="https://dwiuzila.medium.com/list/mlops-megaproject-6a3bf86e45e4?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wq l fo"><span class="bd b dl z dk">6 stories</span></div></div></div><div class="rq dh rr fp ab rs fo di"><div class="di ri bv rj rk"><div class="dh l"><img alt="" class="dh" src="../Images/41b5d7dd3997969f3680648ada22fd7f.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*EBS8CP_UnStLesXoAvjeAQ.png"/></div></div><div class="di ri bv rl rm rn"><div class="dh l"><img alt="" class="dh" src="../Images/41befac52d90334c64eef7fc5c4b4bde.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*XLpRKnIMcJzBzCwvXrLvsw.png"/></div></div><div class="di bv ro rp rn"><div class="dh l"><img alt="" class="dh" src="../Images/80908ef475e97fbc42efe3fae0dfcff5.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*K_gzBmjv-ZHlU0Q6HeXclQ.jpeg"/></div></div></div></div></div><div class="om on gp gr oo"><div role="button" tabindex="0" class="ab bv gv cb fp qv qw bn qx lb ex"><div class="qy l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw qz ra fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l qz ra fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="rd re gw l"><h2 class="bd jd wg pi fp wh fr fs ov fu fw jc bi translated">我最好的故事</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi wi au wj wk wl sx wm an eh ei wn wo wp el em eo de bk ep" href="https://dwiuzila.medium.com/list/my-best-stories-d8243ae80aa0?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wq l fo"><span class="bd b dl z dk">24 stories</span></div></div></div><div class="rq dh rr fp ab rs fo di"><div class="di ri bv rj rk"><div class="dh l"><img alt="" class="dh" src="../Images/0c862c3dee2d867d6996a970dd38360d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*K1SQZ1rzr4cb-lSi"/></div></div><div class="di ri bv rl rm rn"><div class="dh l"><img alt="" class="dh" src="../Images/392d63d181090365a63dc9060573bcff.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*hSKy6kKorAfHjHOK"/></div></div><div class="di bv ro rp rn"><div class="dh l"><img alt="" class="dh" src="../Images/f51725806220b60eccf5d4c385c700e9.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*HiyGwoGOMI5Ao_fd"/></div></div></div></div></div><div class="om on gp gr oo"><div role="button" tabindex="0" class="ab bv gv cb fp qv qw bn qx lb ex"><div class="qy l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw qz ra fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l qz ra fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated">艾伯斯·乌兹拉</p></div></div><div class="rd re gw l"><h2 class="bd jd wg pi fp wh fr fs ov fu fw jc bi translated">R中的数据科学</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi wi au wj wk wl sx wm an eh ei wn wo wp el em eo de bk ep" href="https://dwiuzila.medium.com/list/data-science-in-r-0a8179814b50?source=post_page-----acba013e8420--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wq l fo"><span class="bd b dl z dk">7 stories</span></div></div></div><div class="rq dh rr fp ab rs fo di"><div class="di ri bv rj rk"><div class="dh l"><img alt="" class="dh" src="../Images/e52e43bf7f22bfc0889cc794dcf734dd.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*10B3radiyQGAp-QA"/></div></div><div class="di ri bv rl rm rn"><div class="dh l"><img alt="" class="dh" src="../Images/945fa9100c2a00b46f8aca3d3975f288.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*o6A863Vdwq7ThlmW"/></div></div><div class="di bv ro rp rn"><div class="dh l"><img alt="" class="dh" src="../Images/3ca9e4b148297dbc4e7da0a180cf9c99.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*ekmX89TW6N8Bi8bL"/></div></div></div></div></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://dwiuzila.medium.com/membership"><div class="gh gi rw"><img src="../Images/f767019309a71e9b3b70d2f9b1016aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_dzEmnimgItuotIZ-y73A.png"/></div></a></figure></div></div>    
</body>
</html>