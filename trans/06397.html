<html>
<head>
<title>AutoML in Python: A comparison between Hyperopt Sklearn and TPOT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的AutoML:Hyperopt sk learn和TPOT的比较</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automl-in-python-a-comparison-between-hyperopt-sklearn-and-tpot-8c12aaf7e829?source=collection_archive---------27-----------------------#2021-06-08">https://towardsdatascience.com/automl-in-python-a-comparison-between-hyperopt-sklearn-and-tpot-8c12aaf7e829?source=collection_archive---------27-----------------------#2021-06-08</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="214d" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">数据分析</h2><div class=""/><div class=""><h2 id="51b4" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">两种流行的Python AutoML库的优缺点</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/65ed8aceee50e646c19e1c3608a561f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1kKQqqkS3OL8uEZVzjiL_A.jpeg"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">图片来自<a class="ae lk" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=6281625" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="440f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><strong class="ln jg">自动化机器学习</strong> ( <strong class="ln jg"> AutoML </strong>)涉及将机器学习应用于现实世界问题的任务的自动化。AutoML涵盖了从原始数据集到可部署的机器学习模型的完整管道。</p><p id="f3e0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">Python提供了一些提供AutoML的库。在本教程中，我比较了两个流行的库:Hyperopt Sklearn和TPOT。存在另一个库，名为<a class="ae lk" href="https://automl.github.io/auto-sklearn/master/index.html" rel="noopener ugc nofollow" target="_blank"> AutoSklearn </a>，本文没有对其进行测试，因为它与一些操作系统不兼容。</p><p id="bca2" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">这两个被分析的库都与<a class="ae lk" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>兼容，后者是著名的用于机器学习的Python库。</p><p id="5fc0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">本教程的完整代码可以从<a class="ae lk" href="https://github.com/alod83/data-science/blob/master/DataAnalysis/AutoML.ipynb" rel="noopener ugc nofollow" target="_blank">我的Github库</a>下载。</p><p id="eb54" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">作为本教程的用例，我利用了由<a class="ae lk" href="https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle库</a>提供的<code class="fe mh mi mj mk b">heart.csv</code>数据集。数据集关注心脏病发作，包含14个输入特征，并提供二元分类作为输出(心脏病发作是或否)。</p><h1 id="331a" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">1.远视Sklearn</h1><p id="4f7e" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">这个库很容易安装，如文档中所解释的，并且使用起来非常简单。文档简单明了。它支持许多<code class="fe mh mi mj mk b">scikit-learn</code>分类器、回归器和预处理模型。为了建立一个AutoML模型，创建一个<code class="fe mh mi mj mk b">HyperoptEstimator()</code>的实例，配置一些参数(如估计类型)，然后拟合模型就足够了。<code class="fe mh mi mj mk b">HyperoptEstimator</code>的<code class="fe mh mi mj mk b">bestmodel()</code>返回一个包含完整<code class="fe mh mi mj mk b">scikit-learn</code>管道的对象。</p><p id="db5f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">让我们假设<code class="fe mh mi mj mk b">X</code>和<code class="fe mh mi mj mk b">y</code>分别包含输入特征和目标。我们可以通过<code class="fe mh mi mj mk b">scikit-learn</code>函数<code class="fe mh mi mj mk b">train_test_split()</code>将它们分成训练集和测试集:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="4d99" class="nm mm iw mk b gz nn no l np nq">from sklearn.model_selection import train_test_split</span><span id="bd7d" class="nm mm iw mk b gz nr no l np nq">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span></pre><p id="1407" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我们可以训练<code class="fe mh mi mj mk b">HyperoptEstimator</code>搜索最佳分类器:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="4b1d" class="nm mm iw mk b gz nn no l np nq">from hpsklearn import HyperoptEstimator</span><span id="2618" class="nm mm iw mk b gz nr no l np nq">estim = HyperoptEstimator()<br/>estim.fit( X_train, y_train )</span></pre><p id="9f28" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我们可以得到最好的模型:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="0d39" class="nm mm iw mk b gz nn no l np nq">best_model = estim.best_model()</span></pre><p id="224e" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="b43f" class="nm mm iw mk b gz nn no l np nq">{'learner': ExtraTreesClassifier(criterion='entropy', max_features='sqrt', n_estimators=13,<br/>                      n_jobs=1, random_state=4, verbose=False),<br/> 'preprocs': (),<br/> 'ex_preprocs': ()}</span></pre><p id="9a69" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">键/值对<code class="fe mh mi mj mk b">learner</code>包含最佳模型，第二个模型(<code class="fe mh mi mj mk b">preproc</code>)包含应用的预处理技术。在这种情况下，它是空的。</p><blockquote class="ns nt nu"><p id="f4ca" class="ll lm nv ln b lo lp kg lq lr ls kj lt nw lv lw lx nx lz ma mb ny md me mf mg ip bi translated">Hyperopt Sklearn库反映了机器学习的随机性质:事实上，如果我们试图在相同的训练集上再次运行分类器，我们会获得另一个结果。</p></blockquote><p id="b386" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">使用相同的训练集运行相同的代码(不执行再次训练/测试分割)，我们获得以下最佳模型:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="e63b" class="nm mm iw mk b gz nn no l np nq">{'learner': GradientBoostingClassifier(learning_rate=0.00813591154617836, max_depth=None, max_features=0.6562885234780235, min_samples_leaf=11, n_estimators=63, random_state=0, subsample=0.68797222866341),<br/> 'preprocs': (MinMaxScaler(feature_range=(-1.0, 1.0)),),<br/> 'ex_preprocs': ()}</span></pre><p id="ad4f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">反正我们可以计算模型的性能。我们可以利用内置函数<code class="fe mh mi mj mk b">score()</code>或者定义我们的性能指标。在最后一种情况下，首先，我们必须将获得的预处理(如果有的话)应用于测试集，并将预测结果与实际值进行比较:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="379c" class="nm mm iw mk b gz nn no l np nq">X_test_norm = X_test<br/>if len(best_model['preprocs']) &gt; 0:<br/>    preprocs = best_model['preprocs'][0]<br/>    X_test_norm = preprocs.transform(X_test)</span></pre><p id="b872" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">Hyperopt Sklearn库不提供<code class="fe mh mi mj mk b">predict_proba()</code>函数，因此我们必须手动计算:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="8707" class="nm mm iw mk b gz nn no l np nq">model = best_model['learner']<br/>y_score_hp = model.predict_proba(X_test_norm)</span></pre><p id="7f0c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">然后，我们可以绘制由<code class="fe mh mi mj mk b">scikitplot</code>库提供的ROC曲线和精确召回曲线，如下所示:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="652a" class="nm mm iw mk b gz nn no l np nq">import matplotlib.pyplot as plt<br/>from sklearn.metrics import roc_curve<br/>from scikitplot.metrics import plot_roc,auc<br/>from scikitplot.metrics import plot_precision_recall</span><span id="0b7b" class="nm mm iw mk b gz nr no l np nq"># Plot metrics <br/>plot_roc(y_test, y_score_hp)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score_hp)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj nz"><img src="../Images/d248325ba4915c9947edb476567d43f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MsN7Gfuw90J1FoCj1YELzw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oa"><img src="../Images/f7838ca434709547c94634ea04b47273.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*221D3sET7cqFJfX7rtliyg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="5bd0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我们还可以计算精确度、召回率和准确度:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="77cf" class="nm mm iw mk b gz nn no l np nq">y_test_pred = model.predict(X_test_norm)<br/>accuracy = accuracy_score(y_test, y_test_pred)<br/>precision = precision_score(y_test, y_test_pred)<br/>recall = recall_score(y_test, y_test_pred)</span><span id="70b2" class="nm mm iw mk b gz nr no l np nq">print('accuracy:  %s ' %(round(accuracy, 2)))<br/>print('precision:  %s ' %(round(precision, 2)))<br/>print('recall:  %s ' %(round(recall, 2)))</span></pre><p id="4173" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="7603" class="nm mm iw mk b gz nn no l np nq">accuracy:  0.85 <br/>precision:  0.85 <br/>recall:  0.9</span></pre><p id="ed9c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在我的Github存储库中可用的完整代码中，我还通过10重验证计算了所获得模型的精度、召回率和准确度。下图显示了折叠次数的精度趋势:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oa"><img src="../Images/0f5c69ddf7fd1f0b14a25576064de3a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vxeTcuW42Q3dBu6xbV-frg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="290d" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我注意到模型没有过度拟合。</p><h1 id="67a7" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">2.TPOT</h1><p id="476c" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">TPOT是AutoML的另一个Python库。它的<a class="ae lk" href="http://epistasislab.github.io/tpot/" rel="noopener ugc nofollow" target="_blank">文档</a>做得很好。然而，安装它并不简单，因为它是建立在其他库的基础上的，因此你必须先安装它们才能让TPOT工作和运行。个人觉得在正确安装之前遇到了很多问题。</p><p id="7b88" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">一旦安装完毕，我们就可以创建一个评估器，或者是一个<code class="fe mh mi mj mk b">TPOTClassifier()</code>或者是一个<code class="fe mh mi mj mk b">TPOTRegressor()</code>。在我们的例子中，我们构建了一个TPOT分类器:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="cd2e" class="nm mm iw mk b gz nn no l np nq">from tpot import TPOTClassifier</span><span id="c93a" class="nm mm iw mk b gz nr no l np nq">tpot = TPOTClassifier(generations=5, population_size=50, random_state=42)<br/>tpot.fit(X_train, y_train)</span></pre><p id="952f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">这个过程非常缓慢，需要一段时间才能完成。我们可以计算模型的精度、召回率和准确度:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="24bf" class="nm mm iw mk b gz nn no l np nq">y_test_pred = tpot.predict(X_test)<br/>accuracy = accuracy_score(y_test, y_test_pred)<br/>precision = precision_score(y_test, y_test_pred)<br/>recall = recall_score(y_test, y_test_pred)<br/>print('accuracy:  %s ' %(round(accuracy, 2)))<br/>print('precision:  %s ' %(round(precision, 2)))<br/>print('recall:  %s ' %(round(recall, 2)))</span></pre><p id="d226" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="c2e8" class="nm mm iw mk b gz nn no l np nq">accuracy:  0.8 <br/>precision:  0.84 <br/>recall:  0.81</span></pre><p id="9c82" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">关于通过Hyperopt Sklearn获得的最佳模型，TPOT表现较差。</p><p id="11b3" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">TPOT也提供了<code class="fe mh mi mj mk b">predict_proba()</code>方法，可以用来计算ROC曲线和精确召回曲线。</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ob"><img src="../Images/b1ca4e6616f2992d46382216a4d81953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z_Wi9cnhtidhDc9nSwBOYQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oc"><img src="../Images/22c9a6303c25cca18a62c0c993171690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QJYZWnDh163Df9uxaUeqMg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="3676" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我们可以通过<code class="fe mh mi mj mk b">scikit-learn</code>管道访问最佳模型:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="9545" class="nm mm iw mk b gz nn no l np nq">tpot.fitted_pipeline_</span></pre><p id="b4b8" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu ni mk nj nk aw nl bi"><span id="ddb5" class="nm mm iw mk b gz nn no l np nq">Pipeline(steps=[('logisticregression',<br/>                 LogisticRegression(C=20.0, random_state=42))])</span></pre><p id="41f8" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">虽然在文档中提到模型可能在相同的数据集上产生不同的最佳模型，但是在我们的例子中，在相同的数据集上运行更多次相同的代码会返回相同的模型。</p><p id="e3c8" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我可以通过10重交叉验证来计算精确度、召回率和准确度。TPOT本身提供了交叉验证。然而，在这种情况下，我们手动计算它，因为我们想要绘制度量相对于每个折叠的趋势。</p><p id="acb2" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">下图显示了精度趋势。对于其他情节(回忆和准确性)，请检查我的Github库:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj od"><img src="../Images/9ce1d8a7f75e6fa23e216ad8326f722d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-6eKSR301KTGqrNDiGUUQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="34e7" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">关于Hyperopt Sklearn库，TPOT似乎更稳定，有不同的数据集。</p><h1 id="538c" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">摘要</h1><p id="f90d" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">在本文中，我们比较了两个流行的用于AutoML的Python库:Hyperopt Sklearn和TPOT。</p><p id="5df9" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><strong class="ln jg">远视Sklearn </strong></p><p id="63ae" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><em class="nv">优点</em></p><ul class=""><li id="94da" class="oe of iw ln b lo lp lr ls lu og ly oh mc oi mg oj ok ol om bi translated">易于安装</li><li id="3a01" class="oe of iw ln b lo on lr oo lu op ly oq mc or mg oj ok ol om bi translated">快的</li><li id="47b3" class="oe of iw ln b lo on lr oo lu op ly oq mc or mg oj ok ol om bi translated">最佳模型达到高性能</li></ul><p id="f8cd" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><em class="nv">缺点</em></p><ul class=""><li id="7375" class="oe of iw ln b lo lp lr ls lu og ly oh mc oi mg oj ok ol om bi translated">相同(简单)数据集的不同最佳模型</li><li id="6a1f" class="oe of iw ln b lo on lr oo lu op ly oq mc or mg oj ok ol om bi translated">简单和糟糕的文档</li></ul><p id="734e" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><strong class="ln jg"> TPOT </strong></p><p id="c049" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><em class="nv">优点</em></p><ul class=""><li id="ab7f" class="oe of iw ln b lo lp lr ls lu og ly oh mc oi mg oj ok ol om bi translated">对于相同(简单)的数据集，总是相同的最佳模型</li><li id="0067" class="oe of iw ln b lo on lr oo lu op ly oq mc or mg oj ok ol om bi translated">写得好的文件</li><li id="6e48" class="oe of iw ln b lo on lr oo lu op ly oq mc or mg oj ok ol om bi translated">最佳模型达到良好的性能</li></ul><p id="ce9d" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><em class="nv">缺点</em></p><ul class=""><li id="b9f3" class="oe of iw ln b lo lp lr ls lu og ly oh mc oi mg oj ok ol om bi translated">非常慢</li><li id="0f34" class="oe of iw ln b lo on lr oo lu op ly oq mc or mg oj ok ol om bi translated">难以安装</li></ul><p id="4e3a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae lk" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lk" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae lk" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="4419" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">相关文章</h1><div class="os ot gq gs ou ov"><a rel="noopener follow" target="_blank" href="/a-complete-data-analysis-workflow-in-python-and-scikit-learn-9a77f7c283d3"><div class="ow ab fp"><div class="ox ab oy cl cj oz"><h2 class="bd jg gz z fq pa fs ft pb fv fx jf bi translated">Python和scikit中的完整数据分析工作流程-学习</h2><div class="pc l"><p class="bd b dl z fq pa fs ft pb fv fx dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi le ov"/></div></div></a></div><div class="os ot gq gs ou ov"><a rel="noopener follow" target="_blank" href="/how-to-deal-with-imbalanced-multiclass-datasets-in-python-fe0bb3f2b669"><div class="ow ab fp"><div class="ox ab oy cl cj oz"><h2 class="bd jg gz z fq pa fs ft pb fv fx jf bi translated">如何在Python中处理不平衡的多类数据集</h2><div class="pc l"><p class="bd b dl z fq pa fs ft pb fv fx dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pj l pf pg ph pd pi le ov"/></div></div></a></div><div class="os ot gq gs ou ov"><a rel="noopener follow" target="_blank" href="/how-to-check-if-a-classification-model-is-overfitted-using-scikit-learn-148b6b19af8b"><div class="ow ab fp"><div class="ox ab oy cl cj oz"><h2 class="bd jg gz z fq pa fs ft pb fv fx jf bi translated">如何使用scikit-learn检查分类模型是否过度拟合</h2><div class="pc l"><p class="bd b dl z fq pa fs ft pb fv fx dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pk l pf pg ph pd pi le ov"/></div></div></a></div></div></div>    
</body>
</html>