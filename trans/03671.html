<html>
<head>
<title>Novel Approaches to Similarity Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">相似性学习的新方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/novel-approaches-to-similarity-learning-e680c61d53cd?source=collection_archive---------25-----------------------#2021-03-25">https://towardsdatascience.com/novel-approaches-to-similarity-learning-e680c61d53cd?source=collection_archive---------25-----------------------#2021-03-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/6f41cb6e112bf9151c3c6003203d0dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eNXdDiQ2e0S0pnW3ib3lXw.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">内森·杜姆劳在<a class="ae jd" href="https://unsplash.com/s/photos/similar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="a4b6" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">从连体网络和三重损耗到弧面损耗</h2></div><h1 id="fd95" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">什么是相似性学习？</h1><p id="e97f" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">可以训练神经网络来分类图像或预测某些产品的价格，即分类和回归。这两种方法不仅通常用于深度学习，而且通常用于机器学习。<strong class="lp jh">相似性学习</strong>不是将图像或物体分为两类，而是判断两个物体是否在同一类别或相似，因此得名“相似性学习”。</p></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><p id="ee8f" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">诸如面部验证/识别和推荐系统的许多领域利用相似性学习来实现它们的目标。相似性学习主要应用于图像。</p><h1 id="81d4" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">直觉的理解</h1><p id="f68e" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">当我们想要比较两幅图像并决定它们是否相似时，最好比较它们由训练有素的CNN产生的<strong class="lp jh">嵌入</strong>。简单来说，嵌入只是从网络中提取的包含网络学习到的重要模式和信息的向量。</p><p id="ffdb" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">例如，如果我们想比较一只狗和一只猫的照片是否相似，我们会用相同的权重将这些图像放入同一个神经网络。然后，我们将激活输出层之前的最后一层。产生的矢量是图像的嵌入。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/ea78a2512caf8b9889bc03b86a7fed57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*afjpbpBlYhMM2CgER5rXVg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">嵌入。<em class="na">作者图片</em></p></figure><p id="2f06" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">为了比较图像之间的差异，我们可以找到两个向量之间的距离。数学上，我们可以计算两个向量的距离函数，作为向量之间的差的L2范数，写为</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/9147edb4fe6e59680a3ee0e5d85b1b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NvpByJUu_TLIDohHYAM2YA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">创建于<a class="ae jd" href="https://math.embed.fun/" rel="noopener ugc nofollow" target="_blank"> https://math.embed.fun </a></p></figure><p id="d766" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">其中x1和x2分别是猫和狗的嵌入。如果两个图像是相似的，在这种情况下，他们不是，结果应该是最小的。然而，在这种情况下，两个图像非常不同，结果应该更大。</p><p id="16be" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">比较由同一神经网络创建的嵌入的两个图像的概念被称为<strong class="lp jh">暹罗网络。</strong>我们可以使用<strong class="lp jh"/><strong class="lp jh">三重损失来训练网络。</strong></p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/5b5da22115edd43100a33e33f0b7f3d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JYrVgVKGvf36fLkm.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://www.mdpi.com/symmetry/symmetry-10-00385/article_deploy/html/images/symmetry-10-00385-g001.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="26b7" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">三重损失</h1><p id="6d86" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">仍然使用猫和狗的例子，让我们称狗的图像为<strong class="lp jh">锚</strong>图像或我们将与之比较的原始图像。我们有另一只狗的第二张图片，与第一张相似，但在细节上略有不同，让我们称这张图片为<strong class="lp jh">正面</strong>。我们希望网络将这两幅图像归为同一类别。最后，我们有猫的<strong class="lp jh">负面</strong>形象，它和狗不是一个类别。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/9e4fc22168e6e86e49ba9cd6c93081cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v71sJU6_aKEL893zcOwRQQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">来源:<a class="ae jd" href="http://absfreepic.com/free-photos/download/brown-dog-in-wood-house-4288x2848_68272.html" rel="noopener ugc nofollow" target="_blank">左上图</a>。<a class="ae jd" href="http://absfreepic.com/free-photos/download/brown-dog-lying-front-of-white-background-2835x2126_82078.html" rel="noopener ugc nofollow" target="_blank">右上狗狗形象</a>。<a class="ae jd" href="http://absfreepic.com/free-photos/download/small-baby-cat-4272x2848_82519.html" rel="noopener ugc nofollow" target="_blank">底猫形象。</a></p></figure><p id="edcd" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">为了使网络正确地分类图像是否属于同一类别，我们希望正面和锚点之间的差异小于锚点和负面之间的差异。使用上面的距离函数，我们可以把它写成</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/4b44d2c686c7ea3706883fc6bf79ca3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdHBT3-EONphL9pwsVuuuA.png"/></div></div></figure><p id="12e3" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">其中A、P和N表示锚的嵌入向量，正的和负的。将这些项移到一边，等式变成</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/48d2c29c032bfcc971cf4808e3265ce7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EJ1TKJkXunIbuz0eXVfOcg.png"/></div></div></figure><p id="55c6" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">然而，通过将两个嵌入向量设置为零，网络可以找到“绕过”该函数的方法，而无需任何实际学习。为了解决这个问题，我们可以在等式中增加一个“余量”，称之为alpha。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/03a58e2cc9d2bd15b75a66e027552f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cOmLeCmHcvI0fLuX5aKwVA.png"/></div></div></figure><p id="45d0" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">这样，网络无法找到一个“琐碎的”解决方案，必须学习。将此正式化为损失函数，我们将取(A，P)，(A，N)(上面的等式)和0之间的计算差的最大值。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/d8a3d041c5bb07bcb2c102921fa4cd63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EeNjSHKjvYnieoSzzorUIA.png"/></div></div></figure><p id="1a98" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">那么损失就变成了，</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/b83cd4640a3932657c4f406b9f10c837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X1iuweIOVC2PxDvVDvf4WA.png"/></div></div></figure><p id="3a47" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">当网络发现锚和负之间的差异时，损失将为零。另一方面，如果网络不能发现负锚和锚之间的差异，损失将产生一个误差的度量。</p></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><p id="1b9e" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">三重态损耗有几个应该考虑的缺点。</p><p id="990b" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">首先，它需要仔细选择锚定图像、正面图像和负面图像。负面图像和锚图像之间的差异不能太大，如果是这样，网络将很容易满足损失函数，而无需学习任何东西。锚和负面图像必须相似，但不应该属于同一类。</p><p id="5834" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">其次，它的计算成本很高，最后，三重态损耗需要超参数α，或裕量。如果选择不当，会导致更糟糕的结果。</p><h1 id="6cde" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">替代方案:弧面损失和角度裕度损失</h1><p id="766f" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">三重损耗有许多替代方案，其中之一是<strong class="lp jh">弧面损耗</strong>。这是一种基于交叉熵损失的损失，旨在最大化类别之间的决策边界，从而将相似的数据点更紧密地分组在一起。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/08dfeddbbe67f229e013e2227a8094ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YV3f-_-jKrVQVcLV0JgV8Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://arxiv.org/pdf/1801.07698.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="46da" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">ArcFace背后的想法是，在超球面上，它最大化类间的角度，最小化类内的角度。然后，我们添加角裕度惩罚，该惩罚被插入到真实logit的权重和嵌入之间。这给logit和嵌入之间的原始角度增加了一个角度损失。</p><p id="ac54" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">角度裕度惩罚有助于惩罚走远的嵌入向量，并有助于使某一类的嵌入特征更接近。</p><p id="3dac" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">与ArcFace相比，还有许多其他的losses也是基于类似的想法运行的，例如SphereFace和CosFace。</p><p id="7142" class="pw-post-body-paragraph ln lo jg lp b lq mq kh ls lt mr kk lv lw ms ly lz ma mt mc md me mu mg mh mi ij bi translated">将三元组丢失与暹罗网络一起使用是相似性学习的早期方法，因此具有许多问题和缺点。另一方面，ArcFace在不浪费计算资源的情况下，巧妙地达到了最大化类间决策边界的目的。</p></div></div>    
</body>
</html>