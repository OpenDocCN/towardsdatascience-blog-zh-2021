<html>
<head>
<title>Attention-Based Deep Multiple Instance Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于注意力的深度多示例学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/attention-based-deep-multiple-instance-learning-1bb3df857e24?source=collection_archive---------5-----------------------#2021-06-03">https://towardsdatascience.com/attention-based-deep-multiple-instance-learning-1bb3df857e24?source=collection_archive---------5-----------------------#2021-06-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e0f4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">使用PyTorch和AWS SageMaker数据并行进行前列腺癌诊断</em></h2></div><h1 id="cc60" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">介绍</h1><p id="e85f" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">该帖子由以下部分组成:</p><p id="8941" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated"><a class="ae lz" href="#7081" rel="noopener ugc nofollow"> <strong class="la ir">第1部分</strong> </a> <strong class="la ir"> </strong>概述了为什么人工智能被定位于改变医疗保健行业。</p><p id="8356" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated"><a class="ae lz" href="#e163" rel="noopener ugc nofollow"> <strong class="la ir">第2部分</strong> </a>解释了一种称为多实例学习的机器学习技术，以及它为什么适合病理学应用。</p><p id="f975" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">这些作为<a class="ae lz" href="#8935" rel="noopener ugc nofollow"> <strong class="la ir">第3部分</strong> </a> <strong class="la ir"> </strong>的基础，概述了使用PyTorch和AWS SageMaker的数据并行工具包实现基于注意力的深度多实例学习模型用于前列腺癌诊断。</p><p id="cb4a" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">这篇文章的节略版已经发表在<a class="ae lz" href="https://www.captodayonline.com" rel="noopener ugc nofollow" target="_blank">今日</a>美国病理学家学会2021年11月刊上:<a class="ae lz" href="https://www.captodayonline.com/newsbytes-1121/" rel="noopener ugc nofollow" target="_blank">见此</a>。</p><h1 id="7081" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">第1部分—为什么人工智能定位于改变医疗保健行业</h1><p id="b80a" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在深入研究代码之前，让我们后退一步，考虑一下为什么人工智能被定位于改变医疗保健。</p><p id="c309" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">人工智能今天的势头很大程度上可以归功于深度神经网络的成功，如果没有以下四种驱动力的完美风暴，这是不可能的:</p><ol class=""><li id="bb9e" class="ma mb iq la b lb lu le lv lh mc ll md lp me lt mf mg mh mi bi translated">越来越多的大规模数据集可用，例如ImageNet的1500万张带标签的图像，脸书的数十亿张图像库，YouTube的视频库，每分钟增加300小时的视频，以及Tesla的驾驶数据集合，每小时增加100万英里的数据。</li><li id="9f6c" class="ma mb iq la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">图形处理单元(GPU)的使用，以及后来更多的称为张量处理单元(TPU)的人工智能专用硬件，这些硬件针对训练深度学习模型进行了优化。TPU由许多内核组成，这使它们能够处理大量数据并并行执行多个计算。OpenAI在2018年的一份报告中提出，在2012年之前，人工智能计算的增长密切遵循摩尔定律，每两年翻一倍，而在2012年之后，计算每三到四个月翻一倍。总体而言，自2012年以来，这一计算指标已经增长了300，000多倍，而两年的翻倍期只会产生16倍的增长。</li><li id="7166" class="ma mb iq la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">云计算的可用性使得存储大型数据集并使用它们来训练模型的能力变得更加容易获得和经济。</li><li id="3747" class="ma mb iq la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">开源算法开发模块，如脸书的PyTorch、谷歌的TensorFlow、微软的Cognitive Kit等。</li></ol><p id="7f50" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">这种蓬勃发展的丰富资源推动了人工智能的快速发展，而此时医生们比以往任何时候都更加不知所措。在美国，尽管医疗保健从业人员的数量从1975年的400万增加到今天的1600万，但是新患者就诊的平均就诊时间已经从1975年的60分钟下降到今天的12分钟。除了面对不断增长的人口，医生还越来越多地被电子健康记录、管理式医疗、健康维护组织和相对价值单位所淹没，这转移了他们与患者建立有意义关系的注意力。与病人脱节的精疲力竭的医生更有可能做出带有认知偏见的判断。结果，他们条件反射性地安排不正确的测试，并随后曲解它们，导致误诊。2014年的一项审查得出结论，美国每年面临大约1200万例误诊。</p><p id="6dc6" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">正如斯克里普斯研究转化研究所(Scripps Research Translational Institute)创始人兼主任埃里克·托普(Eric Schmidt)等医学博士所断言的那样，人工智能令人兴奋的前景在于使用相关患者数据的深度和全面收集，以改善决策，减少误诊和不必要的程序，指导测试的选择和解释，并推荐最安全的治疗方案。然而，医疗保健在多大程度上融入了人工智能，需要受到该行业对临床医生和患者之间的同理心和联系的内在需求的影响。医生给病人一种道德观念和核心价值观，这两者都是计算机无法复制的。有人断言，人工智能将很快变得足够复杂，足以导致其他行业的完全自动化，这引发了医疗专业人士的担忧，即人类参与医学是否将成为过去。然而，人工智能导致医学完全自动化的可能性仍然很遥远。那些参与人工智能的人有时间在医生和机器之间取得正确的平衡。</p><p id="99e5" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">一个适当的平衡可能涉及到一个扮演数字助理角色的人工智能系统，它向医生发出最可能的诊断和最佳行动方案的警报，并让医生负责做出最终决定。“人在回路中”的方法符合弗里德曼的基本定理，即人类与计算机合作将永远优于人类单独工作，并保证了算法如何达到特定预测的透明度。⁴可解释人工智能<em class="mo"> </em>是一套提供这种洞察力的流程或方法，对于在依赖人工智能系统的人之间建立信任，同时确保准确性、公平性和符合监管标准至关重要。可解释性为临床医生提供了质量控制和制衡，并可以帮助他们对依靠算法做出最终诊断更加自信。</p><p id="fcdd" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">稳健的模型需要开发出令人满意的可解释水平。但是如果做得正确，由此增加的工作流程和效率可以为临床医生提供更多的时间与患者联系。矛盾的是，机器的兴起可以恢复医学中的人性，并允许医学专业人员重新接触到他们最初追求医学生涯的动机。</p><h1 id="e163" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated"><strong class="ak">第二部分——病理学中的人工智能</strong></h1><p id="6e52" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">人工智能在医疗保健领域最有效的应用之一是医学成像。放射学、病理学和皮肤病学是依赖于视觉模式分析的专业，因此，由于与人工智能的集成，它们将经历快速而戏剧性的转变。</p><p id="fd44" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">病理学家在癌症诊断中发挥着至关重要的作用，他们的报告有助于指导患者的治疗策略。通常，病理学家在显微镜下观察苏木精和伊红(H&amp;E)染色的组织样本，并描述他们看到的细胞类型，它们是如何排列的，它们是否异常，以及任何其他对诊断重要的特征。一个世纪以来，使用显微镜检查含有组织样本的载玻片的做法基本上没有改变。然而，近年来，越来越多地使用数字载玻片扫描仪来数字化载玻片，以产生可以在计算机上检查的完整载玻片图像(WSIs)。然而，病理学家在采用WSIs和其他数字技术方面进展缓慢，这导致人工智能对病理学的入侵比预期的要慢。然而，WSIs为将神经网络图像处理纳入病理学奠定了基础，从而使该领域的新人工智能辅助时代即将到来。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mp"><img src="../Images/4ad84b1b81c80fefe2ca6c3dbda114ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UviZ693Snrpqgged"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated"><a class="ae lz" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国家癌症研究所</a>在<a class="ae lz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="f81d" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">人工智能可用于执行通常由病理学家执行的常规工作流程，例如检测活检样本中的肿瘤组织，并根据形态学确定肿瘤亚型，从而提高效率和准确性。AI在病理学方面的一个重要里程碑是CAMELYON16挑战，该挑战设定了开发算法的目标，以在淋巴结活检的WSIs中检测转移性乳腺癌。<strong class="la ir"> </strong>提供的数据集由400个WSI组成，病理学家在其中人工圈定转移癌的区域，是最大的标记病理数据集之一。这使得提交排名第一的团队(其算法表现与病理学家不相上下)能够利用监督学习。⁶</p><p id="112e" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">一般来说，监督学习是一种机器学习方法，其中向算法显示许多输入数据及其相应输出标签的序列，直到它可以检测到揭示这些输入和输出之间关系的潜在模式。这种技术允许它准确地标记以前没有见过的数据，并可用于分类(将输入分类到给定数量的类别中)或回归(给定输入，预测目标数值)任务。</p><p id="418f" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">监督学习的一个主要缺点是，它通常需要训练数据集由领域专家手工标记。在处理WSIs时尤其如此:就规模而言，大约470幅病理图像包含的像素数量与整个ImageNet数据集大致相同。此外，尽管CAMELYON16数据集是病理学中最大的数据集之一，但400个WSI不足以捕获临床中定期出现的各种病例。因此，获得一个适当大的数据集将是非常昂贵和耗时的，该数据集的数十亿像素的处理对于训练来说也是计算要求很高的。因此，在病理学中设计日常使用的监督学习模型是非常不切实际的。⁷</p><h2 id="f753" class="nf kh iq bd ki ng nh dn km ni nj dp kq lh nk nl ks ll nm nn ku lp no np kw nq bi translated"><strong class="ak">多实例学习(MIL)及其对病理学应用的适用性</strong></h2><p id="ddd9" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">MIL是监督学习的一种变体，更适合于病理学应用。该技术包括为一组输入分配一个类标签——在这种情况下，称为实例包。虽然假设包中的每个实例都有标签，但是无法访问这些标签，并且它们在训练期间是未知的。如果行李中的所有实例都是阴性，则通常将行李标记为阴性；如果至少有一个阳性实例，则标记为阳性(称为标准MIL假设)。下图显示了一个简单的例子，在这个例子中，我们只知道一个钥匙串是否包含可以打开给定门的钥匙。这让我们可以推断绿色钥匙可以开门。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nr"><img src="../Images/9b8e243195883744a3f2d068b6dd5d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2dHiAk7NnBNh-jC18Q1X6A.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">使用钥匙链的多实例学习的简化说明(作者提供的图片——灵感来自[ <a class="ae lz" href="https://www.youtube.com/watch?v=pizZ2fzyYeA&amp;t=163s" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="0dad" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">MIL公式自然适合基于成像的患者诊断的任务:类似于标准MIL假设，患病组织样本具有异常和健康区域，而健康组织样本仅具有健康区域。因此，可以将WSIs划分为多个区块，其中每个区块集合可以被标记为“恶性”或“患病”这些弱标记比强标记(即，由专家手动提供的患病区域的轮廓)更容易获得，因此将病理学家从必须自己注释WSI的艰苦任务中解救出来。MIL模型也可以被制作成高度可解释的，这迎合了前面讨论的人工智能系统在医疗保健中的可解释性要求。⁸</p><p id="ca43" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">此外，在病理学中使用MIL的一个特别令人兴奋的部分是，它可以集成到深度学习模型中，该模型允许创建一个平滑的端到端管道，其中WSI作为输入输入，诊断作为输出返回。作为副产品，深度加工模型可以从WSIs中自动发现新的抽象特征，这些特征在确定存活率、治疗反应和遗传缺陷方面比传统特征表现得更好。值得注意的是，可以直接从病理学实验室容易获得的H&amp;E载玻片中获得这些见解，而不是进行可能昂贵的额外测试。⁹深磨形成了<a class="ae lz" href="https://www.wsj.com/articles/fda-authorizes-ai-software-designed-to-help-spot-prostate-cancer-11632780683" rel="noopener ugc nofollow" target="_blank">佩奇的基础。美国食品和药物管理局于2021年9月授权使用的AI公司前列腺癌软件</a>。⁰</p><h1 id="8935" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">第3部分——使用PyTorch和AWS SageMaker的数据并行性工具包实现前列腺癌诊断的基于注意力的深度密值模型</h1><p id="a635" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在我的<a class="ae lz" href="https://jmg764.medium.com/an-introduction-to-deep-multiple-instance-learning-4a8bdcddb77" rel="noopener">上一篇文章</a>中，我进一步讨论了将MIL公式化为深度学习问题的优点。我还概述了在<a class="ae lz" href="https://arxiv.org/abs/1802.04712" rel="noopener ugc nofollow" target="_blank">基于注意力的深度多示例学习</a> (Ilse等人)中描述的模型的数学基础，该模型允许使用深度密耳进行WSI分类。⁸该模型使用了注意力机制的修改版本作为其聚合运算符，这比依赖于典型聚合运算符(如均值和最大值)的模型具有更大程度的可解释性。换句话说，这种基于注意力的MIL汇集算子提供了对每个实例对预测的包标签的贡献的洞察。</p><p id="3bd9" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">在这里，我们使用<a class="ae lz" href="https://www.kaggle.com/c/prostate-cancer-grade-assessment" rel="noopener ugc nofollow" target="_blank">前列腺癌等级评估(PANDA) Kaggle挑战赛</a>中提供的数据集，包含11，000个数字化H &amp; E染色前列腺活检的WSI，来训练一个基于注意力的深度MIL模型，以根据Ilse等人的方法来诊断前列腺癌。目标是概述如何使用PyTorch和AWS SageMaker的数据并行工具包来实现这一点。</p><h2 id="375e" class="nf kh iq bd ki ng nh dn km ni nj dp kq lh nk nl ks ll nm nn ku lp no np kw nq bi translated">资料组</h2><p id="32cc" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">熊猫挑战数据集中的每个组织样本根据肿瘤的结构生长模式被分类为格里森模式，以及相应的1-5级ISUP等级。Gleason评分是基于白色分支腔或腺组织在整个组织样本中的持续程度来确定的。腺体组织损失的增加意味着更严重，并且对应于更高的Gleason评分。如果在一次活组织检查中出现多个Gleason模式，则可以根据病理学家的判断，将其分为最常出现的模式和第二常出现的模式(分别为多数和少数)。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi ns"><img src="../Images/b97fbb49b57c26a7ac727c5af9101fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IO0xDIATnXj29Srtsq1KWA.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">包含前列腺的前列腺癌活检示例的Gleason分级流程图(作者提供的图片——受[ <a class="ae lz" href="https://www.kaggle.com/c/prostate-cancer-grade-assessment/overview/description" rel="noopener ugc nofollow" target="_blank">来源</a> ]的启发)</p></figure><p id="e9eb" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">为了在深度模型中使用数据集，我参考了Kaggle笔记本后面的<a class="ae lz" href="https://www.kaggle.com/iafoss/panda-16x128x128-tiles/comments?select=train.zip" rel="noopener ugc nofollow" target="_blank">，以便将WSIs划分为每个16x128x128图块的集合。如Ilse等人所述，眼袋被标记为恶性或良性。ISUP等级为1、2、3、4或5的载玻片被标记为“恶性”，而ISUP等级为0的载玻片被标记为“良性”⁸</a></p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nt"><img src="../Images/6d9d988a01e8c8a2a8e2ae82f6e29215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3NtkSgzkFpUWX8fNq9noWg.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">每个16块瓷砖的集合可以被重构为一个由16个实例组成的袋子(图由作者提供)</p></figure><h2 id="ba46" class="nf kh iq bd ki ng nh dn km ni nj dp kq lh nk nl ks ll nm nn ku lp no np kw nq bi translated">模型</h2><p id="5ccd" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在下面的代码中，我们实现了Ilse等人使用的模型的修改版本，它考虑了上面描述的数据集。</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="4344" class="nf kh iq nv b gy nz oa l ob oc">import torch<br/>import torch.nn.functional as F<br/>import torch.nn as nn <br/>class Attention(nn.Module):<br/>    def __init__(self):<br/>        super(Attention, self).__init__()<br/>        self.L = 512 # 512 node fully connected layer<br/>        self.D = 128 # 128 node attention layer<br/>        self.K = 1</span><span id="46a2" class="nf kh iq nv b gy od oa l ob oc">        self.feature_extractor_part1 = nn.Sequential(<br/>            nn.Conv2d(3, 36, kernel_size=4),<br/>            nn.ReLU(),<br/>            nn.MaxPool2d(2, stride=2),<br/>            nn.Conv2d(36, 48, kernel_size=3),<br/>            nn.ReLU(),<br/>            nn.MaxPool2d(2, stride=2)<br/>        )<br/>         <br/>        self.feature_extractor_part2 = nn.Sequential(<br/>            nn.Linear(48 * 30 * 30, self.L),<br/>            nn.ReLU(),<br/>            nn.Dropout(),<br/>            nn.Linear(self.L, self.L),<br/>            nn.ReLU(),<br/>            nn.Dropout()<br/>        )</span><span id="691f" class="nf kh iq nv b gy od oa l ob oc">        self.attention = nn.Sequential(<br/>            nn.Linear(self.L, self.D),<br/>            nn.Tanh(),<br/>            nn.Linear(self.D, self.K)<br/>        )</span><span id="8f01" class="nf kh iq nv b gy od oa l ob oc">        self.classifier = nn.Sequential(<br/>            nn.Linear(self.L * self.K, 1),<br/>            nn.Sigmoid()<br/>        )</span><span id="5451" class="nf kh iq nv b gy od oa l ob oc">    def forward(self, x):<br/>        x = x.squeeze(0)</span><span id="0634" class="nf kh iq nv b gy od oa l ob oc">        H = self.feature_extractor_part1(x)<br/>        H = H.view(-1, 48 * 30 * 30)<br/>        H = self.feature_extractor_part2(H)</span><span id="6c45" class="nf kh iq nv b gy od oa l ob oc">        A = self.attention(H) # NxK<br/>        A = torch.transpose(A, 1, 0) # KxN<br/>        A = F.softmax(A, dim=1) # softmax over N</span><span id="801e" class="nf kh iq nv b gy od oa l ob oc">        M = torch.mm(A, H)</span><span id="b101" class="nf kh iq nv b gy od oa l ob oc">       # The probability that a given bag is malignant or benign<br/>        Y_prob = self.classifier(M) </span><span id="023b" class="nf kh iq nv b gy od oa l ob oc">        # The prediction given the probability (Y_prob &gt;= 0.5 returns a Y_hat of 1 meaning malignant)<br/>        Y_hat = torch.ge(Y_prob, 0.5).float()</span><span id="9d27" class="nf kh iq nv b gy od oa l ob oc">        return Y_prob, Y_hat, A.byte()</span></pre><h2 id="9c09" class="nf kh iq bd ki ng nh dn km ni nj dp kq lh nk nl ks ll nm nn ku lp no np kw nq bi translated">使用AWS SageMaker数据并行性(SDP)进行模型训练</h2><p id="feb9" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">一般来说，神经网络是通过在减少预测误差的方向上系统地调整它们的参数来训练的。一种常见的技术是随机梯度下降，其中这些参数变化使用称为小批量的相同大小的样本迭代发生。可以通过在一组独立的机器上平均分配小批量来加快训练时间，每台机器都有自己的模型、优化器和其他基本组件。这里，我们使用AWS SageMaker的数据并行工具包，该工具包已被证明比PyTorch DistributedDataParallel具有更好的性能。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi oe"><img src="../Images/fc4b15cdb39c99e330cdd87c5a3e8b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVmZpC1aoCx66ARj-RfqbA.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">数据并行性的示意图(作者提供的图片—灵感来自[ <a class="ae lz" href="https://frankdenneman.nl/2020/02/19/multi-gpu-and-distributed-deep-learning/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h2 id="c4c0" class="nf kh iq bd ki ng nh dn km ni nj dp kq lh nk nl ks ll nm nn ku lp no np kw nq bi translated">SageMaker笔记本设置</h2><p id="dd5f" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">为了准备SDP培训，我们可以将上述数据上传到亚马逊S3桶中，并使用SageMaker预建的PyTorch容器启动一个Jupyter笔记本实例。对于这个项目，通过从Amazon SageMaker Python SDK调用PyTorch估计器来初始化训练。值得注意的是，我们传递训练脚本，指定实例计数和类型，并启用SDP分发方法，如下所示:</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="7022" class="nf kh iq nv b gy nz oa l ob oc"><strong class="nv ir">import</strong> <strong class="nv ir">sagemaker<br/></strong>sagemaker_session = sagemaker.Session()<br/>role = sagemaker.get_execution_role()</span><span id="60e7" class="nf kh iq nv b gy od oa l ob oc"><strong class="nv ir">from</strong> <strong class="nv ir">sagemaker.pytorch</strong> <strong class="nv ir">import</strong> PyTorch<br/>estimator = PyTorch(base_job_name='pytorch-smdataparallel-histopathology-mil',<br/>                        source_dir='code',<br/>                        entry_point='train.py',<br/>                        role=role,<br/>                        framework_version='1.8.1',<br/>                        py_version='py36',<br/>                        instance_count=2,<br/>                        instance_type= 'ml.p3.16xlarge',<br/>                        sagemaker_session=sagemaker_session,<br/>                        distribution={'smdistributed':{<br/>                                            'dataparallel':{<br/>                                                    'enabled': <strong class="nv ir">True</strong><br/>                                                 }<br/>                                          }<br/>                                      },<br/>                        debugger_hook_config=<strong class="nv ir">False</strong>,<br/>                        volume_size=40)</span></pre><p id="d2ab" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">ml.p3.16xlarge是SageMaker数据并行工具包支持的三种实例类型之一，AWS建议至少使用2个实例来获得最佳性能和最大收益。这种类型的一个实例包含8个NVIDIA V100 GPUs，每个都有16 GB的内存。在这里，这相当于运行我们模型的16个独立副本。</p><p id="0bfb" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">然后，我们可以通过上传到S3的数据来拟合PyTorch估计值。这将我们的数据导入到训练集群的本地文件系统中，以便我们的train.py脚本可以简单地从磁盘中读取数据。</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="1a1a" class="nf kh iq nv b gy nz oa l ob oc">channels = {<br/>    'training': 's3://sagemaker-us-east-1-318322629142/train/',<br/>    'testing': 's3://sagemaker-us-east-1-318322629142/test/'<br/>}<br/>estimator.fit(inputs=channels)</span></pre><h2 id="c8e3" class="nf kh iq bd ki ng nh dn km ni nj dp kq lh nk nl ks ll nm nn ku lp no np kw nq bi translated">入口点脚本</h2><p id="7692" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在我们的train.py入口点脚本中，我们定义了如下所示的train函数:</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="dcd3" class="nf kh iq nv b gy nz oa l ob oc">def train(model, device, train_loader, optimizer, epoch):<br/>    model.train()</span><span id="39ff" class="nf kh iq nv b gy od oa l ob oc">    train_loss = 0.<br/>    train_error = 0.<br/>    predictions = []<br/>    labels = []</span><span id="8ef2" class="nf kh iq nv b gy od oa l ob oc">    for batch_idx, (data, label) in enumerate(train_loader):<br/><br/>        bag_label = label<br/>        data = torch.squeeze(data)<br/>        data, bag_label = Variable(data), Variable(bag_label)<br/>        data, bag_label = data.to(device), bag_label.to(device)</span><span id="f412" class="nf kh iq nv b gy od oa l ob oc">        # reset gradients<br/>        optimizer.zero_grad()</span><span id="c9e3" class="nf kh iq nv b gy od oa l ob oc">        # calculate error<br/>        bag_label = bag_label.float()<br/>        Y_prob, Y_hat, _ = model(data)<br/>        error = 1. - Y_hat.eq(bag_label).cpu().float().mean().data<br/>        train_error += error</span><span id="192d" class="nf kh iq nv b gy od oa l ob oc">        # calculate loss<br/>        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)<br/>        loss = -1. * (bag_label * torch.log(Y_prob) + (1. - bag_label) * torch.log(1. - Y_prob))<br/>        train_loss += loss.data[0]</span><span id="7298" class="nf kh iq nv b gy od oa l ob oc">        # Keep track of predictions and labels to calculate accuracy after each epoch<br/>        predictions.append(int(Y_hat))<br/>        labels.append(int(bag_label))</span><span id="0d92" class="nf kh iq nv b gy od oa l ob oc">        # backward pass<br/>        loss.backward()</span><span id="60c0" class="nf kh iq nv b gy od oa l ob oc">        # step<br/>        optimizer.step()</span><span id="f350" class="nf kh iq nv b gy od oa l ob oc">    # calculate loss and error for epoch<br/>    train_loss /= len(train_loader)<br/>    train_error /= len(train_loader)</span><span id="ea64" class="nf kh iq nv b gy od oa l ob oc">    print('Train Set, Epoch: {}, Loss: {:.4f}, Error: {:.4f},<br/> Accuracy: {:.2f}%'.format(epoch, train_loss.cpu().numpy()[0],<br/> train_error, accuracy_score(labels, predictions)*100))</span></pre><p id="d15a" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">我们还创建了一个函数，用于在训练完成后保存我们的模型:</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="b8bb" class="nf kh iq nv b gy nz oa l ob oc">def save_model(model, model_dir):<br/>    with open(os.path.join(model_dir, 'model.pth'), 'wb') as f:<br/>        torch.save(model.module.state_dict(), f)</span></pre><p id="0d47" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">在<a class="ae lz" href="https://docs.python.org/3/library/__main__.html" rel="noopener ugc nofollow" target="_blank">主守卫</a>中，我们加载我们的数据集(详见<a class="ae lz" href="https://github.com/jmg764/Histopathology-Multiple-Instance-Learning" rel="noopener ugc nofollow" target="_blank">仓库</a>)，训练超过10个历元，并保存我们的模型:</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="1fc5" class="nf kh iq nv b gy nz oa l ob oc">device = torch.device("cuda")<br/>model = DDP(Attention().to(device))<br/>optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=0.0005)</span><span id="016d" class="nf kh iq nv b gy od oa l ob oc">print('Start Training')<br/>for epoch in range(1, 10 + 1):<br/>    train(model, device, train_loader, optimizer, epoch)</span><span id="56ae" class="nf kh iq nv b gy od oa l ob oc">save_model(model, args.model_dir)</span></pre><h2 id="bc9f" class="nf kh iq bd ki ng nh dn km ni nj dp kq lh nk nl ks ll nm nn ku lp no np kw nq bi translated">部署、预测和评估</h2><p id="d1b6" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">训练完成后，我们可以使用PyTorch estimator部署一个端点，该端点运行SageMaker提供的PyTorch模型服务器并托管我们训练好的模型。一般来说，部署用于在客户端应用程序上执行实时预测，但是这里我们部署是为了演示的目的。</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="621c" class="nf kh iq nv b gy nz oa l ob oc"><strong class="nv ir">import</strong> <strong class="nv ir">sagemaker</strong><br/>role = sagemaker.get_execution_role()<br/><br/><strong class="nv ir">from</strong> <strong class="nv ir">sagemaker.pytorch</strong> <strong class="nv ir">import</strong> PyTorchModel<br/>model = PyTorchModel(model_data=model_data, source_dir='code',<br/>                        entry_point='inference.py', role=role, framework_version='1.6.0', py_version='py3')</span></pre><p id="33d2" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">现在，我们可以使用预测器来预测测试数据的标签，并确定我们的准确度分数:</p><pre class="mq mr ms mt gt nu nv nw nx aw ny bi"><span id="85cc" class="nf kh iq nv b gy nz oa l ob oc">predictions = []<br/>true_labels = []</span><span id="a986" class="nf kh iq nv b gy od oa l ob oc">for batch_idx, (data, label) in enumerate(test_loader):<br/>    _, Y_hat, _ = predictor.predict(data)<br/>    predictions.append(int(Y_hat))<br/>    true_labels.append(int(label))</span><span id="b79f" class="nf kh iq nv b gy od oa l ob oc"><strong class="nv ir">from</strong> <strong class="nv ir">sklearn.metrics</strong> <strong class="nv ir">import</strong> accuracy_score<br/>accuracy_score(true_labels, predictions)</span></pre><p id="9d08" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">根据我在上述实施中的经验，我实现了67.2%的准确率，比Ilse等人报告的准确率低了大约7.5%。这可能是因为我选择了最大限度地降低AWS SageMaker培训成本:在这里，我只使用了数据集中11，000个WSI中的624个WSI。此外，虽然文献中的模型被训练了超过100个时期，但是该模型仅被训练了10个时期。如果有更多的资金投入，我预计更大的训练数据集和更长的训练时间将导致更接近论文中看到的结果。</p><p id="02bf" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated"><a class="ae lz" href="https://github.com/jmg764/Histopathology-Multiple-Instance-Learning" rel="noopener ugc nofollow" target="_blank"> <strong class="la ir">储存库</strong></a><strong class="la ir"/>(2021年10月更新包含单元测试)</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="c3ce" class="kg kh iq bd ki kj om kl km kn on kp kq jw oo jx ks jz op ka ku kc oq kd kw kx bi translated">参考</h1><p id="ae2e" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">1.托普·EJ。深度医学:人工智能如何让医疗保健再次人性化。基础书籍；2019.</p><p id="b604" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">2.Amodei D，Hernandez D. AI和compute。OpenAI。2018年5月16日。<a class="ae lz" href="https://openai.com/blog/ai-and-compute" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/ai-and-compute</a></p><p id="97f9" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">3.辛格H，迈耶安，托马斯EJ。"门诊护理中诊断错误的频率:来自三项涉及美国成年人群的大型观察性研究的估计."BMJ质量安全保险公司。2014.23(9): 727–731.</p><p id="98a9" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">4.弗里德曼(2009年)。生物医学信息学的一个“基本定理”。美国医学信息学协会杂志，16(2)，169–170。<a class="ae lz" href="https://doi.org/10.1197/jamia.m3092" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1197/jamia.m3092</a></p><p id="d0eb" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">5.坎帕内拉G，汉纳MG，Geneslaw L，等。在整个幻灯片图像上使用弱监督深度学习的临床级计算病理学。<em class="mo"> Nat Med </em>。2019;25(8):1301–1309.</p><p id="b3ee" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">6.王博士、科斯拉博士、加尔盖亚博士、博士、贝克博士(2016年)。用于识别转移性乳腺癌的深度学习。arXiv预印本arXiv: 1606.05718。</p><p id="7ff2" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">7.坎帕内拉，g .，汉娜，M. G .，Geneslaw，l .，米拉弗洛尔，a .，韦内克克劳斯席尔瓦，v .，布萨姆，K. J .，布罗吉，e .，路透，V. E .，克林姆斯特拉，D. S .，&amp;富克斯，T. J. (2019)。在整个幻灯片图像上使用弱监督深度学习的临床级计算病理学。自然医学，25(8)，1301–1309。<a class="ae lz" href="https://doi.org/10.1038/s41591-019-0508-1" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1038/s41591-019-0508-1</a></p><p id="af61" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">8.伊尔泽，硕士，托姆扎克，法学硕士，韦林，硕士(2018)。基于注意力的深度多示例学习。第35届国际机器学习会议录，瑞典斯德哥尔摩，PMLR 80。<a class="ae lz" href="https://arxiv.org/abs/1802.04712." rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1802.04712.</a></p><p id="2abe" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">9.Rajpukar P，Saporta A. <em class="mo">人工智能健康播客</em>。PathAI的Aditya Khosla博士的病理学人工智能和企业家精神。2020年12月16日。<a class="ae lz" href="https://theaihealthpodcast.com/episodes/patholgy-ai-and-entrepreneurship-with-pathais-aditya-khosla" rel="noopener ugc nofollow" target="_blank">https://theaihealthcpodcast . com/episodes/path olgy-ai-and-entrepreneurs-with-path ais-aditya-khosla</a>。</p><p id="bb5f" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">10.麦考密克，J. (2021年9月27日)。FDA授权人工智能软件帮助识别前列腺癌。华尔街日报。</p><p id="d552" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">11.韦伯，e . &amp;克鲁尚，O. (2020年12月9日)。在Amazon SageMaker [web log]上使用两个新的分布式培训库扩展深度学习。<a class="ae lz" rel="noopener" target="_blank" href="/scale-neural-network-training-with-sagemaker-distributed-8cf3aefcff51.">https://towards data science . com/scale-neural-network-training-with-sage maker-distributed-8 cf 3 aefcff 51。</a></p><p id="7864" class="pw-post-body-paragraph ky kz iq la b lb lu jr ld le lv ju lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">12.Aws。(未注明)。<em class="mo">AWS/亚马逊-sagemaker-examples </em>。GitHub。<a class="ae lz" href="https://github.com/aws/amazon-sagemaker-examples/blob/35e2faf7d1cc48ccedf0b2ede1da9987a18727a5/training/distributed_training/pytorch/data_parallel/mnist/pytorch_smdataparallel_mnist_demo.ipynb." rel="noopener ugc nofollow" target="_blank">https://github . com/AWS/Amazon-sage maker-examples/blob/35 e 2 faf 7 D1 cc 48 cced f 0 B2 ede 1 da 9987 a 18727 a 5/training/distributed _ training/py torch/data _ parallel/Mn ist/py torch _ smdataparallel _ Mn ist _ demo . ipynb .</a></p></div></div>    
</body>
</html>