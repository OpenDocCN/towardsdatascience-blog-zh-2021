<html>
<head>
<title>Neural Networks in Swift</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Swift中的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-on-swift-ba181dcdfde5?source=collection_archive---------15-----------------------#2021-05-10">https://towardsdatascience.com/neural-networks-on-swift-ba181dcdfde5?source=collection_archive---------15-----------------------#2021-05-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="eb6b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在Swift中从头开始创建神经网络框架</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fb898823bb0e1d833812f38759874990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TtBn650FQJGshnLi"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">安迪·凯利在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="492d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="a506" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们生活在伟大的技术周围，比如自动驾驶汽车、语音助手、图像分析仪。他们中的大多数使用神经网络作为他们算法的基础。我们将使用Swift从头开始构建一个基本的神经网络。</p><h1 id="0b8a" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">一些理论</h1><p id="dde9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在开发应用程序之前，我们必须学习神经网络的理论。神经网络由<em class="mk">输入、输出和隐层</em>组成。全连接简单层由<em class="mk">神经元</em>组成。突触将神经元相互连接起来。每个突触都有自己的<em class="mk">权重值</em>。在生成神经网络的过程中，它用随机值填充权重。它们会在训练时改变(在下面的动画中，<strong class="lq ir">红色</strong>表示<em class="mk">高重量</em>，<strong class="lq ir">蓝色</strong>表示<em class="mk">低重量</em>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/6217c7109027110910d9f476ea65f406.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/1*JdVZlulpawGx63uPXySNEg.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练神经元。图片作者:Yauheni Stsefankou</p></figure><p id="6387" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">训练过程分为几个时期。我们在每个时期处理数据集中的所有数据样本。我们用数据样本的输入填充输入层。然后每一层通过激活功能处理输入，并通过突触发送到下一层。当一个值通过突触时，它会将该值乘以突触权重。当计算神经元的值时，它<em class="mk">将所有输入值和偏差</em>相加。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/5d90b7b0e010b9d2cfaa3b749c96cf66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/1*bej53fIfWFJcykfKCbpP0w.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">正向传播。图片作者:Yauheni Stsefankou</p></figure><p id="8d69" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">这是一个神经网络的例子。它得到<em class="mk">一个无符号的4位数字</em>并返回<em class="mk">该数字是否为偶数</em>。注意<em class="mk">所有偶数的二进制表示都以0结尾</em>。这意味着<strong class="lq ir">预测只取决于最后一位</strong>(输入层的第四个神经元)。这就是为什么我强调了连接到输入层最后一个神经元的突触。输入层的其他突触没有意义，它们的权重在训练期间接近零。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/29118a9f833ea6c50ab9b9e40d411cc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*NC5KCQlgpyjXGhuT_2ErmA.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">神经网络示例。图片作者:Yauheni Stsefankou</p></figure><h1 id="b217" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">短评</strong></h1><p id="4f90" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">由于缺乏非常紧密的优化和GPU兼容性，我们的神经网络框架不会很快。它唯一的优化是通过DispatchQueue的并发执行而不是循环的<em class="mk">多线程。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/65b9a5189821b45dca8749167fdb8378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*4RL6_rC_SyEDmccEzsOOwA.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">并发执行vs For循环。图片作者:Yauheni Stsefankou</p></figure><p id="d3f2" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">该实现由<em class="mk">密集层、sigmoid函数、训练和预测方法</em>组成。</p><p id="4124" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">开始吧！</p><h1 id="67f9" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据集结构</h1><p id="8b97" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们必须实现包含我们想要训练的所有样本的数据集。</p><p id="9679" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">这是一个数据集模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/d5b71b629e34392bf0a124799494c376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*xlos9IAYIQ3o9GPWLlv6MQ.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集模型。图片作者:Yauheni Stsefankou</p></figure><p id="b96e" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">注意<em class="mk">数据集由数据样本</em>组成。让我们在Swift中实现该结构。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="ee42" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我们的第二个观察是<em class="mk">数据样本包括输入和输出数据</em>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="8cc5" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">并且<em class="mk">为了方便起见，数据块由一个体和它的大小</em>组成。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="4c8d" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">数据的大小<em class="mk">必须有宽度，可选变量是高度和深度</em>(取决于数据大小的类型)。这就是我们为所有数据大小类型提供初始化器的原因。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="69a1" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">数据片可以是<em class="mk"> 1D、2D或3D </em>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="d582" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">神经网络模型类</h1><p id="0054" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们在神经网络中实现了一个数据集系统。现在我们需要创建一个神经网络类。它包括<em class="mk">层、学习率、每次训练的次数、每个训练批次的样本数</em>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="f260" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">现在我们需要实现<em class="mk">层类</em>。每层包括几个神经元(卷积层除外)和一个针对它们的激活函数。此外，我们将为反向传播保留输出缓存。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="6379" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">每个神经元存储每个突触的权重和偏向。此外，我们保留一个缓存来更新权重，以支持<em class="mk">批处理</em>梯度下降类型。有3种梯度下降类型:<em class="mk">批量、随机和小批量</em>。使用<em class="mk">批量</em>和<em class="mk">小批量</em>梯度下降，在多次传播后更新权重。此外，我们保留delta用于反向传播。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="35cc" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">神经网络使用许多激活函数如<em class="mk"> sigmoid，ReLU </em>。我们需要将这些激活功能定义为一个协议。每个激活包含传递函数(用于正向传播)和导数函数(用于反向传播)。我们还存储ID (rawValue)用于枚举函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="7efd" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">现在，对于该协议，可以创建激活功能的结构。让我们做一个sigmoid函数。</p><h1 id="2580" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">乙状结肠功能</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/0ae48673ab712994b7a5f2f4d3a263f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*4ZzyNJAz-j_ppzPJFfBYBg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自维基百科的渲染方程</p></figure><p id="5289" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我想你已经看过了sigmoid函数的图表。这是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/79029d07d8ec9f1ecf88a4b829120d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXCBO-Wx5XhuY_OwMl0Phw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">sigmoid函数的图形。图片来自Qef的维基百科</p></figure><p id="b009" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated"><strong class="lq ir">当我们需要获得输出的概率时，sigmoid函数</strong>是合适的。比如偶数的概率。<br/><strong class="lq ir">sigmoid导函数</strong>是输出和输出与1之差的乘积。</p><p id="4ab8" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我们的sigmoid结构包含它的<em class="mk">标识符</em>(raw value)<em class="mk">传递函数和导数函数</em>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="e545" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">此外，我们需要为我们的函数创建一个enum和一个从标识符中获取它们的方法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="6fae" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">层功能</h1><p id="4cca" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">每种类型的层应该有单独的传播。他们在这里:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="720e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">训练算法</h1><p id="b45a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们需要做的第一件事是<em class="mk">将数据集分成批次</em>。我们可以通过改组数据样本，然后将它们分成大小等于首选批量大小的组来实现这一点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/29765c95bf092cd8b03ae82483f356ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/1*ggEl3veUyo_HMYUSjQwmYw.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">分成几批。图片作者:Yauheni Stsefankou</p></figure><p id="fa3e" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">然后，对于一批中的每个样本，该算法执行向前和向后传播。在批量使用所有样本后，该算法更新所有层的权重。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="495c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">传播正在执行</h1><p id="bd65" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><strong class="lq ir">前向传播</strong>通过突触将神经元的输出发送到下一层。</p><p id="1ad9" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated"><strong class="lq ir"> <em class="mk">反向传播</em> </strong>通过使用正向传播缓存传播预测误差，并将其推向输入层。对于第一次传播，样本的期望值用作输入。</p><p id="70ca" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated"><strong class="lq ir">增量权重方法</strong>计算权重的变化，并将其存储在缓存中。它的工作方式类似于正向传播。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="9d36" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">致密层</h1><p id="7ec6" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们的神经网络中的第一层子类是<strong class="lq ir">密集层</strong>。我们在<em class="mk">部分考虑了密集层的一些理论</em>。这是神经网络最简单的一层。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="4016" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">好的。我们已经初始化了一个密集层，现在我们需要为它编写传播函数。我们使用DispatchQueue中的并发执行来代替循环。<em class="mk">正向传播</em>通过将每个神经元的权重与传递给它的输入相乘，生成每个神经元的输出。这也增加了结果的偏差。具有结果的最后一个操作是激活传递函数的使用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="100b" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated"><em class="mk">反向传播</em>使用正向传播的输出将误差传播到所有神经元。它使用激活导数函数传播误差。多线程在这里不是最优的，所以我们不使用它。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="2a86" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated"><em class="mk">增量权数法</em>正在使用并发执行。在建立神经网络模型时，你应该为学习率找到一个甜蜜的运动。此外，在此方法执行期间，偏差也在更新。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="8532" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">在使用批中的所有项目后，神经网络用传播缓存更新神经元的权重。当然，这里最好使用多线程并发执行。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="e7cb" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">神经网络的第二个重要功能是<em class="mk">预测</em>。为了预测结果，函数<em class="mk">接收正向传播结果</em>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="a918" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">使用编写的框架实现神经网络模型</strong></h1><p id="e7b3" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">万岁！我们已经实现了<em class="mk">我们的神经网络框架的基础，sigmoid激活和它的密集层</em>。现在我们可以用一个简单的例子来验证这一点。</p><p id="7b91" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">这个例子的任务是<em class="mk">按照奇偶性对一个数进行分类</em>。对于神经网络来说，这是一项不同寻常的任务，但很容易理解。</p><p id="1a26" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">为了初始化一个新的神经网络模型，我们需要将它写入代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="fae0" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">之后，我们可以更改模型的一些参数(批量大小、时期数和学习率):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="3ca7" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">实现神经网络模型时最重要的部分是建立层结构。下面是层结构示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="d671" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">之后，我们的模型就可以开始训练了。这一切都始于将数据集输入模型。</p><p id="6cdb" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我们将输入的数字<em class="mk">作为它的二进制数</em>，得到<em class="mk">它是偶数的概率</em>。我们数据集中的第一个样本是<em class="mk">【0.0，0.0，0.0，1.0】</em>，它的期望值是<em class="mk"> 0.0 </em>。这意味着输入数字的二进制表示是<em class="mk"> 0001 </em>。用十进制表示，将是<em class="mk"> 1 </em>。这是一个奇数。所以我们期望<em class="mk"> 0.0 </em>(零概率表示数是偶数)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="c8c9" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">训练好神经网络之后，就可以开始用它来进行预测了。您可以通过将数据样本输入模型来获得预测。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/38c7e5db94155dd9f4050d66b8d0f2fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*-0dGeKWzNLSZAE6SUdeQIA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用30个纪元训练的结果。图片作者:Yauheni Stsefankou</p></figure><p id="a692" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">结果是<em class="mk"> 0.45 </em>，表示答案是55%概率的<em class="mk"> 0(奇数)</em>或45%概率的<em class="mk"> 1(偶数】</em>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/4a34f9353e0a8d6bf0961e4fd7065b3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*iJhqP28s6UiwRH0NWSOhQA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用1000个纪元训练的结果。图片作者:Yauheni Stsefankou</p></figure><p id="4652" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">当我们将历元数改为<em class="mk"> 1000 </em>时，训练时间延长了三十倍，但<em class="mk"> 1111 </em>的均匀度概率变为<em class="mk"> 3.8% </em>。这意味着我们的神经网络模型变得更加精确。</p><h1 id="7f5d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">模型保存</h1><p id="f024" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了保存模型，我们需要准备好所有的结构和类。它们必须与JSON编码的可编码协议兼容。几乎所有的类和结构都只需要在声明中添加可编码协议:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="0fc1" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我们将该层实现为一个类，而不是一个结构。该类要求编码和解码方法符合可编码协议。编码和解码方法需要所有变量的密钥。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="9b3e" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">添加之后，我们必须将解码器中的初始化器添加到我们的密集层中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="b749" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我们需要为层写一个包装器，因为层类<em class="mk">不是最终的，它可以有子类</em>。它不仅编码层的子类，还编码子类的类型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="f970" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">写完包装器后，我们需要用自己的方法替换神经网络模型的编码和解码方法。我们对层的包装进行编码，而不是像这样对层进行编码和解码，因为我们需要存储层的类型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="d307" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">现在我们可以编写一个方法来保存模型。首先，我们必须初始化JSON编码器，并使用它来编码模型。然后，我们获取当前应用程序目录的URL，并将编码数据写入其中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="7a90" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">从文件中读取模型并不比保存它更困难。现在，我们不是初始化JSON编码器，而是初始化JSON解码器。然后我们从文件中获取数据并用我们的解码器解码。我们需要做的最后一件事是从解码的模型变量初始化模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="bd06" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="1c6e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们已经创建了基本的神经网络框架，现在我们可以添加任何类型的功能和层。这里有一个git资源库的链接，里面有所有的源代码和一些额外的功能(丢弃、展平和卷积2D层，ReLU激活):<a class="ae kv" href="https://github.com/stefjen07/NeuralNetwork" rel="noopener ugc nofollow" target="_blank">https://github.com/stefjen07/NeuralNetwork</a>。</p><p id="3c80" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">感谢阅读。如果你有任何建议或者你在这篇文章中发现了错误，请在评论中留下你的反馈。我已经准备好改善我的读者的体验。</p></div></div>    
</body>
</html>