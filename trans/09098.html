<html>
<head>
<title>SSWL-IDN: Self-Supervised CT Denoising</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SSWL-IDN:自监督CT去噪</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sswl-idn-self-supervised-ct-denoising-208fde94583e?source=collection_archive---------28-----------------------#2021-08-22">https://towardsdatascience.com/sswl-idn-self-supervised-ct-denoising-208fde94583e?source=collection_archive---------28-----------------------#2021-08-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e1ae" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="5393" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated"><em class="kr">回顾我们最近的CT去噪论文“窗位是强去噪代理”</em></h2></div><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/df9b9000a0646aed8385d7d328ebdd19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*q4KLPZCu8w0BKs5T.jpg"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">作者图片</p></figure><p id="d516" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我将讨论我们最近的工作，一种新的自我监督的CT去噪方法:<a class="ae me" href="https://arxiv.org/abs/2105.07153" rel="noopener ugc nofollow" target="_blank"> SSWL-IDN </a>，由来自萨拉托加高中和斯坦福大学的RSL 的Ayaan Haque(我)、王一行和Abdullah-Al-Zubaer Imran完成。在本文中，我们介绍了SSWL-IDN，一种新的自监督CT去噪窗口级预测代理任务。我们的方法是任务相关的，并且与下游任务相关，与最近的方法相比产生了改进的性能。我们的论文最近被2021年的MLMI MICCAI接受，并将在九月发表。这篇文章将涵盖我们解决的问题，我们的方法，以及(简要地)我们的结果。我们的论文在<a class="ae me" href="https://arxiv.org/abs/2105.07153" rel="noopener ugc nofollow" target="_blank"> ArXiv </a>上可用，<a class="ae me" href="https://github.com/ayaanzhaque/SSWL-IDN" rel="noopener ugc nofollow" target="_blank">代码</a>在Github上可用，我们的项目页面<a class="ae me" href="https://ayaanzhaque.github.io/SSWL-IDN/" rel="noopener ugc nofollow" target="_blank">在这里</a>可用。</p><h1 id="4e63" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">概观</h1><p id="a346" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated"><em class="nc">什么是CT去噪，为什么重要？</em></p><p id="0223" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于那些没有强大的医学成像背景，CT成像是一个突出的成像方式。CT成像依赖于辐射剂量，因此，在图像质量和辐射剂量之间存在权衡。辐射剂量越高，图像包含的噪声就越少。然而，高辐射剂量对患者有害，这意味着最好以较低的剂量扫描患者。然而，随着图像中噪声的增加，CT图像的诊断性能降低，因为噪声可能阻碍某些结构的可见性。因此，对CT图像进行去噪处理以达到两全其美是一个非常关键的医学成像问题。</p><p id="ad5f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了执行基于深度学习的CT图像去噪，模型将输入低剂量CT扫描(LDCT)并预测全剂量CT扫描(FDCT)。全剂量扫描按常规剂量采集，低剂量扫描一般按四分之一剂量采集。然而，这构成了一个明显的挑战。医疗数据通常很难获得，尤其是CT扫描，因为很难同时获得干净的参考和同一扫描的低剂量版本。但是，在标签数据有限的情况下，深度学习性能会下降。这意味着利用未标记数据的学习框架的使用至关重要。</p><p id="7ca6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">什么是自我监督学习？</p><p id="95e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于辐射的有害性质以及在不同辐射剂量下进行两次相同扫描的困难，获取参考图像是具有挑战性的。因此，期望用有限的参考数据来训练去噪模型。自我监督学习(SSL)已经成为完全监督学习的一种有前途的替代方法，以便利用大量的未标记训练样本。在SSL方案中，可以从数据本身为标记和未标记的数据生成合成标签。与迁移学习类似，SSL在代理任务上预先训练模型，但在相同的数据集上而不是来自外部域的数据集上，然后在下游或主要评估任务上微调预先训练的模型。</p><p id="71c6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">自我监督学习是无监督学习的一种形式，因为它使用完全免费的标签对单独的任务进行训练。一些常见的例子包括随机旋转图像和让模型预测图像旋转的角度。</p><p id="6950" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的自我监督学习形式使用两个独立的任务:一个代理任务和一个下游任务。这不要与完全无监督的方法相混淆，例如Noise2Noise ( <a class="ae me" href="https://arxiv.org/abs/1803.04189" rel="noopener ugc nofollow" target="_blank"> Lehtinen等人2018 </a>)和Noise2Void ( <a class="ae me" href="https://arxiv.org/abs/1811.10980" rel="noopener ugc nofollow" target="_blank"> Krull等人2018 </a>)。这些方法根本不使用任何参考扫描。这不是计算机视觉领域的传统SSL定义。由于这些方法不使用任何参考扫描，正如这些论文的作者所争论的那样，以任何方式与使用参考扫描的方法进行比较都是不公平的。为了证明这一说法，我们将我们的SSL算法与Noise2Void进行了比较。</p><p id="c4ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们使用SSL来提高具有有限参考FDCT的深度去噪模型的性能。我们提出了一种新的去噪替代预测窗口水平的ct图像从非窗口水平的图像作为借口。与许多其他现有的自监督学习方法不同，我们提出的自监督窗口水平(SSWL)是一个任务相关的代理，因为它直接与下游任务相关，优先考虑相似的特征学习。此外，我们将所有实验限制在5%的剂量水平，这可能是一种积极的剂量减少机制，并证明即使在如此低的剂量设置下也有效。我们的主要贡献如下:</p><ul class=""><li id="7209" class="nd ne it lk b ll lm lo lp lr nf lv ng lz nh md ni nj nk nl bi translated">一种新的与任务相关的自监督窗口级预测代理，它与下游任务相关</li><li id="b854" class="nd ne it lk b ll nm lo nn lr no lv np lz nq md ni nj nk nl bi translated">一种创新的基于残差的VAE架构，与混合损失函数相结合，同时对模型进行逐像素和感知惩罚</li><li id="4fdc" class="nd ne it lk b ll nm lo nn lr no lv np lz nq md ni nj nk nl bi translated">对域内和跨域数据上不同建议成分的不同数量的标记数据进行的大量实验证明，即使是极低剂量(5%)的CT图像，也能实现改进和有效的去噪</li></ul><h1 id="7e56" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">SSWL-IDN</h1><p id="2e77" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated"><em class="nc">窗口调平及CT去噪</em></p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nr"><img src="../Images/4272605ac72b233d447c92d687261fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*O3zj4tHMBvEd_koE.jpg"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">去噪和窗位的关系(图片由作者提供)</p></figure><p id="3ad0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在CT去噪中，输入图像是LDCT，参考图像是FDCT。两者的关系表示为LD = FD + Noise。去噪模型旨在从LD中去除噪声并重新获得FD。</p><p id="5af9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在CT成像中，窗位调整是使用CT数修改图像灰度的过程，以突出、增亮和对比重要的结构。窗位化(WL)和非窗位化(NWL)图像之间的关系表示为:WL = a * NWL + b，其中a和b是窗位化参数。如图所示，从图像变换的角度来看，窗位扫描和非窗位扫描之间的关系可以比作FDCT和LDCT之间的关系。因此，训练模型以从非窗位图像预测窗位图像是与去噪相关的任务。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/df9b9000a0646aed8385d7d328ebdd19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*q4KLPZCu8w0BKs5T.jpg"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">提议的SSWL-IDN模型的示意图。对于SSL代理任务，该模型从非窗口级别图像预测窗口级别图像。对于下游任务，模型将输入LDCT去噪以匹配FDCT。(图片由作者提供)</p></figure><p id="c228" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">预测分级图像是一项自我监督的任务，因为窗口分级图像可以自由创建，因为这样做的信息在DICOM元数据中是自由可用的。具体而言，当获得全剂量参考图像极其困难时，将其作为下游去噪任务的借口更合适。特别是因为任务是特定领域的，它允许比外来或任意代理更重要和相关的特征学习。</p><p id="86ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，我们提出的自监督学习方法包括两个步骤:在窗口水平任务上的全监督预训练，然后在小标签去噪任务上的微调。对于预训练，我们为标记和未标记的数据准备了每次LDCT扫描的NWL和WL版本。Loss针对从输入NWL LDCT预测WL LDCT进行了优化。我们的代理是端到端的，与许多其他不使用相关任务的方法相反，因为在任务之间不需要架构或损失的改变。</p><p id="f159" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="nc">模型架构和损失函数</em></p><p id="3e7d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于模型结构，我们提出了残差变分自动编码器(RVAE)。我们的模型使用RED-CNN ( <a class="ae me" href="https://arxiv.org/pdf/1702.00288.pdf" rel="noopener ugc nofollow" target="_blank"> Chen et al. 2017 </a>)作为主干架构，并加入了一个瓶颈。虽然已经提出了基于残差的vae，但是它们在编码器和解码器中分别使用残差(ResNet作为编码器，转置ResNet作为解码器)，而不是像以前的方法那样使用编码器和解码器之间的残差连接。在瓶颈中使用参数化技巧改善了FD预测，因为通过添加可调噪声，我们可以减少过拟合，改善泛化，并有助于正则化模型。</p><p id="ed47" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于我们的损失，我们使用MSE和感知损失之间的混合损失。这鼓励了逐像素和感知学习，这将提高定量和定性去噪性能。我们的感知损失使用从预训练的VGG-19网络中提取的特征。我们的总损失函数表示为:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ns"><img src="../Images/a77cf5b6e3f5360b9bffd990030dafd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jBEC1q6vLFTl9i4TLcbJog.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">我们的总损失函数(图片作者)</p></figure><p id="1850" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中，LMSE是标准MSE损失，l感知是感知损失，β是l感知权重。对于VAE，LKL代表KL发散损失，α是LKL重量。是均值项，σ是标准差项，都来自于潜在空间。KL发散试图减少两个参数与目标分布参数的发散。</p><h1 id="61a8" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">结果</h1><p id="fb1d" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">我们使用了梅奥低剂量CT数据集。具体来说，我们的目标是在超低剂量下降噪，因此我们将四分之一剂量扫描缩小到5%剂量。这允许进行彻底的去噪评估。虽然从临床角度来看，与质量较低的去噪5%剂量相比，去噪良好的四分之一剂量更理想，但从计算角度来看，显示去除大量噪声的能力可以更恰当地评估模型准确去除噪声的全部潜力。</p><p id="9629" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将我们的RVAE架构与各种基线和最先进的架构进行了比较，并将我们的SSWL方法与各种基线和最先进的SSL训练算法进行了比较。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nt"><img src="../Images/2623d5c205285c55ee08186513486f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PhI7wx6cxmd8moY0.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">我们的RVAE与各种架构进行了比较，并优于所有架构(图片由作者提供)</p></figure><p id="1c5a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如上表所示，我们的RVAE优于所有具有统计学意义的模型。重要的是，我们优于两个架构，RED-CNN和DnCNN(【张等人2016 )，证明了RVAE方法的有效性。此外，我们的跨域结果显示了我们的架构的改进的通用性。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nu"><img src="../Images/7e65c520dc7b61f7d92815d994662dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/0*REH83WFif0NtLzAh.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">我们的SSWL-IDN模型优于所有的基线SSL方法(图片由作者提供)</p></figure><p id="5ab8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">更重要的是，我们的自监督窗口水平代理任务优于基线和两种最先进的方法，Noise2Void (N2V)和noise-As-Clean(NAC)(<a class="ae me" href="https://arxiv.org/abs/1906.06878" rel="noopener ugc nofollow" target="_blank">Xu et al . 2019</a>)。这显示了任务相关性对于CT去噪的重要性，并且证实了我们的方法的强性能。混合损失也是有益的，与RVAE + SSWL相比，我们的最终模型具有更好的性能。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nv"><img src="../Images/a5fb20d7215be478c03d83368e8ff537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V-htczq2zIWJZ9jUK4ma9A.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">SSWL和我们的RVAE优于其他架构和SSL方法</p></figure><p id="5cf7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上图展示了我们的网络对5%剂量CT扫描进行精确降噪的能力。虽然似乎有过度光滑和丢失的结构细节，这可以归因于低剂量的CT扫描。此外，我们的SSWL算法优于没有SSL和我们的RVAE优于红色CNN本身。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nw"><img src="../Images/b862a29b9d16cb5100a03f1d5715449a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nXdoHiBmXfiK3o_l.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">在基于ROI的定性去噪方面，SSWL优于我们的SSL方法</p></figure><p id="fa0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，我们在上图中证实了我们的算法相对于其他SSL方法的定性优势。如图所示，当检查特定的ROI时，我们比其他方法获得了更清晰的去噪图像。</p><h1 id="c14a" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">最后的想法</h1><p id="c079" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">在这篇文章中，我们提出了SSWL-IDN，一个自我监督的去噪模型，一个新颖的，任务相关的，有效的窗口级预测的替代任务。我们还提出了专门用于去噪的残差VAE，以及利用感知和像素级学习优点的混合损失。我们证实，我们的方法的每个组成部分都优于域内和跨域评估的困难的5%剂量去噪基线，并且当组合时，该模型显著优于最先进的方法。</p><p id="8791" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个框架的最终目的是帮助减少在临床环境中使用高CT辐射剂量。如果我们的方法能够在有限的标记数据上进行训练，并准确地对CT扫描进行去噪，那么可以以较低的剂量对患者进行扫描，并且可以在专家诊断或筛查之前对扫描进行去噪。</p><p id="0ee7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你觉得这篇文章或论文有趣，请告诉我！如果你觉得这项工作有用，下面是引文:</p><pre class="kt ku kv kw gt nx ny nz oa aw ob bi"><span id="6922" class="oc mg it ny b gy od oe l of og">@article{haque2021window,<br/>      title={Window-Level is a Strong Denoising Surrogate},<br/>      author={Haque, Ayaan and Wang, Adam and Imran, Abdullah-Al-Zubaer},<br/>      journal={arXiv preprint arXiv:2105.07153},<br/>      year={2021}<br/>}</span></pre></div></div>    
</body>
</html>