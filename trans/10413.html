<html>
<head>
<title>How our Obsession with Algorithms Broke Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们对算法的痴迷如何打破了计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/synthetic-computer-vision-c53742b4dee1?source=collection_archive---------26-----------------------#2021-10-04">https://towardsdatascience.com/synthetic-computer-vision-c53742b4dee1?source=collection_archive---------26-----------------------#2021-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5f95" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">以及合成计算机视觉如何修复它</strong></h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9806f98e3384b67bd8530b11f69a115d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JVvkCg_Jn48zCYIZZi79lw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">合成计算机视觉旨在将虚拟世界中的内容翻译回现实世界。(图片由作者提供)</p></figure><blockquote class="ky kz la"><p id="20c0" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">深度学习从整体上彻底改善了机器学习。以数据为中心的革命也将如此。在本帖中，我们将看看主流<strong class="le iu">计算机视觉(CV) </strong>的陷阱，并讨论为什么<strong class="le iu">合成计算机视觉(SCV) <em class="it"> </em> </strong>是未来。</p></blockquote><h1 id="3442" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">🗣️计算机视觉的现状</h1><p id="6822" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">根据Crunchbase 的数据，截至今天，在过去的8年里，超过1800家计算机视觉初创公司获得了价值超过150亿美元的投资。据《福布斯》报道，这些公司中有20多家目前的市值超过了1B，还会有更多的公司出现。</p><p id="6d4a" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">为什么这些公司被如此看重？简单地说，他们在教计算机如何看东西。通过这样做，他们正在自动化以前使用人类视觉完成的任务。</p><p id="b58e" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">这一繁荣是在2012年计算机视觉的技术拐点之后，随着神经网络的出现——模仿人脑并使用大量人类标记的数据进行训练的算法。自2012年以来，算法一直在稳步改进，并在许多视觉任务中成为人类的对手，例如计数物体、<a class="ae my" href="https://www.technologyreview.com/2016/11/21/69566/ai-has-beaten-humans-at-lip-reading/" rel="noopener ugc nofollow" target="_blank">唇读</a>或<a class="ae my" href="https://www.nature.com/articles/s41598-019-48995-4" rel="noopener ugc nofollow" target="_blank">癌症筛查</a>。</p><p id="7cfe" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">在接下来的10年里，每个人都尽了自己的职责:学术界用更好的算法引领潮流；大公司投资了一大批人，他们勤奋地给这些图像数据集贴上标签。为了社区的利益，其中一些工作甚至是开源的，例如1400万图像数据集ImageNet。</p><p id="f85c" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">不幸的是，现在随着这些系统被部署到生产中，我们遇到了一个难题:</p><ol class=""><li id="b958" class="mz na it le b lf lg li lj ms nb mu nc mw nd lx ne nf ng nh bi translated">我们拥有的标记为<strong class="le iu">的数据是不可靠的</strong>。麻省理工学院研究人员对流行的ML数据集进行的<a class="ae my" href="https://venturebeat.com/2021/03/28/mit-study-finds-systematic-labeling-errors-in-popular-ai-benchmark-datasets/" rel="noopener ugc nofollow" target="_blank">系统研究发现，ImageNet的平均错误率</a><a class="ae my" href="https://l7.curtisnorthcutt.com/label-errors" rel="noopener ugc nofollow" target="_blank">错误标记率为5.93% </a>，其他数据集的平均错误率为3.4%。</li><li id="afe8" class="mz na it le b lf ni li nj ms nk mu nl mw nm lx ne nf ng nh bi translated">很少有人致力于解决数据问题。学术界的智力努力几乎完全集中在算法开发上，忽略了对良好数据的基本需求——吴恩达的一项猜测认为，99%的算法关注与1%的数据关注的比率为<a class="ae my" href="https://www.youtube.com/watch?t=526&amp;v=06-AZXmwHjo&amp;feature=youtu.be" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="d059" class="mz na it le b lf ni li nj ms nk mu nl mw nm lx ne nf ng nh bi translated">计算机视觉算法不能很好地从一个领域推广到另一个领域，一个被训练用来在法国南部检测汽车的算法将很难在多雪的挪威检测到同样的汽车。同样，在特定摄像机上训练的系统可能在另一个摄像机品牌和型号上失败。</li></ol><h1 id="4a36" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">♟️寻找灵感</h1><p id="78d5" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">早在1946年，艾伦·图灵就建议将国际象棋作为计算机能力的基准，此后这一问题得到了深入研究，并引起了媒体的广泛关注。</p><p id="b088" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">一种普遍接受的衡量国际象棋比赛表现的方法是通过<a class="ae my" href="https://en.wikipedia.org/wiki/Elo_rating_system" rel="noopener ugc nofollow" target="_blank"> Elo评级系统</a>，该系统提供了对玩家技能的有效比较。下图显示了世界冠军和国际象棋游戏引擎。在过去的50年里，人类的表现一直徘徊在2800点左右，然后在2010年被计算机压制。</p><p id="f8f9" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">直到最近十年，我们人类已经设计了象棋算法，根据我们可以设计和理解的规则进行游戏。深度学习革命让我们突破了人类的理解，带来了一次飞跃——就像它对计算机视觉的影响一样。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nn"><img src="../Images/d21dac66f78af6a82548f13cb5ac991c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*h5WMHb5oUwV6KYKjIClO5g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">国际象棋引擎和人类ELO评级(图片由作者提供)</p></figure><p id="a830" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">深度学习国际象棋游戏引擎的进展一样好，但它现在被下一级国际象棋引擎压制了:<strong class="le iu">来自DeepMind的AlphaZero </strong>。更令人印象深刻的是，<strong class="le iu"> AlphaZero没有使用任何人工数据</strong>来实现这一性能。它是在没有任何历史象棋游戏知识的情况下建造的，也没有任何寻找最佳走法的人类指导。AlphaZero是老师也是学生——它通过与自己竞争并在这个过程中学习，教会了自己如何更好地玩游戏。</p><p id="c80f" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">AlphaZero赢了当时最好的引擎Stockfish 8，没有输掉一场比赛，即使Alpha Zero给了<a class="ae my" href="https://chess24.com/en/read/news/alphazero-really-is-that-good" rel="noopener ugc nofollow" target="_blank">少一个数量级的时间</a>来计算它的下一步行动。</p><p id="7520" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">考虑到AlphaZero的显著改进，人们不禁要问:<strong class="le iu"> <em class="ld">我们能否将其在国际象棋中的成功转化为计算机视觉？</em> </strong></p><h1 id="8743" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">📰新浪潮:以数据为中心的人工智能</h1><p id="b930" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">在<a class="ae my" href="https://www.forbes.com/sites/gilpress/2021/06/16/andrew-ng-launches-a-campaign-for-data-centric-ai/?sh=6d7fce8574f5" rel="noopener ugc nofollow" target="_blank">以数据为中心的人工智能</a>的新范式中，目标不是创造更好的算法，而是通过改变数据本身来提高性能。即使我们首先忽略获取和标记图像数据集的障碍，围绕数据质量的问题仍然存在:我们是否一致地覆盖了所有可能的用例？数据是否涵盖了边缘案例？</p><p id="8c44" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">如果我们要走以数据为中心的计算机视觉之路，就必须控制数据源流程。数据需要平衡，我们需要很好地理解影响计算机视觉模型学习内容的参数。</p><p id="afd5" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">让我们举一个简单的例子，看看如何控制3个这样的参数:摄像机角度、照明和遮挡。你能想象收集一个真实的数据集，其中你必须努力控制只有这3个参数的值，同时收集1000个相关的图像吗？对于真实数据，这项任务是永无止境的。</p><h1 id="1779" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">💾我们现在如何管理数据？</h1><p id="45d0" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">在过去的5年里，我们在优化数据收集流程和数据标签质量方面取得了巨大进步。此外，我们已经学会了通过使用各种<em class="ld">数据扩充</em>技术来充分利用数据集。给定我们数据集中的一幅图像，我们对其应用数学函数，以便在我们的数据中创建更多种类。</p><p id="2057" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">现在有超过400家公司，总市值为1.3万亿美元(略高于脸书的市值)，满足我们最新算法的数据需求。</p><p id="9973" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">但是现在的路径是不是通向一个死胡同？我们是否达到了建立在人类数据集之上的算法的极限？就像在国际象棋中一样，只要我们使用人类来源的数据作为算法的输入，我们就会被设计约束，不能明显超越我们自己的能力。</p><p id="d325" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">在国际象棋中，一旦我们停止建立在次优的人类数据上，并允许机器建立自己的数据以优化它们的学习，后深度学习的突破就来了。在计算机视觉中，我们必须做同样的事情，让机器生成优化自身学习所需的数据。</p><h1 id="993a" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">🏔计算机视觉的下一步是什么？</h1><p id="a899" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">真正可扩展的创建训练数据的方式是通过<strong class="le iu">虚拟现实引擎</strong>。就保真度而言，输出已经<a class="ae my" href="https://www.youtube.com/watch?v=S3DEM6XDDTk" rel="noopener ugc nofollow" target="_blank">变得与真实世界无法区分</a>，给了用户完全的场景控制。这允许用户<strong class="le iu">生成智能数据</strong>，这对计算机视觉模型的学习非常有用。<strong class="le iu">合成数据可以成为新的以数据为中心的人工智能框架所需的基石</strong>。</p><p id="5e60" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">我们有充分的理由相信，现在是广泛采用可视化合成数据的时候了。</p><ul class=""><li id="1096" class="mz na it le b lf lg li lj ms nb mu nc mw nd lx no nf ng nh bi translated">虚拟现实引擎有专门的组件用于合成数据生成(<a class="ae my" href="https://developer.nvidia.com/isaac-sim" rel="noopener ugc nofollow" target="_blank"> NVIDIA IsaacSim </a>，<a class="ae my" href="https://github.com/Unity-Technologies/com.unity.perception" rel="noopener ugc nofollow" target="_blank"> Unity Perception </a>)，生成的数据不仅赏心悦目，而且对于训练更好的算法也是必不可少的<a class="ae my" href="https://www.prnewswire.com/news-releases/survey-of-industry-leaders-shows-synthetic-data-is-essential-to-building-more-capable-ai-models-301377167.html" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="de4b" class="mz na it le b lf ni li nj ms nk mu nl mw nm lx no nf ng nh bi translated">3D资产正在迅速成为一种商品——最新的<a class="ae my" href="https://www.geoweeknews.com/news/apple-debuts-its-own-api-for-reality-capture-and-3d-object-creation-but-where-s-the-lidar" rel="noopener ugc nofollow" target="_blank"> iPhone配备了激光雷达</a>并且第一代3D扫描应用程序正在产生巨大的<a class="ae my" href="https://www.linkedin.com/posts/albandenoyel_photogrammetry-objectcapture-3dcapture-activity-6833436374952099840-MPTn" rel="noopener ugc nofollow" target="_blank">效果</a>。</li><li id="4637" class="mz na it le b lf ni li nj ms nk mu nl mw nm lx no nf ng nh bi translated">元宇宙即将到来，这是一件大事。如果《T2》预测的600亿美元增长中的一小部分成为现实，我们将生活在一个虚拟现实将成为习惯的世界中。数字双胞胎今天有了真正的应用:一个例子来自宝马，未来的<a class="ae my" href="https://www.youtube.com/watch?v=6-DaWgg4zF8" rel="noopener ugc nofollow" target="_blank">工厂</a>，另一个例子是谷歌的<a class="ae my" href="https://venturebeat-com.cdn.ampproject.org/c/s/venturebeat.com/2021/09/14/google-launches-digital-twin-tool-for-logistics-and-manufacturing/amp/" rel="noopener ugc nofollow" target="_blank">供应链双胞胎</a>。</li><li id="a6e2" class="mz na it le b lf ni li nj ms nk mu nl mw nm lx no nf ng nh bi translated">该行业的创新者已经开始使用虚拟现实来改进计算机视觉算法:特斯拉<a class="ae my" href="https://www.youtube.com/watch?v=6hkiTejoyms" rel="noopener ugc nofollow" target="_blank">正在使用虚拟世界</a>来生成驾驶场景的边缘案例和新颖视图。</li></ul><h1 id="6d87" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">👁️‍🗨️合成计算机视觉</h1><p id="aa89" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">通过使用正确的工具来构建我们自己的数据，我们可以想象这样一个世界，在这个世界中，计算机视觉算法的开发和训练不再需要繁琐的手动数据标记过程。<a class="ae my" href="https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/" rel="noopener ugc nofollow" target="_blank"> Gartner </a>预测，在未来3年内，合成数据将比真实数据更占主导地位。</p><p id="dcd5" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">为什么不更进一步呢？一个不需要人类为计算机视觉标记图像的世界会怎么样？</p><h1 id="0b9b" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">🚀未来是光明的</h1><p id="ce6f" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">通过合成计算机视觉，我们可以在虚拟现实中构建，并为现实世界进行部署。就像AlphaZero教会自己在国际象棋中什么是重要的一样，我们让算法决定它们需要看到什么，以便最佳地学习。</p><blockquote class="ky kz la"><p id="2b9b" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><em class="it">在</em> <strong class="le iu"> <em class="it">合成计算机视觉(SCV) </em> </strong> <em class="it">中，我们使用虚拟现实引擎训练计算机视觉模型，并将模型部署在</em> <strong class="le iu"> <em class="it">现实世界</em> </strong> <em class="it">中。</em></p></blockquote><h1 id="9dd6" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">🔬超越RGB图像</h1><p id="a5f3" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">现实远不止肉眼所见。我们构建的算法主要关注人类能够理解和标记的东西。但事情并不一定是这样——我们可以为传感器构建算法，以超越人类的感知进行测量。我们可以在虚拟现实中有计划地训练这些算法，而不用怀疑它们的有效性。</p><h1 id="f4ac" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">🤓更聪明而不是更努力</h1><p id="efdb" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">与其建立更大的模型并使用更多的计算能力来解决我们的问题，我们可以明智地选择我们的算法学习的数据来源。算法不需要更多的相同数据来学习，它们需要各种各样的东西。</p><p id="a898" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">Deep Mind表明AlphaZero只是这条路的开始，因为他们已经将相同的原则应用于<a class="ae my" href="https://www.youtube.com/watch?v=WXuK6gekU1Y" rel="noopener ugc nofollow" target="_blank">围棋</a>、<a class="ae my" href="https://www.youtube.com/watch?v=cUTMhmVh1qs" rel="noopener ugc nofollow" target="_blank">星际争霸</a>和<a class="ae my" href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology" rel="noopener ugc nofollow" target="_blank">蛋白质折叠</a>。今天，我们已经拥有了为计算机视觉构建<em class="ld"> AlphaZero的所有必要构件，这是一个在设计上不受<strong class="le iu">人类输入</strong>限制的自我学习系统。一种能够创建和操纵虚拟场景的系统，通过它可以自学如何解决视觉自动化任务。</em></p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="2b18" class="ly lz it bd ma mb nw md me mf nx mh mi jz ny ka mk kc nz kd mm kf oa kg mo mp bi translated">🔭合成数据生成的先驱</h1><p id="c48a" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">合成计算机视觉的基础是建立在<strong class="le iu">合成数据</strong>之上的。大约有<a class="ae my" href="https://drive.google.com/file/d/1xhgmO9U8WZoYFi7tviUDiyLWz-SYvRFe/view" rel="noopener ugc nofollow" target="_blank"> 30家早期公司</a>在视觉合成数据生成领域运营。有些专注于一个垂直领域的特定用例，而大多数则在多个垂直领域横向运营。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/4a32670134644eef3209bf37e1672d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kaAiHbaS1MoZPqlajJCzKQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按焦点分组的合成数据公司(图片由作者提供)。</p></figure><p id="c90e" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">现在是2021年，我们才刚刚开始。请记住，合成数据只是等待解决的谜题的一部分。</p><h1 id="a082" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">亲爱的读者，❓Questions给你</h1><p id="6a81" class="pw-post-body-paragraph lb lc it le b lf mq ju lh li mr jx lk ms mt ln lo mu mv lr ls mw mx lv lw lx im bi translated">1.很容易想象，10年后，你的智能手机将比你的普通视觉感知能力更强，但我们如何实现这一目标？</p><ul class=""><li id="ce3c" class="mz na it le b lf lg li lj ms nb mu nc mw nd lx no nf ng nh bi translated">(增强的)数据标签会一直存在下去，还是只是一块垫脚石？</li><li id="7468" class="mz na it le b lf ni li nj ms nk mu nl mw nm lx no nf ng nh bi translated">标签会从2D转移到3D世界吗，或者我们可以完全不用这种方法吗？</li></ul><p id="5544" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated">2.在计算机视觉中使用深度学习算法可以获得最先进的结果——合成计算机视觉可以实现新一波以前无法实现的改进算法吗？</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><p id="32ec" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated"><em class="ld">由</em> <a class="ae my" href="https://www.linkedin.com/in/paul-pop/" rel="noopener ugc nofollow" target="_blank"> <em class="ld">保罗·波普</em> </a> <em class="ld">撰写，联合创始人兼CEO于</em><a class="ae my" href="https://medium.com/u/1888f854e2da?source=post_page-----c6078bf42def--------------------------------" rel="noopener"><em class="ld">neuro labs</em></a><em class="ld">。</em></p><p id="f2ee" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk ms lm ln lo mu lq lr ls mw lu lv lw lx im bi translated"><a class="ae my" href="https://www.neurolabs.ai/" rel="noopener ugc nofollow" target="_blank"><em class="ld">neuro labs</em></a><em class="ld">为零售业打造合成计算机视觉软件。</em></p></div></div>    
</body>
</html>