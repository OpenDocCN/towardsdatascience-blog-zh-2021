<html>
<head>
<title>5 Must-Know AI Concepts In 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年必须知道的5个人工智能概念</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-must-know-ai-concepts-in-2021-75d8c1ff938?source=collection_archive---------16-----------------------#2021-08-01">https://towardsdatascience.com/5-must-know-ai-concepts-in-2021-75d8c1ff938?source=collection_archive---------16-----------------------#2021-08-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c59d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能|解释</h2><div class=""/><div class=""><h2 id="554d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">这是你不想错过的。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/7b01fff9fb4ddc6b983766feb368f7e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w6WFKWNStVmorvX3"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">道格拉斯·桑切斯在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0542" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">AI应该通过复制我们的生物来模仿人类的智能吗？或者我们的心理生物学本质与人工智能无关，就像鸟类生物学与航空航天工程无关一样？</p><p id="33a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是该领域的人们自其提出以来一直在思考的问题。我们想要建立智能系统，而我们人类可以说是唯一真正智能的物种。从我们身上寻找灵感难道不符合逻辑吗？然而，因为人工智能的构建模块与生物学的基本部件如此不同，我们难道不应该忘记人类，沿着我们的研究引领我们的道路前进吗？</p><p id="19f7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">没有人知道人工智能的未来会怎样。我们知道的是，现在的深度学习越来越接近类人认知。也许人类在智力方面并不特别，但进化给了我们一些独特的特征，我们在创建人工智能系统时最好考虑到这些特征。我们已经在这种环境中进化了几千年，慢慢适应了不变的自然法则。为什么不通过模拟我们的抛光机制来绕过这个过程呢？</p><p id="73d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我将谈论目前处于人工智能研究前沿的五个例子。每一个都至少松散地基于人类认知功能的某些方面。这些概念将是未来几年的核心，所以让我们密切关注它们。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="72fa" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">变形金刚——人类的注意力</h1><p id="acad" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">不久前，基于递归的架构主导了自然语言处理(NLP)。如果你面临一个自然语言处理问题——翻译、语音转文本、生成任务——你要么使用门控循环单元(GRU)，要么使用长短期记忆(LSTM)。这两种架构是为处理顺序输入数据而设计的。例如，该系统可以将一个英语句子和每个连续的单词翻译成西班牙语。</p><p id="03f2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些模型的主要缺点之一是<a class="ae lh" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失梯度问题</a>。因为信息是按顺序处理的，所以当系统要输出第一个法语单词时，第一个英语单词只是被记住了。为了解决这一缺陷，研究人员在2014年引入了<a class="ae lh" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank">注意力机制</a>。通过模仿认知注意力，神经网络可以衡量环境的影响。不再有信息丢失。</p><p id="79aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2017年，谷歌的AI团队发表了开创性的论文<a class="ae lh" href="https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ni">注意力是你所需要的全部</em> </a>。它说:注意力机制强大到足以解决语言任务。我们不需要递归，也不需要顺序处理。他们发明了著名的变压器架构。变形金刚影响深度学习格局的方式只能与2012年辛顿的团队赢得ImageNet挑战赛时CNN在计算机视觉(CV)中的颠覆相媲美。</p><p id="2649" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">转换器的工作原理是并行处理一个句子中的所有单词(记号),并学习它们之间的上下文关系。与LSTM相反，变压器不按顺序处理数据。训练时间要短得多。如今，变压器是任何NLP任务的首选架构。甚至CV的科学家也开始将变形金刚应用于图像和视频问题。即使是卷积也不能幸免于关注。</p><p id="6d38" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从2017年到2021年，研究人员进一步开发了变压器，旨在解决各种缺点，提高性能。<a class="ae lh" href="https://arxiv.org/pdf/1901.02860.pdf" rel="noopener ugc nofollow" target="_blank">transformer-XL</a>更大，允许系统在更大的上下文中学习依赖性。GPT-3——它建立在最初的transformer架构上——不能越过它的上下文窗口，这使得它没有记忆。改革者解决令人望而却步的培训费用。它提高了效率，减少了培训时间，同时实现了最先进的性能。</p><p id="d0cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">近年来，变形金刚最引人注目的一些应用是多任务人工智能，如<a class="ae lh" href="https://blog.google/products/search/search-language-understanding-bert/" rel="noopener ugc nofollow" target="_blank">谷歌的BERT </a>，OpenAI的GPT家族——其中<a class="ae lh" rel="noopener" target="_blank" href="/gpt-3-a-complete-overview-190232eb25fd"> GPT-3是毫无争议的明星</a>——<a class="ae lh" rel="noopener" target="_blank" href="/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484">悟道2.0 </a>，它保持着最大神经网络的记录。变压器也是新一代聊天机器人——<a class="ae lh" href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html" rel="noopener ugc nofollow" target="_blank">Meena</a>、<a class="ae lh" rel="noopener" target="_blank" href="/better-than-gpt-3-meet-blenderbot-2-0-facebooks-latest-chatbot-8941f100d146"> BlenderBot 2.0 </a>或<a class="ae lh" rel="noopener" target="_blank" href="/googles-lamda-the-next-generation-of-chatbots-62294be58426"> LaMDA </a>背后的核心算法。它甚至涉足了生物学领域。几天前DeepMind <a class="ae lh" href="https://deepmind.com/blog/article/putting-the-power-of-alphafold-into-the-worlds-hands" rel="noopener ugc nofollow" target="_blank">宣布</a>他们已经发布了<a class="ae lh" href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology" rel="noopener ugc nofollow" target="_blank"> AlphaFold 2 </a>的代码和数据库。一个有助于更深入理解蛋白质折叠的模型。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="d5d2" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">自我监督培训——人类学习</h1><p id="1b9d" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated"><strong class="lk jd">自2012年以来，有监督的深度学习系统</strong>一直主导着人工智能领域。这些系统从标记的数据中学习，以将新的实例分类到学习的类别中。我们投入大量资源对训练样本进行分类，以方便学习。然而，这些模式匹配系统不像我们一样学习。</p><p id="f679" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">强化学习更像我们学习的方式。这些系统生活在一个受限制的虚拟世界中，在这个世界中，它们可以做一组有限的动作来获得奖励。DeepMind的研究人员几个月前发表了一篇论文，认为“<a class="ae lh" href="https://deepmind.com/research/publications/Reward-is-Enough" rel="noopener ugc nofollow" target="_blank">奖励足以</a>”实现通用人工智能。然而，并不是人们所做的一切都是为了优化奖励，就像增强人工智能所做的那样。更不用说我们世界的复杂性，每时每刻可能的行动数量，或者我们想要或需要的复杂性和细微差别。</p><p id="99f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">出于上述原因，研究人员最近对<strong class="lk jd">无监督</strong>——或<a class="ae lh" href="https://bdtechtalks.com/2020/03/23/yann-lecun-self-supervised-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">自我监督</strong></a>——Yann le Cun喜欢称之为学习——的范式产生了更多的兴趣。他认为我们的学习与这些系统相似(至少与其他范式相比)。人类通过<a class="ae lh" href="https://en.wikipedia.org/wiki/Observational_learning#Observational_causal_learning" rel="noopener ugc nofollow" target="_blank">观察</a>和感知世界学到很多东西。这就是自我监督学习的意义。</p><blockquote class="nj nk nl"><p id="20a5" class="li lj ni lk b ll lm kd ln lo lp kg lq nm ls lt lu nn lw lx ly no ma mb mc md im bi translated"><em class="it">【自我监督学习】就是</em>在学习一个任务之前，先学习代表世界的思想。<em class="it"> </em>这是婴儿和动物做的事情<em class="it">。[……]</em>一旦我们对世界有了很好的描述，学习一项任务就需要很少的试验和样本。”</p></blockquote><ul class=""><li id="a13d" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">监督学习系统学习在数据中寻找模式，而不关心世界。</li><li id="d1fc" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">强化学习系统学习优化奖励，而不关心世界。</li><li id="7f7f" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">自我监督学习系统需要代表世界来理解事物之间的关系。</li></ul><p id="18df" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些系统可以从输入的可见部分中学习输入的隐藏部分。例如，如果你向一个自我监督的系统输入半个句子，它可以预测缺失的单词。要做到这一点，他们需要对事物之间的关系有更深入的了解(这并不是说他们理解世界的方式和我们一样，事实并非如此)。</p><p id="d6af" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对大量标记数据(监督学习)和不可计数模拟(强化学习)的需求是一个障碍。自我监督学习旨在解决这两个问题。这些系统在没有明确告诉它们必须学习什么的情况下学习。没有课。没有任务。</p><p id="2aee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">自我监督学习的一些重要成功都与transformer架构有关。例如，伯特或GPT-3已被证明在语言生成任务中非常成功。在许多NLP领域中，自我监督系统现在是最先进的。这些系统的一个显著缺点是它们不能处理连续的输入，例如图像或音频。</p><blockquote class="od"><p id="4781" class="oe of it bd og oh oi oj ok ol om md dk translated">"人工智能的下一场革命将不会受到监督，也不会得到纯粹的强化."</p><p id="106b" class="oe of it bd og oh oi oj ok ol om md dk translated">——扬·勒昆</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="9ef7" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">即时编程——人际交流</h1><p id="ae41" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">低代码和无代码计划出现在几十年前，是对编码领域日益扩大的技能缺口的一种反应。创建好的代码和知道如何在设计-生产管道的不同点处理任务的技术能力是昂贵的。随着软件产品变得越来越复杂，编程语言也越来越复杂。No-code旨在为非技术业务人员解决这一差距。这是一种绕过编码让任何人都可以访问结果的方法。</p><p id="4c3b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">几年前，知道如何编码可以说和说英语一样重要。你要么知道要么错过了很多。工作机会、书籍和文章、论文以及其他技术工作...在未来，智能房屋(domotics)的比例将会增加。技术软件技能可能和现在一样重要，比如知道如何修理水管或坏掉的灯。</p><p id="e348" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在无代码计划和人工智能的未来的交叉点上，我们有即时编程。GPT 3是最著名的使用提示的人工智能系统。OpenAI去年发布了API，人们很快就认识到了提示的独特性。这是不同的东西；既不是与人交谈，也不是正式意义上的编程。Gwern称之为的提示编程(Prompt programming)，可以理解为一种新的编程形式。它不像无代码那样肤浅，因为我们用自然语言与系统交流——我们给它编程。它不像用C或Python编程那样技术性很强。</p><p id="533f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3引起了研究人员和开发人员的注意，许多人被激励去发现它的缺点。一些人发现GPT 3号在应该成功的地方失败了。然而，格温证明他们错了。他认为我们应该像用英语编程一样接近GPT 3号。我们必须把它做好，不是每件事都顺利。他调整了提示，重复了测试，并成功地教会了GPT-3正确地完成任务。他说:</p><blockquote class="nj nk nl"><p id="f2de" class="li lj ni lk b ll lm kd ln lo lp kg lq nm ls lt lu nn lw lx ly no ma mb mc md im bi translated">"<em class="it">【提示】</em>是使用DL <em class="it">【深度学习】</em>模型的一种相当不同的方式，最好把它看作一种新的编程，其中提示现在是一个“程序”，它对GPT-3进行编程以做新的事情。"</p></blockquote><p id="dc85" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3激发了用英语编写系统程序的可能性。该系统可以理解我们的意图，并以一种它可以毫无疑问地解释它们的方式将它们翻译给计算机。</p><p id="26bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个月前，微软——去年与OpenAI合作的微软——发布了GitHub Copilot。该系统由GPT-3的后代Codex驱动，是一个强大的代码自动完成系统。微软看到了GPT-3在创建代码方面的潜力，以及它如何理解英语并将其转化为编写良好的功能性程序。除了其他功能之外，Copilot还可以阅读用英语描述某个功能的注释，对其进行解释，并记下该功能。</p><p id="4ad4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3和GitHub Copilot将无代码的承诺和即时编程的潜力结合到一个新时代，这将允许非技术人员进入编码世界。</p><p id="2e00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即时编程的主要优势以及它会成功的原因是，我们人类已经进化到用自然语言交流，而不是用正式语言。英语有一系列我们凭直觉知道的规则。在我们理解我们正在使用的规则之前，我们学习正确地说话。我们不会发明规则，然后遵守规则。我们发现我们已经遵循的规则。</p><p id="8bd8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">写Python或者C就不一样了。我们称它们为语言，但它们在很多方面与英语不同。计算机需要明确的、不可解释的命令来知道该做什么。编程语言有严格的语法规则，不能被破坏，否则程序不会运行。这没有捷径可走。在没有提示编程的情况下，如果你想与计算机交流，你必须学习它的语言。甚至像Python这样的高级语言也需要相当程度的技术专长，而大多数人都不具备。</p><p id="ce38" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即时编程是编码的未来:我们将能够用自然语言编写大多数东西。将会有中间系统来处理我们不精确的、细微的、充满上下文的思想和计算机需要工作的正式指令集之间的转换。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="df61" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">多模态——人类感知</h1><p id="38ad" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">直到最近，深度学习系统还被设计用来解决单峰问题。如果您想在机器翻译方面达到最先进的性能，您可以使用英语-西班牙语文本数据对来训练您的系统。如果你想战胜ImageNet挑战，你的系统必须在物体识别方面是最好的，除此之外别无其他。NLP系统和CV系统是截然不同且不可混合的。</p><p id="f1d8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，研究人员从神经科学中获得灵感，试图模拟我们的感知机制，专注于创建从不同类型的数据中学习的人工智能系统。与其按照专业领域来划分系统，为什么不让它们结合来自视觉和语言来源的数据呢？短信里有信息。图像中有信息。但是在两者的交汇处也有信息。这种多模态系统的新趋势就是谷歌和BAAI今年分别用MUM和Wu Dao 2.0 T5所做的。这是试图让人工系统类似人脑的一个进步。</p><p id="d516" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们已经进化成了一个多模态的世界。我们周围的事件和物体产生不同种类的信息:电磁的、机械的、化学的……例如，一个苹果有颜色、形状、质地、味道、气味……这就是为什么<strong class="lk jd">我们的大脑是多感官的</strong>。我们有一套感知系统，可以捕捉世界的多模态性质(其他生物有不同的感知系统，允许它们感知我们在生物学上不知道的模式)。更有趣的是，大脑将来自感知通道的信息整合到现实的单一表征中。</p><p id="e83d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这就是我们可以从给人工智能灌输这种能力中找到效用的地方。如果给一个模型一对文字图像可以让它更准确地表现世界，那么它的预测或行动就会更精确，也能更好地适应环境。这就是今天对<a class="ae lh" href="https://www.simplypsychology.org/intelligence.html" rel="noopener ugc nofollow" target="_blank">智力</a>的定义:“利用遗传能力和学到的知识理解和适应环境的能力。”</p><p id="303b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个拥有相当于眼睛、耳朵和手的人工器官以及作为大脑的GPT-3的机器人将比任何现有的人工智能都要强大得多。大脑是所有处理发生的地方，但处理的数据也很重要。未来的人工智能系统将拥有传感器、控制器和执行器，它们以一种快速、准确和丰富的信息处理方式相互连接。</p><p id="66ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">焦点仍然在以软件为中心的虚拟系统上，但是一些研究小组已经成功地集成了文本和图像数据。这些网络应该如何结合这两种类型的信息仍然是一个谜(人类也没有完全理解)，但目前这些尝试已经成功了。<a class="ae lh" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"> DALL E </a>，<a class="ae lh" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank"> CLIP </a>，<a class="ae lh" rel="noopener" target="_blank" href="/will-googles-mum-kill-seo-d283927f0fde"> MUM </a>，<a class="ae lh" href="https://arxiv.org/pdf/2104.00332.pdf" rel="noopener ugc nofollow" target="_blank"> UC </a>，<a class="ae lh" rel="noopener" target="_blank" href="/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484">武道2.0 </a>就是活生生的证明。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="b847" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">多任务处理和任务转移——人类的多样性</h1><p id="9fe4" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">监督和强化的人工智能系统是糟糕的多任务处理系统。即使是像AlphaZero这样被设计用来学习不同任务的系统，也必须为每个任务进行遗忘和重新学习。然而，自我监督系统在这方面更胜一筹。原因是他们接受的是任务不可知的训练。因为这些系统没有被明确告知从输入数据中学习什么，所以它们可以应用于不同的任务，而不需要改变参数。GPT 3号就是这种情况。</p><p id="1b44" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3最有力的特点之一是它能够用相同的砝码处理不同的任务。该系统不会在内部进行改变，以进行机器翻译、回答问题或生成<a class="ae lh" href="https://www.gwern.net/GPT-3" rel="noopener ugc nofollow" target="_blank">创意小说</a>。该系统是以无监督的方式从大多数互联网文本数据中训练出来的。但是它不知道如何运用它所学到的东西。在快速编程的帮助下，用户可以调节GPT-3来解决给定的任务。根据记录，GPT 3号在几项未经训练的任务中达到了最先进水平。这就是<strong class="lk jd">多任务处理和任务转移</strong>的威力。</p><p id="9ed8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">多任务系统可以将相同的输入应用于不同的任务。例如，如果我把“猫”这个词输入系统，我可以让它找到西班牙语翻译“gato”，我可以让它给我看一只猫的图像，或者我可以让它写一篇关于为什么猫如此怪异的文章。相同输入的不同任务。</p><p id="1fbe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种想法经常与<strong class="lk jd">的少投学习</strong>结合在一起。有监督的深度学习系统在预先选择的一组类上进行训练和测试。如果一个CV系统已经学会了对汽车、飞机和船只图像进行分类，它只会在这三个类别上测试时表现良好。在少量(或零次/一次)学习设置中，系统针对新的类进行测试，而没有权重更新。</p><p id="60fb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个例子是在测试时向系统显示一辆自行车的三幅图像，然后要求它正常地对汽车、飞机、轮船和自行车图像进行分类。这很简单，因为我们已经在测试时展示了3个自行车的例子。一个学会了如何学习的系统(如GPT-3)应该能够在这些极端情况下表现良好。GPT 3号证明了这是可能的。而且它的表现也没有被监督系统羡慕的地方。</p><p id="ceb1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们结合多任务和少镜头设置，我们可以建立一个系统，能够解决它没有训练过的任务。在这种情况下，我们不是在测试时向系统显示新的类，而是让它执行新的任务。在少数镜头设置的情况下，我们会展示几个任务是如何完成的例子。而且，在没有内部学习任何新东西的情况下，系统现在会被调整来解决新的任务。</p><p id="17e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，让我们以一个在巨大的文本语料库中训练的系统为例。在一次性任务转移设置中，我们可以写:“我爱你-&gt; Te quiero。我讨厌你-&gt; ___”我们通过向系统展示一个例子(一次性设置)，隐式地要求系统将一个句子从英语翻译成西班牙语(这是一项未经训练的任务)。</p><p id="5d63" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">想想看，我们人类是可以做到这一点的。我们是元学习者。我们不只是学会做任务，而是知道如何学会做新的任务。如果我看到有人在打扫房间，我会马上知道怎么做。我明白扫帚的运动必须方向一致才能清洁地板，我会努力协调手和脚，使过渡平稳。我们不仅仅在有人训练我们的时候学习。我们通过观察来学习。几杆任务转移就是这样。人工智能系统开始在这方面做得更好。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="a5fe" class="on mm it bd mn oo op dn mr oq or dp mv lr os ot mx lv ou ov mz lz ow ox nb iz bi translated">订阅我的免费每周简讯<a class="ae lh" href="https://mindsoftomorrow.ck.page/" rel="noopener ugc nofollow" target="_blank">明日之心</a>获取更多关于人工智能的内容、新闻、见解和思考！</h2><h2 id="5bbe" class="on mm it bd mn oo op dn mr oq or dp mv lr os ot mx lv ou ov mz lz ow ox nb iz bi translated">此外，欢迎在<a class="ae lh" href="https://www.linkedin.com/in/alberromgar/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae lh" href="https://twitter.com/Alber_RomGar" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上发表评论和联系！:)</h2></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="28c4" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">推荐阅读</h1><div class="oy oz gp gr pa pb"><a rel="noopener follow" target="_blank" href="/5-deep-learning-trends-leading-artificial-intelligence-to-the-next-stage-11f2ef60f97e"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd jd gy z fp pg fr fs ph fu fw jc bi translated">引领人工智能进入下一阶段的5个深度学习趋势</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">深度学习主导了人工智能，但它需要更新以保持其霸权，并推动该领域向前发展。</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">towardsdatascience.com</p></div></div><div class="pk l"><div class="pl l pm pn po pk pp lb pb"/></div></div></a></div><div class="oy oz gp gr pa pb"><a rel="noopener follow" target="_blank" href="/gpt-3-a-complete-overview-190232eb25fd"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd jd gy z fp pg fr fs ph fu fw jc bi translated">GPT-3 —全面概述</h2><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">towardsdatascience.com</p></div></div><div class="pk l"><div class="pq l pm pn po pk pp lb pb"/></div></div></a></div></div></div>    
</body>
</html>