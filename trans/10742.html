<html>
<head>
<title>Overcoming ImageNet dataset biases with PASS.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PASS克服ImageNet数据集偏差。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/overcoming-imagenet-dataset-biases-with-pass-6e54c66e77a?source=collection_archive---------16-----------------------#2021-10-16">https://towardsdatascience.com/overcoming-imagenet-dataset-biases-with-pass-6e54c66e77a?source=collection_archive---------16-----------------------#2021-10-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b5ab" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">PASS:ImageNet替代无人参与的自我监督预训练</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/be629abb58782cc65ee707af13e40cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TRtIoDmOKJBh23GXPuyEjQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者使用@Canva</p></figure><p id="6dfe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>是计算机视觉应用中使用最广泛的数据集之一。然而，研究表明，基于收集方法和图像类型的偏见在该数据集中普遍存在。在这方面，牛津大学视觉几何小组<a class="ae lu" href="https://www.robots.ox.ac.uk/~vgg/" rel="noopener ugc nofollow" target="_blank">的一组研究人员提出了一个名为PASS for self-supervised (SSL)模型预训练的新数据集，专门解决隐私和公平问题。本文是该团队发表的论文的摘要。</a></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="9b75" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">PASS:ImageNet替代无人参与的自我监督预训练</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/ea512a03285d1b2b3dc1b87b61047d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T5qO-Nf281zXoLBlKz5uig.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">arXiv上的及格论文|来源:<a class="ae lu" href="https://arxiv.org/pdf/2109.13228.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2109.13228.pdf</a></p></figure><h2 id="9da1" class="mv md it bd me mw mx dn mi my mz dp mm lh na nb mo ll nc nd mq lp ne nf ms ng bi translated">什么是通行证？</h2><p id="7b51" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">PASS代表<code class="fe nm nn no np b">Pictures without humans for Self-Supervision.</code>它是一个大规模的无标签图像数据集，旨在缓解围绕著名的Imagenet数据集的道德、法律和隐私问题。</p><h2 id="1120" class="mv md it bd me mw mx dn mi my mz dp mm lh na nb mo ll nc nd mq lp ne nf ms ng bi translated">ImageNet的问题</h2><p id="8e66" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">ImageNet当前的一些问题包括:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/ee300b05efbfe07bb26de00559158561.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*9h41elk5472_2pF_gPGCyA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ImageNet |作者图片的问题</p></figure><ul class=""><li id="4bae" class="nr ns it la b lb lc le lf lh nt ll nu lp nv lt nw nx ny nz bi translated"><strong class="la iu">数据保护</strong>:包含未经同意获取的个人信息</li><li id="5615" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated"><strong class="la iu">版权</strong>:许可使用不明</li><li id="637e" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated"><strong class="la iu">偏向</strong>—通过搜索引擎抓取收集数据集，</li><li id="2a6e" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated"><strong class="la iu">有问题的图像内容- </strong> <a class="ae lu" href="https://www.theregister.com/2019/10/23/ai_dataset_imagenet_consent/" rel="noopener ugc nofollow" target="_blank">刻板的、不恰当的特定类别的描绘。</a></li></ul><h2 id="8959" class="mv md it bd me mw mx dn mi my mz dp mm lh na nb mo ll nc nd mq lp ne nf ms ng bi translated">作为备选方案通过</h2><p id="b80b" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">作者指出:</p><blockquote class="of og oh"><p id="8f0c" class="ky kz oi la b lb lc ju ld le lf jx lg oj li lj lk ok lm ln lo ol lq lr ls lt im bi translated">当前最先进的模型预训练使用自我监督学习(SSL ),因此根本不需要标签。受此推动，我们因此考虑在不使用标签的情况下形成数据集，显著增加多样性并消除搜索引擎选择偏差。因为我们去除了带有人的图像，所以我们进一步显著降低了包含与人的外表相关的背景偏见的风险。此外，由于其更随机和无监督的性质，该数据集也可以作为SSL的更好的基准，以研究对没有预定义类别标签集的自然图像的缩放，从而解决当前评估的技术缺点。</p></blockquote><ul class=""><li id="8eb2" class="nr ns it la b lb lc le lf lh nt ll nu lp nv lt nw nx ny nz bi translated"><strong class="la iu">数据保护</strong>:PASS数据集不包含人体或身体部位</li><li id="03da" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated"><strong class="la iu">版权</strong> : PASS仅包含CC-BY授权图片，有完整的归属信息。</li><li id="57ef" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated"><strong class="la iu">偏差</strong> —数据集不包含标签，从而减轻了搜索引擎的偏差。</li><li id="5114" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated"><strong class="la iu">有问题的图像内容-没有</strong>个人身份信息，如车牌、签名或笔迹和NSFW(不适合工作)图像。</li></ul><h2 id="839a" class="mv md it bd me mw mx dn mi my mz dp mm lh na nb mo ll nc nd mq lp ne nf ms ng bi translated">收集方法</h2><p id="d0a1" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">作者从一个名为<a class="ae lu" href="http://webscope.sandbox.yahoo.com/catalog.php?datatype=i&amp;did=67" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> <em class="oi">雅虎Flickr知识共享1亿张</em> (YFCC100m) </strong> </a> <strong class="la iu">的随机Flickr图片数据集开始。</strong>接下来，只过滤具有有效<strong class="la iu"> </strong> CC-BY授权图像的图像，总共1700万。从这里，包含人类的有问题的图像被移除，剩下的净图像总数为1000万。由于每个摄影师的图像分布是高度倾斜的，每个摄影师的图像贡献是平衡的，最后，这些图像被提交给人类标记。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/019685a730b609381cfd701051c6820e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nCZgune_BjSL8LiROqE2Pg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集生成管道|来源:<a class="ae lu" href="https://arxiv.org/pdf/2109.13228.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2109.13228.pdf</a></p></figure><p id="94ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">提交人还提到，注释是由一家注释公司历时三周完成的，该公司支付注释者150%的最低工资。</p><h2 id="26cd" class="mv md it bd me mw mx dn mi my mz dp mm lh na nb mo ll nc nd mq lp ne nf ms ng bi translated">结果</h2><p id="e249" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">作者在论文中提交的结果如下:</p><p id="617f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(I)诸如MoCo、SwAV和DINO的自监督方法在PASS数据集上训练良好，产生强有力的图像表示</p><p id="84c0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(ii)在预训练期间排除人类图像对下游任务表现几乎没有影响，即使这是在ImageNet中进行的；</p><p id="eb7f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(iii)在PASS上训练的模型的性能产生比在ImageNet上预训练更好的结果(包括没有人或者甚至没有<a class="ae lu" href="http://places.csail.mit.edu/downloadData.html" rel="noopener ugc nofollow" target="_blank"> Places 205数据集</a>的ImageNet)，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3b3835184448136abfb0299ea196b1f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*kgVyJyo_xukOZnIpEKG-xg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">冻结编码器评估|来源:<a class="ae lu" href="https://arxiv.org/pdf/2109.13228.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2109.13228.pdf</a></p></figure><p id="0900" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(iv)对于微调评估，例如检测和分割，通过预训练在COCO数据集上产生1% mAP和AP50内的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/b8cc799825653e7c2a67848d897b5c5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*dqGuBwgoDRxFWNxZ_ancIw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">微调代表性评估|来源:<a class="ae lu" href="https://arxiv.org/pdf/2109.13228.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2109.13228.pdf</a></p></figure><p id="a42a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(v)即使在涉及人类的任务上，如密集姿势预测，在我们的数据集上进行预训练也能产生与ImageNet相当的性能，即使PASS没有人类图像</p><h2 id="a789" class="mv md it bd me mw mx dn mi my mz dp mm lh na nb mo ll nc nd mq lp ne nf ms ng bi translated">这对Imagenet意味着什么？</h2><p id="2487" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">作者强调，PASS不会使现有数据集过时，因为它不足以进行基准测试。然而，PASS背后的想法是展示在使用更安全的数据时，模型预训练通常是可能的，并且它还为预训练方法的更稳健的评估提供了基础。</p><h2 id="c462" class="mv md it bd me mw mx dn mi my mz dp mm lh na nb mo ll nc nd mq lp ne nf ms ng bi translated">PASS是无偏差的吗？</h2><p id="b626" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">尽管PASS显著降低了数据主体的数据保护和其他道德风险，但正如作者自己指出的那样，一些问题仍然普遍存在:</p><ul class=""><li id="f9d8" class="nr ns it la b lb lc le lf lh nt ll nu lp nv lt nw nx ny nz bi translated">即使在过滤图像时非常小心，有害图像仍有可能漏网。</li><li id="b3d6" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated">由于图像是随机采样的，地理偏见的问题依然存在。</li><li id="5df3" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated">由于缺少人体图像，PASS不能用于学习人体模型，例如用于姿势识别。</li><li id="d989" class="nr ns it la b lb oa le ob lh oc ll od lp oe lt nw nx ny nz bi translated">PASS(与ImageNet相反)不能单独用于培训和基准测试，因为PASS不包含标签</li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="d40a" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="3355" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">PASS有其局限性，但仍然是研究界朝着降低许多任务和应用的道德和法律风险迈出的令人鼓舞的一步。ImageNet数据集无疑开创了最先进的计算机视觉应用的时代，但作为一个社区，我们不能忽视数据集中的缺点。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="bd0d" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">参考</h1><p id="89ad" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated"><strong class="la iu">论文<em class="oi">:</em></strong><a class="ae lu" href="https://arxiv.org/pdf/2109.13228.pdf" rel="noopener ugc nofollow" target="_blank"><em class="oi">PASS:ImageNet替代无人自监督预训练</em> </a></p><p id="c6aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">作者</strong> : <a class="ae lu" href="https://yukimasano.github.io/" rel="noopener ugc nofollow" target="_blank"> <em class="oi"> YM。</em> </a> <em class="oi">，</em> <a class="ae lu" href="https://chrirupp.github.io/" rel="noopener ugc nofollow" target="_blank"> <em class="oi"> C .鲁普雷希特</em> </a> <em class="oi">，</em> <a class="ae lu" href="http://www.robots.ox.ac.uk/~az/" rel="noopener ugc nofollow" target="_blank"> <em class="oi"> A .齐塞曼</em> </a> <em class="oi">，</em> <a class="ae lu" href="http://www.robots.ox.ac.uk/~vedaldi/" rel="noopener ugc nofollow" target="_blank"> <em class="oi"> A .韦达尔迪</em> </a></p></div></div>    
</body>
</html>