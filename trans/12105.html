<html>
<head>
<title>Zero-Shot Sentiment Classification of Latin (with the Help of Its Descendants)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">拉丁语的零距离情感分类(借助其后代)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sentiments-of-rome-80eb617b5980?source=collection_archive---------42-----------------------#2021-12-06">https://towardsdatascience.com/sentiments-of-rome-80eb617b5980?source=collection_archive---------42-----------------------#2021-12-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="33e4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种用于死(和/或低资源)语言的NLP方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2f68f77113b3e83cf62c9050cded6612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bSRgPaNlACcP-cDC"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kv" href="https://unsplash.com/@lalasza?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> L A L A S Z A </a>拍摄的照片</p></figure><h1 id="fd73" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="10c1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://www.britannica.com/topic/Latin-language" rel="noopener ugc nofollow" target="_blank">拉丁语</a>可以被认为是“旧世界的英语”。我把它与英语进行了比较，以强调这样一个事实，就像英语是当今世界上最流行的语言一样，拉丁语在古代西方世界占据主导地位。这不仅仅是因为受欢迎，而是因为罗马扩张的影响，尤其是在西欧和地中海地区。然而，拉丁语直接塑造了许多现代语言(<a class="ae kv" href="https://en.wikipedia.org/wiki/Romance_languages" rel="noopener ugc nofollow" target="_blank">罗曼语</a>)，也对其他语言产生了一些影响(比如英语)。我想看看拉丁语在现代自然语言处理(NLP)环境中是如何工作的(使用基于transformer的预训练模型)，我在这篇短文中提到了这一点。</p><p id="f4fe" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">古典拉丁语现在被认为是一种死亡的语言，这使得它在NLP领域也是一种低资源语言。拉丁语的近亲被认为是撒丁语和意大利语。然而，它们大多是从“<a class="ae kv" href="https://en.wikipedia.org/wiki/Vulgar_Latin" rel="noopener ugc nofollow" target="_blank">粗俗拉丁语</a>”演变而来，这是一种在平民中流行的非文学拉丁语。我假设涉及拉丁语的NLP任务(情感分类任务)将由这些语言中的一种来帮助，尽管预训练模型在其预训练或微调阶段没有见过拉丁语。这也被称为零起点学习，我们可以将相关语言的知识转移到拉丁语中，而无需在拉丁语语料库中进行微调。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="1389" class="kw kx iq bd ky kz mw lb lc ld mx lf lg jw my jx li jz mz ka lk kc na kd lm ln bi translated"><strong class="ak">方法</strong></h1><p id="f321" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">作为一种资源匮乏的语言，要获得一个庞大的带注释的拉丁语语料库并不容易。我在互联网上使用了一个可访问的<a class="ae kv" href="https://github.com/CIRCSE/Latin_Sentiment_Analysis/blob/main/data/GoldStandardv1-Horace.tsv" rel="noopener ugc nofollow" target="_blank">数据集</a>【4】【5】，它由45个拉丁句子组成，分为3个情感类别(积极、消极、中性、混合)，并从<a class="ae kv" href="https://en.wikipedia.org/wiki/Odes_(Horace)" rel="noopener ugc nofollow" target="_blank">贺拉斯的颂歌</a>中提取(数据集的创建者有一篇即将发表的论文使用了相同的数据集，请检查参考文献)。为了简单起见，我去掉了混合句和中性句。我使用了基于transformer的微调单语模型(用于情感分类)，可用于<a class="ae kv" href="https://huggingface.co/MilaNLProc/feel-it-italian-sentiment" rel="noopener ugc nofollow" target="_blank">意大利语</a> (Bert)、<a class="ae kv" href="https://huggingface.co/siebert/sentiment-roberta-large-english" rel="noopener ugc nofollow" target="_blank">英语</a> (Roberta)、<a class="ae kv" href="https://huggingface.co/finiteautomata/beto-sentiment-analysis" rel="noopener ugc nofollow" target="_blank">西班牙语</a> (Bert)、<a class="ae kv" href="https://huggingface.co/oliverguhr/german-sentiment-bert" rel="noopener ugc nofollow" target="_blank">德语</a> (Bert)、以及<a class="ae kv" href="https://huggingface.co/w11wo/indonesian-roberta-base-indolem-sentiment-classifier-fold-3" rel="noopener ugc nofollow" target="_blank">印尼语</a> (Roberta)上的<a class="ae kv" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> Huggingface </a>。撒丁语也是一种资源匮乏的语言(或者至少网上没有足够的资源)，因此它被抛弃了。拉丁语数据集由如下句子组成，</p><blockquote class="nb nc nd"><p id="55b7" class="lo lp ne lq b lr mk jr lt lu ml ju lw nf mm lz ma ng mn md me nh mo mh mi mj ij bi translated">“这是一个很好的例子”——否定的<br/>“非自我的酒神是我的朋友”——肯定的</p></blockquote><p id="4d40" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于Huggingface模型，剩下的工作很容易，每个模型都遵循通常的步骤(在Huggingface中也提到过)。结果是通过将标记化的拉丁句子直接输入到微调模型中获得的。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="c46a" class="nn kx iq nj b gy no np l nq nr">import torch<br/>import numpy as np<br/>from transformers import AutoTokenizer, AutoModelForSequenceClassification<br/>import pandas</span><span id="bfbb" class="nn kx iq nj b gy ns np l nq nr">#Read the corpus</span><span id="d8b1" class="nn kx iq nj b gy ns np l nq nr">lat=pandas.read_csv('latin.tsv',sep='\t')</span><span id="3237" class="nn kx iq nj b gy ns np l nq nr">lat=lat[lat['Value']!='mixed']<br/>lat=lat[lat['Value']!='neutral']</span><span id="0aab" class="nn kx iq nj b gy ns np l nq nr">sentences=lat.loc[:,'Text']</span><span id="3d6f" class="nn kx iq nj b gy ns np l nq nr">labels=lat.loc[:,'Value']<br/>true_val=map(lambda x:1 if x=='positive' else 0,labels)</span><span id="a68e" class="nn kx iq nj b gy ns np l nq nr"># Load model and tokenizer</span><span id="f92f" class="nn kx iq nj b gy ns np l nq nr">tokenizer = AutoTokenizer.from_pretrained(“MilaNLProc/feel-it-italian-sentiment”)</span><span id="2d52" class="nn kx iq nj b gy ns np l nq nr">model = utoModelForSequenceClassification.from_pretrained(“MilaNLProc/feel-it-italian-sentiment”)</span><span id="458e" class="nn kx iq nj b gy ns np l nq nr">#tokenize the sentences</span><span id="b789" class="nn kx iq nj b gy ns np l nq nr">inputs = tokenizer(list(sentences),padding=True, return_tensors="pt")</span><span id="ff4d" class="nn kx iq nj b gy ns np l nq nr">#first 4 lines can slightly change with the model, e.g.- for spanish model, outputs = model(**inputs),logits = outputs.logits</span><span id="33fe" class="nn kx iq nj b gy ns np l nq nr">proba = torch.nn.functional.softmax(logits, dim=0)</span><span id="d848" class="nn kx iq nj b gy ns np l nq nr">labels = torch.tensor([0]*len(list(sentences)).unsqueeze(0)<br/>outputs = model(**inputs, labels=labels)<br/>loss, logits = outputs[:2]<br/>logits = logits.squeeze(0)</span><span id="5e72" class="nn kx iq nj b gy ns np l nq nr">prob = torch.nn.functional.softmax(logits, dim=0)</span><span id="752b" class="nn kx iq nj b gy ns np l nq nr">result=[]</span><span id="9aff" class="nn kx iq nj b gy ns np l nq nr">for i in prob:<br/>result.append(list(i.detach().numpy()).index(np.max(i.detach().numpy       ())))</span><span id="fcf1" class="nn kx iq nj b gy ns np l nq nr">from sklearn.metrics import accuracy_score<br/>accuracy_score(list(true_val),result)</span><span id="55e3" class="nn kx iq nj b gy ns np l nq nr">#for some models, their output further needs to be processed in order to have numerical value</span><span id="5cbe" class="nn kx iq nj b gy ns np l nq nr">result=[]</span><span id="3a6b" class="nn kx iq nj b gy ns np l nq nr">for i in sentences:<br/>     result.append(1 if sentiment_analysis(i)[0]['label']=='POSITIVE' else 0)</span></pre><p id="d1cc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于包括任务流水线的模型，</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="867c" class="nn kx iq nj b gy no np l nq nr">from transformers import pipeline</span><span id="ab6e" class="nn kx iq nj b gy ns np l nq nr">#Here the pytorch models are not created explicitly like in the previous snippet. Yet, the models gives an output similar to previous</span><span id="d655" class="nn kx iq nj b gy ns np l nq nr">sentiment_analysis = pipeline(“sentiment-analysis”,model=”siebert/sentiment-roberta-large-english”)</span><span id="63f8" class="nn kx iq nj b gy ns np l nq nr">result=[]</span><span id="95c8" class="nn kx iq nj b gy ns np l nq nr">for i in sentences:<br/>     result.append(1 if sentiment_analysis(i)[0]['label']=='POSITIVE' else 0)</span><span id="c735" class="nn kx iq nj b gy ns np l nq nr">accuracy_score(list(true_val),result)</span></pre><h1 id="8a28" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结果</h1><p id="4048" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Genetic_relationship_(linguistics)" rel="noopener ugc nofollow" target="_blank">遗传相似度</a>是语言学中用来衡量一对语言之间的相似性或关联性的一种尺度。它的值越高，这一对语言之间的距离就越大！。我使用了一个<a class="ae kv" href="http://www.elinguistics.net/Compare_Languages.aspx" rel="noopener ugc nofollow" target="_blank">在线工具</a>来测量拉丁语和上面提到的其他语言之间的相似性。它显示了如下关系。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/ff4718d5df06f88cf6a09796a2c7c293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtqJM2ICiqMb6r21vlFBZg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者</p></figure><p id="4e86" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">像意大利语和西班牙语这样的罗曼语最接近拉丁语，而像英语和德语这样的日耳曼语则稍远一些。印尼语和拉丁语没有关系，但是印尼语在其拼写中采用了拉丁语。让我们来看看所选语言的每个模型如何执行零镜头分类。对于具有3个类别输出(德语)的模型，将少数中性/混合预测分别改为阴性和阳性，并考虑其中的最高准确度得分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/b2610f64fbcd863f0660a3bac723f636.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XpJCW9ZGK9g_ipQEN5s-2w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者</p></figure><p id="b1a1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">令人惊讶的是，语言之间的关系模式在这里没有出现。每个实例(除了印度尼西亚语)的准确度都大于0.5，西班牙语显示了罗曼语的最高准确度分数。英语表现的最好，同时也是最接近拉丁语的语言；意大利语在后面。尽管一种语言与拉丁语相差甚远，但这并不总是意味着性能下降。</p><p id="3a5d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这种结果的一个可能原因是模型的能力(这取决于模型中的参数数量、预训练目标和用于预训练模型的语料库)。另一个主要原因是每个语言模型中使用的预训练/微调数据集的大小。意大利模型[1]使用由2k条推文组成的情感数据集进行了微调，而英国模型[2]也在属于不同领域的多个数据集(推文、评论等)上进行了微调。).西班牙模型[3]利用了大约5k的tweets进行微调。</p><p id="cbd9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">有人可能会认为，无论源语言是什么，用于模型的训练语料库的质量/规模都会直接影响其零炮性能。此外，该模型可能能够学习句子情感的底层表示，而不管语言如何，并且所学习的知识可以在目标语言的零射击任务期间使用。你怎么想呢?在评论里提！！！这不是一套广泛/完整的实验和分析，因此无法对导致这一结果的因素做出明确的结论。甚至其他可用的和未经测试的模型也可能揭示一个新的结果。然而，据观察，语言相关度并不是唯一决定拉丁语情感分类零命中率的因素。我相信这是一个有趣的研究领域。</p><p id="61fd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">感谢您的阅读！</p><h1 id="488e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><p id="65c4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1]——“感受:意大利语的情感和情绪分类，比安奇等人”，<a class="ae kv" href="https://aclanthology.org/2021.wassa-1.8/" rel="noopener ugc nofollow" target="_blank">https://aclanthology.org/2021.wassa-1.8/</a></p><p id="f5d6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[2]——“不止是一种感觉:情感分析准确性的基准，<a class="ae kv" href="https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1911466" rel="noopener ugc nofollow" target="_blank">海特曼</a>等，【https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3489963】T4</p><p id="ef0c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[3]—<a class="ae kv" href="https://github.com/finiteautomata/pysentimiento/" rel="noopener ugc nofollow" target="_blank">https://github.com/finiteautomata/pysentimiento/</a></p><p id="82fd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[4]——<a class="ae kv" href="https://github.com/CIRCSE/Latin_Sentiment_Analysis" rel="noopener ugc nofollow" target="_blank">https://github.com/CIRCSE/Latin_Sentiment_Analysis</a></p><p id="502b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[5]——“拉丁诗歌的情感分析:贺拉斯颂歌的第一次实验。，曼布里尼等人，“CLiC-it，202，<a class="ae kv" href="https://clic2021.disco.unimib.it/" rel="noopener ugc nofollow" target="_blank">https://clic2021.disco.unimib.it/</a></p></div></div>    
</body>
</html>