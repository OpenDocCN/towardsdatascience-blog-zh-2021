<html>
<head>
<title>An Intro to Machine Learning for Biomedical Scientists— part II: Hands-on Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生物医学科学家机器学习导论——第二部分:实践教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/storytelling-machine-learning-intro-part-ii-hands-on-coding-tutorial-b3fc9dc8ae07?source=collection_archive---------25-----------------------#2021-09-30">https://towardsdatascience.com/storytelling-machine-learning-intro-part-ii-hands-on-coding-tutorial-b3fc9dc8ae07?source=collection_archive---------25-----------------------#2021-09-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="10df" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">生物医学科学家的ML介绍:动手编码教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a6815034a0131845b5b0ebdc05fa5501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1_wOxFCt0hTuQUn35rpyXQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自<a class="ae kv" href="https://unsplash.com/photos/rnr8D3FNUNY" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="8e68" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是帖子<a class="ae kv" rel="noopener" target="_blank" href="/storytelling-machine-learning-intro-d46e339cb6de">的第二部分，介绍生物医学科学家的机器学习</a>，它为生物医学科学家介绍了机器学习(ML)的概念。在本帖中，我们将获得使用生物医学数据的实践编码教程。</p><p id="b187" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在谷歌实验室<a class="ae kv" href="https://colab.research.google.com/drive/1u30tFot_JROnrdZYB-yIhZQBcETefZAW?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>轻松运行这个教程</p><p id="94be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将建立一个模型来预测乳腺肿块患者的诊断。我们将使用的<a class="ae kv" href="https://goo.gl/U2Uwz2" rel="noopener ugc nofollow" target="_blank">数据集</a>是由美国威斯康辛州麦迪逊市威斯康辛大学医院的医生威廉·h·沃尔伯格博士创建的。为了创建数据集，沃尔伯格博士使用了取自乳腺实性肿块患者的液体样本，并使用图形计算机软件来计算样本中细胞的特征。数据集包含30个像元特征，其中包括:</p><ul class=""><li id="871a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">半径(从中心到周边各点的平均距离)</li><li id="b2cc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">纹理(灰度值的标准偏差)</li><li id="182b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">周长</li><li id="1dc9" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">区域</li><li id="3122" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">平滑度(半径长度的局部变化)</li><li id="d344" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">紧凑性(周长/面积— 1.0)</li><li id="169e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">凹度(轮廓凹陷部分的严重程度)</li><li id="160e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">凹点(轮廓凹陷部分的数量)</li><li id="077a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">对称</li><li id="dde3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">分形维数(“海岸线近似值”-1)</li></ul><p id="5131" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">首先，让我们加载所有的包和数据集:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="4f1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mi"><img src="../Images/541d31f99b04aa776455628c59b3b76d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nzJbm0PTPGOIzrbiiTHyUA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">[图片由作者提供]</p></figure><p id="402c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如我们所见，该数据集包含569名患者，其中212名为恶性乳腺肿块，357名为良性乳腺肿块。诊断(恶性/良性)编码在<em class="mj">目标</em>中，作为二进制指示器(即0代表恶性诊断，1代表良性诊断)。</p><p id="ccc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">现在让我们想象几个特征:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="e47e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/46d4141c7bd2391d256b3a2b2ada7e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fY8_LpJSLRSmXG_yRJe2tQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">[图片由作者提供]</p></figure><p id="f2d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在这里可以看到的一件事是，具有恶性诊断的患者倾向于具有较高凹度值(y轴)的乳房肿块，而具有较低平滑度值(例如，低于0.08；x轴)倾向于良性诊断。看到这种情况，我们可能会想，‘嗯，我们可以探索所有的特征，并创建<em class="mj">边界</em>来对患者进行分类，对吗？".当然，我们有可能遍历所有的特征，并找到<em class="mj">边界</em>来分离这些组。但是如果我们有100个或者1000个特征呢？即使只有30个特征，这个过程也是棘手和耗时的。相反，让我们转向ML来为我们做这件事。我们将使用一个决策树分类器，它会自动执行这个过程。</p><p id="2185" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">首先，我们将数据分成训练集和测试集:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="111d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/3edc4f60d3f9ee478e15647ae9384c4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1kasTrnTP_wI1m01DCkkmg.png"/></div></div></figure><p id="c0a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在训练集中有426名患者，在测试集中有143名患者。</p><p id="34e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">现在，我们实例化该模型，并使用三重交叉验证对其进行训练:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="f503" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">和我们在测试集中的表现:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="39f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mm"><img src="../Images/77737723a20c36c71b113282f97fe6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rRUz3qkpI2_1-ES8qcpV-Q.png"/></div></div></figure><p id="67fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，测试集中93.57%的患者被正确诊断</p><p id="e024" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">我们可以看到为诊断患者而创建的树:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="0dde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mn"><img src="../Images/367199c42636a3ba30106054ac783f97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NZ0oruDMjQKquU_LowU7QQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">[图片由作者提供]</p></figure><p id="946e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在每一层上，该算法找到将患者分类成不同组的界限。在这种情况下，它从特征<em class="mj">开始表示凹点。</em>如果患者的<em class="mj">平均凹点</em> ≤ 0.049，则沿左侧路径，进入<em class="mj">良性</em>组，而<em class="mj">平均凹点&gt; </em> 0.049的患者则相反。在下一个级别，对每个组重复这个过程。这一过程被优化以最小化<em class="mj">基尼系数</em>。基尼系数是一个量化群体纯度的指标。大于零的基尼系数意味着包含在该节点内的样本属于不同的类别。基尼系数为零意味着该组是纯的，在该组中只存在一类样本。通过探索生成的决策树，我们能够解释算法做出的决策。</p><p id="ed10" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了这个，我们就完事了！</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><p id="4643" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">欢迎在评论区提出任何问题</strong></p></div></div>    
</body>
</html>