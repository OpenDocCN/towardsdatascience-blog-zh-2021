<html>
<head>
<title>How to Mitigate Overfitting with Dimensionality Reduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过降维来减轻过度拟合</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-mitigate-overfitting-with-dimensionality-reduction-555b755b3d66?source=collection_archive---------22-----------------------#2021-09-27">https://towardsdatascience.com/how-to-mitigate-overfitting-with-dimensionality-reduction-555b755b3d66?source=collection_archive---------22-----------------------#2021-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="69c4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">解决过度拟合问题</h2><div class=""/><div class=""><h2 id="e339" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">解决过度拟合问题—第3部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/1dd2496774ebdc236616773b69cdfabb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WPFZY84nNx1iP1dGQPXi1Q.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Rene b hmer在<a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="94b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">到目前为止，我们已经完成了<strong class="lk jd"/>文章系列的<a class="ae lh" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-k-fold-cross-validation-518947ed7428">第1部分</a>和<a class="ae lh" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-regularization-befcf4e41865">第2部分</a>。你已经知道有很多方法可以解决过度拟合的问题。<strong class="lk jd">交叉验证</strong>和<strong class="lk jd">正则化</strong>是我们已经讨论过的两种众所周知的技术。<strong class="lk jd">降维</strong><strong class="lk jd">【DR】</strong>是另一种可以用来减轻机器学习模型中过拟合的有用技术。请记住，除了减轻过度拟合，DR还有许多其他用例。</p><p id="74ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当解决过度拟合时，DR处理模型复杂性。当数据中有许多要素时，模型会变得更加复杂。复杂的模型往往会过度拟合数据。DR通过减少数据中特征(维度)的数量来处理模型的复杂性。有两种方法可以减少数据的维数:</p><ul class=""><li id="4117" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">查找包含不同于原始数据集中的值的一组新要素。应用变换。这就是我们今天讨论的方法。</li><li id="5e3d" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">保留数据集中最重要的要素，移除冗余(不必要)的要素。数据集中的原始值保持不变，并且不应用任何变换。这种方法被称为<strong class="lk jd">特征选择</strong>，是一种DR。这将在本系列的<a class="ae lh" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-feature-selection-164897c0c3db">第5部分</a>中讨论。</li></ul><p id="5cf8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">降维的技术非常多。在这里，我们使用<strong class="lk jd">主成分分析(PCA) </strong>来寻找一组包含不同值的新特征，同时尽可能多地保留原始数据集中的变化。</p><p id="a153" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">注:</strong>如果你想详细研究各种DR方法(尤其是PCA)及其对Python的诅咒，点击下图可以看到我之前的内容列表:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/dimensionality-reduction-146045a5acb5"><div class="gh gi ms"><img src="../Images/6f4389bd6afabdd31f6a153960f4f359.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*RvPR_hE2ypre6Kn-WT5zdg.png"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">(作者截图)</p></figure><h1 id="b768" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">不应用主成分分析建立模型</h1><p id="a154" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">首先，我们在“<a class="ae lh" href="https://drive.google.com/file/d/19s5qMRjssBoohFb2NY4FFYQ3YW2eCxP4/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">心脏病</strong> </a>”数据集上建立逻辑回归模型，并查看输出。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">不应用主成分分析的逻辑回归模型</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/bf7603b61a6974719cc3c8f6354ebb0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*ga4JKBG-WD7HyN0qvxF2Ww.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="4549" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看我们可以做些什么来进一步提高模型的性能。</p><h1 id="8805" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">应用主成分分析后建立模型</h1><p id="af7e" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">现在，我们在相同的数据集上构建相同的模型，但是在应用PCA之后。原始数据集中有13个特征(用<strong class="lk jd"> X </strong>表示)。PCA将它们转换成一组新的9个变量。所有这些捕获了数据中总可变性的85.03%。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">应用主成分分析后的逻辑回归模型</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/3ab57203e45b8b3d2e133b2358911b1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*3J3J4MVJicWtTgdZcE1Y-w.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="d09c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">模型的精度提高了3%。因此，我们通过应用主成分分析进一步改进了模型。</p><h1 id="ee39" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">见解和结论</h1><p id="2fc2" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">当我们应用PCA时，我们丢失了原始数据中的一些可变性。这取决于我们在<strong class="lk jd"> n_components </strong>中指定的特性数量。在我们的例子中，我们丢失了原始数据中大约15%的可变性。我们损失的可变性越低，结果就越好。然而，主成分分析仍然能够提高模型的性能。这是因为PCA去除了数据中的噪声，只保留了数据集中最重要的特征。这将减轻数据的过度拟合，并提高模型的性能。我们得到一个简单而精确的模型。</p><p id="69ce" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">更新(2021–10–01):</strong>第4部分现已推出！<br/> [ <a class="ae lh" href="https://rukshanpramoditha.medium.com/how-to-mitigate-overfitting-by-creating-ensembles-77e9299b9ad0" rel="noopener">如何通过创建集合来减轻过度拟合</a></p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><p id="33a0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天的帖子到此结束。我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><p id="17b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">报名链接:</strong><a class="ae lh" href="https://rukshanpramoditha.medium.com/membership" rel="noopener">https://rukshanpramoditha.medium.com/membership</a></p><p id="a514" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢你一直以来的支持！下一个故事再见。祝大家学习愉快！</p><p id="5d0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别要感谢Unsplash上的<strong class="lk jd">Rene b hmer</strong>，<strong class="lk jd"> </strong>他为我提供了这篇文章的漂亮封面图片(我对图片做了一些修改:在上面添加了一些文字并删除了一些部分)。</p><p id="d7fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ob oc ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----555b755b3d66--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lk jd">2021–09–27</strong></p></div></div>    
</body>
</html>