<html>
<head>
<title>Multi-Label Classification in fast.ai Using Spreadsheets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用电子表格在fast.ai中进行多标签分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-label-classification-in-fastai-using-spreadsheets-25ae570c8ff9?source=collection_archive---------17-----------------------#2021-08-22">https://towardsdatascience.com/multi-label-classification-in-fastai-using-spreadsheets-25ae570c8ff9?source=collection_archive---------17-----------------------#2021-08-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8a3e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">识别单个图像中的多个实体</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/b81d4730362d0c40da48eb2a00d28475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fDJVMiC3mImjsokm"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><a class="ae kw" href="https://unsplash.com/@flipboo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Philippe Bout </a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片(人/椅子/桌子)</p></figure><h1 id="a598" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated">目录</h1><ol class=""><li id="70eb" class="lp lq iq lr b ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><a class="ae kw" href="#98d5" rel="noopener ugc nofollow">简介</a></li><li id="07a0" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated"><a class="ae kw" href="#d26f" rel="noopener ugc nofollow">数据集</a></li><li id="b3b7" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated"><a class="ae kw" href="#2537" rel="noopener ugc nofollow">型号、激活功能和损耗</a></li><li id="b2b1" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated"><a class="ae kw" href="#6315" rel="noopener ugc nofollow">模型评估</a></li><li id="cc5d" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated"><a class="ae kw" href="#ed1d" rel="noopener ugc nofollow">结论</a></li><li id="94f3" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated"><a class="ae kw" href="#e4d8" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="98d5" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated">介绍</h1><p id="b50b" class="pw-post-body-paragraph mm mn iq lr b ls lt jr mo lu lv ju mp lw mq mr ms ly mt mu mv ma mw mx my mc ij bi translated">很多时候，我们会遇到这样的图像，其中包含我们想要识别的多个感兴趣的对象。例如，在下图中，我们可以看到我们有一把椅子和一台电视显示器。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/cb5f6a0f91b33c178a27930ec00daf3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/0*-X_aDwsGxf0MxAWx.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="6dae" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">为了解决上述问题，我们需要能够检测给定图像中的多个类别/标签。这就是多标签分类。给定一幅图像，将其分为多个类别/标签/种类。</p><p id="7926" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">由于<code class="fe nf ng nh ni b">fastai</code>是围绕<code class="fe nf ng nh ni b">Pytorch</code>的一个非常方便的包装器，从代码的角度来看，我们需要做的改变很少，但是解决这个问题背后的逻辑会有些不同。我们不能仅仅使用我们常规的<code class="fe nf ng nh ni b">softmax</code>激活和<code class="fe nf ng nh ni b">cross-entropy loss</code>功能；此外，这里的评估位比单标签分类问题要复杂得多。我们将在下面的章节中详细讨论每一点。让我们首先从数据集开始。</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="d26f" class="kx ky iq bd kz la nq lc ld le nr lg lh jw ns jx lj jz nt ka ll kc nu kd ln lo bi translated">资料组</h1><p id="987d" class="pw-post-body-paragraph mm mn iq lr b ls lt jr mo lu lv ju mp lw mq mr ms ly mt mu mv ma mw mx my mc ij bi translated">我们将在这个任务中使用<code class="fe nf ng nh ni b">PASCAL_2007</code>数据集。这是一个总共包含20个标签的数据集，注意一个图像可以有多个标签！</p><p id="c6f2" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">只需使用fastai的<code class="fe nf ng nh ni b">untar_data</code>将数据集下载到您的磁盘。它将存储在您的主目录/根目录下一个名为<code class="fe nf ng nh ni b">.fastai</code>的特殊目录中</p><pre class="kh ki kj kk gt nv ni nw nx aw ny bi"><span id="fac9" class="nz ky iq ni b gy oa ob l oc od">from fastai.vision.all import *<br/>path = untar_data(URLs.PASCAL_2007)</span></pre><p id="c2a1" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">如果我们从训练数据集的标签视点查看统计信息，我们将获得以下内容。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oe"><img src="../Images/ae85d8559ed9c1ea5e24f7eb2ec53de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HjKD1oYBlDxH7CCh.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="ef35" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">从上图中我们可以看到,“人”是训练数据集中出现频率很高的类别，其他类别也或多或少地出现了。因此，我们的数据集中存在不平衡。</p><p id="e9a1" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">另一个值得注意的有趣的事情是<strong class="lr ir">标签计数的总和与数据点的数量</strong>不同。在单标签中，这曾经是正确的，因为每个图像有一个且只有一个标签，但是在多标签分类器的情况下，由于每个数据点不一定只有一个对象，值得注意的是标签可以多于图像的数量。这将导致我们改变构建分类器的策略，而不是单一标签分类。</p><p id="1e27" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">在这个数据集中，我们以数据帧的形式给出标签，而不是像Imagenet那样以文件夹结构给出。因此，我们必须从数据帧中读取每个条目，并定义getter方法来检索输入和输出的值。此外，使用数据帧中名为<code class="fe nf ng nh ni b">is_valid</code>的列来定义分割。我们将定义一个自定义函数，为数据集中的所有点分别提供分割，即训练和验证集的索引。</p><p id="66d7" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">在代码中，如下所示</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="2d67" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">现在，我们可以定义一个数据加载器，一旦我们有了三个主要任务的合适的getters，即获取因变量和自变量，以及如何将它们分成训练和验证文件。与单标签分类任务不同，对于这个任务，我们将不得不使用<code class="fe nf ng nh ni b">MultiCategoryBlock</code>来读取我们的因变量作为一个热码编码向量。其余的负载保持不变。我们可以如下加载数据</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="of og l"/></div></figure><ul class=""><li id="a92d" class="lp lq iq lr b ls na lu nb lw oh ly oi ma oj mc ok me mf mg bi translated">我们的自变量是一个图像，因此<code class="fe nf ng nh ni b">ImageBlock</code>作为输入，后跟一个<code class="fe nf ng nh ni b">MultiCategoryBlock</code>用于一次性编码和加载因变量。</li><li id="76fd" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc ok me mf mg bi translated">上面定义了我们的拆分器，它从我们的数据帧中取出<code class="fe nf ng nh ni b">is_valid</code>列，并基于该布尔变量来分隔训练和验证条目</li><li id="1693" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc ok me mf mg bi translated"><code class="fe nf ng nh ni b">get_x</code>函数读取列<code class="fe nf ng nh ni b">fname</code>中的文件名，并将基本路径附加到要加载的文件中</li><li id="d69b" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc ok me mf mg bi translated"><code class="fe nf ng nh ni b">get_y</code>函数从dataframe中读取列<code class="fe nf ng nh ni b">labels</code>,由于我们的标签是空格分隔的，所以它使用空格分隔符分割标签字符串。</li><li id="cd05" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc ok me mf mg bi translated"><code class="fe nf ng nh ni b">item_tfms</code>和<code class="fe nf ng nh ni b">batch_tfms</code>:我们使用fastai的<code class="fe nf ng nh ni b">presizing</code>技巧来避免有损图像裁剪(如填充边框等)。)和标准增强方法，然后使用<code class="fe nf ng nh ni b">imagenet_stats</code>进行标准化，因为我们将使用预训练的<code class="fe nf ng nh ni b">resnet50</code>进行分类任务。</li></ul><p id="a25d" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">现在，如果我们看一个批次的例子，我们可以观察到以下情况。看看我们如何在这些例子的图像中有多个标签。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/aaa788790118e7726bea8306d7b06c99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jHJejEHFeiUj31Et.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="2537" class="kx ky iq bd kz la nq lc ld le nr lg lh jw ns jx lj jz nt ka ll kc nu kd ln lo bi translated">模型和激活函数</h1><p id="1a91" class="pw-post-body-paragraph mm mn iq lr b ls lt jr mo lu lv ju mp lw mq mr ms ly mt mu mv ma mw mx my mc ij bi translated">虽然使用fast.ai API定义模型和损失非常简单，但我们应该暂停一下，看看损失函数和模型，尤其是详细的损失函数。</p><p id="a680" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">我们将对模型头部做一些改动。我们不会像以前一样使用softmax，而是使用sigmoid激活。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi om"><img src="../Images/79649ee04927a6181fd2362f50e39b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*X9DeEHMxni9SqSXkJJ4Zfg.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="a264" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">softmax所做的是将来自最终分类线性图层的逻辑值转换为总和1。这对于多标签分类来说意味着，当我们遇到具有多个标签的例子时，我们会遭受很高的损失。例如，考虑下面的场景</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi on"><img src="../Images/491fbed26767bf171035cf48d4c0c7ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*U0ttXu1KOy37LARo.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><blockquote class="oo op oq"><p id="8d5e" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">我们看到，在这个假设的例子中，数据点实际上属于类别1和4，但我们的softmax最多只能将这两个类别的概率分数推至0.5，而将其余两个类别的概率分数推至0，但也不会比这更好。这是因为概率总和必须始终为1。想象一下，如果这是一个三类的例子，那么softmax可以做的最好的事情就是将三个概率分数推至0.33，将剩余的1个概率分数推至0。</p></blockquote><p id="8962" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">现在，让我们看看乙状结肠激活。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/96f28e04153eebe63dd53c2a9eb4e288.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*7pk35-LmMTYkOaoJvtuLmg.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="9f49" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">现在，我们看到激活函数并不关心其他标签是什么。与softmax不同，它只关注相关标签的logit。</p><blockquote class="oo op oq"><p id="6b4a" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">这些逻辑都是解耦的，它们之间不会像softmax那样相互影响。</p></blockquote><p id="236e" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">这就是为什么在上图中，你可以看到类别1和3的Sigmoid激活概率可以攀升到接近1，而另外两个可以独立地接近0。</p><p id="62f5" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">现在，你可以更好地理解为什么我们不能使用<code class="fe nf ng nh ni b">softmax activation function</code>而是需要一个单独的<code class="fe nf ng nh ni b">sigmoid activation function</code>来解决这个问题。</p><p id="d49c" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">既然我们已经改变了激活函数，我们应该重新考虑我们对损失函数的选择。</p><p id="2f70" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">对于单标签分类，我们使用如下定义的交叉熵损失函数</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/274b8598299e3392e1a0f1f2c5198449.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*TK0P6pU6QF_cTOyK5MI6CQ.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="dacd" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated"><em class="or">其中ti是真实值，pi是标签的预测概率</em></p><p id="1837" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">如果我们继续将这个损失函数应用于我们的sigmoid激活输出，我们就有麻烦了。我们将不会惩罚任何事实标签为0的东西。对于上面的同一个示例，如果我们计算CE损失，我们会看到如下图</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ox"><img src="../Images/10114ab9f49e2114485f3ec573b9d37d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZRiFkpvXB21S-4oK.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="1a53" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">另一方面，二元交叉熵定义如下</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oy"><img src="../Images/98260ef5559d66d52e13f05abf3d0a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kjlKI_QWgv2rCLyZNZaAyg.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="691f" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated"><em class="or">其中ti是真实值，pi是标签的预测概率</em></p><p id="2d2d" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">这真的很有趣。它确保了无论标签是什么(0/1 ),总会有一些损失来惩罚模型的错误预测。永远不会是零。当地面真实值为1时，损失为-log(p ),当地面真实值为0时，损失为log(1-p)。这对于模型通过分类器头中的不同神经元针对它们的错误预测单独惩罚模型是非常有用的。</p><p id="366b" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">在上图中，我们可以看到，即使地面真实标签为0，我们也可以获得这些神经元的有限损失值，以及单标签分类中使用的普通交叉熵损失。</p><p id="8545" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">对于模型，我们仍然可以继续使用我们的imagenet预训练主干，并从迁移学习开始。</p><p id="cc78" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated"><strong class="lr ir">为什么即使任务不同，模型也是一样的——单标签而不是多标签分类？</strong></p><blockquote class="oo op oq"><p id="249d" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">虽然最终我们必须预测每个输出的多个标签，但是我们仍然可以利用预先训练的相同过滤器来识别人、动物、物体等。这是大型imagenet数据集的一部分。已经智能地学习了这1000个类的预训练主干具有过滤器，可以检测人脸、猫毛、狗尾巴等。PASCAL_2007数据集中也有类似的类。因此，以此为起点来利用我们已经拥有的资源是有意义的！</p></blockquote><p id="cf3f" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">因此，我们现在可以定义一个<code class="fe nf ng nh ni b">fastai learner</code>来进行培训。内容如下:</p><pre class="kh ki kj kk gt nv ni nw nx aw ny bi"><span id="4f5c" class="nz ky iq ni b gy oa ob l oc od">learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.5))</span></pre><p id="c9b9" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">在这里，我们更改了指标，使用accuracy_multi代替了原来的accuracy。我们将在模型评估中详细讨论这一点，但除此之外，我们还没有从我们做单标签分类时开始做任何改变，是吗？</p><p id="3e9e" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated"><em class="or">事实上，fastai选择BCE loss是因为我们已经在dls中指定，我们的因变量是一个多类别块。我们可以明确地指定它，但我们至少需要知道它。</em></p><p id="23d5" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">然后，训练和lr_find以及其他内容保持不变，如下面的代码片段所示。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oz"><img src="../Images/8b80c7d3427c3a69211e011fdaedca7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K1gUXp1imbj76w5B.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="6315" class="kx ky iq bd kz la nq lc ld le nr lg lh jw ns jx lj jz nt ka ll kc nu kd ln lo bi translated">模型评估</h1><p id="6e2d" class="pw-post-body-paragraph mm mn iq lr b ls lt jr mo lu lv ju mp lw mq mr ms ly mt mu mv ma mw mx my mc ij bi translated">这是最重要的部分，因为这与多标签分类有很大不同。</p><p id="9452" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated"><strong class="lr ir"> <em class="or">首先，什么是精度_多？</em> </strong></p><p id="b727" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">如果是多标签分类，我们的目标是<code class="fe nf ng nh ni b">one-hot encoded</code>。同样，我们得到的输出与目标的形状相同，但它们是逻辑的。所以我们对这些应用sigmoid激活，并得到概率。</p><p id="12e3" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">在单标签分类中，我们只比较一个数据点的一个标签，如果它匹配，我们的结果是准确的，否则就不是。但是，对于多标签分类，对于每个数据点，我们预测一个向量，输出也是一个向量。所以我们需要比较这些向量，而不是每个数据点的单个标量。因为我们必须比较多个值，然后取这些比较的平均值；因此得名<code class="fe nf ng nh ni b">accuracy_multi</code>。下表将对此进行更好的总结。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi pa"><img src="../Images/16a87722f939fe19807d5be8cb5254b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*u_RAZQiSQeILH59b.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="eefa" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated"><strong class="lr ir"> <em class="or">预测- &gt;出席/缺席概率</em> </strong></p><p id="a9bc" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">正如我们在上面的例子中看到的，我们假设预测是一个二进制字段，但是神经网络本身并不能为每个类/标签提供一个离散值。它给了我们一个浮点数组，我们需要将它转换成一个概率分布，然后转换成一个离散值，代表一个类/标签的存在/不存在。</p><p id="1e28" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">第一部分很简单，我们已经介绍过，即从神经网络输出的逻辑值到概率分布，只涉及对各个类别的概率值应用sigmoid激活。</p><p id="5531" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">对于下一部分，即将概率转换成离散值；我们必须设定阈值。这意味着我们选择一个概率值，并以此为支点，将连续概率转换成离散分布。下面的例子将更好地解释这一现象。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi pb"><img src="../Images/eeb9b72054d7f5ef0cec9539f284d29e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uWpX0JRU43MXZzGn.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="5482" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">如图所示，我们首先获取网络输出，并应用sigmoid激活，从而获得概率。接下来，我们任意挑选5个阈值<code class="fe nf ng nh ni b">[0.1, 0.3, 0.5, 0.7, 0.9]</code>。现在，我们要做的是将这些概率与阈值进行比较。当<code class="fe nf ng nh ni b">probability &gt; threshold</code>时，我们将其标记为真，否则标记为假。然后取预测值的平均值，就可以得到该数据点的精确度。</p><blockquote class="oo op oq"><p id="005b" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">在单标签分类中，单个数据点的精度可以是0或1，而在多标签分类中，精度可以是0和1之间的连续值，包括0和1。</p></blockquote><p id="2de6" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">现在，既然我们在讨论阈值，那么在评估过程中找出最佳阈值就变得很重要。此外，目前我们对所有类别/标签使用相同的阈值。我们可以分别调整每个类的阈值，以得出每个类的最佳分数，然后使用这些阈值来获得整个数据集的多精度。让我们看看如何做到这一点。</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="e6d5" class="kx ky iq bd kz la nq lc ld le nr lg lh jw ns jx lj jz nt ka ll kc nu kd ln lo bi translated">全局阈值</h1><p id="5bc8" class="pw-post-body-paragraph mm mn iq lr b ls lt jr mo lu lv ju mp lw mq mr ms ly mt mu mv ma mw mx my mc ij bi translated">我们上面所做的在某种意义上可以称为<code class="fe nf ng nh ni b">Global Thresholding</code>,我们对所有的类使用一个阈值，比较每个数据点的精确度，得出一个比较精确度和阈值的图，并选择一个给出最好精确度的。</p><p id="3d0f" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">下面是我们如何用代码实现它</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="of og l"/></div></figure><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/0522eae698b5e57ab5856345b050d4e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/0*q6VkvWSqkGomz1nS.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="94b4" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">上述函数为我们提供了最佳精度点和发生该点的阈值，该阈值可以简单地保存为模型的人工制品，并且在推断过程中，当我们想要获得单个标签的预测时，我们可以将它们的概率与该阈值进行比较，并获得离散结果来表示某个类别的存在/不存在。</p><p id="7426" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">然而，我们可以做得更好。</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h1 id="432b" class="kx ky iq bd kz la nq lc ld le nr lg lh jw ns jx lj jz nt ka ll kc nu kd ln lo bi translated">类别/标签级别阈值</h1><p id="f7a8" class="pw-post-body-paragraph mm mn iq lr b ls lt jr mo lu lv ju mp lw mq mr ms ly mt mu mv ma mw mx my mc ij bi translated">实际上，准确性并不总是最好的评估标准。例如，假设世界上只有1%的人是富人，预测每个人都是穷人会让你99%准确，但这真的好吗？</p><p id="d1da" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">不是吧？当您创建一个分类器时，如果存在严重的类不平衡，您会希望您的性能在所有类中都很好，而不仅仅是在数据集中占主导地位的一两个类。准确性不能告诉我们这样的信息。在这里，有其他度量，如<code class="fe nf ng nh ni b">Precision</code>、<code class="fe nf ng nh ni b">Recall/TPR</code>、<code class="fe nf ng nh ni b">FPR</code>、<code class="fe nf ng nh ni b">f1-score</code>等。变得非常有用。这篇文章并不打算深入研究这些指标，但让我们粗略地看一下，我将在最后提供良好的资源来深入研究每一个指标。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi pd"><img src="../Images/bf2cf10cb9047ab39c7d74ca0c80d403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YsoWZGb_eI0S_pBf7aoIMA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供(混淆矩阵)</p></figure><ul class=""><li id="559c" class="lp lq iq lr b ls na lu nb lw oh ly oi ma oj mc ok me mf mg bi translated"><code class="fe nf ng nh ni b">Precision</code>:这个量基本上告诉你所有那些被预测为某种类型的例子，实际上有多少是那种类型的。如果我们看看上面的混淆矩阵，我们可以将精度定义为</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/a8a77be8cc2a2a00929678e7d0f9bc83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*xmk_v36blCUkyDzXhTIIwA.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><ul class=""><li id="3627" class="lp lq iq lr b ls na lu nb lw oh ly oi ma oj mc ok me mf mg bi translated"><code class="fe nf ng nh ni b">Recall/TPR</code>:这个数量基本上指定分类器正确识别了多少个特定类别的样本。也简称为<code class="fe nf ng nh ni b">True Positive Rate</code>或TPR。它是由</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/a8a77be8cc2a2a00929678e7d0f9bc83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*xmk_v36blCUkyDzXhTIIwA.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><ul class=""><li id="1f45" class="lp lq iq lr b ls na lu nb lw oh ly oi ma oj mc ok me mf mg bi translated">当我们定义一个分类器时，我们希望这两个值尽可能的高，最好是1，但是它们之间有一种反比关系。因此，我们定义了一个度量标准，它找到了两者的最佳平衡点。这是f1分数，原则上是召回率和精确度之间的调和平均值，定义如下</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/647626993da44a7d8315cc4dfbbf66ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*IISJiRnBtJAEHvvtg2az_Q.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><ul class=""><li id="3a98" class="lp lq iq lr b ls na lu nb lw oh ly oi ma oj mc ok me mf mg bi translated"><code class="fe nf ng nh ni b">FPR</code>:假阳性率是被错误分类的阴性样本的数量。它是由</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/9365ce9d9fe869a5112fd442159f6518.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*FPHJ63XwluUCYelxmRCOAA.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="8525" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">对分类器的评估可以从几个方面进行。对一些人来说,<code class="fe nf ng nh ni b">accuracy</code>仍然是评估的黄金标准；对于其他一些人来说，<code class="fe nf ng nh ni b">f1-score</code>可能是确保分类器跨多个类别性能的重要数字。在许多情况下，<code class="fe nf ng nh ni b">ROC</code>或接收器操作特性图可用于计算分类器性能。我们将使用所有三种技术评估我们的模型，以获得给定特定标准的最佳性能模型。</p><p id="3bff" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">下面是我们用来训练模型的<code class="fe nf ng nh ni b">PASCAL_2007</code>数据集的<code class="fe nf ng nh ni b">bus</code>类别的ROC图</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/591bf0de6dc7f3ea209a6934bfdcd134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/0*7jnabxhG5H6ELU7G.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><p id="8cc7" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">X轴表示FPR，Y轴表示召回/TPR。我们需要确定在不增加FPR的情况下TPR尽可能高的点。我们可以通过找到最接近<code class="fe nf ng nh ni b">(0, 1)</code>点的点来解决这个问题，即FPR为0而TPR为1。这显示在带有红点的曲线中。对于一个完美的分类器，我们应该有一个单位矩形类型的图，但实际上在大多数情况下，这两类的分布从来没有完全区分。</p><p id="dfb4" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">完成这项工作的完整代码会变得非常大，但可以在GitHub上找到，我已经在<a class="ae kw" href="https://elisonsherton.github.io/fastbook/deep%20learning/2021/08/18/fastbook-multilabel-classification-1.html#references" rel="noopener ugc nofollow" target="_blank">参考资料部分</a>附上了它。我将勾画出伪代码做这个局部阈值，然后最终的预测汇总。</p><blockquote class="oo op oq"><p id="b0fc" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">1.从fastai学习者那里获得预测和目标</p><p id="0267" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">2.分离出每个标签的预测和目标。fastai预测的形状为“N_EXAMPLES x N_CLASSES ”,因此将它们分成N _ CLASSES个长度为“N_EXAMPLES”的向量。对目标也进行类似的操作。</p><p id="2bfc" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">3.选择一系列阈值，并评估每个类别/标签的所有示例的指标精度、召回率、fpr、f1-得分，并构建ROC-AUC曲线。</p><p id="5871" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">4.在您改变阈值的所有点中，选择最接近的点、最佳准确度和最佳f1得分点。记录您获得这些指标最佳值的每个点的阈值。</p><p id="3723" class="mm mn or lr b ls na jr mo lu nb ju mp os nc mr ms ot nd mu mv ou ne mx my mc ij bi translated">5.使用从4中获得的每个类别的记录阈值，将概率分布转换为离散分布，并找到多标签分类器的总体精度。</p></blockquote><p id="dfbd" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">如果我们要进行比较，对于每个类别，使用bestAccuracy策略的单个类别/标签的阈值调整使我们在准确性上比全局阈值略有提高，这也使我们在默认阈值0.5上有所提高，默认阈值0.5通常用于所有分类问题。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi pi"><img src="../Images/aa17f7cd34a947f3b84714140d97cfe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NrJNqYGerWTAvJBK.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由Vinayak提供</p></figure><h1 id="ed1d" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated">结论</h1><ol class=""><li id="c7cd" class="lp lq iq lr b ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">多标签分类器(MLC)可以用多个类别/标签标记给定的数据点。</li><li id="f886" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated">MLC中使用的激活是<code class="fe nf ng nh ni b">sigmoid</code>而不是<code class="fe nf ng nh ni b">softmax</code>。</li><li id="fd39" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated">用于MLC的损失函数是<code class="fe nf ng nh ni b">BinaryCrossEntropy</code>而不是<code class="fe nf ng nh ni b">CrossEntropy</code>。</li><li id="637b" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated">一个好的阈值可以在获得更好/更差的MLC精度方面产生显著的差异。</li><li id="a6a2" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated">在模型评估过程中，准确性可能不是黄金标准，回忆/精度/f1分数等指标将非常有用，尤其是在训练模型时存在类别不平衡的情况下。</li></ol><p id="75b2" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">我希望你喜欢阅读这篇博文！我很高兴在推特上与你联系。如果你有任何意见/建议/想法，欢迎在下面评论或在Twitter上联系我。</p><p id="2945" class="pw-post-body-paragraph mm mn iq lr b ls na jr mo lu nb ju mp lw nc mr ms ly nd mu mv ma ne mx my mc ij bi translated">如果你喜欢你所读的，请随意查看<a class="ae kw" href="https://nayakvinayak95.medium.com/" rel="noopener">我在这里的其他帖子。</a></p><h1 id="e4d8" class="kx ky iq bd kz la lb lc ld le lf lg lh jw li jx lj jz lk ka ll kc lm kd ln lo bi translated">参考</h1><ol class=""><li id="f272" class="lp lq iq lr b ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><a class="ae kw" href="https://www.youtube.com/watch?v=SfzNEz5ASAY" rel="noopener ugc nofollow" target="_blank"> wandb fastbook sessions链接</a></li><li id="4533" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated"><a class="ae kw" href="https://github.com/ElisonSherton/fastbook_sessions/tree/master/ch6MultiLabel" rel="noopener ugc nofollow" target="_blank">在帖子</a>中创建的应用程序的Github代码</li><li id="03bf" class="lp lq iq lr b ls mh lu mi lw mj ly mk ma ml mc md me mf mg bi translated"><a class="ae kw" rel="noopener" target="_blank" href="/accuracy-precision-recall-or-f1-331fb37c5cb9">对评估指标的良好解释</a></li></ol></div></div>    
</body>
</html>