<html>
<head>
<title>Google’s Open Images: Now easier to download and evaluate with FiftyOne</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌的开放图像:现在更容易下载和评估与51</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/googles-open-images-now-easier-to-download-and-evaluate-with-fiftyone-615ce0482c02?source=collection_archive---------7-----------------------#2021-05-12">https://towardsdatascience.com/googles-open-images-now-easier-to-download-and-evaluate-with-fiftyone-615ce0482c02?source=collection_archive---------7-----------------------#2021-05-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3d7c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">高效下载开放图像，并使用开放图像风格的评估功能对您的模型进行评估</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a232beb11f10b5fe9ca7110d4a31354d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S_82GoWWu5u3_4bBx9uI_g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/open_images.html" rel="noopener ugc nofollow" target="_blank">打开图像数据集</a>在<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">五十一</a>下载并可视化(图片由作者提供)</p></figure><p id="7ac8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://storage.googleapis.com/openimages/web/download.html" rel="noopener ugc nofollow" target="_blank">谷歌的开放图像</a>是一个数据集的庞然大物。它拥有超过900万张图像、8000万条注释和跨越多个任务的600个类，是计算机视觉社区中领先的数据集之一。</p><blockquote class="ls"><p id="23e1" class="lt lu iq bd lv lw lx ly lz ma mb lr dk translated">使用<a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/open_images.html" rel="noopener ugc nofollow" target="_blank">开放图像</a>现在比以往任何时候都更容易，因为它集成到了开源ML开发工具<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>。</p></blockquote><figure class="mc md me mf mg kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="ca62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算机视觉模型比以往任何时候都更加渴求数据。开发您自己的模型需要您自己收集和注释大量数据，或者求助于公共数据集，希望它们包含与您的任务相关的数据。Open Images背后的团队致力于为任何人提供一个巨大的数据湖。通过仅在<a class="ae kv" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名(CC-BY) </a>许可下管理图像，任何感兴趣的人都可以使用开放图像。</p><p id="511e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">凭借图像级标签、分段、视觉关系、本地化叙述和比下一个最大的检测数据集 多15倍的<a class="ae kv" href="https://arxiv.org/pdf/1811.00982.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">对象检测，开放图像可以很容易地添加到您的数据湖和训练工作流中。然而，学习一种新的数据集格式并将其合并到您的工作流程中通常是乏味且耗时的。以前，下载开放图像的过程包括编写定制脚本来下载和解析您想要的图像和标签。这催生了多种工具来帮助加载数据集，但它们都有严重的缺点，比如<a class="ae kv" href="https://github.com/EscVM/OIDv4_ToolKit" rel="noopener ugc nofollow" target="_blank">不支持分段和关系</a>、<a class="ae kv" href="https://github.com/monocongo/openimages" rel="noopener ugc nofollow" target="_blank">没有可视化能力</a>以及<a class="ae kv" href="https://github.com/DmitryRyumin/OIDv6" rel="noopener ugc nofollow" target="_blank">不能指定下载格式</a>。</strong></a></p><p id="a791" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://voxel51.com/" rel="noopener ugc nofollow" target="_blank"> Voxel51 </a>，我们<a class="ae kv" href="https://storage.googleapis.com/openimages/web/2021-05-12-oid-and-fiftyone.html" rel="noopener ugc nofollow" target="_blank">与Google </a>合作，通过将它整合到我们的开源ML工具<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/index.html" rel="noopener ugc nofollow" target="_blank">数据集Zoo </a>中，创建了一个易于使用的下载开放图像的来源。使用<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">五十一</a>，您可以准确指定您想要下载的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/datasets.html#dataset-zoo-open-images" rel="noopener ugc nofollow" target="_blank">开放图像的子集，</a><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html" rel="noopener ugc nofollow" target="_blank">将其导出</a>成几十种不同的格式，在<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank">五十一应用</a>中可视化，甚至<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/user_guide/evaluation.html#open-images-style-evaluation" rel="noopener ugc nofollow" target="_blank">使用开放图像风格的对象检测评估</a>来评估您的模型。</p><p id="cead" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇博文将带你了解如何使用<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>来:</p><ul class=""><li id="176f" class="mj mk iq ky b kz la lc ld lf ml lj mm ln mn lr mo mp mq mr bi translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/open_images.html" rel="noopener ugc nofollow" target="_blank">下载开放图片</a></li><li id="e27d" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html" rel="noopener ugc nofollow" target="_blank">以不同的数据集格式导出</a>打开的图像</li><li id="0482" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/user_guide/evaluation.html#open-images-style-evaluation" rel="noopener ugc nofollow" target="_blank">使用开放图像风格的评估来评估对象检测模型</a></li></ul><p id="9e0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们开始之前，确保<a class="ae kv" href="https://voxel51.com/docs/fiftyone/getting_started/install.html" rel="noopener ugc nofollow" target="_blank">安装51个</a>:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="49db" class="nc nd iq my b gy ne nf l ng nh">pip install fiftyone</span></pre><h1 id="5866" class="ni nd iq bd nj nk nl nm nn no np nq nr jw ns jx nt jz nu ka nv kc nw kd nx ny bi translated">跟随在科拉布</h1><p id="ae47" class="pw-post-body-paragraph kw kx iq ky b kz nz jr lb lc oa ju le lf ob lh li lj oc ll lm ln od lp lq lr ij bi translated">你可以直接在<a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/open_images.html" rel="noopener ugc nofollow" target="_blank">这个Google Colab笔记本</a>的浏览器中运行这篇博文中的例子。跟随链接，点击“在Google Colab中运行”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/9361c6d764bd36f1c7bbe1fe6c188470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Vuy2WXcMff8UcyYYI-ZOA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">可视化嵌入在笔记本中的开放图像(作者图片)</p></figure></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="e9bc" class="ni nd iq bd nj nk om nm nn no on nq nr jw oo jx nt jz op ka nv kc oq kd nx ny bi translated">打开51数据集动物园中的图像</h1><p id="1fda" class="pw-post-body-paragraph kw kx iq ky b kz nz jr lb lc oa ju le lf ob lh li lj oc ll lm ln od lp lq lr ij bi translated">现在只需要<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/index.html#basic-recipe" rel="noopener ugc nofollow" target="_blank">一个命令或一行Python代码</a>就可以从开放图像中准确下载您想要的样本。然后，您可以在<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne应用程序</a>中用多一行代码探索数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/0bab42d70e2572f5c054140838c83909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*elxuTKZYFoD3QWgzL3vlsA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank">打开图像数据集</a>在<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">五十一</a>下载并可视化(图片由作者提供)</p></figure><p id="474c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将Open Images集成到FiftyOne中提供了多个参数<a class="ae kv" href="https://voxel51.com/docs/fiftyone/api/fiftyone.zoo.datasets.base.html#fiftyone.zoo.datasets.base.OpenImagesV6Dataset" rel="noopener ugc nofollow" target="_blank"/>,您可以使用这些参数来指定您想要下载的样本及其数量:</p><ul class=""><li id="64f9" class="mj mk iq ky b kz la lc ld lf ml lj mm ln mn lr mo mp mq mr bi translated"><code class="fe os ot ou my b">label_types</code>:要加载的标签类型列表。值为<code class="fe os ot ou my b">("detections", "classifications", "relationships", "segmentations")</code>。默认情况下，会加载所有标签，但并非每个样本都会包含每种标签类型。如果同时指定了<code class="fe os ot ou my b">max_samples</code>和<code class="fe os ot ou my b">label_types</code>，那么每个样本都将包含指定的标签类型。</li><li id="d6c6" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">split</code>和<code class="fe os ot ou my b">splits</code>:一个字符串或字符串列表，指示要加载的拆分。可用的拆分是<code class="fe os ot ou my b">("test", "train", "validation")</code>。</li><li id="1a4d" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">classes</code>:指定需要加载的类的字符串列表。只有包含至少一个指定类实例的示例才会被下载。</li><li id="51c6" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">attrs</code>:要加载的关系属性的字符串列表。该参数仅在<code class="fe os ot ou my b">"relationships"</code>处于<code class="fe os ot ou my b">label_types</code>时有用。</li><li id="4099" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">max_samples</code>:导入样本的最大数量。默认情况下，会导入所有样本。</li><li id="c510" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">shuffle</code>:布尔型，指示是否随机打乱导入样本的顺序。</li><li id="a0c8" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">seed</code>:洗牌时使用的随机种子。</li><li id="2372" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">image_ids</code>:要加载的特定图像id列表。id可以指定为<code class="fe os ot ou my b">&lt;split&gt;/&lt;image-id&gt;</code>或<code class="fe os ot ou my b">&lt;image-id&gt;</code></li><li id="37b2" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><code class="fe os ot ou my b">image_ids_file</code>:换行分隔的<code class="fe os ot ou my b">.txt</code>、<code class="fe os ot ou my b">.json</code>或<code class="fe os ot ou my b">.csv</code>文件的路径，包含要加载的图像id列表。id可以指定为<code class="fe os ot ou my b">&lt;split&gt;/&lt;image-id&gt;</code>或<code class="fe os ot ou my b">&lt;image-id&gt;</code>。如果提供了<code class="fe os ot ou my b">image_ids</code>，该参数被忽略</li></ul><p id="3c6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中一些参数允许您指定希望包含在子集中的特定类和属性。您可以使用以下命令查看打开的图像中的可用选项列表:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="a37a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">利用这一功能，我们可以为特定任务筛选数据集，而无需下载整个数据集或解析任何原始注释文件。例如，如果我们想要训练一个木制物体的检测器，我们可以指定我们只想要来自包含带有注释为<code class="fe os ot ou my b">Wooden</code>的<code class="fe os ot ou my b">visual relationship</code>的物体的开放图像的样本:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/fefa1f3494ec5e852a961c28415ead63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9axJd5LXlKjRFuInTyVlQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">木制乒乓球台在五十一年可视化(图片由作者提供)</p></figure><p id="5bac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再比如，我们建立一个检测猫狗的数据集。我们可以为类别<code class="fe os ot ou my b">Dog</code>和<code class="fe os ot ou my b">Cat</code>获得<code class="fe os ot ou my b">detections</code>以及图像级别<code class="fe os ot ou my b">classifications</code>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/4f120a0872e18e3a2d44ad6fb5d04ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RMdF-YoBS5SPPq9r3oiPFg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在51中可视化的开放图像的猫/狗子集(图像由作者提供)</p></figure><p id="4b80" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当处理包含对象检测的数据集时，FiftyOne允许您创建一个<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-object-patches" rel="noopener ugc nofollow" target="_blank">补丁视图</a>，其中每个样本包含一个对象。当试图分析特定的对象类或属性时，这非常有用，尤其是在混乱的场景中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/1f25a4ac2edf12bb2848049823bfc2be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*hdwpZNoimZ4HKZapXAxKHw.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第五十一个应用程序中对象的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-object-patches" rel="noopener ugc nofollow" target="_blank">补丁视图</a>示例(图片由作者提供)</p></figure><h1 id="d18a" class="ni nd iq bd nj nk nl nm nn no np nq nr jw ns jx nt jz nu ka nv kc nw kd nx ny bi translated">导出到不同的格式</h1><p id="1188" class="pw-post-body-paragraph kw kx iq ky b kz nz jr lb lc oa ju le lf ob lh li lj oc ll lm ln od lp lq lr ij bi translated">多年来，COCO数据集一直是最重要的对象检测数据集，导致相当大比例的计算机视觉(CV)社区采用<a class="ae kv" rel="noopener" target="_blank" href="/how-to-work-with-object-detection-datasets-in-coco-format-9bf4fb5848a4"> COCO格式</a>来解决他们的对象检测问题。为项目选择数据集格式决定了加载和处理数据集所需的解析器，这使得很难处理不同格式的新数据。FiftyOne允许您<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html" rel="noopener ugc nofollow" target="_blank">将数据集导出成几十种不同的格式</a>让您可以轻松地将其集成到现有的工作流程中。</p><p id="75d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，您可以导出为类似于<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#cocodetectiondataset" rel="noopener ugc nofollow" target="_blank"> COCO </a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#vocdetectiondataset" rel="noopener ugc nofollow" target="_blank"> Pascal VOC </a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#cvatimagedataset" rel="noopener ugc nofollow" target="_blank"> CVAT </a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#yolodataset" rel="noopener ugc nofollow" target="_blank"> YOLO </a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#tfobjectdetectiondataset" rel="noopener ugc nofollow" target="_blank"> TFRecords </a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#imageclassificationdirectorytree" rel="noopener ugc nofollow" target="_blank">分类目录树</a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#supported-formats" rel="noopener ugc nofollow" target="_blank"> more </a>的格式。其中许多格式还支持导出分段掩码。</p><p id="58ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">实际上，以<a class="ae kv" rel="noopener" target="_blank" href="/how-to-work-with-object-detection-datasets-in-coco-format-9bf4fb5848a4"> COCO格式</a>导出我们之前加载到磁盘的打开图像的子集非常简单:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="4eee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您想<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html" rel="noopener ugc nofollow" target="_blank">将您的数据重新导入到FiftyOne </a>中，并且数据集遵循一种受支持的格式，这也可以在一行代码中完成:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="a945" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">即使你的数据集是完全自定义的格式，将它加载到fiftone中仍然很容易<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/samples.html" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="00a4" class="ni nd iq bd nj nk nl nm nn no np nq nr jw ns jx nt jz nu ka nv kc nw kd nx ny bi translated">开放图像目标检测评估</h1><p id="50ec" class="pw-post-body-paragraph kw kx iq ky b kz nz jr lb lc oa ju le lf ob lh li lj oc ll lm ln od lp lq lr ij bi translated">FiftyOne不仅可以轻松加载和导出开放图像和自定义数据集，还可以让您<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank">可视化您的数据</a>和<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html" rel="noopener ugc nofollow" target="_blank">评估模型结果</a>。</p><p id="6d84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#open-images-style-evaluation" rel="noopener ugc nofollow" target="_blank"> Open Images风格的对象检测评估</a>是为<a class="ae kv" href="https://storage.googleapis.com/openimages/web/challenge_overview.html" rel="noopener ugc nofollow" target="_blank"> Open Images challenges </a>创建的。它与可可式评估有几个显著的不同:</p><ul class=""><li id="aa2b" class="mj mk iq ky b kz la lc ld lf ml lj mm ln mn lr mo mp mq mr bi translated">图像级标签指示在每个图像中评估哪些对象类。如果预测了一个类，但没有将其注释为正或负图像级标签，则该类将被忽略。</li><li id="2209" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated"><a class="ae kv" href="https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy_visualizer/circle.html" rel="noopener ugc nofollow" target="_blank">语义类层次</a>用于扩展预测和基础事实对象列表，以包括和评估所有父类。默认情况下，基本事实检测仅包括叶类，并且必须在评估发生之前展开。这是在五十一中自动执行的。</li><li id="e4c1" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated">像COCO一样，“人群”地面真相检测能够与多个预测相匹配。但与COCO不同的是，每个人群中只有一个预测是真正积极的。</li><li id="d3ca" class="mj mk iq ky b kz ms lc mt lf mu lj mv ln mw lr mo mp mq mr bi translated">COCO式评估在10个不同的IoU值范围内对AP求平均值，Open Images式评估仅使用0.5的IoU来计算mAP。</li></ul><p id="fe0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="oy">如果您想查看</em> <a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#open-images-style-evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="oy">开放式图像式评估</em> </a> <em class="oy">或</em> <a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#coco-style-evaluation-default" rel="noopener ugc nofollow" target="_blank"> <em class="oy"> COCO式评估</em> </a>的评估协议的详细步骤，请点击这些链接。</p><p id="be01" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了尝试开放图像风格的评估，我们可以使用来自<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html" rel="noopener ugc nofollow" target="_blank">51模型动物园</a>的模型来生成对我们下载的开放图像的猫和狗子集的检测预测。我们将向数据集添加一个新的<code class="fe os ot ou my b">predictions</code> <a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/using_datasets.html#fields" rel="noopener ugc nofollow" target="_blank">字段</a>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="8ec6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="oy">注意:运行该模型需要TensorFlow 1.14。</em></p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="4d39" class="nc nd iq my b gy ne nf l ng nh">pip install tensorflow==1.14</span></pre><p id="619d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个例子，我们只对“猫”和“狗”这两个类的预测感兴趣，所以我们可以利用FiftyOne灵活的数据集表示来创建一个<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/using_views.html" rel="noopener ugc nofollow" target="_blank">视图</a>到只包含这些类的数据集中。此外，我们运行的模型是在COCO上训练的，COCO使用小写类名，因此我们需要<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/using_views.html#modifying-fields" rel="noopener ugc nofollow" target="_blank">重新映射</a>它们以匹配打开图像的大写类名:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="360a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在可以对数据集和预测运行开放图像风格的评估:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="31f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">返回的<code class="fe os ot ou my b">results</code> <a class="ae kv" href="https://voxel51.com/docs/fiftyone/api/fiftyone.utils.eval.openimages.html#fiftyone.utils.eval.openimages.OpenImagesDetectionResults" rel="noopener ugc nofollow" target="_blank">对象</a>包含了我们需要的一切，从<a class="ae kv" href="https://voxel51.com/docs/fiftyone/api/fiftyone.utils.eval.openimages.html#fiftyone.utils.eval.openimages.OpenImagesDetectionResults.mAP" rel="noopener ugc nofollow" target="_blank">地图</a>，到<a class="ae kv" href="https://voxel51.com/docs/fiftyone/api/fiftyone.utils.eval.openimages.html#fiftyone.utils.eval.openimages.OpenImagesDetectionResults.plot_pr_curves" rel="noopener ugc nofollow" target="_blank"> PR曲线</a>，到<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#confusion-matrices" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/fb03148bce273f01110e83aefa61f989.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpJK8yuSK4EW4rIvQ8GZ5Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#computing-map-and-pr-curves" rel="noopener ugc nofollow" target="_blank">51年绘制的PR曲线</a>(图片由作者提供)</p></figure><p id="6eca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">应该注意的是，默认情况下，这些检测协议将只把预测对象与同一类别的基本事实对象进行匹配。这意味着，如果我们想要一个有趣的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#confusion-matrices" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>，我们将需要用等于<code class="fe os ot ou my b">False</code>的参数<code class="fe os ot ou my b">classwise</code>进行评估:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="aa1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在可以查看一个<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/plots.html#confusion-matrices" rel="noopener ugc nofollow" target="_blank">交互式混淆矩阵</a>，其中如果我们单击一个单元格，则<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank">51个应用程序</a>将会更新，仅显示该单元格中存在的样本。因此，例如，如果我们单击包含与预测的“猫”检测相匹配的真实“狗”检测的单元，我们可以深入了解我们模型的故障模式:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><div class="kg kh ki kj gt ab cb"><figure class="pa kk pb pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/3500ca68401439575ef9f5f6396682f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*AZvolFBZ_UERx7gSiUTifg.png"/></div></figure><figure class="pa kk pg pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/94b727d6a26ee7bdce454eac636ac146.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*eetXa252ngr8Ux20IRjEGg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk ph di pi pj translated">假阳性在51中交互可视化(图片由作者提供)</p></figure></div><p id="355d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="oy">注:</em> <a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/plots.html" rel="noopener ugc nofollow" target="_blank"> <em class="oy">互动剧情</em> </a> <em class="oy">目前仅在Jupyter笔记本中支持。对其他环境的支持将很快增加。</em></p><p id="8e46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当在51中评估对象检测数据集时，在运行<code class="fe os ot ou my b">evaluate_detections</code>并用<code class="fe os ot ou my b">eval_key</code>将结果存储在数据集上之后，我们能够创建所谓的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches" rel="noopener ugc nofollow" target="_blank">评估视图</a>。这是数据集的一个视图，其中每个样本都是一个单独的基础事实或预测对象补丁，允许您按真阳性、假阳性和假阴性、匹配的IoU以及单击按钮的其他评估元数据进行排序。</p><div class="kg kh ki kj gt ab cb"><figure class="pa kk pk pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/3b3f0409c19b9d1c9a4bccd26b711a4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*lX-SyC3fvBDsitD7ExAqNw.png"/></div></figure><figure class="pa kk pl pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/f7a8da669f0a6b93876e8924e60e0a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*wVKMngjt7NXquwgDVviL8w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk pm di pn pj translated">在第五十一个应用中创建<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches" rel="noopener ugc nofollow" target="_blank">评估视图</a>(图片由作者提供)</p></figure></div><h1 id="566f" class="ni nd iq bd nj nk nl nm nn no np nq nr jw ns jx nt jz nu ka nv kc nw kd nx ny bi translated">高级数据集探索</h1><p id="6cd7" class="pw-post-body-paragraph kw kx iq ky b kz nz jr lb lc oa ju le lf ob lh li lj oc ll lm ln od lp lq lr ij bi translated">如果我们想对我们的模型有一个更细致的了解，那么在低维空间中<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/brain.html#brain-embeddings-visualization" rel="noopener ugc nofollow" target="_blank">可视化对象嵌入是很有用的，它允许我们快速挑选出数据中的模式、集群和异常。51号大脑</a>正是提供了这种工作流程。</p><p id="dca5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="oy">注意:大脑</em>  <em class="oy">默认使用的</em> <a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/brain.html#dimensionality-reduction-methods" rel="noopener ugc nofollow" target="_blank"> <em class="oy">降维方法是</em> <code class="fe os ot ou my b"><em class="oy">umap</em></code> <em class="oy">我们需要安装:</em></a></p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="23d1" class="nc nd iq my b gy ne nf l ng nh">pip install umap-learn</span></pre><p id="68fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以再次使用<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html#embeddings" rel="noopener ugc nofollow" target="_blank">51模型动物园来生成嵌入</a>，然后我们将可视化这些嵌入:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi po"><img src="../Images/995b810328ca45093f210b7443919956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/1*W2h8r-inOSg20SM0Ga8CLA.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/image_embeddings.html" rel="noopener ugc nofollow" target="_blank">第五十一届互动嵌入可视化</a>(图片由作者提供)</p></figure><p id="8c88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于多种原因，这种可视化非常有价值，尤其是对于像包含机器生成标签的开放图像这样的数据集。可视化和交互式探索嵌入使您可以快速抽查哪些机器生成的标签可能需要检查并发送进行重新标注。</p><p id="0404" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还可以使用这些嵌入来自动<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#sorting-by-visual-similarity" rel="noopener ugc nofollow" target="_blank">查找相似和重复的样本</a>，只需点击一个按钮。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><div class="kg kh ki kj gt ab cb"><figure class="pa kk pp pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/571e689d4535eee992ac75c7586323e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*iIhAazgyWSGjV8s2SEdVzg.png"/></div></figure><figure class="pa kk pq pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/a3fb9bd51996845aab82b3316b2cf2f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*End91PhiSHexo2tgOa5q6Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk pr di ps pj translated">选取样本并按相似度排序<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#sorting-by-visual-similarity" rel="noopener ugc nofollow" target="_blank">第五十一(图片由作者提供)</a></p></figure></div><p id="b85a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦我们彻底探索了我们的数据集，并找到了我们想要进一步分析或改进的方面，就很容易<a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/open_images.html#Tagging" rel="noopener ugc nofollow" target="_blank">标记单个样本或标签</a>以便将其隔离用于下游用例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi po"><img src="../Images/0c757b23441ac7b941c67003dd2b5889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/1*hJo4dS3_IiqieeIgzj1Y2w.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">51中的标签样本(图片由作者提供)</p></figure></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="8177" class="ni nd iq bd nj nk om nm nn no on nq nr jw oo jx nt jz op ka nv kc oq kd nx ny bi translated">摘要</h1><p id="8474" class="pw-post-body-paragraph kw kx iq ky b kz nz jr lb lc oa ju le lf ob lh li lj oc ll lm ln od lp lq lr ij bi translated"><a class="ae kv" href="https://storage.googleapis.com/openimages/web/download.html" rel="noopener ugc nofollow" target="_blank"> Open Images </a>是一个大规模但经过彻底标记的数据集，可以为您的数据湖和模型训练工作流增加有用的内容。下载和探索<a class="ae kv" href="https://storage.googleapis.com/openimages/web/download.html" rel="noopener ugc nofollow" target="_blank">开放图像</a>最简单的方法是使用<a class="ae kv" href="https://voxel51.com/docs/fiftyone/index.html" rel="noopener ugc nofollow" target="_blank">51</a>。对于像<a class="ae kv" href="https://storage.googleapis.com/openimages/web/download.html" rel="noopener ugc nofollow" target="_blank">开放图像</a>一样大的数据集，动手评估您的模型结果可能会很困难。通过可视化嵌入，FiftyOne可以轻松理解数据集，找到模型中的故障模式，并揭示数据中的模式。</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="f74f" class="ni nd iq bd nj nk om nm nn no on nq nr jw oo jx nt jz op ka nv kc oq kd nx ny bi translated">关于体素51</h1><p id="4074" class="pw-post-body-paragraph kw kx iq ky b kz nz jr lb lc oa ju le lf ob lh li lj oc ll lm ln od lp lq lr ij bi translated"><a class="ae kv" href="https://voxel51.com/" rel="noopener ugc nofollow" target="_blank"> Voxel51 </a>总部位于密歇根州安阿伯，由Jason Corso博士和Brian Moore博士于2016年创立，是一家人工智能软件公司，通过提供开放核心软件构建模块，使计算机视觉和机器学习工程师能够快速设计数据驱动的工作流，从而实现软件2.0的民主化。</p><p id="bbbc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">想了解更多？在<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> fiftyone.ai </a>查看我们的网站。</p></div></div>    
</body>
</html>