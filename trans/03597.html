<html>
<head>
<title>Boost basic Dataset and simple CNN to answer real environment problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">增强基本数据集和简单CNN来回答实际环境问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/boost-basic-dataset-and-simple-cnn-to-answer-real-environment-problem-3622c28b3fad?source=collection_archive---------28-----------------------#2021-03-23">https://towardsdatascience.com/boost-basic-dataset-and-simple-cnn-to-answer-real-environment-problem-3622c28b3fad?source=collection_archive---------28-----------------------#2021-03-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="307d" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="0ab8" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">CNN——具有数据扩充、背景和多输出的树叶分类。</h2></div><blockquote class="ko kp kq"><p id="c874" class="kr ks kt ku b kv kw ka kx ky kz kd la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">由<a class="lo lp ep" href="https://medium.com/u/35892034f8ca?source=post_page-----3622c28b3fad--------------------------------" rel="noopener" target="_blank">克莱曼婷执笔页面</a>、<a class="lo lp ep" href="https://medium.com/u/5311199e1416?source=post_page-----3622c28b3fad--------------------------------" rel="noopener" target="_blank">让·琼邦</a>和<a class="lo lp ep" href="https://medium.com/u/d1d27f890fbd?source=post_page-----3622c28b3fad--------------------------------" rel="noopener" target="_blank">塞尔瓦·克莱伯</a>—2021年3月</p></blockquote><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/753752d511b62ca0c8f8af807970191b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9h1xY3_Tm-uXx0WR"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">克里斯·劳顿在<a class="ae mg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="f8b4" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">1.语境</h1><p id="c3a2" class="pw-post-body-paragraph kr ks iq ku b kv mz ka kx ky na kd la nb nc ld le nd ne lh li nf ng ll lm ln ij bi translated">该项目是我们在Data Scientist的<a class="ae mg" href="https://datascientest.com/formation-data-scientist" rel="noopener ugc nofollow" target="_blank">数据科学家训练营课程</a>验证的一部分，将我们在这11周的理论课中学到的一切付诸实践，并确保每个主题都已掌握。</p><p id="44df" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">这个项目的目标是从图片中定位和分类植物的种类。一旦分类完成，返回植物的描述，并确定最终的疾病。</p></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><h1 id="e1dc" class="mh mi iq bd mj mk no mm mn mo np mq mr kf nq kg mt ki nr kj mv kl ns km mx my bi translated">2.项目</h1><h2 id="b9a8" class="nt mi iq bd mj nu nv dn mn nw nx dp mr nb ny nz mt nd oa ob mv nf oc od mx iw bi translated">数据集—迭代1</h2><p id="d5fc" class="pw-post-body-paragraph kr ks iq ku b kv mz ka kx ky na kd la nb nc ld le nd ne lh li nf ng ll lm ln ij bi translated">数据集<a class="ae mg" href="https://www.kaggle.com/vipoooool/new-plant-diseases-dataset" rel="noopener ugc nofollow" target="_blank">新植物病害数据集</a>来自Kaggle，被许多用户彻底使用，不包含任何错误或错误分类的图像。</p><p id="c98f" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">该数据集由放置在统一背景上的树叶组成:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/33ade1bdfb2f9a692f6e4ae1b20c8a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*aEG7ZhCkNirbHuXMQ2400Q.png"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">来自数据集的图像样本(<a class="ae mg" href="https://www.kaggle.com/vipoooool/new-plant-diseases-dataset" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="5d7f" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">包含大约87，000张叶子的图片——患病的和健康的。这些图片代表了38类14种植物:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi of"><img src="../Images/b114f06070d0b710fa32117ebdadcab3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mripH4PKO0o52izJLauEdw.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">每株植物病害</p></figure><p id="437c" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">分配情况如下:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi og"><img src="../Images/71664395d6acb05bb840aae5e4745078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6zpYYbl_R2TE7ilG"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">数据集中类的分布— <em class="oh">作者提供的图片</em></p></figure><p id="74d3" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">该数据集是使用另一个数据集的离线扩充重新创建的，因此，正如我们在前面的图表中看到的那样，这些类非常平衡(每个类约占3%—外部层)。</p><p id="d9fd" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">为了在植物环境中的树叶图像上测试我们的模型，我们实现了一个<em class="kt"> web抓取</em>脚本来从“Google image”中提取图像。这个测试数据集类似地由38个类加上另一个代表没有植物的图像的类“其他”组成。</p><p id="7f99" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">与原始数据集相比，测试集中的图像不遵循相同的格式(每个图像一片叶子)。</p></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><h2 id="0b15" class="nt mi iq bd mj nu nv dn mn nw nx dp mr nb ny nz mt nd oa ob mv nf oc od mx iw bi translated">深度学习—迭代1</h2><p id="248e" class="pw-post-body-paragraph kr ks iq ku b kv mz ka kx ky na kd la nb nc ld le nd ne lh li nf ng ll lm ln ij bi translated">作为第一次迭代，我们用<strong class="ku ja"> TensorFlow </strong>开发了自己的CNN模型:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oi"><img src="../Images/388f480bb2f3e6fa0fa4f47a56a6782d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2yCp_3iUWTTZ_3qKbfofw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">CNN模型— <em class="oh">作者图片</em></p></figure><p id="7bed" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">该模型由三个卷积块和一个分类块组成。</p><p id="5091" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">卷积块层数:</strong></p><ul class=""><li id="7bda" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated"><strong class="ku ja">图像大小</strong>:图像大小调整为128x128x3，这是时间计算和信息损失之间的一个很好的折衷。</li><li id="d92d" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated"><strong class="ku ja"> Conv2D </strong>:使用滤镜从图像中提取图案。为了捕捉更大的图案组合，每个Conv2D层的滤镜数量都比前一层增加了一倍。</li><li id="5036" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated"><strong class="ku ja">激活功能</strong>:使用CNN最常用的Relu应用非线性。</li><li id="9cf4" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated"><strong class="ku ja">batch normalization(BN)</strong>:BN用于归一化前几层的输出。它使CNN更快，更稳定，并减少过度拟合。</li><li id="42ca" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated"><strong class="ku ja"> MaxPool2D </strong>:通过减少像素数量来降低图像的维数，它减少了模型的参数数量，并为内部表示提供了轻微的尺度不变性。</li></ul><p id="5bae" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">分类块层数:</strong></p><ul class=""><li id="73e4" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated"><strong class="ku ja">密集</strong>:用于分类的三个全连通层。</li><li id="f6c9" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated"><strong class="ku ja">退出</strong>:通过在训练过程中随机忽略选定的神经元来防止过拟合。</li></ul><p id="2045" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">conv区块与分类区块之间的层:</strong></p><ul class=""><li id="f27c" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated"><strong class="ku ja">globalaveragepool2d</strong>(GAP):它对每个特征图的值进行平均。与“展平”层不同，“间隙”移除了大量可训练参数，提供了平移不变性，从而减少了过度拟合的趋势。</li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ox"><img src="../Images/5239126340f80952a74344f0ec25174f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YMV_mJZ3n0f2-9dsJRPWwg.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">Flatten和GlobalAveragePooling之间的差异— <em class="oh">作者图片</em></p></figure><p id="c467" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">正则化</strong>:为了防止过度拟合，我们使用了<strong class="ku ja"> L2 </strong>正则化，它将参数(权重)的平方和添加到损失函数中。</p><p id="8a7b" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">型号代码如下所示:</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="0d92" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">该模型在<strong class="ku ja">验证数据集上的准确率为99.3% </strong>。</p><p id="25ac" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">然而，它在测试数据集上给出了非常糟糕的预测，准确率为<strong class="ku ja"> 13.2% </strong>。</p><p id="ac21" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">迭代1总结:</strong></p><ul class=""><li id="1610" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated">数据集:“新植物疾病数据集”，其是在统一背景上的叶子图像</li><li id="23b2" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">对验证数据集的出色预测— val准确率&gt; 99%。</li><li id="ac50" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">对由自然环境中的树叶图像组成的测试数据集的错误预测。</li><li id="9ad8" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">即使图像上没有任何植物，模型也能预测植物。</li></ul><p id="039f" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">对自然环境中的树叶图像预测不佳的主要原因是我们的模型是用统一背景上的树叶图像数据集训练的</strong>。此外，正如在训练数据集中一样，没有图像是没有植物的，如果发生这种情况，我们的模型不可能预测图像中不存在植物。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pa"><img src="../Images/28adfd10974d463252848b2802f1c86d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewW3EZDgPqvyZjffc6V7vw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">迭代1图— <em class="oh">作者图片</em></p></figure></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><h2 id="a68e" class="nt mi iq bd mj nu nv dn mn nw nx dp mr nb ny nz mt nd oa ob mv nf oc od mx iw bi translated">深度学习—迭代2</h2><p id="f120" class="pw-post-body-paragraph kr ks iq ku b kv mz ka kx ky na kd la nb nc ld le nd ne lh li nf ng ll lm ln ij bi translated">在第二次迭代中，我们试图通过给树叶图像添加植物背景来改进我们的模型。我们修改了我们的数据集，并使用了来自Kaggle的<a class="ae mg" href="https://www.kaggle.com/abdallahalidev/plantvillage-dataset" rel="noopener ugc nofollow" target="_blank">植物村数据集</a>，它与我们的第一个数据集相似(在统一的背景上留下图像)，但没有任何数据扩充。因此，数据集是高度不平衡的(来自一些类的超过5000幅图像，而来自其他类的不到200幅图像)，但是包含我们可以用来添加植物背景的分割的叶子图像。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pb"><img src="../Images/0f65099ef6138ef42b75b1cd9153ab9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Mc3nqmUt-yGHeKeD5XbTg.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">来自新数据集的分割图像样本(<a class="ae mg" href="https://www.kaggle.com/abdallahalidev/plantvillage-dataset" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="8ef3" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">为了重新平衡该数据集，按照以下描述的转换进行了数据扩充:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pc"><img src="../Images/3cb232c4a7df95882d446608b62c622f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kyAiT18bnkKQcHTfzHKbKA.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">数据扩充— <em class="oh">作者提供的图片</em></p></figure><p id="3fb6" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">为了检测图像中植物的缺失，我们使用来自<a class="ae mg" href="http://www.image-net.org" rel="noopener ugc nofollow" target="_blank">“Image-net”数据集</a>的随机图像向我们的数据集添加了另一个类“<em class="kt"> Others </em>”。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pd"><img src="../Images/b74e1854d689697a9fbf23f31abcf463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8hWoMzi4wD81btO2Z2Z-iA.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">来自新类别"<em class="oh">其他</em> " ( <a class="ae mg" href="http://www.image-net.org" rel="noopener ugc nofollow" target="_blank">来源</a>)的图像样本</p></figure><p id="1fe9" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">在数据扩充和添加新类别“其他”之后，该数据集包含114 077幅图像，分布如下:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pe"><img src="../Images/abb273d8ed0f11e1fa3c394307bd1881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5wmd10js5uWWqwzdUs_n6g.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">数据扩充后数据集中类的分布— <em class="oh">作者图片</em></p></figure><p id="1eef" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">我们使用“自定义数据集”来加载图片并添加背景，用我们的背景像素替换分段图片的黑色像素。</p><p id="9a43" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">用函数“tf.where”替换像素，如果叶子图像像素的值低于定义的阈值，则用背景图像之一替换叶子图像的像素。</p><p id="8dcd" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">注意，在第二次迭代中，我们对每种植物只使用了<strong class="ku ja">一个</strong>背景。例如，任何番茄类都使用相同的番茄植物背景。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pf"><img src="../Images/16938138aff322f13519759446e68b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GnpNrhegekXGA05KtWxaIg.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">背景添加过程— <em class="oh">作者图片</em></p></figure><p id="3cf4" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">代码如下所示:</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="e2d3" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">我们使用相同的模型来比较两次迭代的结果，只是最后一个密集层的输出形状为39 (38株植物+其他)。</p><p id="8343" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">该模型在新的验证数据集上给出了95.1% 的准确度。</p><p id="1697" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">然而，它在测试数据集上给出了非常糟糕的预测，准确率为<strong class="ku ja"> 10.5% </strong>。</p><p id="bf5a" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">第二次迭代总结:</strong></p><ul class=""><li id="e750" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated">数据集“Plant Village”增加了数据，并从数据集“Image-Net”添加了新的类。</li><li id="1de4" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">在模型训练期间添加背景(每个植物类型只有一个背景)。</li><li id="722e" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">好的<strong class="ku ja"> </strong>预测与数据集相关的图像。</li><li id="c218" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">测试数据集上的预测略有改进，但性能仍低于预期，尤其是在无法完全看到树叶的图像上。</li><li id="a6bc" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">该模型似乎能够预测图像是否不是植物。</li><li id="04eb" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">该模型似乎专注于背景而不是叶子本身。</li></ul><p id="34e8" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">在迭代2期间，我们的模型学会了使用背景而不是树叶，所以我们使用完全相同的模型和方法做了另一次迭代“<em class="kt"> 2-bis </em>”，但不是每株植物只有一个背景，我们为每株植物创建了一组背景，每次都将随机选择<strong class="ku ja"/>。</p><p id="11dc" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">因此，我们为每株植物(我们的数据集中有14株植物)创建了一个文件夹，在每个文件夹中:</p><ul class=""><li id="51e3" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated">5幅实际植物的图像(即:所有马铃薯种类的马铃薯植物)。</li><li id="5730" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">4植物、草坪和森林的图像将在每个文件夹中共享。</li></ul><p id="b195" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">这应该有助于模型:</p><ul class=""><li id="2b3f" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated">而不是聚焦在背景图像上。</li><li id="5897" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">在真实环境中有更好的表现。</li></ul><p id="d379" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">该模型(2-bis)在验证数据集<strong class="ku ja">上给出了98.4% </strong>的准确度。</p><p id="fc57" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">然而，它在测试数据集上给出了非常糟糕的预测，准确率为<strong class="ku ja"> 18.1% </strong>。</p><p id="6926" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">迭代2之二的总结:</strong></p><ul class=""><li id="4a01" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated">数据集:“植物村”，增加了数据，并从数据集“Image-Net”添加了新的类。</li><li id="8664" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">在模型训练期间添加背景(随机)。</li><li id="a3b2" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">好的<strong class="ku ja"> </strong>预测与数据集相关的图像。</li><li id="203b" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">与迭代2相比，测试数据集上的预测略有改进，因为背景是随机的，所以模型没有关注它。</li><li id="92bf" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">该模型似乎能够预测图像是否不是植物。</li></ul><p id="fe34" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">我们可以在测试数据集上看到一些预测性能的改进，尽管结果仍然低于预期。然而，这个模型可以预测一个图像是否是植物，这与我们的第一次迭代相比是一个增强。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pg"><img src="../Images/eaa26e0bb3ee4dba8cef1d63588786ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QNCsHlhFGRSqeaKeSC27bw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">迭代2图— <em class="oh">作者图片</em></p></figure></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><h2 id="5005" class="nt mi iq bd mj nu nv dn mn nw nx dp mr nb ny nz mt nd oa ob mv nf oc od mx iw bi translated">深度学习——迭代3</h2><p id="9a3c" class="pw-post-body-paragraph kr ks iq ku b kv mz ka kx ky na kd la nb nc ld le nd ne lh li nf ng ll lm ln ij bi translated">在迭代2中，我们包含了一个名为“Others”的新类，表示“任何东西”的图像。这一举措是为了帮助模型避免在图像中没有植物时预测植物。但是我们可以看到，在测试数据集上的结果不如预期的好。一种解决方案是预测图像中植物出现的概率。一个输出表示图像是否包含植物，第二个输出表示植物分类。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/59296fce552ba2d890c6ea721e89a3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*AShAqSkEBtDh-32x_9X4fA.png"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">模型迭代3 — <em class="oh">作者图片</em></p></figure><p id="dbbb" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">此后，模型的代码—我们使用功能模型:</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="0f2a" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">为了评估我们的模型预测数据集的效果，我们需要创建一个自定义损失函数:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pi"><img src="../Images/d444f10787ea928629df877799218534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oNPA-a4XPltylkYAIifatA.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">定制损失函数</p></figure><p id="8919" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">用<em class="kt"> P_other </em> ={0，1}。图像是植物(=1)还是植物(=0)。如果图像不是植物，则不计算<em class="kt">分类交叉熵</em>。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="ed4d" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">根据我们的模型，第一个神经元代表图像是否包含植物，其他38个神经元代表植物分类。</p><p id="67e5" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">该模型(3)在验证数据集<strong class="ku ja">上给出了97.4% </strong>的准确度。</p><p id="0317" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">然而，它在测试数据集上给出了非常糟糕的预测，准确率为<strong class="ku ja"> 19.2% </strong>。</p><p id="a5e2" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">但是，在测试数据集上对没有植物的图像(类别:<em class="kt">其他</em>)的预测比用迭代2-bis模型完成的预测要好。</p><p id="1dc5" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated"><strong class="ku ja">迭代3总结:</strong></p><ul class=""><li id="33c9" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated">数据集:“植物村”，增加了数据，并从数据集“Image-Net”添加了新的类。</li><li id="5f6e" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">对验证数据集的出色预测— val准确率&gt; 99%。</li><li id="0147" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">对测试数据集的预测仍然很差。</li><li id="b417" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">在测试数据集上更好地预测没有植物的图像(类别:<em class="kt">其他</em>)。</li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pj"><img src="../Images/3d6594d1d2a5f97d36663ad10e397dc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G1O1yotprfWniiGL0i1HHA.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">迭代3图— <em class="oh">作者提供的图片</em></p></figure></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><h1 id="916f" class="mh mi iq bd mj mk no mm mn mo np mq mr kf nq kg mt ki nr kj mv kl ns km mx my bi translated">改进</h1><ol class=""><li id="bd30" class="oj ok iq ku b kv mz ky na nb pk nd pl nf pm ln pn op oq or bi translated"><strong class="ku ja">包含真实环境中图像的新数据集:</strong>正如我们在几个测试阶段发现的那样，该模型在只有一片叶子和统一背景的图像上表现很好，但无法预测自然环境中的图像。我们试图通过添加背景来解决这个问题，但我们仍然可以在结果中看到一些缺陷。从直接在真实环境中拍摄的图像(或两者的组合)创建完整的数据集可能有助于提高结果的可靠性。这可以使用<em class="kt">网页抓取</em>来完成。</li><li id="c4ad" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln pn op oq or bi translated"><strong class="ku ja">两个模型串联(多输出)</strong>:在当前数据集中，一些植物有相同的病害(<em class="kt">即</em> : <em class="kt">番茄和桃叶的细菌性斑点病</em>或马铃薯和番茄叶的晚疫病……)。在自然环境中，我们的模型似乎能发现正确的疾病，但不能发现正确的植物。一个解决方案是创建一个多输出模型:</li></ol><ul class=""><li id="fd3b" class="oj ok iq ku b kv kw ky kz nb ol nd om nf on ln oo op oq or bi translated">一个关注休假分类的模型</li><li id="72d6" class="oj ok iq ku b kv os ky ot nb ou nd ov nf ow ln oo op oq or bi translated">一个侧重于疾病分类的模型</li></ul><p id="526a" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">用这种方法，我们可以分别预测植物和疾病。因此，这可以改进模型，并可能预测新植物的已知疾病——即苹果上的<em class="kt">细菌性斑点</em>(已知疾病)。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi po"><img src="../Images/4ecf1eca7962641787f4cd768c4e7982.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*11TrluHadrqlGlUyrSGm5Q.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">多输出模型— <em class="oh">作者图片</em></p></figure><p id="c094" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">3.<strong class="ku ja">语义分割:</strong>为了提高在自然环境中的预测，使用像UNET这样的语义分割模型，将有助于提取树叶的像素，然后我们将使用树叶分类模型来预测植物本身。</p><p id="e7bd" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">4.<strong class="ku ja">更深的模型:</strong>由于真实环境中的叶子图像更复杂，具有更多卷积块的更深的模型，为了捕捉更多模式，应该给出更好的预测。</p></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><h1 id="416c" class="mh mi iq bd mj mk no mm mn mo np mq mr kf nq kg mt ki nr kj mv kl ns km mx my bi translated">概括起来</h1><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pp"><img src="../Images/fe1fcf3de2bfc63bae3206dee729ece4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Mw7GewroAVQYJ5Ok"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">照片由<a class="ae mg" href="https://unsplash.com/@ashishjha?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿维纳什·库马尔</a>在<a class="ae mg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="50f3" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">通过这三次迭代开发的模型在验证数据集上进行了出色的预测，结果高达97%。在自然环境中的图像上测试这些模型是一个自然的选择，以代表一个真实的商业案例。</p><p id="48fa" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">但我们很快发现，即使我们尽最大努力改进我们的模型，以检测真实环境中的图像，我们也无法实现这个目标。</p><p id="5ded" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">我们可以尽可能地调整模型，它只能预测它被训练的内容——统一背景上的树叶图像。</p><p id="3795" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">我们能够验证一些假设——检测没有植物的图像，对具有统一背景的图像进行分类…——并拒绝添加背景有助于提高模型鲁棒性的事实。</p><p id="1f87" class="pw-post-body-paragraph kr ks iq ku b kv kw ka kx ky kz kd la nb lc ld le nd lg lh li nf lk ll lm ln ij bi translated">这个模型仍有改进的空间，但在此之前，我们应该考虑使用一个更接近有问题的的<strong class="ku ja">数据集——从任何照片中预测植物病害。</strong></p><blockquote class="pq"><p id="7022" class="pr ps iq bd pt pu pv pw px py pz ln dk translated">由<a class="lo lp ep" href="https://medium.com/u/35892034f8ca?source=post_page-----3622c28b3fad--------------------------------" rel="noopener" target="_blank">克莱曼婷·佩奇</a>、<a class="lo lp ep" href="https://medium.com/u/5311199e1416?source=post_page-----3622c28b3fad--------------------------------" rel="noopener" target="_blank">让·琼邦</a>和<a class="lo lp ep" href="https://medium.com/u/d1d27f890fbd?source=post_page-----3622c28b3fad--------------------------------" rel="noopener" target="_blank">塞尔瓦·克莱伯</a>撰写。感谢DataScientest团队的帮助。</p></blockquote><p id="a769" class="pw-post-body-paragraph kr ks iq ku b kv qa ka kx ky qb kd la nb qc ld le nd qd lh li nf qe ll lm ln ij bi translated"><em class="kt">迭代代码可以在</em><a class="ae mg" href="https://github.com/clementine-pages/ML-doctoplant_tensorflow" rel="noopener ugc nofollow" target="_blank"><em class="kt">Github</em></a><em class="kt">上找到。</em></p><h2 id="e826" class="nt mi iq bd mj nu nv dn mn nw nx dp mr nb ny nz mt nd oa ob mv nf oc od mx iw bi translated">承认</h2><pre class="lr ls lt lu gt qf qg qh qi aw qj bi"><span id="cd1d" class="nt mi iq qg b gy qk ql l qm qn"><a class="ae mg" href="https://www.kaggle.com/vipoooool" rel="noopener ugc nofollow" target="_blank">Samir Bhattara</a> (2018, Nov.), <a class="ae mg" href="https://www.kaggle.com/vipoooool/new-plant-diseases-dataset" rel="noopener ugc nofollow" target="_blank">New Plant Diseases Dataset</a> v2<br/><strong class="qg ja">Orignial Dataset</strong>: <a class="ae mg" href="https://github.com/spMohanty" rel="noopener ugc nofollow" target="_blank">spMohanty</a> (2018, Sept.), <a class="ae mg" href="https://github.com/spMohanty/PlantVillage-Dataset" rel="noopener ugc nofollow" target="_blank">PlantVillage-Dataset</a></span><span id="2f68" class="nt mi iq qg b gy qo ql l qm qn"><a class="ae mg" href="https://www.kaggle.com/abdallahalidev" rel="noopener ugc nofollow" target="_blank">Abdallah Ali</a> (2019, Sep.), <a class="ae mg" href="https://www.kaggle.com/abdallahalidev/plantvillage-dataset" rel="noopener ugc nofollow" target="_blank">Plant Village dataset</a> v3</span><span id="6470" class="nt mi iq qg b gy qo ql l qm qn"><a class="ae mg" href="http://image-net.org/" rel="noopener ugc nofollow" target="_blank">ImageNet</a> (2016), <a class="ae mg" href="http://vision.stanford.edu/" rel="noopener ugc nofollow" target="_blank">Stanford Vision Lab, </a><a class="ae mg" href="http://www.stanford.edu/" rel="noopener ugc nofollow" target="_blank">Stanford University</a>, <a class="ae mg" href="http://www.princeton.edu/" rel="noopener ugc nofollow" target="_blank">Princeton University</a></span></pre></div></div>    
</body>
</html>