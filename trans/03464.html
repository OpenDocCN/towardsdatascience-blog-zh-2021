<html>
<head>
<title>How To Run Logistic Regression On Aggregate Data In Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Python中对聚合数据运行逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-run-logistic-regression-on-aggregate-data-in-python-a779ab7970b3?source=collection_archive---------24-----------------------#2021-03-19">https://towardsdatascience.com/how-to-run-logistic-regression-on-aggregate-data-in-python-a779ab7970b3?source=collection_archive---------24-----------------------#2021-03-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="89a7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">每个数据科学家都应该知道的3个简单解决方案</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f89d6ac254a557b8d03f37fd8bf6d350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v3MeBxMtDgaSiGBOCpWBzQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@project2204?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">叶小开·克里斯托弗·古特瓦尔德</a>在<a class="ae ky" href="/s/photos/group-of-people-beach?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="5d0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ι将向您展示3种技术，当您想要执行逻辑回归时，它们将帮助您处理Python中的聚集数据。</p><p id="887b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们创建一些虚拟数据。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4dd9" class="ma mb it lw b gy mc md l me mf">import pandas as pd<br/>import numpy as np<br/>import statsmodels.api as sm<br/>import statsmodels.formula.api as smf<br/><br/>df=pd.DataFrame(<br/>{<br/>'Gender':np.random.choice(["m","f"],200,p=[0.6,0.4]),<br/>'Age':np.random.choice(["[&lt;30]","[30-65]", "[65+]"],200,p=[0.3,0.6,0.1]),<br/>"Response":np.random.binomial(1,size=200,p=0.2)<br/>    }<br/>)<br/><br/>df.head()</span><span id="bf77" class="ma mb it lw b gy mg md l me mf">Gender      Age  Response<br/>0      f  [30-65]         0<br/>1      m  [30-65]         0<br/>2      m    [&lt;30]         0<br/>3      f  [30-65]         1<br/>4      f    [65+]         0</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="c301" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">非聚集数据的逻辑回归</h1><p id="c81b" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">首先，我们将对非汇总数据运行逻辑回归模型。我们将使用库<a class="ae ky" href="https://www.statsmodels.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">统计模型</a>，因为这是我们将用于聚合数据的库，并且更容易比较我们的模型。此外，统计模型可以以更经典的统计方式(如r)给我们一个模型的摘要。</p><p id="c1f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nk">提示:如果您不想将分类数据转换成二进制来执行逻辑回归，您可以使用</em> <a class="ae ky" href="https://www.statsmodels.org/devel/example_formulas.html" rel="noopener ugc nofollow" target="_blank"> <em class="nk">统计模型公式</em> </a> <em class="nk">来代替Sklearn。</em></p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="80b7" class="ma mb it lw b gy mc md l me mf">model=smf.logit('Response~Gender+Age',data=df)<br/>result = model.fit()<br/>print(result.summary())</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><pre class="lv lw lx ly aw lz bi"><span id="06e6" class="ma mb it lw b gy nl nm nn no np md l me mf">Logit Regression Results                           <br/>==============================================================================<br/>Dep. Variable:               Response   No. Observations:                  200<br/>Model:                          Logit   Df Residuals:                      196<br/>Method:                           MLE   Df Model:                            3<br/>Date:                Mon, 22 Feb 2021   Pseudo R-squ.:                 0.02765<br/>Time:                        18:09:11   Log-Likelihood:                -85.502<br/>converged:                       True   LL-Null:                       -87.934<br/>Covariance Type:            nonrobust   LLR p-value:                    0.1821<br/>================================================================================<br/>                   coef    std err          z      P&gt;|z|      [0.025      0.975]<br/>--------------------------------------------------------------------------------<br/>Intercept       -2.1741      0.396     -5.494      0.000      -2.950      -1.399<br/>Gender[T.m]      0.8042      0.439      1.831      0.067      -0.057       1.665<br/>Age[T.[65+]]    -0.7301      0.786     -0.929      0.353      -2.270       0.810<br/>Age[T.[&lt;30]]     0.1541      0.432      0.357      0.721      -0.693       1.001<br/>================================================================================</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="3168" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">聚合数据的逻辑回归</h1></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h2 id="f36b" class="ma mb it bd mp nq nr dn mt ns nt dp mx li nu nv mz lm nw nx nb lq ny nz nd oa bi translated">1.使用有反应者和无反应者的逻辑回归</h2><p id="f386" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">在下面的代码中，我们对数据进行了分组，并为响应者(<strong class="lb iu"> Yes </strong>)和非响应者(<strong class="lb iu"> No </strong>)创建了列。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="bcd9" class="ma mb it lw b gy mc md l me mf">grouped=df.groupby(['Gender','Age']).agg({'Response':[sum,'count']}).droplevel(0, axis=1).rename(columns={'sum':'Yes','count':'Impressions'}).eval('No=Impressions-Yes')<br/>grouped.reset_index(inplace=True)<br/>grouped</span><span id="4755" class="ma mb it lw b gy mg md l me mf">Gender      Age  Yes  Impressions  No<br/>0      f  [30-65]    9           38  29<br/>1      f    [65+]    2            7   5<br/>2      f    [&lt;30]    8           25  17<br/>3      m  [30-65]   17           79  62<br/>4      m    [65+]    2           12  10<br/>5      m    [&lt;30]    9           39  30</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><pre class="lv lw lx ly aw lz bi"><span id="23ec" class="ma mb it lw b gy nl nm nn no np md l me mf">glm_binom = smf.glm('Yes + No ~ Age + Gender',grouped, family=sm.families.Binomial())<br/>result_grouped=glm_binom.fit()<br/>print(result_grouped.summary())</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><pre class="lv lw lx ly aw lz bi"><span id="e5cc" class="ma mb it lw b gy nl nm nn no np md l me mf">Generalized Linear Model Regression Results                  <br/>==============================================================================<br/>Dep. Variable:          ['Yes', 'No']   No. Observations:                    6<br/>Model:                            GLM   Df Residuals:                        2<br/>Model Family:                Binomial   Df Model:                            3<br/>Link Function:                  logit   Scale:                          1.0000<br/>Method:                          IRLS   Log-Likelihood:                -8.9211<br/>Date:                Mon, 22 Feb 2021   Deviance:                       1.2641<br/>Time:                        18:15:15   Pearson chi2:                    0.929<br/>No. Iterations:                     5                                         <br/>Covariance Type:            nonrobust                                         <br/>================================================================================<br/>                   coef    std err          z      P&gt;|z|      [0.025      0.975]<br/>--------------------------------------------------------------------------------<br/>Intercept       -2.1741      0.396     -5.494      0.000      -2.950      -1.399<br/>Age[T.[65+]]    -0.7301      0.786     -0.929      0.353      -2.270       0.810<br/>Age[T.[&lt;30]]     0.1541      0.432      0.357      0.721      -0.693       1.001<br/>Gender[T.m]      0.8042      0.439      1.831      0.067      -0.057       1.665<br/>================================================================================</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h2 id="2a6e" class="ma mb it bd mp nq nr dn mt ns nt dp mx li nu nv mz lm nw nx nb lq ny nz nd oa bi translated">2.加权逻辑回归</h2><p id="cb33" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">对于这个方法，我们需要创建一个新列，其中包含每个组的<strong class="lb iu">响应率</strong>。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="0cea" class="ma mb it lw b gy mc md l me mf">grouped['RR']=grouped['Yes']/grouped['Impressions']</span><span id="6983" class="ma mb it lw b gy mg md l me mf">glm = smf.glm('RR ~ Age + Gender',data=grouped, family=sm.families.Binomial(), freq_weights=np.asarray(grouped['Impressions']))<br/>result_grouped2=glm.fit()<br/>print(result_grouped2.summary())</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><pre class="lv lw lx ly aw lz bi"><span id="0ba4" class="ma mb it lw b gy nl nm nn no np md l me mf">Generalized Linear Model Regression Results                  <br/>==============================================================================<br/>Dep. Variable:                     RR   No. Observations:                    6<br/>Model:                            GLM   Df Residuals:                      196<br/>Model Family:                Binomial   Df Model:                            3<br/>Link Function:                  logit   Scale:                          1.0000<br/>Method:                          IRLS   Log-Likelihood:                -59.807<br/>Date:                Mon, 22 Feb 2021   Deviance:                       1.2641<br/>Time:                        18:18:16   Pearson chi2:                    0.929<br/>No. Iterations:                     5                                         <br/>Covariance Type:            nonrobust                                         <br/>================================================================================<br/>                   coef    std err          z      P&gt;|z|      [0.025      0.975]<br/>--------------------------------------------------------------------------------<br/>Intercept       -2.1741      0.396     -5.494      0.000      -2.950      -1.399<br/>Age[T.[65+]]    -0.7301      0.786     -0.929      0.353      -2.270       0.810<br/>Age[T.[&lt;30]]     0.1541      0.432      0.357      0.721      -0.693       1.001<br/>Gender[T.m]      0.8042      0.439      1.831      0.067      -0.057       1.665<br/>================================================================================</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h2 id="ac8f" class="ma mb it bd mp nq nr dn mt ns nt dp mx li nu nv mz lm nw nx nb lq ny nz nd oa bi translated">3.展开聚合数据</h2><p id="596b" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">最后，我们可以“解组”我们的数据，并将我们的因变量转换为二进制，这样我们就可以像往常一样执行逻辑回归。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="e848" class="ma mb it lw b gy mc md l me mf">grouped['No']=grouped['No'].apply(lambda x: [0]*x)<br/>grouped['Yes']=grouped['Yes'].apply(lambda x: [1]*x)<br/>grouped['Response']=grouped['Yes']+grouped['No']<br/><br/>expanded=grouped.explode("Response")[['Gender','Age','Response']]<br/>expanded['Response']=expanded['Response'].astype(int)<br/><br/>expanded.head()<br/></span><span id="fd9d" class="ma mb it lw b gy mg md l me mf">Gender      Age Response<br/>0      f  [30-65]        1<br/>0      f  [30-65]        1<br/>0      f  [30-65]        1<br/>0      f  [30-65]        1<br/>0      f  [30-65]        1</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><pre class="lv lw lx ly aw lz bi"><span id="0723" class="ma mb it lw b gy nl nm nn no np md l me mf">model=smf.logit('Response~ Gender + Age',data=expanded)<br/>result = model.fit()<br/>print(result.summary())</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><pre class="lv lw lx ly aw lz bi"><span id="c69d" class="ma mb it lw b gy nl nm nn no np md l me mf">Logit Regression Results                           <br/>==============================================================================<br/>Dep. Variable:               Response   No. Observations:                  200<br/>Model:                          Logit   Df Residuals:                      196<br/>Method:                           MLE   Df Model:                            3<br/>Date:                Mon, 22 Feb 2021   Pseudo R-squ.:                 0.02765<br/>Time:                        18:29:33   Log-Likelihood:                -85.502<br/>converged:                       True   LL-Null:                       -87.934<br/>Covariance Type:            nonrobust   LLR p-value:                    0.1821<br/>================================================================================<br/>                   coef    std err          z      P&gt;|z|      [0.025      0.975]<br/>--------------------------------------------------------------------------------<br/>Intercept       -2.1741      0.396     -5.494      0.000      -2.950      -1.399<br/>Gender[T.m]      0.8042      0.439      1.831      0.067      -0.057       1.665<br/>Age[T.[65+]]    -0.7301      0.786     -0.929      0.353      -2.270       0.810<br/>Age[T.[&lt;30]]     0.1541      0.432      0.357      0.721      -0.693       1.001<br/>================================================================================</span></pre><h1 id="04bf" class="mo mb it bd mp mq ob ms mt mu oc mw mx jz od ka mz kc oe kd nb kf of kg nd ne bi translated">结论</h1><p id="fefe" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">对于所有4个模型，我们得出了相同的系数和p值。</p><p id="2051" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据我的经验，我发现获取项目的原始数据并不常见，在大多数情况下，我们处理的是聚合/分组数据。这些技术将帮助你轻松地处理它们，这就是为什么我认为是你的Python工具箱的一个很好的附件。</p><p id="d214" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你正在使用R，你可以阅读这个<a class="ae ky" href="https://predictivehacks.com/how-to-run-logistic-regression-on-aggregate-data-in-r/" rel="noopener ugc nofollow" target="_blank">非常有用的帖子</a>。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><p id="0f67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以后我会写更多初学者友好的帖子。<a class="ae ky" href="https://medium.com/@billybonaros" rel="noopener">在媒体上关注我</a>或<a class="ae ky" href="https://predictivehacks.com/" rel="noopener ugc nofollow" target="_blank">访问我的博客</a>了解他们。</p><p id="5f30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我欢迎提问、反馈和建设性的批评，你可以通过推特(Twitter)或社交网站(Instagram)联系我。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><p id="336a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nk">原载于</em><a class="ae ky" href="https://predictivehacks.com/logistic-regression-on-aggregate-data-python/" rel="noopener ugc nofollow" target="_blank"><em class="nk">https://predictivehacks.com</em></a></p></div></div>    
</body>
</html>