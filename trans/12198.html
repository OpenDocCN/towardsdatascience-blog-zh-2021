<html>
<head>
<title>How to Create a Vector-Based Movie Recommendation System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何创建基于矢量的电影推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-create-a-vector-based-movie-recommendation-system-b6d4f7582d66?source=collection_archive---------10-----------------------#2021-12-10">https://towardsdatascience.com/how-to-create-a-vector-based-movie-recommendation-system-b6d4f7582d66?source=collection_archive---------10-----------------------#2021-12-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9d60" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">相关事件</h2><div class=""/><div class=""><h2 id="26a6" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用变形金刚和矢量技术构建电影推荐系统。</h2></div><p id="cfb0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我将向你展示如何对电影数据集进行矢量化，在教程的最后，我将使用最近邻完成电影推荐系统。完整的代码可在我的回购处获得。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/ca252aae1573e56873e2298ceaf096ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5RHsf9SpKt8xlbWd"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">由<a class="ae lk" href="https://unsplash.com/@rswebsols?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">苏维克·班纳吉</a>在<a class="ae lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="de30" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">电影推荐系统是目前最受欢迎的人工智能应用之一。建立电影推荐系统有几种方法，从基于线性代数方程的简单算法到试图预测哪个是用户最佳选择的复杂神经网络。</p><p id="7004" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于技术在过去几年里进步很大，建立电影推荐系统的新的复杂方法已经被开发出来，以增强网飞或淘宝等平台的用户体验。公司只对最新技术感兴趣，因为它会使旧型号过时。目前，基于向量的搜索主导着推荐系统市场。</p><p id="7aac" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我将下载一个电影数据集，清理它，编码它，最后对它进行矢量搜索:该软件将有一部电影作为输入，并将推荐5部电影作为输出。</p><h1 id="0668" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">构建软件</h1><p id="6be3" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">这个电影推荐系统将通过以下步骤来构建:</p><ol class=""><li id="7757" class="my mz iq kq b kr ks ku kv kx na lb nb lf nc lj nd ne nf ng bi translated">安装库</li><li id="d2e1" class="my mz iq kq b kr nh ku ni kx nj lb nk lf nl lj nd ne nf ng bi translated">下载数据集</li><li id="a92e" class="my mz iq kq b kr nh ku ni kx nj lb nk lf nl lj nd ne nf ng bi translated">预处理数据集</li><li id="7b48" class="my mz iq kq b kr nh ku ni kx nj lb nk lf nl lj nd ne nf ng bi translated">编码数据</li><li id="6d14" class="my mz iq kq b kr nh ku ni kx nj lb nk lf nl lj nd ne nf ng bi translated">执行矢量搜索</li></ol><h2 id="51a1" class="nm mc iq bd md nn no dn mh np nq dp ml kx nr ns mn lb nt nu mp lf nv nw mr iw bi translated">1.安装库</h2><p id="1aea" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">我将用来编码数据的主要库是relevanceai，它为您提供了最新的转换器来编码您的数据:</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="928b" class="nm mc iq ny b gy oc od l oe of">!pip install -U relevanceai</span></pre><p id="84c2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我还打算安装第二个库，这样我们就可以在电脑工作时跟踪编码进度。因为这个过程可能会很长(可能需要2个小时),如果您不希望使用我提供给您的已经编码的数据集，最好使用一个进度条，您可以用一个名为<a class="ae lk" href="https://github.com/tqdm/tqdm" rel="noopener ugc nofollow" target="_blank"> tqdm </a>的库来实现它:</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="d5bb" class="nm mc iq ny b gy oc od l oe of">!pip install tqdm&gt;=4.62.2</span></pre><h2 id="469e" class="nm mc iq bd md nn no dn mh np nq dp ml kx nr ns mn lb nt nu mp lf nv nw mr iw bi translated">2.下载电影数据集</h2><p id="c108" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">原始数据集已经从Kaggle 下载<a class="ae lk" href="https://www.kaggle.com/cryptexcode/mpst-movie-plot-synopses-with-tags" rel="noopener ugc nofollow" target="_blank">(MPST:带标签的电影情节概要，由Sudipta Kar出版)。我将使用</a><a class="ae lk" href="https://pandas.pydata.org/docs/" rel="noopener ugc nofollow" target="_blank">熊猫</a>库来处理这个数据集。我们在这个过程中只需要两种数据(我会尽量保持简单)就是电影标题和描述。用户将使用标题来引用他们想看的电影，而电影的描述将被编码在向量空间中。对数据进行编码后，我们不再需要电影描述。</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="883b" class="nm mc iq ny b gy oc od l oe of">import pandas as pd</span><span id="de62" class="nm mc iq ny b gy og od l oe of">df = pd.read_csv('mpst_full_data.csv')</span></pre><h2 id="8029" class="nm mc iq bd md nn no dn mh np nq dp ml kx nr ns mn lb nt nu mp lf nv nw mr iw bi translated">3.预处理电影数据集</h2><p id="d0ac" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">除了去掉我们实验中不会用到的所有其他额外特性，电影数据集还包含不完全相同的副本，因此我们不能简单地使用drop_duplicates pandas函数来去掉它们。举个例子，我找到过同名电影:《复仇者联盟》和《复仇者联盟》。</p><p id="4f26" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在预处理阶段，我需要确保从我们的数据中删除大多数重复的内容，否则，用户体验将与功能良好的推荐系统不一样。</p><p id="371f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了避免重名，我只关注电影名。有几种方法可以解决这个问题，我已经为这个特定的目的构建了一个现成的算法:我将按字母顺序对标题进行排序，然后查看连续的标题是否相似(通过使用Levenshtein距离)，如果相似，我将删除连续的标题。</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="3e8d" class="nm mc iq ny b gy oc od l oe of">df = df.sort_values('title').reset_index(drop=True)<br/>df['lev'] = None<br/>df</span><span id="a3ff" class="nm mc iq ny b gy og od l oe of">from Levenshtein import distance</span><span id="21eb" class="nm mc iq ny b gy og od l oe of">for a in range(len(df)-1):<br/>    if distance(df.iloc[a].title, df.iloc[a+1].title) &lt;= 3:<br/>        print(a, df.iloc[a].title, df.iloc[a+1].title)<br/>        df.at[a, 'lev'] = distance(df.iloc[a].title, df.iloc[a+1].title)<br/>df<br/>#we filter similar movies<br/>df = df[df['lev'].isnull()].reset_index(drop=True)<br/>df</span></pre><p id="df9b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于一些非常著名的电影，我将亲自执行手动检查以避免任何问题:我将尝试使用该软件的第一部电影显然是《复仇者联盟》:</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="a306" class="nm mc iq ny b gy oc od l oe of">#find Avengers duplicates<br/>for a in range(len(df)):<br/>    if df.iloc[a]['title'].find('Avengers') != -1:<br/>        pass<br/>        #print(a)<br/>#drop extra<br/>df = df.drop([9572]).reset_index(drop=True) #i can do 1, 2, 3... to drop multiple<br/>df<br/>df.to_csv('mpst_no_duplicates.csv')</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oh"><img src="../Images/50c31091fcb1e297aed7cb0e3bdc16fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uyePhZIF6fttN7nZN2LdDA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">电影数据集的屏幕截图，图片由作者提供</p></figure><h2 id="7959" class="nm mc iq bd md nn no dn mh np nq dp ml kx nr ns mn lb nt nu mp lf nv nw mr iw bi translated">4.编码数据</h2><p id="7453" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">如果您想更详细地了解什么是转换器，以及对您的数据进行编码的其他可行选择，您可以关注我的技术解释。有几种型号可以选择:最快的一种(我要用的那种)叫做<strong class="kq ja">全迷你L6 v2</strong>。还有更复杂的模型，如<strong class="kq ja"> all-mpnet-base-v2 </strong>，它们更精确，但它们需要大量的计算能力。例如，通过使用最后一个模型，我们的计算机可能需要10小时，而不是2小时。</p><p id="848c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这段代码中，我将使用relevance API将电影描述编码成向量。我习惯使用这个库，因为它是一个比它的许多替代品更灵活的包装器。因为它不直接接受pandas DataFrame作为输入，所以我需要将我的数据转换成一个字典列表:</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="e722" class="nm mc iq ny b gy oc od l oe of">json_files = df[['title', 'plot_synopsis']]<br/>json_files = json_files.reset_index()<br/>json_files.columns = ['_id', 'title', 'plot_synopsis']<br/>json_files=json_files.to_dict(orient='records')<br/>json_files</span></pre><p id="27d9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些文件看起来是这样的:</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="6dc5" class="nm mc iq ny b gy oc od l oe of">{'_id': 0,<br/>  'title': '$',<br/>  'plot_synopsis': 'Set in Hamburg, West Germany, sev...<br/> {'_id': 1,<br/>  'title': '$windle',<br/>  'plot_synopsis': 'A 6th grader named...<br/> {'_id': 2,<br/>  'title': "'71",<br/>  'plot_synopsis': "Gary Hook, a new recruit to the British Army, takes leave of ...</span></pre><p id="7235" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们可以通过选择一个可用的模型来开始编码过程。</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="b699" class="nm mc iq ny b gy oc od l oe of">#encode on local<br/>from vectorhub.encoders.text.sentence_transformers import SentenceTransformer2Vec<br/>model = SentenceTransformer2Vec("bert-base-uncased")<br/>df_json = model.encode_documents(documents=json_files, fields=['plot_synopsis'])<br/>df_json</span></pre><p id="821b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一旦编码完成，relevanceai库并没有替换原来的字段<strong class="kq ja"> plot_synopsis </strong>，而是创建了另一个带有<strong class="kq ja">sentence _ transformers _ vector _</strong>后缀的字段。</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="d865" class="nm mc iq ny b gy oc od l oe of">[{'_id': 0,<br/>  'title': '$',<br/>  'plot_synopsis': 'Set in Hamburg, West Germany, several criminals take...<br/>  'plot_synopsis_sentence_transformers_vector_': [-0.25144392251968384,<br/>   -0.03958860784769058,<br/>   0.15455105900764465,<br/>   -0.08302052319049835,<br/>   0.5842940807342529,<br/>   0.07232926040887833,<br/>   0.28563958406448364</span></pre><h2 id="7241" class="nm mc iq bd md nn no dn mh np nq dp ml kx nr ns mn lb nt nu mp lf nv nw mr iw bi translated">4.用熊猫编码数据</h2><p id="2b98" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">或者，如果你想继续学习熊猫，你仍然可以使用句子变形库。选择不同的格式取决于你希望如何使用你的数据:例如，在前一种格式中，我可以使用relevanceAI API来在线上传我的数据，因此它是可扩展的，可以被成千上万的用户使用。</p><p id="4a8d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因为这个过程可能需要一个多小时才能完成(有些编码模型可能需要12个小时，所以要小心选择哪一个)，所以我用一个进度条来记录进度(关于实现它的更多信息，<a class="ae lk" href="https://pythonkai.org/2021/12/04/schrodingers-pandas-and-how-to-open-the-box-with-python/" rel="noopener ugc nofollow" target="_blank">我写了这个有趣的指南</a>):</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="a29f" class="nm mc iq ny b gy oc od l oe of">from tqdm import tqdm<br/>from sentence_transformers import SentenceTransformer<br/>import numpy as np</span><span id="814b" class="nm mc iq ny b gy og od l oe of">tqdm.pandas()</span><span id="1353" class="nm mc iq ny b gy og od l oe of">model = SentenceTransformer('all-MiniLM-L6-v2') #all-MiniLM-L6-v2 #all-mpnet-base-v2</span><span id="2091" class="nm mc iq ny b gy og od l oe of">df_ = df.copy()<br/>df_['plot_synopsis'] = df_['plot_synopsis'].progress_apply(lambda x : model.encode(x))<br/>df_index = df_.pop('title')<br/>df_ = df_[['plot_synopsis']]<br/>df_ = pd.DataFrame(np.column_stack(list(zip(*df_.values))))<br/>df_.index = df_index<br/>df_</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oi"><img src="../Images/2ef28a4455c869c75219481ddbca9e29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cb3HixIVx7exdBKHSSUigQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">带有熊猫的矢量化数据的屏幕截图，图片由作者提供</p></figure><p id="745e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">完成后，不要忘记将您的数据保存到一个. csv文件中！</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="d295" class="nm mc iq ny b gy oc od l oe of">df_.to_csv('mpst_encoded_no_duplicates.csv')</span></pre><h2 id="dfe3" class="nm mc iq bd md nn no dn mh np nq dp ml kx nr ns mn lb nt nu mp lf nv nw mr iw bi translated">5.执行矢量搜索:测试你的电影推荐系统</h2><p id="2774" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">通过执行矢量搜索，我将把一部电影输入到数据集中。因此，该软件将找到空间中最近的5个点是什么，每个点代表一部类似的电影:这就是我们所说的推荐系统。</p><p id="4362" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我提供的解决方案将在您的本地机器上完美地工作。然而，部署基于向量的产品的问题是伸缩性。我发现的最好的解决方案之一是<a class="ae lk" href="https://relevance.ai/" rel="noopener ugc nofollow" target="_blank"> relevanceai API </a>，你可以用它将你的矢量数据库转换成API调用。</p><p id="bdca" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">相反，要在本地执行矢量搜索，我可以使用为我提供最近邻算法的<a class="ae lk" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn API </a>。我要做的第一件事是再次加载数据集(您不需要这样做，但最好用同一个数据集的导入和导出来分隔每个代码段):</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="fdf4" class="nm mc iq ny b gy oc od l oe of">import pandas as pd</span><span id="2b62" class="nm mc iq ny b gy og od l oe of">df_movies_encoded = pd.read_csv('mpst_encoded_no_duplicates.csv')<br/>df_movies_encoded.index = df_movies_encoded.pop('title')<br/>df_movies_encoded</span></pre><p id="5317" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们现在可以在最近的邻居sklearn类上训练该算法:我们将把训练好的模型存储在名为nbrs的变量中，这将允许我们在给定一个输入的情况下检索两个点(初始点的坐标加上其最近邻居的坐标)。</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="118f" class="nm mc iq ny b gy oc od l oe of">from Levenshtein import distance<br/>from sklearn.neighbors import NearestNeighbors<br/>import numpy as np<br/>import pandas as pd</span><span id="85f5" class="nm mc iq ny b gy og od l oe of">nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(df_movies_encoded)</span><span id="7a96" class="nm mc iq ny b gy og od l oe of">#string-searching algorithm<br/>def closest_title(title):<br/>    m = pd.DataFrame(df_movies_encoded.index)<br/>    m['lev'] = m['title'].apply(lambda x : distance(x, 'Prince of Egypt'))<br/>    return m.sort_values('lev', ascending=True)['title'].iloc[0]</span></pre><p id="e26c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当前数据集的主要问题是在搜索不在数据集中的电影的情况下，或者如果您打错了。例如，如果你搜索“复仇者联盟”，因为数据集只有“复仇者联盟”这个词，它将无法搜索到你的关键字，并将抛出一个错误。这很不方便，尤其是因为我们假设许多用户会快速输入搜索，甚至会输入错误。这个问题的解决方案是使用一种字符串搜索算法，无论我们输入什么，都会找到最佳答案。我使用Levenshtein距离创建了一个自定义的:</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="d90c" class="nm mc iq ny b gy oc od l oe of">def find_similar_movies(df, nbrs, title):<br/>    #if title not in df it will choose the best search<br/>    title = closest_title(title)</span><span id="1762" class="nm mc iq ny b gy og od l oe of">distances, indices = nbrs.kneighbors([df.loc[title]])<br/>    #print(indices)</span><span id="22b2" class="nm mc iq ny b gy og od l oe of">#we print df data, no longer df_<br/>    for index in indices[0][1:]:<br/>        print('index', index)<br/>        print(title, '-&gt;', df.iloc[index].name)</span></pre><p id="ff97" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该算法将接收电影的名称作为输入，并将输出最近邻的名称:</p><pre class="lm ln lo lp gt nx ny nz oa aw ob bi"><span id="82b0" class="nm mc iq ny b gy oc od l oe of">find_similar_movies(df_movies_encoded, nbrs, 'Prince of Egypt')</span><span id="acf1" class="nm mc iq ny b gy og od l oe of">index 11440<br/>The Prince of Egypt -&gt; The Ten Commandments: The Musical</span></pre><p id="b36d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">精彩:似乎在起作用！</p><h1 id="992b" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">结论</h1><p id="ebe8" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">在这篇文章中，我向你展示了如何构建一个简化的推荐系统。对于这类任务，我们是否已经达到了复杂性的顶峰？差远了。在本教程中，我们使用一个包含数据集中所有电影关系的向量空间，但我们忽略了个人用户历史。</p><p id="1441" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了给平台上的每个用户提供增强的体验，我们应该收集其选择历史，并为每个用户创建独特的推荐。能够达到这种复杂程度的模型被称为多模态嵌入，它们将在后续文章中进行分析。尽管有其局限性，像这样的向量空间电影推荐系统仍然能够很好地执行，并提供令人满意的用户体验。</p></div></div>    
</body>
</html>